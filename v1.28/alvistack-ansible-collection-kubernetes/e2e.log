  I0415 06:16:24.802157      13 e2e.go:117] Starting e2e run "09b869e7-e058-491d-bad7-361809188490" on Ginkgo node 1
  Apr 15 06:16:24.891: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1713161783 - will randomize all specs

Will run 380 of 7389 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:153
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Apr 15 06:16:25.278: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:16:25.291: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Apr 15 06:16:25.354: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Apr 15 06:16:25.360: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
  Apr 15 06:16:25.361: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  Apr 15 06:16:25.361: INFO: e2e test version: v1.28.8
  Apr 15 06:16:25.362: INFO: kube-apiserver version: v1.28.8
  Apr 15 06:16:25.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:16:25.369: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 04/15/24 06:16:25.817
  Apr 15 06:16:25.817: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:16:25.819
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:16:25.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:16:25.849
  STEP: Setting up server cert @ 04/15/24 06:16:25.894
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:16:26.464
  STEP: Deploying the webhook pod @ 04/15/24 06:16:26.47
  STEP: Wait for the deployment to be ready @ 04/15/24 06:16:26.489
  Apr 15 06:16:26.503: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/15/24 06:16:28.522
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:16:28.539
  Apr 15 06:16:29.540: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 15 06:16:29.554: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3919-crds.webhook.example.com via the AdmissionRegistration API @ 04/15/24 06:16:30.082
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/15/24 06:16:30.133
  Apr 15 06:16:32.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-877" for this suite. @ 04/15/24 06:16:32.963
  STEP: Destroying namespace "webhook-markers-618" for this suite. @ 04/15/24 06:16:32.975
â€¢ [7.174 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 04/15/24 06:16:32.992
  Apr 15 06:16:32.992: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename deployment @ 04/15/24 06:16:32.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:16:33.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:16:33.032
  Apr 15 06:16:33.037: INFO: Creating deployment "test-recreate-deployment"
  Apr 15 06:16:33.047: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Apr 15 06:16:33.067: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  Apr 15 06:16:35.086: INFO: Waiting deployment "test-recreate-deployment" to complete
  Apr 15 06:16:35.094: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Apr 15 06:16:35.116: INFO: Updating deployment test-recreate-deployment
  Apr 15 06:16:35.116: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Apr 15 06:16:35.340: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-806",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "275c902a-6a91-43fe-bd71-c91102d1d508",
      ResourceVersion: (string) (len=6) "143378",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848758593,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758593,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 15 06:16:35.360: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-806",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d790ed82-c2c6-474f-868b-60da7de15d1a",
      ResourceVersion: (string) (len=6) "143375",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848758595,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "275c902a-6a91-43fe-bd71-c91102d1d508",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 37 35 63 39 30  32 61 2d 36 61 39 31 2d  |\"275c902a-6a91-|
              00000120  34 33 66 65 2d 62 64 37  31 2d 63 39 31 31 30 32  |43fe-bd71-c91102|
              00000130  64 31 64 35 30 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |d1d508\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:16:35.364: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Apr 15 06:16:35.364: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-5cf87b5b86",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-806",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3b7a4387-273b-4daf-9eca-d3ff9e00d332",
      ResourceVersion: (string) (len=6) "143366",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848758593,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "275c902a-6a91-43fe-bd71-c91102d1d508",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 37 35 63 39 30  32 61 2d 36 61 39 31 2d  |\"275c902a-6a91-|
              00000120  34 33 66 65 2d 62 64 37  31 2d 63 39 31 31 30 32  |43fe-bd71-c91102|
              00000130  64 31 64 35 30 38 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |d1d508\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5cf87b5b86"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:16:35.380: INFO: Pod "test-recreate-deployment-76fb77d45-c4bbj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-c4bbj",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=14) "deployment-806",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "18ea1851-c7aa-444a-ad7b-77bfcd513598",
      ResourceVersion: (string) (len=6) "143376",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848758595,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "d790ed82-c2c6-474f-868b-60da7de15d1a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 37  39 30 65 64 38 32 2d 63  |d\":\"d790ed82-c|
              00000090  32 63 36 2d 34 37 34 66  2d 38 36 38 62 2d 36 30  |2c6-474f-868b-60|
              000000a0  64 61 37 64 65 31 35 64  31 61 5c 22 7d 22 3a 7b  |da7de15d1a\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fkfhj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fkfhj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758595,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.206",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848758595,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:16:35.386: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-806" for this suite. @ 04/15/24 06:16:35.398
â€¢ [2.420 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 04/15/24 06:16:35.413
  Apr 15 06:16:35.413: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:16:35.416
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:16:35.445
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:16:35.45
  STEP: Creating the pod @ 04/15/24 06:16:35.459
  Apr 15 06:16:38.090: INFO: Successfully updated pod "annotationupdate1b70062b-a1b1-440c-ac5e-106515194c12"
  Apr 15 06:16:40.127: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7509" for this suite. @ 04/15/24 06:16:40.147
â€¢ [4.750 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 04/15/24 06:16:40.168
  Apr 15 06:16:40.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:16:40.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:16:40.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:16:40.224
  STEP: Setting up server cert @ 04/15/24 06:16:40.28
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:16:41.825
  STEP: Deploying the webhook pod @ 04/15/24 06:16:41.836
  STEP: Wait for the deployment to be ready @ 04/15/24 06:16:41.859
  Apr 15 06:16:41.872: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/15/24 06:16:43.898
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:16:43.92
  Apr 15 06:16:44.922: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 04/15/24 06:16:44.942
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/15/24 06:16:44.984
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 04/15/24 06:16:45.005
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/15/24 06:16:45.025
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 04/15/24 06:16:45.043
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/15/24 06:16:45.063
  Apr 15 06:16:45.084: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3944" for this suite. @ 04/15/24 06:16:45.21
  STEP: Destroying namespace "webhook-markers-5691" for this suite. @ 04/15/24 06:16:45.23
â€¢ [5.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 04/15/24 06:16:45.253
  Apr 15 06:16:45.255: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename deployment @ 04/15/24 06:16:45.259
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:16:45.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:16:45.308
  Apr 15 06:16:45.335: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  Apr 15 06:16:50.345: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/15/24 06:16:50.345
  Apr 15 06:16:50.345: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 04/15/24 06:16:50.369
  Apr 15 06:16:50.390: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5368",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c249f19d-642c-4907-883f-9abfae22e3a6",
      ResourceVersion: (string) (len=6) "143534",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848758610,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848758610,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 15 06:16:50.411: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  Apr 15 06:16:50.419: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5368" for this suite. @ 04/15/24 06:16:50.432
â€¢ [5.193 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:252
  STEP: Creating a kubernetes client @ 04/15/24 06:16:50.446
  Apr 15 06:16:50.446: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename namespaces @ 04/15/24 06:16:50.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:16:50.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:16:50.511
  STEP: Creating a test namespace @ 04/15/24 06:16:50.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:16:50.557
  STEP: Creating a service in the namespace @ 04/15/24 06:16:50.562
  STEP: Deleting the namespace @ 04/15/24 06:16:50.58
  STEP: Waiting for the namespace to be removed. @ 04/15/24 06:16:50.607
  STEP: Recreating the namespace @ 04/15/24 06:16:56.616
  STEP: Verifying there is no service in the namespace @ 04/15/24 06:16:56.653
  Apr 15 06:16:56.662: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3742" for this suite. @ 04/15/24 06:16:56.674
  STEP: Destroying namespace "nsdeletetest-2270" for this suite. @ 04/15/24 06:16:56.685
  Apr 15 06:16:56.691: INFO: Namespace nsdeletetest-2270 was already deleted
  STEP: Destroying namespace "nsdeletetest-1220" for this suite. @ 04/15/24 06:16:56.691
â€¢ [6.258 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 04/15/24 06:16:56.712
  Apr 15 06:16:56.712: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename daemonsets @ 04/15/24 06:16:56.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:16:56.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:16:56.753
  Apr 15 06:16:56.793: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/15/24 06:16:56.806
  Apr 15 06:16:56.825: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:16:56.825: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  Apr 15 06:16:57.856: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:16:57.856: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  Apr 15 06:16:58.848: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 15 06:16:58.849: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  Apr 15 06:16:59.847: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 15 06:16:59.847: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 04/15/24 06:16:59.891
  STEP: Check that daemon pods images are updated. @ 04/15/24 06:16:59.942
  Apr 15 06:16:59.948: INFO: Wrong image for pod: daemon-set-mnlgn. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 15 06:16:59.949: INFO: Wrong image for pod: daemon-set-njx2r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 15 06:16:59.949: INFO: Wrong image for pod: daemon-set-zmqh9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 15 06:17:00.972: INFO: Wrong image for pod: daemon-set-njx2r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 15 06:17:00.973: INFO: Wrong image for pod: daemon-set-zmqh9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 15 06:17:01.966: INFO: Pod daemon-set-5n6w9 is not available
  Apr 15 06:17:01.967: INFO: Wrong image for pod: daemon-set-njx2r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 15 06:17:01.967: INFO: Wrong image for pod: daemon-set-zmqh9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 15 06:17:02.969: INFO: Wrong image for pod: daemon-set-njx2r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 15 06:17:03.974: INFO: Wrong image for pod: daemon-set-njx2r. Expected: registry.k8s.io/e2e-test-images/agnhost:2.47, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 15 06:17:04.980: INFO: Pod daemon-set-vrxxm is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 04/15/24 06:17:05
  Apr 15 06:17:05.031: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 15 06:17:05.032: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  Apr 15 06:17:06.062: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 15 06:17:06.062: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/15/24 06:17:06.101
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7579, will wait for the garbage collector to delete the pods @ 04/15/24 06:17:06.101
  Apr 15 06:17:06.174: INFO: Deleting DaemonSet.extensions daemon-set took: 13.587221ms
  Apr 15 06:17:06.275: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.150181ms
  Apr 15 06:17:09.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:17:09.284: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 15 06:17:09.291: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"143750"},"items":null}

  Apr 15 06:17:09.298: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"143750"},"items":null}

  Apr 15 06:17:09.333: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7579" for this suite. @ 04/15/24 06:17:09.343
â€¢ [12.649 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 04/15/24 06:17:09.363
  Apr 15 06:17:09.364: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/15/24 06:17:09.37
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:17:09.401
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:17:09.407
  Apr 15 06:17:11.489: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Cleaning up the secret @ 04/15/24 06:17:11.5
  STEP: Cleaning up the configmap @ 04/15/24 06:17:11.515
  STEP: Cleaning up the pod @ 04/15/24 06:17:11.529
  STEP: Destroying namespace "emptydir-wrapper-1643" for this suite. @ 04/15/24 06:17:11.551
â€¢ [2.204 seconds]
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 04/15/24 06:17:11.568
  Apr 15 06:17:11.568: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename containers @ 04/15/24 06:17:11.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:17:11.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:17:11.63
  STEP: Creating a pod to test override command @ 04/15/24 06:17:11.637
  STEP: Saw pod success @ 04/15/24 06:17:15.691
  Apr 15 06:17:15.699: INFO: Trying to get logs from node phiefi7ighaa-3 pod client-containers-1c2e86bd-7398-4b8f-b412-54ff7e65feed container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 06:17:15.713
  Apr 15 06:17:15.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8990" for this suite. @ 04/15/24 06:17:15.751
â€¢ [4.197 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
test/e2e/apimachinery/resource_quota.go:328
  STEP: Creating a kubernetes client @ 04/15/24 06:17:15.768
  Apr 15 06:17:15.768: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 06:17:15.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:17:15.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:17:15.819
  STEP: Counting existing ResourceQuota @ 04/15/24 06:17:32.832
  STEP: Creating a ResourceQuota @ 04/15/24 06:17:37.84
  STEP: Ensuring resource quota status is calculated @ 04/15/24 06:17:37.85
  STEP: Creating a ConfigMap @ 04/15/24 06:17:39.861
  STEP: Ensuring resource quota status captures configMap creation @ 04/15/24 06:17:39.886
  STEP: Deleting a ConfigMap @ 04/15/24 06:17:41.896
  STEP: Ensuring resource quota status released usage @ 04/15/24 06:17:41.911
  Apr 15 06:17:43.919: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6761" for this suite. @ 04/15/24 06:17:43.933
â€¢ [28.182 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
test/e2e/kubectl/kubectl.go:1342
  STEP: Creating a kubernetes client @ 04/15/24 06:17:43.95
  Apr 15 06:17:43.950: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:17:43.953
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:17:44.001
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:17:44.008
  Apr 15 06:17:44.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1361 create -f -'
  Apr 15 06:17:46.077: INFO: stderr: ""
  Apr 15 06:17:46.077: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Apr 15 06:17:46.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1361 create -f -'
  Apr 15 06:17:46.638: INFO: stderr: ""
  Apr 15 06:17:46.638: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/15/24 06:17:46.638
  Apr 15 06:17:47.648: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 15 06:17:47.648: INFO: Found 1 / 1
  Apr 15 06:17:47.648: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 15 06:17:47.657: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 15 06:17:47.657: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 15 06:17:47.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1361 describe pod agnhost-primary-qn4zh'
  Apr 15 06:17:47.856: INFO: stderr: ""
  Apr 15 06:17:47.856: INFO: stdout: "Name:             agnhost-primary-qn4zh\nNamespace:        kubectl-1361\nPriority:         0\nService Account:  default\nNode:             phiefi7ighaa-3/192.168.121.206\nStart Time:       Mon, 15 Apr 2024 06:17:46 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.66.201\nIPs:\n  IP:           10.233.66.201\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://9c9a392de1238cd0f8be177041ea24a17cf2f9460cf9f3021200a3a4f6ff0f51\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.47\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:c9997bf8d2e223d7d2a0078dcfb11a653e9b16cf09418829ec03e1d57ca9628a\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 15 Apr 2024 06:17:46 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-5w2th (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-5w2th:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-1361/agnhost-primary-qn4zh to phiefi7ighaa-3\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.47\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  Apr 15 06:17:47.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1361 describe rc agnhost-primary'
  Apr 15 06:17:48.050: INFO: stderr: ""
  Apr 15 06:17:48.051: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-1361\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.47\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-qn4zh\n"
  Apr 15 06:17:48.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1361 describe service agnhost-primary'
  Apr 15 06:17:48.281: INFO: stderr: ""
  Apr 15 06:17:48.281: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-1361\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.36.42\nIPs:               10.233.36.42\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.66.201:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Apr 15 06:17:48.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1361 describe node phiefi7ighaa-1'
  Apr 15 06:17:48.533: INFO: stderr: ""
  Apr 15 06:17:48.533: INFO: stdout: "Name:               phiefi7ighaa-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=phiefi7ighaa-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"c6:35:78:b9:ce:4b\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.121.141\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 14 Apr 2024 14:57:43 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  phiefi7ighaa-1\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 15 Apr 2024 06:17:39 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 15 Apr 2024 06:16:22 +0000   Mon, 15 Apr 2024 06:16:22 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Mon, 15 Apr 2024 06:15:05 +0000   Mon, 15 Apr 2024 06:12:42 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 15 Apr 2024 06:15:05 +0000   Mon, 15 Apr 2024 06:12:42 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 15 Apr 2024 06:15:05 +0000   Mon, 15 Apr 2024 06:12:42 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 15 Apr 2024 06:15:05 +0000   Mon, 15 Apr 2024 06:12:42 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.141\n  Hostname:    phiefi7ighaa-1\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      115008636Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 8123560Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    1600m\n  ephemeral-storage:      111880401014\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 3273896Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 942448af11ce475d8dffd11a54118ecc\n  System UUID:                942448af-11ce-475d-8dff-d11a54118ecc\n  Boot ID:                    4696b51d-4b58-4974-93d1-7cfef98b3722\n  Kernel Version:             6.5.0-27-generic\n  OS Image:                   Ubuntu 22.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.28.4\n  Kubelet Version:            v1.28.8\n  Kube-Proxy Version:         v1.28.8\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-5dd5756b68-6h4pb                                   100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     94s\n  kube-system                 kube-addon-manager-phiefi7ighaa-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         94s\n  kube-system                 kube-apiserver-phiefi7ighaa-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         94s\n  kube-system                 kube-controller-manager-phiefi7ighaa-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         94s\n  kube-system                 kube-flannel-ds-wkm7k                                      100m (6%)     0 (0%)      50Mi (1%)        0 (0%)         92s\n  kube-system                 kube-proxy-qgvqr                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         93s\n  kube-system                 kube-scheduler-phiefi7ighaa-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         93s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-f9ld5    0 (0%)        0 (0%)      0 (0%)           0 (0%)         86s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests    Limits\n  --------               --------    ------\n  cpu                    755m (47%)  0 (0%)\n  memory                 170Mi (5%)  170Mi (5%)\n  ephemeral-storage      0 (0%)      0 (0%)\n  hugepages-1Gi          0 (0%)      0 (0%)\n  hugepages-2Mi          0 (0%)      0 (0%)\n  scheduling.k8s.io/foo  0           0\nEvents:\n  Type    Reason                   Age                    From             Message\n  ----    ------                   ----                   ----             -------\n  Normal  Starting                 14m                    kube-proxy       \n  Normal  Starting                 4m28s                  kube-proxy       \n  Normal  Starting                 90s                    kube-proxy       \n  Normal  RegisteredNode           11m                    node-controller  Node phiefi7ighaa-1 event: Registered Node phiefi7ighaa-1 in Controller\n  Normal  RegisteredNode           6m21s                  node-controller  Node phiefi7ighaa-1 event: Registered Node phiefi7ighaa-1 in Controller\n  Normal  Starting                 5m49s                  kubelet          Starting kubelet.\n  Normal  NodeHasSufficientMemory  5m49s (x8 over 5m49s)  kubelet          Node phiefi7ighaa-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    5m49s (x8 over 5m49s)  kubelet          Node phiefi7ighaa-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     5m49s (x7 over 5m49s)  kubelet          Node phiefi7ighaa-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  5m49s                  kubelet          Updated Node Allocatable limit across pods\n  Normal  NodeNotReady             5m41s                  node-controller  Node phiefi7ighaa-1 status is now: NodeNotReady\n"
  Apr 15 06:17:48.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1361 describe namespace kubectl-1361'
  Apr 15 06:17:48.703: INFO: stderr: ""
  Apr 15 06:17:48.703: INFO: stdout: "Name:         kubectl-1361\nLabels:       e2e-framework=kubectl\n              e2e-run=09b869e7-e058-491d-bad7-361809188490\n              kubernetes.io/metadata.name=kubectl-1361\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Apr 15 06:17:48.703: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1361" for this suite. @ 04/15/24 06:17:48.711
â€¢ [4.775 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:91
  STEP: Creating a kubernetes client @ 04/15/24 06:17:48.727
  Apr 15 06:17:48.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:17:48.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:17:48.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:17:48.775
  STEP: Creating a pod to test downward api env vars @ 04/15/24 06:17:48.78
  STEP: Saw pod success @ 04/15/24 06:17:52.823
  Apr 15 06:17:52.830: INFO: Trying to get logs from node phiefi7ighaa-3 pod downward-api-68923d56-dd64-45e9-92e1-9451fe0e4fa8 container dapi-container: <nil>
  STEP: delete the pod @ 04/15/24 06:17:52.848
  Apr 15 06:17:52.885: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1744" for this suite. @ 04/15/24 06:17:52.897
â€¢ [4.184 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
test/e2e/apps/statefulset.go:792
  STEP: Creating a kubernetes client @ 04/15/24 06:17:52.913
  Apr 15 06:17:52.913: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename statefulset @ 04/15/24 06:17:52.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:17:52.951
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:17:52.959
  STEP: Creating service test in namespace statefulset-8959 @ 04/15/24 06:17:52.966
  STEP: Looking for a node to schedule stateful set and pod @ 04/15/24 06:17:52.989
  STEP: Creating pod with conflicting port in namespace statefulset-8959 @ 04/15/24 06:17:52.999
  STEP: Waiting until pod test-pod will start running in namespace statefulset-8959 @ 04/15/24 06:17:53.021
  STEP: Creating statefulset with conflicting port in namespace statefulset-8959 @ 04/15/24 06:17:55.079
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8959 @ 04/15/24 06:17:55.091
  Apr 15 06:17:55.150: INFO: Observed stateful pod in namespace: statefulset-8959, name: ss-0, uid: b5747139-90a1-40c1-8433-d09637b9ffb3, status phase: Pending. Waiting for statefulset controller to delete.
  Apr 15 06:17:55.173: INFO: Observed stateful pod in namespace: statefulset-8959, name: ss-0, uid: b5747139-90a1-40c1-8433-d09637b9ffb3, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 15 06:17:55.198: INFO: Observed stateful pod in namespace: statefulset-8959, name: ss-0, uid: b5747139-90a1-40c1-8433-d09637b9ffb3, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 15 06:17:55.210: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8959
  STEP: Removing pod with conflicting port in namespace statefulset-8959 @ 04/15/24 06:17:55.211
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8959 and will be in running state @ 04/15/24 06:17:55.254
  Apr 15 06:18:11.367: INFO: Deleting all statefulset in ns statefulset-8959
  Apr 15 06:18:11.374: INFO: Scaling statefulset ss to 0
  Apr 15 06:18:21.408: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 15 06:18:21.415: INFO: Deleting statefulset ss
  Apr 15 06:18:21.450: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8959" for this suite. @ 04/15/24 06:18:21.46
â€¢ [28.565 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 04/15/24 06:18:21.488
  Apr 15 06:18:21.488: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:18:21.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:18:21.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:18:21.565
  STEP: Creating the pod @ 04/15/24 06:18:21.572
  Apr 15 06:18:24.165: INFO: Successfully updated pod "labelsupdate64e2a86b-df31-4c51-8b68-d710ad1c31d3"
  Apr 15 06:18:26.201: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2449" for this suite. @ 04/15/24 06:18:26.215
â€¢ [4.744 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
test/e2e/apps/statefulset.go:320
  STEP: Creating a kubernetes client @ 04/15/24 06:18:26.242
  Apr 15 06:18:26.243: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename statefulset @ 04/15/24 06:18:26.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:18:26.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:18:26.297
  STEP: Creating service test in namespace statefulset-7869 @ 04/15/24 06:18:26.307
  STEP: Creating a new StatefulSet @ 04/15/24 06:18:26.32
  Apr 15 06:18:26.359: INFO: Found 0 stateful pods, waiting for 3
  Apr 15 06:18:36.371: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 06:18:36.371: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 06:18:36.372: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 06:18:36.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-7869 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 15 06:18:36.745: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:18:36.745: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:18:36.745: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/15/24 06:18:46.776
  Apr 15 06:18:46.808: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/15/24 06:18:46.808
  STEP: Updating Pods in reverse ordinal order @ 04/15/24 06:18:56.876
  Apr 15 06:18:56.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-7869 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 15 06:18:57.314: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 15 06:18:57.315: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 15 06:18:57.315: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  STEP: Rolling back to a previous revision @ 04/15/24 06:19:07.374
  Apr 15 06:19:07.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-7869 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 15 06:19:07.689: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:19:07.689: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:19:07.689: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 15 06:19:17.771: INFO: Updating stateful set ss2
  STEP: Rolling back update in reverse ordinal order @ 04/15/24 06:19:27.812
  Apr 15 06:19:27.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-7869 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 15 06:19:28.170: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 15 06:19:28.170: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 15 06:19:28.170: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 15 06:19:38.220: INFO: Deleting all statefulset in ns statefulset-7869
  Apr 15 06:19:38.228: INFO: Scaling statefulset ss2 to 0
  Apr 15 06:19:48.268: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 15 06:19:48.275: INFO: Deleting statefulset ss2
  Apr 15 06:19:48.306: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7869" for this suite. @ 04/15/24 06:19:48.319
â€¢ [82.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 04/15/24 06:19:48.353
  Apr 15 06:19:48.354: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:19:48.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:19:48.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:19:48.415
  STEP: Creating configMap with name configmap-test-volume-map-b69f9a6d-2f6a-4bd1-83b9-1c23ec56cc6e @ 04/15/24 06:19:48.421
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:19:48.433
  STEP: Saw pod success @ 04/15/24 06:19:52.477
  Apr 15 06:19:52.484: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-c4eaaa0d-3922-4c98-a5a9-8e4c7252220e container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 06:19:52.498
  Apr 15 06:19:52.530: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5404" for this suite. @ 04/15/24 06:19:52.541
â€¢ [4.207 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:157
  STEP: Creating a kubernetes client @ 04/15/24 06:19:52.562
  Apr 15 06:19:52.562: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:19:52.565
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:19:52.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:19:52.611
  STEP: Creating a pod to test emptydir volume type on node default medium @ 04/15/24 06:19:52.62
  STEP: Saw pod success @ 04/15/24 06:19:56.701
  Apr 15 06:19:56.709: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-f4851543-eb77-49c6-9bbe-b6f55b9bf223 container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:19:56.726
  Apr 15 06:19:56.766: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6472" for this suite. @ 04/15/24 06:19:56.788
â€¢ [4.245 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:341
  STEP: Creating a kubernetes client @ 04/15/24 06:19:56.812
  Apr 15 06:19:56.812: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:19:56.816
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:19:56.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:19:56.875
  STEP: creating a replication controller @ 04/15/24 06:19:56.885
  Apr 15 06:19:56.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 create -f -'
  Apr 15 06:19:57.623: INFO: stderr: ""
  Apr 15 06:19:57.623: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/15/24 06:19:57.623
  Apr 15 06:19:57.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 15 06:19:57.876: INFO: stderr: ""
  Apr 15 06:19:57.876: INFO: stdout: "update-demo-nautilus-5wc6t update-demo-nautilus-gznml "
  Apr 15 06:19:57.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 get pods update-demo-nautilus-5wc6t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 15 06:19:58.101: INFO: stderr: ""
  Apr 15 06:19:58.101: INFO: stdout: ""
  Apr 15 06:19:58.101: INFO: update-demo-nautilus-5wc6t is created but not running
  Apr 15 06:20:03.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 15 06:20:03.270: INFO: stderr: ""
  Apr 15 06:20:03.271: INFO: stdout: "update-demo-nautilus-5wc6t update-demo-nautilus-gznml "
  Apr 15 06:20:03.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 get pods update-demo-nautilus-5wc6t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 15 06:20:03.473: INFO: stderr: ""
  Apr 15 06:20:03.473: INFO: stdout: "true"
  Apr 15 06:20:03.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 get pods update-demo-nautilus-5wc6t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 15 06:20:03.663: INFO: stderr: ""
  Apr 15 06:20:03.663: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 15 06:20:03.663: INFO: validating pod update-demo-nautilus-5wc6t
  Apr 15 06:20:03.684: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 15 06:20:03.684: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 15 06:20:03.684: INFO: update-demo-nautilus-5wc6t is verified up and running
  Apr 15 06:20:03.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 get pods update-demo-nautilus-gznml -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 15 06:20:03.842: INFO: stderr: ""
  Apr 15 06:20:03.842: INFO: stdout: "true"
  Apr 15 06:20:03.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 get pods update-demo-nautilus-gznml -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 15 06:20:03.998: INFO: stderr: ""
  Apr 15 06:20:03.998: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 15 06:20:03.998: INFO: validating pod update-demo-nautilus-gznml
  Apr 15 06:20:04.032: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 15 06:20:04.032: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 15 06:20:04.032: INFO: update-demo-nautilus-gznml is verified up and running
  STEP: using delete to clean up resources @ 04/15/24 06:20:04.032
  Apr 15 06:20:04.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 delete --grace-period=0 --force -f -'
  Apr 15 06:20:04.251: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 15 06:20:04.251: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 15 06:20:04.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 get rc,svc -l name=update-demo --no-headers'
  Apr 15 06:20:04.480: INFO: stderr: "No resources found in kubectl-56 namespace.\n"
  Apr 15 06:20:04.480: INFO: stdout: ""
  Apr 15 06:20:04.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-56 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 15 06:20:04.786: INFO: stderr: ""
  Apr 15 06:20:04.786: INFO: stdout: ""
  Apr 15 06:20:04.788: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-56" for this suite. @ 04/15/24 06:20:04.797
â€¢ [8.000 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:123
  STEP: Creating a kubernetes client @ 04/15/24 06:20:04.822
  Apr 15 06:20:04.822: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sysctl @ 04/15/24 06:20:04.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:04.915
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:04.92
  STEP: Creating a pod with one valid and two invalid sysctls @ 04/15/24 06:20:04.944
  Apr 15 06:20:04.961: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-6651" for this suite. @ 04/15/24 06:20:04.979
â€¢ [0.176 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 04/15/24 06:20:04.999
  Apr 15 06:20:04.999: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename var-expansion @ 04/15/24 06:20:05.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:05.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:05.042
  Apr 15 06:20:07.095: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 06:20:07.105: INFO: Deleting pod "var-expansion-7acf9209-7d92-4f80-95bc-0f1bb44e1f92" in namespace "var-expansion-7964"
  Apr 15 06:20:07.121: INFO: Wait up to 5m0s for pod "var-expansion-7acf9209-7d92-4f80-95bc-0f1bb44e1f92" to be fully deleted
  STEP: Destroying namespace "var-expansion-7964" for this suite. @ 04/15/24 06:20:09.151
â€¢ [4.170 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 04/15/24 06:20:09.17
  Apr 15 06:20:09.170: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 06:20:09.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:09.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:09.218
  Apr 15 06:20:09.223: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: creating the pod @ 04/15/24 06:20:09.225
  STEP: submitting the pod to kubernetes @ 04/15/24 06:20:09.226
  Apr 15 06:20:11.468: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8570" for this suite. @ 04/15/24 06:20:11.483
â€¢ [2.330 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
test/e2e/kubectl/kubectl.go:1575
  STEP: Creating a kubernetes client @ 04/15/24 06:20:11.503
  Apr 15 06:20:11.504: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:20:11.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:11.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:11.568
  STEP: creating the pod @ 04/15/24 06:20:11.574
  Apr 15 06:20:11.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-4978 create -f -'
  Apr 15 06:20:12.172: INFO: stderr: ""
  Apr 15 06:20:12.173: INFO: stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 04/15/24 06:20:14.193
  Apr 15 06:20:14.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-4978 label pods pause testing-label=testing-label-value'
  Apr 15 06:20:14.515: INFO: stderr: ""
  Apr 15 06:20:14.515: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 04/15/24 06:20:14.515
  Apr 15 06:20:14.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-4978 get pod pause -L testing-label'
  Apr 15 06:20:14.680: INFO: stderr: ""
  Apr 15 06:20:14.680: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 04/15/24 06:20:14.68
  Apr 15 06:20:14.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-4978 label pods pause testing-label-'
  Apr 15 06:20:14.875: INFO: stderr: ""
  Apr 15 06:20:14.875: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 04/15/24 06:20:14.875
  Apr 15 06:20:14.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-4978 get pod pause -L testing-label'
  Apr 15 06:20:15.053: INFO: stderr: ""
  Apr 15 06:20:15.053: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 04/15/24 06:20:15.054
  Apr 15 06:20:15.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-4978 delete --grace-period=0 --force -f -'
  Apr 15 06:20:15.227: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 15 06:20:15.227: INFO: stdout: "pod \"pause\" force deleted\n"
  Apr 15 06:20:15.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-4978 get rc,svc -l name=pause --no-headers'
  Apr 15 06:20:15.480: INFO: stderr: "No resources found in kubectl-4978 namespace.\n"
  Apr 15 06:20:15.480: INFO: stdout: ""
  Apr 15 06:20:15.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-4978 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 15 06:20:15.718: INFO: stderr: ""
  Apr 15 06:20:15.718: INFO: stdout: ""
  Apr 15 06:20:15.718: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4978" for this suite. @ 04/15/24 06:20:15.738
â€¢ [4.258 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance]
test/e2e/network/ingress.go:556
  STEP: Creating a kubernetes client @ 04/15/24 06:20:15.769
  Apr 15 06:20:15.770: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename ingress @ 04/15/24 06:20:15.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:15.829
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:15.837
  STEP: getting /apis @ 04/15/24 06:20:15.848
  STEP: getting /apis/networking.k8s.io @ 04/15/24 06:20:15.868
  STEP: getting /apis/networking.k8s.iov1 @ 04/15/24 06:20:15.871
  STEP: creating @ 04/15/24 06:20:15.874
  STEP: getting @ 04/15/24 06:20:15.921
  STEP: listing @ 04/15/24 06:20:15.93
  STEP: watching @ 04/15/24 06:20:15.945
  Apr 15 06:20:15.946: INFO: starting watch
  STEP: cluster-wide listing @ 04/15/24 06:20:15.949
  STEP: cluster-wide watching @ 04/15/24 06:20:15.959
  Apr 15 06:20:15.960: INFO: starting watch
  STEP: patching @ 04/15/24 06:20:15.964
  STEP: updating @ 04/15/24 06:20:15.991
  Apr 15 06:20:16.039: INFO: waiting for watch events with expected annotations
  Apr 15 06:20:16.040: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/15/24 06:20:16.04
  STEP: updating /status @ 04/15/24 06:20:16.063
  STEP: get /status @ 04/15/24 06:20:16.09
  STEP: deleting @ 04/15/24 06:20:16.103
  STEP: deleting a collection @ 04/15/24 06:20:16.148
  Apr 15 06:20:16.198: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-3665" for this suite. @ 04/15/24 06:20:16.208
â€¢ [0.469 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 04/15/24 06:20:16.24
  Apr 15 06:20:16.240: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:20:16.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:16.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:16.299
  STEP: Setting up server cert @ 04/15/24 06:20:16.381
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:20:17.979
  STEP: Deploying the webhook pod @ 04/15/24 06:20:17.995
  STEP: Wait for the deployment to be ready @ 04/15/24 06:20:18.024
  Apr 15 06:20:18.037: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/15/24 06:20:20.064
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:20:20.094
  Apr 15 06:20:21.095: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 04/15/24 06:20:21.122
  STEP: create a configmap that should be updated by the webhook @ 04/15/24 06:20:21.182
  Apr 15 06:20:21.217: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6976" for this suite. @ 04/15/24 06:20:21.33
  STEP: Destroying namespace "webhook-markers-8878" for this suite. @ 04/15/24 06:20:21.348
â€¢ [5.142 seconds]
------------------------------
SS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:46
  STEP: Creating a kubernetes client @ 04/15/24 06:20:21.385
  Apr 15 06:20:21.385: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 06:20:21.392
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:21.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:21.463
  STEP: Creating secret with name secret-test-1a66cd78-ac58-452f-b199-70b3a84501cf @ 04/15/24 06:20:21.472
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:20:21.482
  STEP: Saw pod success @ 04/15/24 06:20:25.528
  Apr 15 06:20:25.535: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-secrets-1218affd-37a5-4cea-b95a-d5f1936abb45 container secret-env-test: <nil>
  STEP: delete the pod @ 04/15/24 06:20:25.556
  Apr 15 06:20:25.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9251" for this suite. @ 04/15/24 06:20:25.622
â€¢ [4.255 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 04/15/24 06:20:25.647
  Apr 15 06:20:25.647: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:20:25.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:25.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:25.711
  STEP: Setting up server cert @ 04/15/24 06:20:25.767
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:20:26.189
  STEP: Deploying the webhook pod @ 04/15/24 06:20:26.198
  STEP: Wait for the deployment to be ready @ 04/15/24 06:20:26.223
  Apr 15 06:20:26.243: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  Apr 15 06:20:28.310: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 20, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 20, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 20, 26, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 20, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 04/15/24 06:20:30.325
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:20:30.36
  Apr 15 06:20:31.360: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 04/15/24 06:20:31.377
  STEP: create a pod that should be updated by the webhook @ 04/15/24 06:20:31.418
  Apr 15 06:20:31.460: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6983" for this suite. @ 04/15/24 06:20:31.657
  STEP: Destroying namespace "webhook-markers-7093" for this suite. @ 04/15/24 06:20:31.678
â€¢ [6.053 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:85
  STEP: Creating a kubernetes client @ 04/15/24 06:20:31.701
  Apr 15 06:20:31.701: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/15/24 06:20:31.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:31.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:31.757
  Apr 15 06:20:31.765: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:20:38.303: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6873" for this suite. @ 04/15/24 06:20:38.317
â€¢ [6.634 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 04/15/24 06:20:38.354
  Apr 15 06:20:38.354: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename hostport @ 04/15/24 06:20:38.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:38.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:38.413
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 04/15/24 06:20:38.431
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.141 on the node which pod1 resides and expect scheduled @ 04/15/24 06:20:40.485
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.141 but use UDP protocol on the node which pod2 resides @ 04/15/24 06:20:42.526
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 04/15/24 06:20:48.653
  Apr 15 06:20:48.653: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.141 http://127.0.0.1:54323/hostname] Namespace:hostport-2247 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:20:48.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:20:48.657: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:20:48.657: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-2247/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.141+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.141, port: 54323 @ 04/15/24 06:20:48.924
  Apr 15 06:20:48.924: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.141:54323/hostname] Namespace:hostport-2247 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:20:48.925: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:20:48.927: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:20:48.927: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-2247/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.141%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.141, port: 54323 UDP @ 04/15/24 06:20:49.085
  Apr 15 06:20:49.086: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.141 54323] Namespace:hostport-2247 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:20:49.086: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:20:49.088: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:20:49.088: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-2247/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.141+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  Apr 15 06:20:54.220: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-2247" for this suite. @ 04/15/24 06:20:54.233
â€¢ [15.896 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:127
  STEP: Creating a kubernetes client @ 04/15/24 06:20:54.256
  Apr 15 06:20:54.256: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:20:54.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:54.297
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:54.302
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/15/24 06:20:54.307
  STEP: Saw pod success @ 04/15/24 06:20:58.351
  Apr 15 06:20:58.362: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-cefbfbed-943a-4844-8390-9552fe6aa37a container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:20:58.382
  Apr 15 06:20:58.422: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7490" for this suite. @ 04/15/24 06:20:58.431
â€¢ [4.187 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]
test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 04/15/24 06:20:58.444
  Apr 15 06:20:58.444: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename daemonsets @ 04/15/24 06:20:58.448
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:20:58.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:20:58.511
  STEP: Creating simple DaemonSet "daemon-set" @ 04/15/24 06:20:58.56
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/15/24 06:20:58.57
  Apr 15 06:20:58.585: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:20:58.585: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  Apr 15 06:20:59.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:20:59.891: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  Apr 15 06:21:00.621: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 15 06:21:00.621: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  Apr 15 06:21:01.628: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 15 06:21:01.628: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 04/15/24 06:21:01.638
  Apr 15 06:21:01.736: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 15 06:21:01.736: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  Apr 15 06:21:02.759: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 15 06:21:02.759: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  Apr 15 06:21:03.758: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 15 06:21:03.758: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  Apr 15 06:21:04.761: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 15 06:21:04.761: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  Apr 15 06:21:05.758: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 15 06:21:05.758: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/15/24 06:21:05.768
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3261, will wait for the garbage collector to delete the pods @ 04/15/24 06:21:05.769
  Apr 15 06:21:05.847: INFO: Deleting DaemonSet.extensions daemon-set took: 20.603659ms
  Apr 15 06:21:05.948: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.798534ms
  Apr 15 06:21:07.556: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:21:07.556: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 15 06:21:07.562: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"145470"},"items":null}

  Apr 15 06:21:07.569: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"145470"},"items":null}

  Apr 15 06:21:07.602: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3261" for this suite. @ 04/15/24 06:21:07.611
â€¢ [9.184 seconds]
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:84
  STEP: Creating a kubernetes client @ 04/15/24 06:21:07.628
  Apr 15 06:21:07.628: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pod-network-test @ 04/15/24 06:21:07.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:07.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:07.689
  STEP: Performing setup for networking test in namespace pod-network-test-3336 @ 04/15/24 06:21:07.692
  STEP: creating a selector @ 04/15/24 06:21:07.694
  STEP: Creating the service pods in kubernetes @ 04/15/24 06:21:07.695
  Apr 15 06:21:07.696: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/15/24 06:21:19.903
  Apr 15 06:21:21.955: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 15 06:21:21.956: INFO: Breadth first check of 10.233.64.80 on host 192.168.121.141...
  Apr 15 06:21:21.963: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.219:9080/dial?request=hostname&protocol=http&host=10.233.64.80&port=8083&tries=1'] Namespace:pod-network-test-3336 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:21:21.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:21:21.971: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:21:21.972: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3336/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.219%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.80%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 15 06:21:22.189: INFO: Waiting for responses: map[]
  Apr 15 06:21:22.189: INFO: reached 10.233.64.80 after 0/1 tries
  Apr 15 06:21:22.189: INFO: Breadth first check of 10.233.65.100 on host 192.168.121.17...
  Apr 15 06:21:22.196: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.219:9080/dial?request=hostname&protocol=http&host=10.233.65.100&port=8083&tries=1'] Namespace:pod-network-test-3336 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:21:22.196: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:21:22.197: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:21:22.197: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3336/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.219%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.100%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 15 06:21:22.312: INFO: Waiting for responses: map[]
  Apr 15 06:21:22.312: INFO: reached 10.233.65.100 after 0/1 tries
  Apr 15 06:21:22.312: INFO: Breadth first check of 10.233.66.218 on host 192.168.121.206...
  Apr 15 06:21:22.324: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.219:9080/dial?request=hostname&protocol=http&host=10.233.66.218&port=8083&tries=1'] Namespace:pod-network-test-3336 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:21:22.325: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:21:22.327: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:21:22.327: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3336/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.219%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.218%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 15 06:21:22.441: INFO: Waiting for responses: map[]
  Apr 15 06:21:22.441: INFO: reached 10.233.66.218 after 0/1 tries
  Apr 15 06:21:22.442: INFO: Going to retry 0 out of 3 pods....
  Apr 15 06:21:22.442: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3336" for this suite. @ 04/15/24 06:21:22.454
â€¢ [14.837 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 04/15/24 06:21:22.468
  Apr 15 06:21:22.468: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename watch @ 04/15/24 06:21:22.472
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:22.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:22.518
  STEP: creating a watch on configmaps @ 04/15/24 06:21:22.524
  STEP: creating a new configmap @ 04/15/24 06:21:22.526
  STEP: modifying the configmap once @ 04/15/24 06:21:22.543
  STEP: closing the watch once it receives two notifications @ 04/15/24 06:21:22.563
  Apr 15 06:21:22.563: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-863  ced44f19-73fc-4733-88e7-c11fa8dcbf25 145566 0 2024-04-15 06:21:22 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-15 06:21:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 06:21:22.564: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-863  ced44f19-73fc-4733-88e7-c11fa8dcbf25 145567 0 2024-04-15 06:21:22 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-15 06:21:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 04/15/24 06:21:22.565
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 04/15/24 06:21:22.58
  STEP: deleting the configmap @ 04/15/24 06:21:22.582
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 04/15/24 06:21:22.598
  Apr 15 06:21:22.598: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-863  ced44f19-73fc-4733-88e7-c11fa8dcbf25 145568 0 2024-04-15 06:21:22 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-15 06:21:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 06:21:22.599: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-863  ced44f19-73fc-4733-88e7-c11fa8dcbf25 145569 0 2024-04-15 06:21:22 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-15 06:21:22 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 06:21:22.599: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-863" for this suite. @ 04/15/24 06:21:22.613
â€¢ [0.160 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
test/e2e/apimachinery/resource_quota.go:887
  STEP: Creating a kubernetes client @ 04/15/24 06:21:22.629
  Apr 15 06:21:22.629: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 06:21:22.632
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:22.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:22.674
  STEP: Creating a ResourceQuota @ 04/15/24 06:21:22.679
  STEP: Getting a ResourceQuota @ 04/15/24 06:21:22.692
  STEP: Updating a ResourceQuota @ 04/15/24 06:21:22.705
  STEP: Verifying a ResourceQuota was modified @ 04/15/24 06:21:22.73
  STEP: Deleting a ResourceQuota @ 04/15/24 06:21:22.74
  STEP: Verifying the deleted ResourceQuota @ 04/15/24 06:21:22.754
  Apr 15 06:21:22.762: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3942" for this suite. @ 04/15/24 06:21:22.773
â€¢ [0.165 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:647
  STEP: Creating a kubernetes client @ 04/15/24 06:21:22.799
  Apr 15 06:21:22.799: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename svcaccounts @ 04/15/24 06:21:22.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:22.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:22.842
  STEP: creating a ServiceAccount @ 04/15/24 06:21:22.85
  STEP: watching for the ServiceAccount to be added @ 04/15/24 06:21:22.867
  STEP: patching the ServiceAccount @ 04/15/24 06:21:22.875
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 04/15/24 06:21:22.889
  STEP: deleting the ServiceAccount @ 04/15/24 06:21:22.899
  Apr 15 06:21:22.925: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9050" for this suite. @ 04/15/24 06:21:22.937
â€¢ [0.159 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]
test/e2e/apps/rc.go:112
  STEP: Creating a kubernetes client @ 04/15/24 06:21:22.962
  Apr 15 06:21:22.962: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replication-controller @ 04/15/24 06:21:22.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:22.999
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:23.003
  STEP: creating a ReplicationController @ 04/15/24 06:21:23.016
  STEP: waiting for RC to be added @ 04/15/24 06:21:23.031
  STEP: waiting for available Replicas @ 04/15/24 06:21:23.031
  STEP: patching ReplicationController @ 04/15/24 06:21:24.352
  STEP: waiting for RC to be modified @ 04/15/24 06:21:24.377
  STEP: patching ReplicationController status @ 04/15/24 06:21:24.378
  STEP: waiting for RC to be modified @ 04/15/24 06:21:24.394
  STEP: waiting for available Replicas @ 04/15/24 06:21:24.395
  STEP: fetching ReplicationController status @ 04/15/24 06:21:24.414
  STEP: patching ReplicationController scale @ 04/15/24 06:21:24.428
  STEP: waiting for RC to be modified @ 04/15/24 06:21:24.47
  STEP: waiting for ReplicationController's scale to be the max amount @ 04/15/24 06:21:24.47
  STEP: fetching ReplicationController; ensuring that it's patched @ 04/15/24 06:21:25.476
  STEP: updating ReplicationController status @ 04/15/24 06:21:25.484
  STEP: waiting for RC to be modified @ 04/15/24 06:21:25.499
  STEP: listing all ReplicationControllers @ 04/15/24 06:21:25.5
  STEP: checking that ReplicationController has expected values @ 04/15/24 06:21:25.508
  STEP: deleting ReplicationControllers by collection @ 04/15/24 06:21:25.509
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 04/15/24 06:21:25.531
  Apr 15 06:21:25.667: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:21:25.668613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-9188" for this suite. @ 04/15/24 06:21:25.677
â€¢ [2.729 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:147
  STEP: Creating a kubernetes client @ 04/15/24 06:21:25.693
  Apr 15 06:21:25.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:21:25.701
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:25.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:25.741
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/15/24 06:21:25.746
  E0415 06:21:26.668973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:27.669720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:28.669957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:29.670156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:21:29.796
  Apr 15 06:21:29.804: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-093c9329-30e2-4ecd-b348-494ea9a1115f container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:21:29.823
  Apr 15 06:21:29.857: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1091" for this suite. @ 04/15/24 06:21:29.869
â€¢ [4.190 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/rc.go:69
  STEP: Creating a kubernetes client @ 04/15/24 06:21:29.892
  Apr 15 06:21:29.892: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replication-controller @ 04/15/24 06:21:29.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:29.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:29.933
  STEP: Creating replication controller my-hostname-basic-b575d1c8-9cdf-417d-ba12-506534c5316b @ 04/15/24 06:21:29.939
  Apr 15 06:21:29.957: INFO: Pod name my-hostname-basic-b575d1c8-9cdf-417d-ba12-506534c5316b: Found 0 pods out of 1
  E0415 06:21:30.670420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:31.672487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:32.672647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:33.672683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:34.673694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:21:34.965: INFO: Pod name my-hostname-basic-b575d1c8-9cdf-417d-ba12-506534c5316b: Found 1 pods out of 1
  Apr 15 06:21:34.965: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b575d1c8-9cdf-417d-ba12-506534c5316b" are running
  Apr 15 06:21:34.975: INFO: Pod "my-hostname-basic-b575d1c8-9cdf-417d-ba12-506534c5316b-z9cgh" is running and ready(conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-15 06:21:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-15 06:21:31 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-15 06:21:31 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-15 06:21:29 +0000 UTC Reason: Message:}])
  Apr 15 06:21:34.975: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/15/24 06:21:34.976
  Apr 15 06:21:35.004: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6923" for this suite. @ 04/15/24 06:21:35.016
â€¢ [5.149 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance]
test/e2e/apps/rc.go:103
  STEP: Creating a kubernetes client @ 04/15/24 06:21:35.041
  Apr 15 06:21:35.041: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replication-controller @ 04/15/24 06:21:35.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:35.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:35.104
  STEP: Given a ReplicationController is created @ 04/15/24 06:21:35.115
  STEP: When the matched label of one of its pods change @ 04/15/24 06:21:35.129
  Apr 15 06:21:35.138: INFO: Pod name pod-release: Found 0 pods out of 1
  E0415 06:21:35.673908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:36.674539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:37.674256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:38.674445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:39.674659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:21:40.149: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/15/24 06:21:40.177
  E0415 06:21:40.675109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:21:41.199: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2627" for this suite. @ 04/15/24 06:21:41.216
â€¢ [6.189 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 04/15/24 06:21:41.232
  Apr 15 06:21:41.232: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:21:41.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:41.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:41.281
  STEP: Setting up server cert @ 04/15/24 06:21:41.387
  E0415 06:21:41.675855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:42.677982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:21:42.854
  STEP: Deploying the webhook pod @ 04/15/24 06:21:42.878
  STEP: Wait for the deployment to be ready @ 04/15/24 06:21:42.901
  Apr 15 06:21:42.923: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 06:21:43.677366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:44.677298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 06:21:44.955
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:21:44.982
  E0415 06:21:45.677610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:21:45.983: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 04/15/24 06:21:45.996
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/15/24 06:21:45.997
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 04/15/24 06:21:46.028
  E0415 06:21:46.677832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 04/15/24 06:21:47.046
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/15/24 06:21:47.046
  E0415 06:21:47.678203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 04/15/24 06:21:48.115
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/15/24 06:21:48.117
  E0415 06:21:48.678539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:49.679350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:50.679647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:51.680586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:52.681271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 04/15/24 06:21:53.207
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/15/24 06:21:53.207
  E0415 06:21:53.681810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:54.682626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:55.683174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:56.683271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:57.683395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:21:58.267: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4025" for this suite. @ 04/15/24 06:21:58.446
  STEP: Destroying namespace "webhook-markers-1397" for this suite. @ 04/15/24 06:21:58.459
â€¢ [17.242 seconds]
------------------------------
S
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 04/15/24 06:21:58.475
  Apr 15 06:21:58.475: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 06:21:58.479
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:21:58.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:21:58.524
  STEP: Creating pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144 @ 04/15/24 06:21:58.532
  E0415 06:21:58.684258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:21:59.684618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/15/24 06:22:00.579
  Apr 15 06:22:00.586: INFO: Initial restart count of pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d is 0
  Apr 15 06:22:00.597: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:00.685470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:01.686115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:02.616: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:02.686192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:03.686338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:04.629: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:04.686523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:05.687122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:06.641: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:06.687769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:07.688118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:08.648: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:08.688638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:09.689579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:10.657: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:10.689739      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:11.689946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:12.668: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:12.690748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:13.691264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:14.677: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:14.692061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:15.693083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:16.684: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:16.693907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:17.694671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:18.694: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:18.694979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:19.695799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:20.696522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:20.705: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  Apr 15 06:22:20.705: INFO: Restart count of pod container-probe-1144/liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d is now 1 (20.118477312s elapsed)
  E0415 06:22:21.697237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:22.697137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:22.714: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:23.697412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:24.698001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:24.727: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:25.698020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:26.698753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:26.735: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:27.698889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:28.699541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:28.747: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:29.699591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:30.699685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:30.758: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:31.699979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:32.701129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:32.768: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:33.702002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:34.701955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:34.784: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:35.702570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:36.703369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:36.793: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:37.703828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:38.703854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:38.804: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:39.704327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:40.704346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:40.813: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  Apr 15 06:22:40.813: INFO: Restart count of pod container-probe-1144/liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d is now 2 (40.226453421s elapsed)
  E0415 06:22:41.704459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:42.705377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:42.821: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:43.705519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:44.706537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:44.830: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:45.706685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:46.709123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:46.842: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:47.709593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:48.708735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:48.853: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:49.709584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:50.709718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:50.862: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:51.709790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:52.710825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:52.872: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:53.710981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:54.711957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:54.881: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:55.712834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:56.713175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:56.891: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:57.713606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:22:58.713782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:22:58.899: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:22:59.714712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:00.714912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:00.909: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  Apr 15 06:23:00.909: INFO: Restart count of pod container-probe-1144/liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d is now 3 (1m0.322737897s elapsed)
  E0415 06:23:01.715592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:02.715714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:02.918: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:03.715988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:04.716255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:04.929: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:05.716389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:06.717152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:06.940: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:07.717340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:08.717518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:08.949: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:09.718626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:10.718828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:10.957: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:11.719233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:12.719434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:12.968: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:13.722322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:14.721635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:14.980: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:15.722389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:16.722176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:16.990: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:17.722561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:18.722648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:19.007: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:19.722899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:20.723562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:21.019: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  Apr 15 06:23:21.019: INFO: Restart count of pod container-probe-1144/liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d is now 4 (1m20.432138983s elapsed)
  E0415 06:23:21.724412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:22.724503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:23.029: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:23.724695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:24.724735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:25.041: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:25.725240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:26.725394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:27.051: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:27.725855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:28.726264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:29.064: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:29.726675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:30.726982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:31.084: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:31.727063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:32.727181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:33.098: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:33.728689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:34.729403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:35.109: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:35.730878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:36.731438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:37.118: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:37.732512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:38.732876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:39.135: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:39.733091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:40.733338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:41.144: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:41.733473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:42.736130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:43.153: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:43.736427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:44.737649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:45.165: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:45.738035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:46.738201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:47.175: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:47.738586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:48.738763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:49.183: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:49.739995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:50.740298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:51.191: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:51.740408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:52.740719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:53.203: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:53.741186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:54.742496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:55.215: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:55.742601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:56.743209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:57.228: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:57.743955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:23:58.745090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:23:59.237: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:23:59.745604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:00.746493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:01.248: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:01.747445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:02.748460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:03.257: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:03.749301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:04.750176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:05.267: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:05.750496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:06.750860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:07.279: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:07.751083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:08.751578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:09.288: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:09.752216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:10.753031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:11.296: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:11.753220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:12.754005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:13.309: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:13.754158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:14.754456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:15.343: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:15.755328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:16.755481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:17.357: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:17.755986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:18.756237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:19.366: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:19.757089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:20.757372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:21.376: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:21.758062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:22.758824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:23.384: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:23.759070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:24.759905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:25.393: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:25.760093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:26.760453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:27.404: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:27.761377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:28.762263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:29.416: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  E0415 06:24:29.762265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:30.762473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:31.425: INFO: Get pod liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d in namespace container-probe-1144
  Apr 15 06:24:31.426: INFO: Restart count of pod container-probe-1144/liveness-98fc59d3-9646-4a43-9109-b8d5eaa2dd9d is now 5 (2m30.838936878s elapsed)
  Apr 15 06:24:31.426: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 06:24:31.445
  STEP: Destroying namespace "container-probe-1144" for this suite. @ 04/15/24 06:24:31.489
â€¢ [153.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]
test/e2e/apps/replica_set.go:143
  STEP: Creating a kubernetes client @ 04/15/24 06:24:31.523
  Apr 15 06:24:31.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replicaset @ 04/15/24 06:24:31.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:24:31.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:24:31.578
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 04/15/24 06:24:31.583
  Apr 15 06:24:31.611: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0415 06:24:31.763099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:32.764235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:33.765043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:34.765067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:35.765235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:36.619: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/15/24 06:24:36.619
  STEP: getting scale subresource @ 04/15/24 06:24:36.619
  STEP: updating a scale subresource @ 04/15/24 06:24:36.628
  STEP: verifying the replicaset Spec.Replicas was modified @ 04/15/24 06:24:36.639
  STEP: Patch a scale subresource @ 04/15/24 06:24:36.646
  Apr 15 06:24:36.663: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1446" for this suite. @ 04/15/24 06:24:36.673
â€¢ [5.165 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance]
test/e2e/auth/service_accounts.go:275
  STEP: Creating a kubernetes client @ 04/15/24 06:24:36.691
  Apr 15 06:24:36.691: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename svcaccounts @ 04/15/24 06:24:36.695
  E0415 06:24:36.765660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:24:36.776
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:24:36.782
  STEP: Creating a pod to test service account token:  @ 04/15/24 06:24:36.788
  E0415 06:24:37.765883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:38.766694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:39.767637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:40.767688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:24:40.878
  Apr 15 06:24:40.887: INFO: Trying to get logs from node phiefi7ighaa-3 pod test-pod-ce4f57dc-2934-4f41-9c83-035d82019278 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 06:24:40.931
  Apr 15 06:24:40.961: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3329" for this suite. @ 04/15/24 06:24:40.974
â€¢ [4.299 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
test/e2e/apimachinery/resource_quota.go:76
  STEP: Creating a kubernetes client @ 04/15/24 06:24:40.993
  Apr 15 06:24:40.993: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 06:24:40.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:24:41.032
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:24:41.039
  STEP: Counting existing ResourceQuota @ 04/15/24 06:24:41.045
  E0415 06:24:41.767732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:42.767949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:43.768396      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:44.769151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:45.769328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/15/24 06:24:46.057
  STEP: Ensuring resource quota status is calculated @ 04/15/24 06:24:46.07
  E0415 06:24:46.769604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:47.770529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:48.086: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3432" for this suite. @ 04/15/24 06:24:48.095
â€¢ [7.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
test/e2e/apimachinery/resource_quota.go:451
  STEP: Creating a kubernetes client @ 04/15/24 06:24:48.124
  Apr 15 06:24:48.124: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 06:24:48.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:24:48.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:24:48.177
  STEP: Counting existing ResourceQuota @ 04/15/24 06:24:48.19
  E0415 06:24:48.771937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:49.772813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:50.774053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:51.774464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:52.774783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/15/24 06:24:53.201
  STEP: Ensuring resource quota status is calculated @ 04/15/24 06:24:53.215
  E0415 06:24:53.775713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:54.776283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 04/15/24 06:24:55.225
  STEP: Ensuring resource quota status captures replicaset creation @ 04/15/24 06:24:55.296
  E0415 06:24:55.777688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:56.777745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 04/15/24 06:24:57.308
  STEP: Ensuring resource quota status released usage @ 04/15/24 06:24:57.323
  E0415 06:24:57.777957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:24:58.778644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:24:59.337: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6621" for this suite. @ 04/15/24 06:24:59.359
â€¢ [11.251 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]
test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 04/15/24 06:24:59.381
  Apr 15 06:24:59.381: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-pred @ 04/15/24 06:24:59.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:24:59.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:24:59.423
  Apr 15 06:24:59.429: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 15 06:24:59.451: INFO: Waiting for terminating namespaces to be deleted...
  Apr 15 06:24:59.458: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-1 before test
  Apr 15 06:24:59.472: INFO: coredns-5dd5756b68-6h4pb from kube-system started at 2024-04-15 06:16:14 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.473: INFO: 	Container coredns ready: true, restart count 0
  Apr 15 06:24:59.473: INFO: kube-addon-manager-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.473: INFO: 	Container kube-addon-manager ready: true, restart count 4
  Apr 15 06:24:59.474: INFO: kube-apiserver-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.474: INFO: 	Container kube-apiserver ready: true, restart count 4
  Apr 15 06:24:59.474: INFO: kube-controller-manager-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.474: INFO: 	Container kube-controller-manager ready: true, restart count 4
  Apr 15 06:24:59.474: INFO: kube-flannel-ds-wkm7k from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.475: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 06:24:59.475: INFO: kube-proxy-qgvqr from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.475: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 06:24:59.475: INFO: kube-scheduler-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.475: INFO: 	Container kube-scheduler ready: true, restart count 4
  Apr 15 06:24:59.476: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-f9ld5 from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (2 container statuses recorded)
  Apr 15 06:24:59.476: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:24:59.476: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 15 06:24:59.476: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-2 before test
  Apr 15 06:24:59.494: INFO: kube-addon-manager-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.494: INFO: 	Container kube-addon-manager ready: true, restart count 4
  Apr 15 06:24:59.494: INFO: kube-apiserver-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.495: INFO: 	Container kube-apiserver ready: true, restart count 4
  Apr 15 06:24:59.495: INFO: kube-controller-manager-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.495: INFO: 	Container kube-controller-manager ready: true, restart count 4
  Apr 15 06:24:59.495: INFO: kube-flannel-ds-5txx7 from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.495: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 06:24:59.495: INFO: kube-proxy-rkzlb from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.495: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 06:24:59.495: INFO: kube-scheduler-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.495: INFO: 	Container kube-scheduler ready: true, restart count 4
  Apr 15 06:24:59.495: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-jn669 from sonobuoy started at 2024-04-15 06:16:23 +0000 UTC (2 container statuses recorded)
  Apr 15 06:24:59.495: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:24:59.495: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 15 06:24:59.495: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-3 before test
  Apr 15 06:24:59.508: INFO: coredns-5dd5756b68-hggvw from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.508: INFO: 	Container coredns ready: true, restart count 0
  Apr 15 06:24:59.508: INFO: kube-flannel-ds-q9jkx from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.509: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 06:24:59.509: INFO: kube-proxy-rw79s from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.509: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 06:24:59.509: INFO: sonobuoy from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (1 container statuses recorded)
  Apr 15 06:24:59.510: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 15 06:24:59.510: INFO: sonobuoy-e2e-job-c84246e43b2d459a from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (2 container statuses recorded)
  Apr 15 06:24:59.510: INFO: 	Container e2e ready: true, restart count 0
  Apr 15 06:24:59.510: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:24:59.510: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-5gbvc from sonobuoy started at 2024-04-15 06:16:23 +0000 UTC (2 container statuses recorded)
  Apr 15 06:24:59.511: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:24:59.511: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 04/15/24 06:24:59.511
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17c66008e38b74df], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling..] @ 04/15/24 06:24:59.566
  E0415 06:24:59.778952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:25:00.564: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-200" for this suite. @ 04/15/24 06:25:00.578
â€¢ [1.212 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:152
  STEP: Creating a kubernetes client @ 04/15/24 06:25:00.597
  Apr 15 06:25:00.597: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/15/24 06:25:00.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:00.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:00.641
  STEP: create the container to handle the HTTPGet hook request. @ 04/15/24 06:25:00.66
  E0415 06:25:00.780243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:01.780421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/15/24 06:25:02.717
  E0415 06:25:02.781056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:03.781792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/15/24 06:25:04.765
  E0415 06:25:04.783332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:05.784191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:06.784585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/15/24 06:25:06.829
  Apr 15 06:25:06.845: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-7397" for this suite. @ 04/15/24 06:25:06.863
â€¢ [6.291 seconds]
------------------------------
SS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:77
  STEP: Creating a kubernetes client @ 04/15/24 06:25:06.889
  Apr 15 06:25:06.889: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sysctl @ 04/15/24 06:25:06.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:06.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:06.955
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 04/15/24 06:25:06.975
  STEP: Watching for error events or started pod @ 04/15/24 06:25:07.003
  E0415 06:25:07.784751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:08.785423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 04/15/24 06:25:09.015
  E0415 06:25:09.786279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:10.786578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 04/15/24 06:25:11.045
  STEP: Getting logs from the pod @ 04/15/24 06:25:11.045
  STEP: Checking that the sysctl is actually updated @ 04/15/24 06:25:11.059
  Apr 15 06:25:11.060: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-5752" for this suite. @ 04/15/24 06:25:11.076
â€¢ [4.201 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:187
  STEP: Creating a kubernetes client @ 04/15/24 06:25:11.113
  Apr 15 06:25:11.113: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:25:11.118
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:11.157
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:11.162
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/15/24 06:25:11.167
  E0415 06:25:11.787676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:12.788045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:13.789058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:14.790370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:25:15.215
  Apr 15 06:25:15.221: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-bb0a76c1-2642-478a-b82c-7375ae33e8ae container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:25:15.234
  Apr 15 06:25:15.281: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9895" for this suite. @ 04/15/24 06:25:15.292
â€¢ [4.195 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 04/15/24 06:25:15.311
  Apr 15 06:25:15.311: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:25:15.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:15.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:15.387
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:25:15.395
  E0415 06:25:15.789542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:16.790356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:17.790038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:18.790419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:25:19.453
  Apr 15 06:25:19.461: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-09b91a77-4434-4ca9-aaa6-d7d4c3a95580 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:25:19.477
  Apr 15 06:25:19.506: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3706" for this suite. @ 04/15/24 06:25:19.516
â€¢ [4.230 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]
test/e2e/apps/replica_set.go:165
  STEP: Creating a kubernetes client @ 04/15/24 06:25:19.543
  Apr 15 06:25:19.544: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replicaset @ 04/15/24 06:25:19.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:19.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:19.59
  STEP: Create a ReplicaSet @ 04/15/24 06:25:19.595
  STEP: Verify that the required pods have come up @ 04/15/24 06:25:19.609
  Apr 15 06:25:19.621: INFO: Pod name sample-pod: Found 0 pods out of 3
  E0415 06:25:19.791458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:20.791730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:21.792809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:22.793719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:23.794104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:25:24.641: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 04/15/24 06:25:24.642
  Apr 15 06:25:24.652: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 04/15/24 06:25:24.652
  STEP: DeleteCollection of the ReplicaSets @ 04/15/24 06:25:24.662
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 04/15/24 06:25:24.681
  Apr 15 06:25:24.694: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8892" for this suite. @ 04/15/24 06:25:24.702
â€¢ [5.176 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]
test/e2e/kubectl/kubectl.go:1781
  STEP: Creating a kubernetes client @ 04/15/24 06:25:24.727
  Apr 15 06:25:24.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:25:24.734
  E0415 06:25:24.800512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:24.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:24.882
  STEP: starting the proxy server @ 04/15/24 06:25:24.893
  Apr 15 06:25:24.894: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-6663 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 04/15/24 06:25:25.132
  Apr 15 06:25:25.162: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6663" for this suite. @ 04/15/24 06:25:25.191
â€¢ [0.481 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 04/15/24 06:25:25.211
  Apr 15 06:25:25.211: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubelet-test @ 04/15/24 06:25:25.216
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:25.363
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:25.373
  E0415 06:25:25.801510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:26.802378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:25:27.462: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4914" for this suite. @ 04/15/24 06:25:27.473
â€¢ [2.279 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 04/15/24 06:25:27.497
  Apr 15 06:25:27.497: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:25:27.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:27.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:27.545
  STEP: Creating configMap with name projected-configmap-test-volume-map-5e0701da-82b2-4280-a9e7-0438c1d500d7 @ 04/15/24 06:25:27.554
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:25:27.565
  E0415 06:25:27.803662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:28.804386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:29.804790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:30.805102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:25:31.633
  Apr 15 06:25:31.647: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-configmaps-e77b013c-d051-4fc3-bd27-310154998989 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 06:25:31.678
  Apr 15 06:25:31.720: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2518" for this suite. @ 04/15/24 06:25:31.736
â€¢ [4.252 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 04/15/24 06:25:31.752
  Apr 15 06:25:31.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:25:31.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:31.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:31.798
  E0415 06:25:31.805171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:25:31.806
  E0415 06:25:32.805572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:33.805675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:34.805701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:35.810247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:25:35.859
  Apr 15 06:25:35.866: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-7296cf05-66cd-4a2f-a48d-8615bbe2a9de container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:25:35.885
  Apr 15 06:25:35.923: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5290" for this suite. @ 04/15/24 06:25:35.937
â€¢ [4.202 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 04/15/24 06:25:35.963
  Apr 15 06:25:35.964: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:25:35.967
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:36.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:36.011
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:25:36.021
  E0415 06:25:36.810252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:37.811443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:38.812971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:39.812615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:25:40.082
  Apr 15 06:25:40.090: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-482e585a-77fe-44b0-8f18-8cc13850241a container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:25:40.107
  Apr 15 06:25:40.172: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8502" for this suite. @ 04/15/24 06:25:40.184
â€¢ [4.241 seconds]
------------------------------
SSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:213
  STEP: Creating a kubernetes client @ 04/15/24 06:25:40.206
  Apr 15 06:25:40.206: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/15/24 06:25:40.211
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:40.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:40.253
  STEP: create the container to handle the HTTPGet hook request. @ 04/15/24 06:25:40.273
  E0415 06:25:40.813188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:41.813266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/15/24 06:25:42.329
  E0415 06:25:42.815720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:43.816099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/15/24 06:25:44.376
  E0415 06:25:44.816530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:45.816677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/15/24 06:25:46.413
  Apr 15 06:25:46.457: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5247" for this suite. @ 04/15/24 06:25:46.471
â€¢ [6.281 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
test/e2e/kubectl/kubectl.go:1741
  STEP: Creating a kubernetes client @ 04/15/24 06:25:46.501
  Apr 15 06:25:46.501: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:25:46.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:46.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:46.552
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/15/24 06:25:46.556
  Apr 15 06:25:46.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3158 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 15 06:25:46.797: INFO: stderr: ""
  Apr 15 06:25:46.797: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 04/15/24 06:25:46.797
  E0415 06:25:46.816867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:47.817178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:48.817478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:49.817954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:50.818187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:51.819557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/15/24 06:25:51.849
  Apr 15 06:25:51.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3158 get pod e2e-test-httpd-pod -o json'
  Apr 15 06:25:52.040: INFO: stderr: ""
  Apr 15 06:25:52.040: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2024-04-15T06:25:46Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3158\",\n        \"resourceVersion\": \"146819\",\n        \"uid\": \"144123db-3bf2-44e6-a16f-481e7800b421\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-6x4jt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"phiefi7ighaa-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-6x4jt\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-15T06:25:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-15T06:25:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-15T06:25:47Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-15T06:25:46Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://485a77d3dc2d8af8a45669fa7deb9f7b87153af7f1ffb4b22bcda18429d68bb4\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-04-15T06:25:47Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.206\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.66.239\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.66.239\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-04-15T06:25:46Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 04/15/24 06:25:52.041
  Apr 15 06:25:52.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3158 replace -f -'
  E0415 06:25:52.819375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:25:52.900: INFO: stderr: ""
  Apr 15 06:25:52.900: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 @ 04/15/24 06:25:52.9
  Apr 15 06:25:52.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3158 delete pods e2e-test-httpd-pod'
  E0415 06:25:53.819431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:54.820347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:25:55.023: INFO: stderr: ""
  Apr 15 06:25:55.023: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 15 06:25:55.023: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3158" for this suite. @ 04/15/24 06:25:55.036
â€¢ [8.550 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 04/15/24 06:25:55.057
  Apr 15 06:25:55.057: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename cronjob @ 04/15/24 06:25:55.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:55.101
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:55.109
  STEP: Creating a cronjob @ 04/15/24 06:25:55.118
  STEP: creating @ 04/15/24 06:25:55.118
  STEP: getting @ 04/15/24 06:25:55.144
  STEP: listing @ 04/15/24 06:25:55.161
  STEP: watching @ 04/15/24 06:25:55.169
  Apr 15 06:25:55.169: INFO: starting watch
  STEP: cluster-wide listing @ 04/15/24 06:25:55.175
  STEP: cluster-wide watching @ 04/15/24 06:25:55.187
  Apr 15 06:25:55.187: INFO: starting watch
  STEP: patching @ 04/15/24 06:25:55.192
  STEP: updating @ 04/15/24 06:25:55.21
  Apr 15 06:25:55.231: INFO: waiting for watch events with expected annotations
  Apr 15 06:25:55.231: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/15/24 06:25:55.231
  STEP: updating /status @ 04/15/24 06:25:55.245
  STEP: get /status @ 04/15/24 06:25:55.268
  STEP: deleting @ 04/15/24 06:25:55.277
  STEP: deleting a collection @ 04/15/24 06:25:55.354
  Apr 15 06:25:55.379: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1349" for this suite. @ 04/15/24 06:25:55.386
â€¢ [0.346 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:198
  STEP: Creating a kubernetes client @ 04/15/24 06:25:55.409
  Apr 15 06:25:55.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/15/24 06:25:55.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:55.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:55.459
  STEP: fetching the /apis discovery document @ 04/15/24 06:25:55.464
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 04/15/24 06:25:55.468
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 04/15/24 06:25:55.468
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 04/15/24 06:25:55.468
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 04/15/24 06:25:55.47
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 04/15/24 06:25:55.471
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 04/15/24 06:25:55.474
  Apr 15 06:25:55.474: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6454" for this suite. @ 04/15/24 06:25:55.485
â€¢ [0.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]
test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 04/15/24 06:25:55.511
  Apr 15 06:25:55.511: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename subpath @ 04/15/24 06:25:55.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:25:55.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:25:55.554
  STEP: Setting up data @ 04/15/24 06:25:55.559
  STEP: Creating pod pod-subpath-test-configmap-vh9c @ 04/15/24 06:25:55.583
  STEP: Creating a pod to test atomic-volume-subpath @ 04/15/24 06:25:55.584
  E0415 06:25:55.820715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:56.821651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:57.822345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:58.822494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:25:59.823109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:00.823340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:01.823961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:02.824462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:03.825835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:04.826192      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:05.827572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:06.831104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:07.830260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:08.830668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:09.831432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:10.831588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:11.832760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:12.832782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:13.833544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:14.834186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:15.834684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:16.834966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:17.835336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:18.835777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:26:19.795
  Apr 15 06:26:19.804: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-subpath-test-configmap-vh9c container test-container-subpath-configmap-vh9c: <nil>
  STEP: delete the pod @ 04/15/24 06:26:19.829
  E0415 06:26:19.836469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pod pod-subpath-test-configmap-vh9c @ 04/15/24 06:26:19.872
  Apr 15 06:26:19.872: INFO: Deleting pod "pod-subpath-test-configmap-vh9c" in namespace "subpath-2395"
  Apr 15 06:26:19.879: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2395" for this suite. @ 04/15/24 06:26:19.893
â€¢ [24.398 seconds]
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]
test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 04/15/24 06:26:19.913
  Apr 15 06:26:19.913: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-pred @ 04/15/24 06:26:19.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:26:19.965
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:26:19.97
  Apr 15 06:26:19.976: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 15 06:26:20.001: INFO: Waiting for terminating namespaces to be deleted...
  Apr 15 06:26:20.013: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-1 before test
  Apr 15 06:26:20.042: INFO: coredns-5dd5756b68-6h4pb from kube-system started at 2024-04-15 06:16:14 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.043: INFO: 	Container coredns ready: true, restart count 0
  Apr 15 06:26:20.046: INFO: kube-addon-manager-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.047: INFO: 	Container kube-addon-manager ready: true, restart count 4
  Apr 15 06:26:20.047: INFO: kube-apiserver-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.048: INFO: 	Container kube-apiserver ready: true, restart count 4
  Apr 15 06:26:20.048: INFO: kube-controller-manager-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.049: INFO: 	Container kube-controller-manager ready: true, restart count 4
  Apr 15 06:26:20.049: INFO: kube-flannel-ds-wkm7k from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.049: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 06:26:20.050: INFO: kube-proxy-qgvqr from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.050: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 06:26:20.051: INFO: kube-scheduler-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.052: INFO: 	Container kube-scheduler ready: true, restart count 4
  Apr 15 06:26:20.052: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-f9ld5 from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (2 container statuses recorded)
  Apr 15 06:26:20.053: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:26:20.054: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 15 06:26:20.054: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-2 before test
  Apr 15 06:26:20.080: INFO: kube-addon-manager-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.081: INFO: 	Container kube-addon-manager ready: true, restart count 4
  Apr 15 06:26:20.081: INFO: kube-apiserver-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.081: INFO: 	Container kube-apiserver ready: true, restart count 4
  Apr 15 06:26:20.081: INFO: kube-controller-manager-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.081: INFO: 	Container kube-controller-manager ready: true, restart count 4
  Apr 15 06:26:20.081: INFO: kube-flannel-ds-5txx7 from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.081: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 06:26:20.081: INFO: kube-proxy-rkzlb from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.081: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 06:26:20.081: INFO: kube-scheduler-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.081: INFO: 	Container kube-scheduler ready: true, restart count 4
  Apr 15 06:26:20.081: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-jn669 from sonobuoy started at 2024-04-15 06:16:23 +0000 UTC (2 container statuses recorded)
  Apr 15 06:26:20.081: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:26:20.081: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 15 06:26:20.081: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-3 before test
  Apr 15 06:26:20.103: INFO: coredns-5dd5756b68-hggvw from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.103: INFO: 	Container coredns ready: true, restart count 0
  Apr 15 06:26:20.104: INFO: kube-flannel-ds-q9jkx from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.104: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 06:26:20.105: INFO: kube-proxy-rw79s from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.105: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 06:26:20.105: INFO: sonobuoy from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (1 container statuses recorded)
  Apr 15 06:26:20.106: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 15 06:26:20.106: INFO: sonobuoy-e2e-job-c84246e43b2d459a from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (2 container statuses recorded)
  Apr 15 06:26:20.107: INFO: 	Container e2e ready: true, restart count 0
  Apr 15 06:26:20.107: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:26:20.108: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-5gbvc from sonobuoy started at 2024-04-15 06:16:23 +0000 UTC (2 container statuses recorded)
  Apr 15 06:26:20.109: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:26:20.109: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/15/24 06:26:20.111
  E0415 06:26:20.837946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:21.838926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/15/24 06:26:22.179
  STEP: Trying to apply a random label on the found node. @ 04/15/24 06:26:22.213
  STEP: verifying the node has the label kubernetes.io/e2e-8b47a5fa-5589-4b91-92c0-c99aae55725f 42 @ 04/15/24 06:26:22.249
  STEP: Trying to relaunch the pod, now with labels. @ 04/15/24 06:26:22.291
  E0415 06:26:22.838879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:23.839304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-8b47a5fa-5589-4b91-92c0-c99aae55725f off the node phiefi7ighaa-3 @ 04/15/24 06:26:24.36
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-8b47a5fa-5589-4b91-92c0-c99aae55725f @ 04/15/24 06:26:24.395
  Apr 15 06:26:24.413: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-4079" for this suite. @ 04/15/24 06:26:24.43
â€¢ [4.549 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 04/15/24 06:26:24.474
  Apr 15 06:26:24.474: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 06:26:24.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:26:24.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:26:24.531
  STEP: creating the pod @ 04/15/24 06:26:24.54
  STEP: submitting the pod to kubernetes @ 04/15/24 06:26:24.54
  W0415 06:26:24.574125      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0415 06:26:24.839508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:25.840685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/15/24 06:26:26.599
  STEP: updating the pod @ 04/15/24 06:26:26.61
  E0415 06:26:26.840826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:26:27.140: INFO: Successfully updated pod "pod-update-activedeadlineseconds-ddf58cea-5782-4f78-a49a-f7f51b781f2b"
  E0415 06:26:27.841034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:28.841424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:29.841728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:30.842933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:26:31.176: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2697" for this suite. @ 04/15/24 06:26:31.186
â€¢ [6.729 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]
test/e2e/network/ingressclass.go:266
  STEP: Creating a kubernetes client @ 04/15/24 06:26:31.204
  Apr 15 06:26:31.204: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename ingressclass @ 04/15/24 06:26:31.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:26:31.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:26:31.253
  STEP: getting /apis @ 04/15/24 06:26:31.266
  STEP: getting /apis/networking.k8s.io @ 04/15/24 06:26:31.277
  STEP: getting /apis/networking.k8s.iov1 @ 04/15/24 06:26:31.282
  STEP: creating @ 04/15/24 06:26:31.287
  STEP: getting @ 04/15/24 06:26:31.353
  STEP: listing @ 04/15/24 06:26:31.362
  STEP: watching @ 04/15/24 06:26:31.368
  Apr 15 06:26:31.368: INFO: starting watch
  STEP: patching @ 04/15/24 06:26:31.37
  STEP: updating @ 04/15/24 06:26:31.382
  Apr 15 06:26:31.393: INFO: waiting for watch events with expected annotations
  Apr 15 06:26:31.393: INFO: saw patched and updated annotations
  STEP: deleting @ 04/15/24 06:26:31.394
  STEP: deleting a collection @ 04/15/24 06:26:31.422
  Apr 15 06:26:31.469: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-6447" for this suite. @ 04/15/24 06:26:31.486
â€¢ [0.295 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:243
  STEP: Creating a kubernetes client @ 04/15/24 06:26:31.505
  Apr 15 06:26:31.505: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename namespaces @ 04/15/24 06:26:31.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:26:31.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:26:31.551
  STEP: Creating a test namespace @ 04/15/24 06:26:31.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:26:31.593
  STEP: Creating a pod in the namespace @ 04/15/24 06:26:31.606
  STEP: Waiting for the pod to have running status @ 04/15/24 06:26:31.634
  E0415 06:26:31.843468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:32.843680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 04/15/24 06:26:33.657
  STEP: Waiting for the namespace to be removed. @ 04/15/24 06:26:33.673
  E0415 06:26:33.845136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:34.845630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:35.846172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:36.846407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:37.846854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:38.847800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:39.848390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:40.849416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:41.850432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:42.851007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:43.851610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 04/15/24 06:26:44.681
  STEP: Verifying there are no pods in the namespace @ 04/15/24 06:26:44.717
  Apr 15 06:26:44.723: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2161" for this suite. @ 04/15/24 06:26:44.733
  STEP: Destroying namespace "nsdeletetest-2569" for this suite. @ 04/15/24 06:26:44.746
  Apr 15 06:26:44.752: INFO: Namespace nsdeletetest-2569 was already deleted
  STEP: Destroying namespace "nsdeletetest-2788" for this suite. @ 04/15/24 06:26:44.753
â€¢ [13.272 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 04/15/24 06:26:44.78
  Apr 15 06:26:44.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:26:44.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:26:44.822
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:26:44.829
  STEP: Creating configMap with name projected-configmap-test-volume-2101db98-d555-4446-a958-ca47a6d2fa56 @ 04/15/24 06:26:44.835
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:26:44.844
  E0415 06:26:44.852101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:45.852634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:46.853286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:47.854186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:48.856248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:26:48.9
  Apr 15 06:26:48.906: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-configmaps-03f8107c-0cbd-482d-96b3-93248405b5cd container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 06:26:48.923
  Apr 15 06:26:48.950: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7938" for this suite. @ 04/15/24 06:26:48.961
â€¢ [4.196 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 04/15/24 06:26:48.982
  Apr 15 06:26:48.982: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 06:26:48.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:26:49.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:26:49.026
  STEP: creating a Pod with a static label @ 04/15/24 06:26:49.053
  STEP: watching for Pod to be ready @ 04/15/24 06:26:49.077
  Apr 15 06:26:49.082: INFO: observed Pod pod-test in namespace pods-8016 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Apr 15 06:26:49.082: INFO: observed Pod pod-test in namespace pods-8016 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:26:49 +0000 UTC  }]
  Apr 15 06:26:49.124: INFO: observed Pod pod-test in namespace pods-8016 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:26:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:26:49 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:26:49 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:26:49 +0000 UTC  }]
  E0415 06:26:49.855590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:26:50.300: INFO: Found Pod pod-test in namespace pods-8016 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:26:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:26:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:26:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:26:49 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 04/15/24 06:26:50.317
  STEP: getting the Pod and ensuring that it's patched @ 04/15/24 06:26:50.349
  STEP: replacing the Pod's status Ready condition to False @ 04/15/24 06:26:50.356
  STEP: check the Pod again to ensure its Ready conditions are False @ 04/15/24 06:26:50.379
  STEP: deleting the Pod via a Collection with a LabelSelector @ 04/15/24 06:26:50.379
  STEP: watching for the Pod to be deleted @ 04/15/24 06:26:50.4
  Apr 15 06:26:50.402: INFO: observed event type MODIFIED
  E0415 06:26:50.855762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:51.855774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:26:52.314: INFO: observed event type MODIFIED
  Apr 15 06:26:52.493: INFO: observed event type MODIFIED
  E0415 06:26:52.856693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:26:53.325: INFO: observed event type MODIFIED
  Apr 15 06:26:53.353: INFO: observed event type MODIFIED
  Apr 15 06:26:53.368: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8016" for this suite. @ 04/15/24 06:26:53.382
â€¢ [4.419 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 04/15/24 06:26:53.407
  Apr 15 06:26:53.407: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename var-expansion @ 04/15/24 06:26:53.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:26:53.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:26:53.468
  STEP: creating the pod @ 04/15/24 06:26:53.48
  STEP: waiting for pod running @ 04/15/24 06:26:53.503
  E0415 06:26:53.857778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:54.858366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 04/15/24 06:26:55.526
  Apr 15 06:26:55.532: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4918 PodName:var-expansion-b4eb2abc-1009-4c7e-a011-70ca37ec4098 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:26:55.533: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:26:55.535: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:26:55.536: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-4918/pods/var-expansion-b4eb2abc-1009-4c7e-a011-70ca37ec4098/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 04/15/24 06:26:55.676
  Apr 15 06:26:55.685: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4918 PodName:var-expansion-b4eb2abc-1009-4c7e-a011-70ca37ec4098 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:26:55.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:26:55.688: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:26:55.689: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-4918/pods/var-expansion-b4eb2abc-1009-4c7e-a011-70ca37ec4098/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 04/15/24 06:26:55.804
  E0415 06:26:55.858574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:26:56.330: INFO: Successfully updated pod "var-expansion-b4eb2abc-1009-4c7e-a011-70ca37ec4098"
  STEP: waiting for annotated pod running @ 04/15/24 06:26:56.33
  STEP: deleting the pod gracefully @ 04/15/24 06:26:56.341
  Apr 15 06:26:56.341: INFO: Deleting pod "var-expansion-b4eb2abc-1009-4c7e-a011-70ca37ec4098" in namespace "var-expansion-4918"
  Apr 15 06:26:56.354: INFO: Wait up to 5m0s for pod "var-expansion-b4eb2abc-1009-4c7e-a011-70ca37ec4098" to be fully deleted
  E0415 06:26:56.858667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:57.859580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:58.860527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:26:59.860791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:00.861287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:01.861994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:02.862360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:03.862542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:04.863526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:05.863661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:06.863963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:07.864202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:08.865165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:09.866329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:10.866672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:11.866992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:12.867967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:13.868962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:14.869627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:15.870759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:16.871711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:17.872014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:18.872622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:19.873787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:20.874718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:21.875462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:22.876507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:23.876660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:24.877776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:25.878743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:26.879495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:27.881423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:28.881211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:29.882178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:27:30.544: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4918" for this suite. @ 04/15/24 06:27:30.557
â€¢ [37.167 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]
test/e2e/common/node/podtemplates.go:53
  STEP: Creating a kubernetes client @ 04/15/24 06:27:30.58
  Apr 15 06:27:30.580: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename podtemplate @ 04/15/24 06:27:30.584
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:27:30.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:27:30.653
  Apr 15 06:27:30.724: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-6792" for this suite. @ 04/15/24 06:27:30.733
â€¢ [0.169 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 04/15/24 06:27:30.75
  Apr 15 06:27:30.750: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:27:30.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:27:30.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:27:30.796
  STEP: Creating the pod @ 04/15/24 06:27:30.803
  E0415 06:27:30.882843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:31.883041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:32.883179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:27:33.390: INFO: Successfully updated pod "labelsupdate44744492-f0e3-494c-9f0d-5fce7f156002"
  E0415 06:27:33.883364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:34.883910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:27:35.452: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4283" for this suite. @ 04/15/24 06:27:35.469
â€¢ [4.743 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 04/15/24 06:27:35.505
  Apr 15 06:27:35.505: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 06:27:35.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:27:35.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:27:35.571
  E0415 06:27:35.885487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:36.884834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:37.885073      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:38.885774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:39.886770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:40.887553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:41.888074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:42.888461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:43.888592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:44.889068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:45.889494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:46.889933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:47.890345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:48.890599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:49.891712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:50.892793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:51.893549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:52.894434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:53.895321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:54.895557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:55.895774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:56.896588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:57.897660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:58.898671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:27:59.899234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:00.900395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:01.900752      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:02.900493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:03.901272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:04.902051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:05.902405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:06.902494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:07.902758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:08.902927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:09.904113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:10.904799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:11.904710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:12.905007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:13.905852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:14.906126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:15.906565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:16.907887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:17.908897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:18.909654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:19.909833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:20.910202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:21.911046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:22.911270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:23.911432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:24.912049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:25.912579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:26.912726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:27.912919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:28.913103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:29.913903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:30.914025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:31.915247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:32.915709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:33.916002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:34.916797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:28:35.643: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7786" for this suite. @ 04/15/24 06:28:35.666
â€¢ [60.187 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:207
  STEP: Creating a kubernetes client @ 04/15/24 06:28:35.695
  Apr 15 06:28:35.695: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:28:35.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:28:35.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:28:35.767
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/15/24 06:28:35.778
  E0415 06:28:35.917246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:36.917500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:37.917620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:38.917777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:28:39.839
  Apr 15 06:28:39.849: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-6c720ec5-3da1-462e-a7ef-a6046e3fb9aa container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:28:39.868
  Apr 15 06:28:39.906: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:28:39.918357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "emptydir-4210" for this suite. @ 04/15/24 06:28:39.921
â€¢ [4.244 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:107
  STEP: Creating a kubernetes client @ 04/15/24 06:28:39.941
  Apr 15 06:28:39.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pod-network-test @ 04/15/24 06:28:39.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:28:39.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:28:39.991
  STEP: Performing setup for networking test in namespace pod-network-test-9028 @ 04/15/24 06:28:39.998
  STEP: creating a selector @ 04/15/24 06:28:39.999
  STEP: Creating the service pods in kubernetes @ 04/15/24 06:28:39.999
  Apr 15 06:28:39.999: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0415 06:28:40.919667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:41.919177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:42.919885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:43.920431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:44.921514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:45.922480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:46.922277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:47.922775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:48.923006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:49.924048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:50.924578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:51.924640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/15/24 06:28:52.242
  E0415 06:28:52.925395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:53.925577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:28:54.339: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 15 06:28:54.340: INFO: Going to poll 10.233.64.82 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 15 06:28:54.349: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.82:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9028 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:28:54.349: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:28:54.351: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:28:54.352: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9028/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.82%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 15 06:28:54.568: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 15 06:28:54.568: INFO: Going to poll 10.233.65.105 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 15 06:28:54.577: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.105:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9028 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:28:54.577: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:28:54.579: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:28:54.579: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9028/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.105%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 15 06:28:54.700: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 15 06:28:54.700: INFO: Going to poll 10.233.66.251 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Apr 15 06:28:54.708: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.251:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9028 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:28:54.708: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:28:54.710: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:28:54.710: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9028/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.251%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 15 06:28:54.841: INFO: Found all 1 expected endpoints: [netserver-2]
  Apr 15 06:28:54.841: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9028" for this suite. @ 04/15/24 06:28:54.852
â€¢ [14.927 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 04/15/24 06:28:54.876
  Apr 15 06:28:54.877: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/15/24 06:28:54.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:28:54.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:28:54.924
  E0415 06:28:54.925275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set up a multi version CRD @ 04/15/24 06:28:54.932
  Apr 15 06:28:54.934: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:28:55.926252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:56.927642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:57.927155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:28:58.927074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 04/15/24 06:28:59.891
  STEP: check the new version name is served @ 04/15/24 06:28:59.924
  E0415 06:28:59.927498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:00.933890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 04/15/24 06:29:01.756
  E0415 06:29:01.928755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/15/24 06:29:02.68
  E0415 06:29:02.928970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:03.929249      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:04.929690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:05.930778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:29:06.323: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8818" for this suite. @ 04/15/24 06:29:06.345
â€¢ [11.483 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 04/15/24 06:29:06.361
  Apr 15 06:29:06.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubelet-test @ 04/15/24 06:29:06.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:29:06.401
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:29:06.405
  STEP: Waiting for pod completion @ 04/15/24 06:29:06.432
  E0415 06:29:06.930687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:07.931391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:08.931266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:09.931400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:29:10.518: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5029" for this suite. @ 04/15/24 06:29:10.53
â€¢ [4.188 seconds]
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 04/15/24 06:29:10.55
  Apr 15 06:29:10.551: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename watch @ 04/15/24 06:29:10.555
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:29:10.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:29:10.594
  STEP: creating a new configmap @ 04/15/24 06:29:10.599
  STEP: modifying the configmap once @ 04/15/24 06:29:10.61
  STEP: modifying the configmap a second time @ 04/15/24 06:29:10.63
  STEP: deleting the configmap @ 04/15/24 06:29:10.649
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 04/15/24 06:29:10.672
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 04/15/24 06:29:10.676
  Apr 15 06:29:10.677: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3566  e45d6d0e-4597-4581-8057-efd2757b1ed0 147714 0 2024-04-15 06:29:10 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-15 06:29:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 06:29:10.678: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3566  e45d6d0e-4597-4581-8057-efd2757b1ed0 147715 0 2024-04-15 06:29:10 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-15 06:29:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 06:29:10.680: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3566" for this suite. @ 04/15/24 06:29:10.692
â€¢ [0.155 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 04/15/24 06:29:10.714
  Apr 15 06:29:10.714: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:29:10.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:29:10.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:29:10.754
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:29:10.759
  E0415 06:29:10.931980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:11.932080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:12.933274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:13.933503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:29:14.837
  Apr 15 06:29:14.844: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-b9ace9b0-3c2b-4815-8f92-40d80c9746f5 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:29:14.869
  Apr 15 06:29:14.906: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8690" for this suite. @ 04/15/24 06:29:14.92
  E0415 06:29:14.934218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [4.226 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance]
test/e2e/apps/replica_set.go:154
  STEP: Creating a kubernetes client @ 04/15/24 06:29:14.941
  Apr 15 06:29:14.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replicaset @ 04/15/24 06:29:14.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:29:14.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:29:14.99
  Apr 15 06:29:15.037: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0415 06:29:15.935652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:16.936404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:17.936576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:18.936881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:19.937929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:29:20.053: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/15/24 06:29:20.053
  STEP: Scaling up "test-rs" replicaset  @ 04/15/24 06:29:20.054
  Apr 15 06:29:20.090: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 04/15/24 06:29:20.091
  Apr 15 06:29:20.150: INFO: observed ReplicaSet test-rs in namespace replicaset-9985 with ReadyReplicas 1, AvailableReplicas 1
  Apr 15 06:29:20.246: INFO: observed ReplicaSet test-rs in namespace replicaset-9985 with ReadyReplicas 1, AvailableReplicas 1
  Apr 15 06:29:20.289: INFO: observed ReplicaSet test-rs in namespace replicaset-9985 with ReadyReplicas 1, AvailableReplicas 1
  Apr 15 06:29:20.316: INFO: observed ReplicaSet test-rs in namespace replicaset-9985 with ReadyReplicas 1, AvailableReplicas 1
  E0415 06:29:20.938563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:29:21.526: INFO: observed ReplicaSet test-rs in namespace replicaset-9985 with ReadyReplicas 2, AvailableReplicas 2
  E0415 06:29:21.940417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:29:22.646: INFO: observed Replicaset test-rs in namespace replicaset-9985 with ReadyReplicas 3 found true
  Apr 15 06:29:22.646: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9985" for this suite. @ 04/15/24 06:29:22.665
â€¢ [7.738 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 04/15/24 06:29:22.687
  Apr 15 06:29:22.687: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename cronjob @ 04/15/24 06:29:22.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:29:22.726
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:29:22.731
  STEP: Creating a suspended cronjob @ 04/15/24 06:29:22.735
  STEP: Ensuring no jobs are scheduled @ 04/15/24 06:29:22.75
  E0415 06:29:22.939163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:23.939697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:24.940392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:25.941024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:26.942032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:27.942392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:28.942779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:29.943636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:30.944318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:31.944763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:32.944921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:33.946100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:34.946569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:35.947500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:36.948094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:37.948808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:38.950629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:39.950998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:40.951773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:41.952491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:42.952782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:43.952930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:44.953584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:45.954007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:46.954185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:47.954662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:48.954731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:49.955664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:50.956422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:51.956590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:52.957472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:53.958358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:54.958501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:55.958926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:56.959725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:57.959942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:58.961119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:29:59.961801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:00.962297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:01.962478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:02.963330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:03.963545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:04.964011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:05.964395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:06.965122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:07.965732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:08.965793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:09.966809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:10.967793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:11.972953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:12.973662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:13.973336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:14.974243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:15.974425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:16.976853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:17.975605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:18.976269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:19.976981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:20.977208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:21.977423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:22.977595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:23.978655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:24.978911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:25.979589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:26.980750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:27.981290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:28.981430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:29.982753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:30.982693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:31.983458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:32.984621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:33.984932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:34.985333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:35.986113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:36.986681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:37.986750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:38.987535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:39.987747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:40.988205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:41.989117      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:42.990583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:43.990421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:44.990912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:45.990977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:46.991969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:47.992423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:48.993513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:49.993952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:50.994574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:51.994634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:52.994897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:53.995298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:54.997149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:55.997327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:56.997470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:57.998231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:58.998313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:30:59.999412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:00.999876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:02.000610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:03.001851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:04.001851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:05.001716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:06.002070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:07.002901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:08.003051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:09.004041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:10.005015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:11.005890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:12.006342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:13.006453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:14.007076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:15.008702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:16.009099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:17.009741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:18.010295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:19.010993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:20.011977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:21.012367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:22.013089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:23.013625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:24.014164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:25.014199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:26.015099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:27.015686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:28.015754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:29.016756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:30.016910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:31.017272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:32.017444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:33.017644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:34.017886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:35.018572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:36.018897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:37.019548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:38.019799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:39.020012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:40.020937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:41.021576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:42.021680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:43.022928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:44.023253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:45.023179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:46.024216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:47.024717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:48.025263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:49.026268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:50.027536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:51.028613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:52.028560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:53.029982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:54.030090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:55.030588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:56.031357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:57.032461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:58.032522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:31:59.033512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:00.036496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:01.037286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:02.037465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:03.038346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:04.043264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:05.039112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:06.039241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:07.039259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:08.040062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:09.040098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:10.041274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:11.042214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:12.042413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:13.043571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:14.043789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:15.044308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:16.044606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:17.045144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:18.045447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:19.046157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:20.047274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:21.047518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:22.047686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:23.048618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:24.048853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:25.049308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:26.049568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:27.050388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:28.051056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:29.051662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:30.051858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:31.052392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:32.052733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:33.053353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:34.053974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:35.055011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:36.055098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:37.055166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:38.055989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:39.056475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:40.057052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:41.057191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:42.057943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:43.058128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:44.059127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:45.059373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:46.060384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:47.060898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:48.061695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:49.062607      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:50.063810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:51.064785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:52.065079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:53.065959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:54.066209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:55.066883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:56.067863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:57.068012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:58.068470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:32:59.068947      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:00.069173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:01.070157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:02.070503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:03.070960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:04.071006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:05.071798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:06.072010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:07.076547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:08.072564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:09.073414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:10.073643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:11.074484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:12.074750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:13.075787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:14.076056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:15.077012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:16.077084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:17.078028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:18.078631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:19.079299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:20.079011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:21.079949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:22.080990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:23.081293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:24.081691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:25.083060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:26.083325      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:27.083736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:28.084714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:29.085517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:30.085672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:31.087104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:32.087336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:33.088107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:34.088641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:35.088998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:36.090049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:37.090332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:38.090560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:39.091267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:40.092625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:41.092796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:42.093037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:43.094175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:44.094420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:45.095409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:46.096291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:47.100136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:48.097361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:49.097367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:50.098394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:51.099262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:52.099410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:53.100241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:54.100774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:55.101179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:56.101614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:57.102172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:58.102814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:33:59.102789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:00.103155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:01.103996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:02.104429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:03.105604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:04.105664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:05.106452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:06.106487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:07.106729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:08.106834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:09.107054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:10.107236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:11.108430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:12.108922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:13.108983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:14.109239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:15.110125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:16.110428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:17.110694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:18.110948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:19.111220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:20.112243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:21.113212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:22.113938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 04/15/24 06:34:22.772
  STEP: Removing cronjob @ 04/15/24 06:34:22.784
  Apr 15 06:34:22.803: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6303" for this suite. @ 04/15/24 06:34:22.829
â€¢ [300.162 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 04/15/24 06:34:22.865
  Apr 15 06:34:22.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:34:22.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:34:22.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:34:22.916
  STEP: Setting up server cert @ 04/15/24 06:34:22.974
  E0415 06:34:23.114813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:34:23.831
  STEP: Deploying the webhook pod @ 04/15/24 06:34:23.854
  STEP: Wait for the deployment to be ready @ 04/15/24 06:34:23.887
  Apr 15 06:34:23.919: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 06:34:24.115544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:25.115759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 06:34:25.945
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:34:25.976
  E0415 06:34:26.116227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:34:26.977: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 04/15/24 06:34:26.993
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 04/15/24 06:34:26.996
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 04/15/24 06:34:26.997
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 04/15/24 06:34:26.997
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 04/15/24 06:34:26.999
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/15/24 06:34:27
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/15/24 06:34:27.002
  Apr 15 06:34:27.003: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:34:27.117179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-1836" for this suite. @ 04/15/24 06:34:27.128
  STEP: Destroying namespace "webhook-markers-1726" for this suite. @ 04/15/24 06:34:27.15
â€¢ [4.309 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
test/e2e/kubectl/kubectl.go:1481
  STEP: Creating a kubernetes client @ 04/15/24 06:34:27.179
  Apr 15 06:34:27.179: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:34:27.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:34:27.263
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:34:27.274
  STEP: creating Agnhost RC @ 04/15/24 06:34:27.285
  Apr 15 06:34:27.285: INFO: namespace kubectl-1994
  Apr 15 06:34:27.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1994 create -f -'
  E0415 06:34:28.117644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:34:28.182: INFO: stderr: ""
  Apr 15 06:34:28.182: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/15/24 06:34:28.182
  E0415 06:34:29.118010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:34:29.192: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 15 06:34:29.192: INFO: Found 0 / 1
  E0415 06:34:30.119080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:34:30.196: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 15 06:34:30.197: INFO: Found 1 / 1
  Apr 15 06:34:30.197: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 15 06:34:30.214: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 15 06:34:30.214: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 15 06:34:30.214: INFO: wait on agnhost-primary startup in kubectl-1994 
  Apr 15 06:34:30.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1994 logs agnhost-primary-zcvtx agnhost-primary'
  Apr 15 06:34:30.422: INFO: stderr: ""
  Apr 15 06:34:30.422: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 04/15/24 06:34:30.422
  Apr 15 06:34:30.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1994 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Apr 15 06:34:30.627: INFO: stderr: ""
  Apr 15 06:34:30.627: INFO: stdout: "service/rm2 exposed\n"
  Apr 15 06:34:30.646: INFO: Service rm2 in namespace kubectl-1994 found.
  E0415 06:34:31.119867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:32.119992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 04/15/24 06:34:32.669
  Apr 15 06:34:32.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1994 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Apr 15 06:34:32.929: INFO: stderr: ""
  Apr 15 06:34:32.929: INFO: stdout: "service/rm3 exposed\n"
  Apr 15 06:34:32.945: INFO: Service rm3 in namespace kubectl-1994 found.
  E0415 06:34:33.121176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:34.122796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:34:34.960: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1994" for this suite. @ 04/15/24 06:34:34.97
â€¢ [7.810 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 04/15/24 06:34:34.991
  Apr 15 06:34:34.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename var-expansion @ 04/15/24 06:34:34.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:34:35.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:34:35.03
  STEP: Creating a pod to test substitution in container's command @ 04/15/24 06:34:35.036
  E0415 06:34:35.123145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:36.123973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:37.124260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:38.124460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:39.124559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:34:39.13
  Apr 15 06:34:39.138: INFO: Trying to get logs from node phiefi7ighaa-3 pod var-expansion-80a24590-dce0-47e9-ad40-40606d791a2d container dapi-container: <nil>
  STEP: delete the pod @ 04/15/24 06:34:39.169
  Apr 15 06:34:39.207: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1652" for this suite. @ 04/15/24 06:34:39.222
â€¢ [4.252 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
test/e2e/apps/job.go:513
  STEP: Creating a kubernetes client @ 04/15/24 06:34:39.255
  Apr 15 06:34:39.255: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename job @ 04/15/24 06:34:39.26
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:34:39.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:34:39.346
  STEP: Creating a job @ 04/15/24 06:34:39.354
  STEP: Ensuring active pods == parallelism @ 04/15/24 06:34:39.377
  E0415 06:34:40.124616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:41.124832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:42.125478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:43.126539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 04/15/24 06:34:43.384
  Apr 15 06:34:43.917: INFO: Successfully updated pod "adopt-release-k58k6"
  STEP: Checking that the Job readopts the Pod @ 04/15/24 06:34:43.917
  E0415 06:34:44.126889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:45.126959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 04/15/24 06:34:45.959
  E0415 06:34:46.127332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:34:46.488: INFO: Successfully updated pod "adopt-release-k58k6"
  STEP: Checking that the Job releases the Pod @ 04/15/24 06:34:46.489
  E0415 06:34:47.128435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:48.128522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:34:48.514: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6571" for this suite. @ 04/15/24 06:34:48.547
â€¢ [9.307 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:135
  STEP: Creating a kubernetes client @ 04/15/24 06:34:48.566
  Apr 15 06:34:48.566: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/15/24 06:34:48.57
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:34:48.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:34:48.613
  STEP: create the container to handle the HTTPGet hook request. @ 04/15/24 06:34:48.628
  E0415 06:34:49.129166      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:50.129748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/15/24 06:34:50.676
  E0415 06:34:51.130360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:52.130827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/15/24 06:34:52.736
  STEP: delete the pod with lifecycle hook @ 04/15/24 06:34:52.782
  E0415 06:34:53.130821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:54.131796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:34:54.837: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9436" for this suite. @ 04/15/24 06:34:54.849
â€¢ [6.298 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 04/15/24 06:34:54.888
  Apr 15 06:34:54.888: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 06:34:54.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:34:54.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:34:54.931
  STEP: Creating secret with name secret-test-map-071ff8d9-2467-4876-a350-ac04f8f1fd45 @ 04/15/24 06:34:54.941
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:34:54.959
  E0415 06:34:55.132368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:56.137209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:57.134795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:34:58.134934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:34:59.028
  Apr 15 06:34:59.046: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-secrets-4af907c7-69fe-47e8-b8df-97ad23e0ca51 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:34:59.07
  Apr 15 06:34:59.123: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:34:59.138783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "secrets-4231" for this suite. @ 04/15/24 06:34:59.148
â€¢ [4.279 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]
test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 04/15/24 06:34:59.182
  Apr 15 06:34:59.182: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename daemonsets @ 04/15/24 06:34:59.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:34:59.237
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:34:59.246
  STEP: Creating simple DaemonSet "daemon-set" @ 04/15/24 06:34:59.395
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/15/24 06:34:59.415
  Apr 15 06:34:59.445: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:34:59.446: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:35:00.137777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:35:00.469: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:35:00.469: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:35:01.138646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:35:01.474: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 15 06:35:01.474: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 04/15/24 06:35:01.481
  Apr 15 06:35:01.493: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 04/15/24 06:35:01.493
  Apr 15 06:35:01.519: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 04/15/24 06:35:01.521
  Apr 15 06:35:01.530: INFO: Observed &DaemonSet event: ADDED
  Apr 15 06:35:01.531: INFO: Observed &DaemonSet event: MODIFIED
  Apr 15 06:35:01.531: INFO: Observed &DaemonSet event: MODIFIED
  Apr 15 06:35:01.531: INFO: Observed &DaemonSet event: MODIFIED
  Apr 15 06:35:01.532: INFO: Observed &DaemonSet event: MODIFIED
  Apr 15 06:35:01.532: INFO: Found daemon set daemon-set in namespace daemonsets-1836 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 15 06:35:01.533: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 04/15/24 06:35:01.534
  STEP: watching for the daemon set status to be patched @ 04/15/24 06:35:01.555
  Apr 15 06:35:01.563: INFO: Observed &DaemonSet event: ADDED
  Apr 15 06:35:01.564: INFO: Observed &DaemonSet event: MODIFIED
  Apr 15 06:35:01.564: INFO: Observed &DaemonSet event: MODIFIED
  Apr 15 06:35:01.564: INFO: Observed &DaemonSet event: MODIFIED
  Apr 15 06:35:01.565: INFO: Observed &DaemonSet event: MODIFIED
  Apr 15 06:35:01.566: INFO: Observed daemon set daemon-set in namespace daemonsets-1836 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 15 06:35:01.567: INFO: Observed &DaemonSet event: MODIFIED
  Apr 15 06:35:01.567: INFO: Found daemon set daemon-set in namespace daemonsets-1836 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Apr 15 06:35:01.567: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 04/15/24 06:35:01.574
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1836, will wait for the garbage collector to delete the pods @ 04/15/24 06:35:01.575
  Apr 15 06:35:01.663: INFO: Deleting DaemonSet.extensions daemon-set took: 29.599384ms
  Apr 15 06:35:01.764: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.770467ms
  E0415 06:35:02.139317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:03.139938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:35:03.373: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:35:03.373: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 15 06:35:03.379: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"148766"},"items":null}

  Apr 15 06:35:03.386: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"148766"},"items":null}

  Apr 15 06:35:03.421: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1836" for this suite. @ 04/15/24 06:35:03.434
â€¢ [4.267 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 04/15/24 06:35:03.454
  Apr 15 06:35:03.454: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename endpointslicemirroring @ 04/15/24 06:35:03.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:35:03.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:35:03.495
  STEP: mirroring a new custom Endpoint @ 04/15/24 06:35:03.528
  Apr 15 06:35:03.562: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0415 06:35:04.140227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:05.141128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 04/15/24 06:35:05.573
  Apr 15 06:35:05.593: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0415 06:35:06.140883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:07.141041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 04/15/24 06:35:07.615
  Apr 15 06:35:07.637: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0415 06:35:08.141364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:09.141435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:35:09.647: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-7925" for this suite. @ 04/15/24 06:35:09.657
â€¢ [6.220 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 04/15/24 06:35:09.678
  Apr 15 06:35:09.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-watch @ 04/15/24 06:35:09.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:35:09.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:35:09.718
  Apr 15 06:35:09.722: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:35:10.142839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:11.143033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:12.143561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 04/15/24 06:35:12.467
  Apr 15 06:35:12.511: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-15T06:35:12Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-15T06:35:12Z]] name:name1 resourceVersion:148835 uid:94116b46-93d6-472d-a8a8-e7cec2650d40] num:map[num1:9223372036854775807 num2:1000000]]}
  E0415 06:35:13.143619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:14.143974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:15.144481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:16.145013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:17.144980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:18.145371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:19.145699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:20.145823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:21.145972      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:22.146824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 04/15/24 06:35:22.511
  Apr 15 06:35:22.533: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-15T06:35:22Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-15T06:35:22Z]] name:name2 resourceVersion:148859 uid:ef7a1f67-dd2b-4533-a598-efa775e610ce] num:map[num1:9223372036854775807 num2:1000000]]}
  E0415 06:35:23.147220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:24.147213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:25.147732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:26.148217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:27.148406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:28.149102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:29.149206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:30.150203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:31.150491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:32.151005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 04/15/24 06:35:32.533
  Apr 15 06:35:32.557: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-15T06:35:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-15T06:35:32Z]] name:name1 resourceVersion:148893 uid:94116b46-93d6-472d-a8a8-e7cec2650d40] num:map[num1:9223372036854775807 num2:1000000]]}
  E0415 06:35:33.152048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:34.152373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:35.153152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:36.153570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:37.153714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:38.155080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:39.155546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:40.156438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:41.157118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:42.157893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 04/15/24 06:35:42.558
  Apr 15 06:35:42.573: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-15T06:35:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-15T06:35:42Z]] name:name2 resourceVersion:148911 uid:ef7a1f67-dd2b-4533-a598-efa775e610ce] num:map[num1:9223372036854775807 num2:1000000]]}
  E0415 06:35:43.158226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:44.159493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:45.160040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:46.160277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:47.160503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:48.160753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:49.161432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:50.161552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:51.162538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:52.162561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 04/15/24 06:35:52.574
  Apr 15 06:35:52.606: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-15T06:35:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-15T06:35:32Z]] name:name1 resourceVersion:148929 uid:94116b46-93d6-472d-a8a8-e7cec2650d40] num:map[num1:9223372036854775807 num2:1000000]]}
  E0415 06:35:53.163097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:54.163592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:55.164225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:56.164740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:57.164726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:58.165426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:35:59.166181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:00.166067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:01.167021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:02.167344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 04/15/24 06:36:02.607
  Apr 15 06:36:02.629: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-15T06:35:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-15T06:35:42Z]] name:name2 resourceVersion:148947 uid:ef7a1f67-dd2b-4533-a598-efa775e610ce] num:map[num1:9223372036854775807 num2:1000000]]}
  E0415 06:36:03.167392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:04.167886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:05.168032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:06.168635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:07.169261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:08.169866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:09.170473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:10.171509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:11.172368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:12.172381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:13.173543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:13.181: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-5679" for this suite. @ 04/15/24 06:36:13.193
â€¢ [63.529 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 04/15/24 06:36:13.208
  Apr 15 06:36:13.208: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:36:13.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:36:13.243
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:36:13.25
  STEP: Setting up server cert @ 04/15/24 06:36:13.309
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:36:13.767
  STEP: Deploying the webhook pod @ 04/15/24 06:36:13.785
  STEP: Wait for the deployment to be ready @ 04/15/24 06:36:13.818
  Apr 15 06:36:13.837: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 06:36:14.174707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:15.175481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 06:36:15.859
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:36:15.882
  E0415 06:36:16.175785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:16.883: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 15 06:36:16.903: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:36:17.176550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 04/15/24 06:36:17.443
  STEP: Creating a custom resource that should be denied by the webhook @ 04/15/24 06:36:17.491
  E0415 06:36:18.176989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:19.177163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 04/15/24 06:36:19.634
  STEP: Updating the custom resource with disallowed data should be denied @ 04/15/24 06:36:19.65
  STEP: Deleting the custom resource should be denied @ 04/15/24 06:36:19.676
  STEP: Remove the offending key and value from the custom resource data @ 04/15/24 06:36:19.697
  STEP: Deleting the updated custom resource should be successful @ 04/15/24 06:36:19.722
  Apr 15 06:36:19.742: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:36:20.177688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-4615" for this suite. @ 04/15/24 06:36:20.435
  STEP: Destroying namespace "webhook-markers-4506" for this suite. @ 04/15/24 06:36:20.448
â€¢ [7.254 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
test/e2e/apimachinery/garbage_collector.go:638
  STEP: Creating a kubernetes client @ 04/15/24 06:36:20.463
  Apr 15 06:36:20.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename gc @ 04/15/24 06:36:20.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:36:20.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:36:20.501
  STEP: create the rc @ 04/15/24 06:36:20.518
  W0415 06:36:20.530014      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0415 06:36:21.177902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:22.178682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:23.178370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:24.178465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:25.178754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:26.178917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/15/24 06:36:26.608
  STEP: wait for the rc to be deleted @ 04/15/24 06:36:26.791
  E0415 06:36:27.180035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:28.180245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:28.482: INFO: 81 pods remaining
  Apr 15 06:36:28.482: INFO: 80 pods has nil DeletionTimestamp
  Apr 15 06:36:28.482: INFO: 
  Apr 15 06:36:29.032: INFO: 73 pods remaining
  Apr 15 06:36:29.032: INFO: 70 pods has nil DeletionTimestamp
  Apr 15 06:36:29.033: INFO: 
  E0415 06:36:29.180381      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:30.121: INFO: 56 pods remaining
  Apr 15 06:36:30.122: INFO: 51 pods has nil DeletionTimestamp
  Apr 15 06:36:30.122: INFO: 
  E0415 06:36:30.180554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:31.069: INFO: 50 pods remaining
  Apr 15 06:36:31.081: INFO: 49 pods has nil DeletionTimestamp
  Apr 15 06:36:31.096: INFO: 
  E0415 06:36:31.181281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:32.066: INFO: 30 pods remaining
  Apr 15 06:36:32.067: INFO: 30 pods has nil DeletionTimestamp
  Apr 15 06:36:32.067: INFO: 
  E0415 06:36:32.181532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:33.021: INFO: 16 pods remaining
  Apr 15 06:36:33.021: INFO: 12 pods has nil DeletionTimestamp
  Apr 15 06:36:33.022: INFO: 
  E0415 06:36:33.182233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:33.973: INFO: 0 pods remaining
  Apr 15 06:36:33.974: INFO: 0 pods has nil DeletionTimestamp
  Apr 15 06:36:33.974: INFO: 
  E0415 06:36:34.182451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/15/24 06:36:34.849
  E0415 06:36:35.183044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:35.657: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 15 06:36:35.657: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5035" for this suite. @ 04/15/24 06:36:35.674
â€¢ [15.234 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:168
  STEP: Creating a kubernetes client @ 04/15/24 06:36:35.704
  Apr 15 06:36:35.704: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/15/24 06:36:35.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:36:35.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:36:35.758
  STEP: create the container to handle the HTTPGet hook request. @ 04/15/24 06:36:35.787
  E0415 06:36:36.183362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:37.183580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:38.184794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:39.184950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:40.187719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:41.187815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:42.188384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:43.188639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/15/24 06:36:44.016
  E0415 06:36:44.188639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:45.189769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/15/24 06:36:46.095
  STEP: delete the pod with lifecycle hook @ 04/15/24 06:36:46.134
  E0415 06:36:46.190178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:47.190289      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:48.191199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:48.294: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-9869" for this suite. @ 04/15/24 06:36:48.309
â€¢ [12.660 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 04/15/24 06:36:48.366
  Apr 15 06:36:48.367: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:36:48.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:36:48.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:36:48.457
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:36:48.463
  E0415 06:36:49.191740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:50.191920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:51.191930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:52.198076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:36:52.56
  Apr 15 06:36:52.569: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-6cdd1094-f97f-4d8c-817b-1d597223a38f container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:36:52.598
  Apr 15 06:36:52.645: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8411" for this suite. @ 04/15/24 06:36:52.668
â€¢ [4.321 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]
test/e2e/apimachinery/resource_quota.go:1013
  STEP: Creating a kubernetes client @ 04/15/24 06:36:52.695
  Apr 15 06:36:52.695: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 06:36:52.701
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:36:52.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:36:52.732
  STEP: Creating resourceQuota "e2e-rq-status-zlld8" @ 04/15/24 06:36:52.75
  Apr 15 06:36:52.777: INFO: Resource quota "e2e-rq-status-zlld8" reports spec: hard cpu limit of 500m
  Apr 15 06:36:52.778: INFO: Resource quota "e2e-rq-status-zlld8" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-zlld8" /status @ 04/15/24 06:36:52.778
  STEP: Confirm /status for "e2e-rq-status-zlld8" resourceQuota via watch @ 04/15/24 06:36:52.806
  Apr 15 06:36:52.810: INFO: observed resourceQuota "e2e-rq-status-zlld8" in namespace "resourcequota-4653" with hard status: v1.ResourceList(nil)
  Apr 15 06:36:52.810: INFO: Found resourceQuota "e2e-rq-status-zlld8" in namespace "resourcequota-4653" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 15 06:36:52.811: INFO: ResourceQuota "e2e-rq-status-zlld8" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 04/15/24 06:36:52.817
  Apr 15 06:36:52.836: INFO: Resource quota "e2e-rq-status-zlld8" reports spec: hard cpu limit of 1
  Apr 15 06:36:52.836: INFO: Resource quota "e2e-rq-status-zlld8" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-zlld8" /status @ 04/15/24 06:36:52.836
  STEP: Confirm /status for "e2e-rq-status-zlld8" resourceQuota via watch @ 04/15/24 06:36:52.855
  Apr 15 06:36:52.857: INFO: observed resourceQuota "e2e-rq-status-zlld8" in namespace "resourcequota-4653" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 15 06:36:52.858: INFO: Found resourceQuota "e2e-rq-status-zlld8" in namespace "resourcequota-4653" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Apr 15 06:36:52.858: INFO: ResourceQuota "e2e-rq-status-zlld8" /status was patched
  STEP: Get "e2e-rq-status-zlld8" /status @ 04/15/24 06:36:52.858
  Apr 15 06:36:52.872: INFO: Resourcequota "e2e-rq-status-zlld8" reports status: hard cpu of 1
  Apr 15 06:36:52.872: INFO: Resourcequota "e2e-rq-status-zlld8" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-zlld8" /status before checking Spec is unchanged @ 04/15/24 06:36:52.882
  Apr 15 06:36:52.904: INFO: Resourcequota "e2e-rq-status-zlld8" reports status: hard cpu of 2
  Apr 15 06:36:52.904: INFO: Resourcequota "e2e-rq-status-zlld8" reports status: hard memory of 2Gi
  Apr 15 06:36:52.911: INFO: Found resourceQuota "e2e-rq-status-zlld8" in namespace "resourcequota-4653" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  E0415 06:36:53.194938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:54.195251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:55.195801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:56.196344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:36:57.197125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:36:57.954: INFO: ResourceQuota "e2e-rq-status-zlld8" Spec was unchanged and /status reset
  Apr 15 06:36:57.955: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4653" for this suite. @ 04/15/24 06:36:57.976
â€¢ [5.308 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 04/15/24 06:36:58.02
  Apr 15 06:36:58.021: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename subjectreview @ 04/15/24 06:36:58.024
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:36:58.068
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:36:58.112
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-2763" @ 04/15/24 06:36:58.123
  Apr 15 06:36:58.142: INFO: saUsername: "system:serviceaccount:subjectreview-2763:e2e"
  Apr 15 06:36:58.143: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-2763"}
  Apr 15 06:36:58.143: INFO: saUID: "caf12e94-6dc2-48fa-85ff-d5a9d6e6660a"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-2763:e2e" @ 04/15/24 06:36:58.143
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-2763:e2e" @ 04/15/24 06:36:58.145
  Apr 15 06:36:58.151: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-2763:e2e" api 'list' configmaps in "subjectreview-2763" namespace @ 04/15/24 06:36:58.151
  Apr 15 06:36:58.174: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-2763:e2e" @ 04/15/24 06:36:58.174
  Apr 15 06:36:58.195: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Apr 15 06:36:58.196: INFO: LocalSubjectAccessReview has been verified
  Apr 15 06:36:58.196: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:36:58.196937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "subjectreview-2763" for this suite. @ 04/15/24 06:36:58.208
â€¢ [0.204 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 04/15/24 06:36:58.233
  Apr 15 06:36:58.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename field-validation @ 04/15/24 06:36:58.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:36:58.294
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:36:58.303
  STEP: apply creating a deployment @ 04/15/24 06:36:58.309
  Apr 15 06:36:58.313: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9994" for this suite. @ 04/15/24 06:36:58.38
â€¢ [0.164 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 04/15/24 06:36:58.407
  Apr 15 06:36:58.407: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 06:36:58.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:36:58.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:36:58.454
  STEP: creating pod @ 04/15/24 06:36:58.464
  E0415 06:36:59.198170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:00.199026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:00.524: INFO: Pod pod-hostip-a5077741-9c9a-4486-a4fe-0fddad26bdd2 has hostIP: 192.168.121.206
  Apr 15 06:37:00.525: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1189" for this suite. @ 04/15/24 06:37:00.535
â€¢ [2.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 04/15/24 06:37:00.565
  Apr 15 06:37:00.565: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:37:00.568
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:37:00.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:37:00.619
  STEP: Setting up server cert @ 04/15/24 06:37:00.698
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:37:01.216
  E0415 06:37:01.216711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook pod @ 04/15/24 06:37:01.243
  STEP: Wait for the deployment to be ready @ 04/15/24 06:37:01.274
  Apr 15 06:37:01.310: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 06:37:02.216852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:03.217931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 06:37:03.37
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:37:03.401
  E0415 06:37:04.218966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:04.401: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/15/24 06:37:04.419
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/15/24 06:37:04.469
  STEP: Creating a dummy validating-webhook-configuration object @ 04/15/24 06:37:04.498
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 04/15/24 06:37:04.518
  STEP: Creating a dummy mutating-webhook-configuration object @ 04/15/24 06:37:04.535
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 04/15/24 06:37:04.551
  Apr 15 06:37:04.566: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9417" for this suite. @ 04/15/24 06:37:04.726
  STEP: Destroying namespace "webhook-markers-2566" for this suite. @ 04/15/24 06:37:04.743
â€¢ [4.193 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]
test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 04/15/24 06:37:04.766
  Apr 15 06:37:04.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/15/24 06:37:04.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:37:04.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:37:04.807
  STEP: creating @ 04/15/24 06:37:04.814
  STEP: getting @ 04/15/24 06:37:04.859
  STEP: listing in namespace @ 04/15/24 06:37:04.869
  STEP: patching @ 04/15/24 06:37:04.879
  STEP: deleting @ 04/15/24 06:37:04.895
  Apr 15 06:37:04.914: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-685" for this suite. @ 04/15/24 06:37:04.924
â€¢ [0.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 04/15/24 06:37:04.944
  Apr 15 06:37:04.944: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:37:04.946
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:37:04.974
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:37:04.982
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:37:04.987
  E0415 06:37:05.219102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:06.219133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:07.220279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:08.220472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:37:09.043
  Apr 15 06:37:09.050: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-d8ebbb80-d4c6-4949-afef-1b88459d9798 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:37:09.065
  Apr 15 06:37:09.119: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4015" for this suite. @ 04/15/24 06:37:09.132
â€¢ [4.205 seconds]
------------------------------
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 04/15/24 06:37:09.149
  Apr 15 06:37:09.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-runtime @ 04/15/24 06:37:09.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:37:09.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:37:09.184
  STEP: create the container @ 04/15/24 06:37:09.189
  W0415 06:37:09.203047      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/15/24 06:37:09.203
  E0415 06:37:09.221307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:10.222133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:11.222387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/15/24 06:37:11.236
  STEP: the container should be terminated @ 04/15/24 06:37:11.248
  STEP: the termination message should be set @ 04/15/24 06:37:11.249
  Apr 15 06:37:11.250: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 04/15/24 06:37:11.251
  Apr 15 06:37:11.283: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-8541" for this suite. @ 04/15/24 06:37:11.302
â€¢ [2.167 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:177
  STEP: Creating a kubernetes client @ 04/15/24 06:37:11.317
  Apr 15 06:37:11.317: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:37:11.322
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:37:11.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:37:11.373
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/15/24 06:37:11.377
  E0415 06:37:12.222572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:13.222662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:14.223513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:15.223746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:37:15.42
  Apr 15 06:37:15.426: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-aff76dce-61ca-4dce-b10f-309f5d4432da container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:37:15.445
  Apr 15 06:37:15.483: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1086" for this suite. @ 04/15/24 06:37:15.495
â€¢ [4.204 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 04/15/24 06:37:15.524
  Apr 15 06:37:15.525: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename dns @ 04/15/24 06:37:15.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:37:15.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:37:15.564
  STEP: Creating a test headless service @ 04/15/24 06:37:15.57
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1356 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1356;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1356 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1356;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1356.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1356.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1356.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1356.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1356.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1356.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1356.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1356.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1356.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1356.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1356.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1356.svc;check="$$(dig +notcp +noall +answer +search 209.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.209_udp@PTR;check="$$(dig +tcp +noall +answer +search 209.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.209_tcp@PTR;sleep 1; done
   @ 04/15/24 06:37:15.627
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1356 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1356;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1356 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1356;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1356.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1356.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1356.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1356.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1356.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1356.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1356.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1356.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1356.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1356.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1356.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1356.svc;check="$$(dig +notcp +noall +answer +search 209.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.209_udp@PTR;check="$$(dig +tcp +noall +answer +search 209.7.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.7.209_tcp@PTR;sleep 1; done
   @ 04/15/24 06:37:15.627
  STEP: creating a pod to probe DNS @ 04/15/24 06:37:15.628
  STEP: submitting the pod to kubernetes @ 04/15/24 06:37:15.628
  E0415 06:37:16.225500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:17.225010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/15/24 06:37:17.688
  STEP: looking for the results for each expected name from probers @ 04/15/24 06:37:17.698
  Apr 15 06:37:17.711: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.719: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.729: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.737: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.744: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.754: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.826: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.836: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.848: INFO: Unable to read jessie_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.858: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.868: INFO: Unable to read jessie_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.881: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:17.935: INFO: Lookups using dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1356 wheezy_tcp@dns-test-service.dns-1356 wheezy_udp@dns-test-service.dns-1356.svc wheezy_tcp@dns-test-service.dns-1356.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1356 jessie_tcp@dns-test-service.dns-1356 jessie_udp@dns-test-service.dns-1356.svc jessie_tcp@dns-test-service.dns-1356.svc]

  Apr 15 06:37:17.949: INFO: Pod client logs for webserver: 
  Apr 15 06:37:17.962: INFO: Pod client logs for querier: 
  Apr 15 06:37:17.980: INFO: Pod client logs for jessie-querier: 
  E0415 06:37:18.226507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:19.226757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:20.226480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:21.226759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:22.226934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:22.993: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.001: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.009: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.017: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.028: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.041: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.104: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.118: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.127: INFO: Unable to read jessie_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.135: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.145: INFO: Unable to read jessie_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.152: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:23.199: INFO: Lookups using dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1356 wheezy_tcp@dns-test-service.dns-1356 wheezy_udp@dns-test-service.dns-1356.svc wheezy_tcp@dns-test-service.dns-1356.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1356 jessie_tcp@dns-test-service.dns-1356 jessie_udp@dns-test-service.dns-1356.svc jessie_tcp@dns-test-service.dns-1356.svc]

  Apr 15 06:37:23.223: INFO: Pod client logs for webserver: 
  E0415 06:37:23.228293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:23.240: INFO: Pod client logs for querier: 
  Apr 15 06:37:23.255: INFO: Pod client logs for jessie-querier: 
  E0415 06:37:24.228375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:25.228651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:26.229269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:27.229188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:27.997: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.007: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.015: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.026: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.036: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.047: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.144: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.162: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.214: INFO: Unable to read jessie_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  E0415 06:37:28.229798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:28.230: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.236: INFO: Unable to read jessie_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.254: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:28.298: INFO: Lookups using dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1356 wheezy_tcp@dns-test-service.dns-1356 wheezy_udp@dns-test-service.dns-1356.svc wheezy_tcp@dns-test-service.dns-1356.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1356 jessie_tcp@dns-test-service.dns-1356 jessie_udp@dns-test-service.dns-1356.svc jessie_tcp@dns-test-service.dns-1356.svc]

  Apr 15 06:37:28.310: INFO: Pod client logs for webserver: 
  Apr 15 06:37:28.322: INFO: Pod client logs for querier: 
  Apr 15 06:37:28.335: INFO: Pod client logs for jessie-querier: 
  E0415 06:37:29.230055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:30.231729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:31.232368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:32.232796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:32.994: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.008: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.021: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.027: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.035: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.048: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.172: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.181: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.194: INFO: Unable to read jessie_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.202: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.216: INFO: Unable to read jessie_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:33.228: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  E0415 06:37:33.233729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:33.280: INFO: Lookups using dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1356 wheezy_tcp@dns-test-service.dns-1356 wheezy_udp@dns-test-service.dns-1356.svc wheezy_tcp@dns-test-service.dns-1356.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1356 jessie_tcp@dns-test-service.dns-1356 jessie_udp@dns-test-service.dns-1356.svc jessie_tcp@dns-test-service.dns-1356.svc]

  Apr 15 06:37:33.291: INFO: Pod client logs for webserver: 
  Apr 15 06:37:33.306: INFO: Pod client logs for querier: 
  Apr 15 06:37:33.322: INFO: Pod client logs for jessie-querier: 
  E0415 06:37:34.234011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:35.235211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:36.235353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:37.235931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:37.996: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.011: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.029: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.043: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.055: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.066: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.164: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.177: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.185: INFO: Unable to read jessie_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.194: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.208: INFO: Unable to read jessie_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:38.219: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  E0415 06:37:38.236761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:38.277: INFO: Lookups using dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1356 wheezy_tcp@dns-test-service.dns-1356 wheezy_udp@dns-test-service.dns-1356.svc wheezy_tcp@dns-test-service.dns-1356.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1356 jessie_tcp@dns-test-service.dns-1356 jessie_udp@dns-test-service.dns-1356.svc jessie_tcp@dns-test-service.dns-1356.svc]

  Apr 15 06:37:38.297: INFO: Pod client logs for webserver: 
  Apr 15 06:37:38.312: INFO: Pod client logs for querier: 
  Apr 15 06:37:38.328: INFO: Pod client logs for jessie-querier: 
  E0415 06:37:39.237597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:40.237569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:41.238602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:42.240268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:42.992: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.003: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.013: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.024: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.032: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.040: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.116: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.124: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.136: INFO: Unable to read jessie_udp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.158: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356 from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.185: INFO: Unable to read jessie_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:43.204: INFO: Unable to read jessie_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  E0415 06:37:43.239999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:43.276: INFO: Lookups using dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1356 wheezy_tcp@dns-test-service.dns-1356 wheezy_udp@dns-test-service.dns-1356.svc wheezy_tcp@dns-test-service.dns-1356.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1356 jessie_tcp@dns-test-service.dns-1356 jessie_udp@dns-test-service.dns-1356.svc jessie_tcp@dns-test-service.dns-1356.svc]

  Apr 15 06:37:43.290: INFO: Pod client logs for webserver: 
  Apr 15 06:37:43.304: INFO: Pod client logs for querier: 
  Apr 15 06:37:43.352: INFO: Pod client logs for jessie-querier: 
  E0415 06:37:44.239907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:45.240284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:46.240865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:47.241463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:48.031: INFO: Unable to read wheezy_udp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  Apr 15 06:37:48.044: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1356.svc from pod dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6: the server could not find the requested resource (get pods dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6)
  E0415 06:37:48.242408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:48.300: INFO: Lookups using dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6 failed for: [wheezy_udp@dns-test-service.dns-1356.svc wheezy_tcp@dns-test-service.dns-1356.svc]

  Apr 15 06:37:48.319: INFO: Pod client logs for webserver: 
  Apr 15 06:37:48.340: INFO: Pod client logs for querier: 
  Apr 15 06:37:48.356: INFO: Pod client logs for jessie-querier: 
  E0415 06:37:49.242842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:50.245198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:51.244493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:52.244735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:37:53.245682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:53.256: INFO: DNS probes using dns-1356/dns-test-aff18e80-f833-4045-9287-edbb2cb3eae6 succeeded

  Apr 15 06:37:53.257: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 06:37:53.273
  STEP: deleting the test service @ 04/15/24 06:37:53.326
  STEP: deleting the test headless service @ 04/15/24 06:37:53.469
  STEP: Destroying namespace "dns-1356" for this suite. @ 04/15/24 06:37:53.531
â€¢ [38.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 04/15/24 06:37:53.557
  Apr 15 06:37:53.557: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename deployment @ 04/15/24 06:37:53.563
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:37:53.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:37:53.617
  STEP: creating a Deployment @ 04/15/24 06:37:53.633
  STEP: waiting for Deployment to be created @ 04/15/24 06:37:53.669
  STEP: waiting for all Replicas to be Ready @ 04/15/24 06:37:53.678
  Apr 15 06:37:53.690: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 15 06:37:53.690: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 15 06:37:53.697: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 15 06:37:53.697: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 15 06:37:53.747: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 15 06:37:53.747: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 15 06:37:53.858: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 15 06:37:53.858: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0415 06:37:54.247724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:54.853: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 15 06:37:54.853: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  E0415 06:37:55.249914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:55.331: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 04/15/24 06:37:55.331
  Apr 15 06:37:55.375: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 04/15/24 06:37:55.376
  Apr 15 06:37:55.380: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0
  Apr 15 06:37:55.380: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 0
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:55.381: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:55.415: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:55.416: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:55.464: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:55.464: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:55.507: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  Apr 15 06:37:55.507: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  Apr 15 06:37:55.534: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  Apr 15 06:37:55.534: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  E0415 06:37:56.248641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:56.351: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:56.351: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:56.462: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  STEP: listing Deployments @ 04/15/24 06:37:56.463
  Apr 15 06:37:56.473: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 04/15/24 06:37:56.474
  Apr 15 06:37:56.534: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 04/15/24 06:37:56.535
  Apr 15 06:37:56.564: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 15 06:37:56.589: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 15 06:37:56.831: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 15 06:37:56.937: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0415 06:37:57.249108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:57.969: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0415 06:37:58.250478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:58.387: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 15 06:37:58.492: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 15 06:37:58.546: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0415 06:37:59.250666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:37:59.807: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 04/15/24 06:37:59.908
  STEP: fetching the DeploymentStatus @ 04/15/24 06:37:59.933
  Apr 15 06:37:59.954: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  Apr 15 06:37:59.954: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  Apr 15 06:37:59.954: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  Apr 15 06:37:59.955: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 1
  Apr 15 06:37:59.956: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:59.956: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 3
  Apr 15 06:37:59.957: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:59.958: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 2
  Apr 15 06:37:59.958: INFO: observed Deployment test-deployment in namespace deployment-1864 with ReadyReplicas 3
  STEP: deleting the Deployment @ 04/15/24 06:37:59.959
  Apr 15 06:38:00.014: INFO: observed event type MODIFIED
  Apr 15 06:38:00.015: INFO: observed event type MODIFIED
  Apr 15 06:38:00.015: INFO: observed event type MODIFIED
  Apr 15 06:38:00.015: INFO: observed event type MODIFIED
  Apr 15 06:38:00.015: INFO: observed event type MODIFIED
  Apr 15 06:38:00.017: INFO: observed event type MODIFIED
  Apr 15 06:38:00.017: INFO: observed event type MODIFIED
  Apr 15 06:38:00.017: INFO: observed event type MODIFIED
  Apr 15 06:38:00.018: INFO: observed event type MODIFIED
  Apr 15 06:38:00.018: INFO: observed event type MODIFIED
  Apr 15 06:38:00.018: INFO: observed event type MODIFIED
  Apr 15 06:38:00.018: INFO: observed event type MODIFIED
  Apr 15 06:38:00.047: INFO: Log out all the ReplicaSets if there is no deployment created
  Apr 15 06:38:00.073: INFO: ReplicaSet "test-deployment-64fd565c98":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-64fd565c98",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1864",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2d687ba8-1590-45f3-bde4-829b4b837ad0",
      ResourceVersion: (string) (len=6) "150852",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848759875,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "45899bad-5feb-461f-a602-82257c5752ae",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848759879,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 34 35 38 39  39 62 61 64 2d 35 66 65  |":\"45899bad-5fe|
              00000130  62 2d 34 36 31 66 2d 61  36 30 32 2d 38 32 32 35  |b-461f-a602-8225|
              00000140  37 63 35 37 35 32 61 65  5c 22 7d 22 3a 7b 7d 7d  |7c5752ae\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848759879,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=25) "registry.k8s.io/pause:3.9",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Apr 15 06:38:00.129: INFO: pod: "test-deployment-64fd565c98-wl4l9":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-64fd565c98-wl4l9",
      GenerateName: (string) (len=27) "test-deployment-64fd565c98-",
      Namespace: (string) (len=15) "deployment-1864",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "224af22a-e2c8-4794-b951-8f1304a9b320",
      ResourceVersion: (string) (len=6) "150845",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848759876,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848759881,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-64fd565c98",
          UID: (types.UID) (len=36) "2d687ba8-1590-45f3-bde4-829b4b837ad0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848759876,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  32 64 36 38 37 62 61 38  |uid\":\"2d687ba8|
              000000a0  2d 31 35 39 30 2d 34 35  66 33 2d 62 64 65 34 2d  |-1590-45f3-bde4-|
              000000b0  38 32 39 62 34 62 38 33  37 61 64 30 5c 22 7d 22  |829b4b837ad0\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848759877,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  35 2e 31 34 33 5c 22 7d  |10.233.65.143\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lht75",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lht75",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848759876,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848759877,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848759877,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848759876,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.65.143",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.143"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848759876,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848759877,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=72) "cri-o://2ed57e8efdd1c37f1e346d22b273cf6b1e19435396dab8d96021233f7ae4f9ee",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Apr 15 06:38:00.144: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1864" for this suite. @ 04/15/24 06:38:00.178
  E0415 06:38:00.251058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [6.711 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 04/15/24 06:38:00.276
  Apr 15 06:38:00.276: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:38:00.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:38:00.363
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:38:00.371
  STEP: Setting up server cert @ 04/15/24 06:38:00.469
  E0415 06:38:01.251293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:38:01.945
  STEP: Deploying the webhook pod @ 04/15/24 06:38:01.973
  STEP: Wait for the deployment to be ready @ 04/15/24 06:38:02
  Apr 15 06:38:02.024: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 06:38:02.252218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:03.252626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 06:38:04.046
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:38:04.077
  E0415 06:38:04.252669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:05.077: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 04/15/24 06:38:05.127
  STEP: Creating a custom resource definition that should be denied by the webhook @ 04/15/24 06:38:05.171
  Apr 15 06:38:05.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:38:05.205: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:38:05.253919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-531" for this suite. @ 04/15/24 06:38:05.368
  STEP: Destroying namespace "webhook-markers-1363" for this suite. @ 04/15/24 06:38:05.393
â€¢ [5.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 04/15/24 06:38:05.415
  Apr 15 06:38:05.415: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 06:38:05.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:38:05.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:38:05.466
  STEP: creating the pod @ 04/15/24 06:38:05.474
  STEP: submitting the pod to kubernetes @ 04/15/24 06:38:05.475
  STEP: verifying QOS class is set on the pod @ 04/15/24 06:38:05.501
  Apr 15 06:38:05.514: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1392" for this suite. @ 04/15/24 06:38:05.533
â€¢ [0.145 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
test/e2e/apimachinery/garbage_collector.go:379
  STEP: Creating a kubernetes client @ 04/15/24 06:38:05.573
  Apr 15 06:38:05.573: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename gc @ 04/15/24 06:38:05.576
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:38:05.621
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:38:05.633
  STEP: create the rc @ 04/15/24 06:38:05.659
  W0415 06:38:05.674620      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0415 06:38:06.253958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:07.257529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:08.256427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:09.314839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:10.285241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:11.285710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/15/24 06:38:11.701
  STEP: wait for the rc to be deleted @ 04/15/24 06:38:12.094
  E0415 06:38:12.286301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:13.287040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:14.287814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:15.288863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:16.289332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 04/15/24 06:38:17.137
  E0415 06:38:17.289855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:18.290976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:19.291368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:20.292066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:21.293030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:22.294015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:23.294444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:24.294803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:25.295052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:26.295560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:27.295842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:28.296356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:29.296445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:30.297250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:31.298100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:32.298254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:33.298487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:34.298857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:35.300000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:36.300263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:37.301180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:38.302689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:39.302460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:40.308558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:41.308850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:42.310441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:43.310088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:44.310271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:45.310580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:46.310952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/15/24 06:38:47.221
  E0415 06:38:47.320882      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:47.619: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 15 06:38:47.619: INFO: Deleting pod "simpletest.rc-25qxc" in namespace "gc-3807"
  Apr 15 06:38:47.678: INFO: Deleting pod "simpletest.rc-44vpn" in namespace "gc-3807"
  Apr 15 06:38:47.718: INFO: Deleting pod "simpletest.rc-47kgd" in namespace "gc-3807"
  Apr 15 06:38:47.780: INFO: Deleting pod "simpletest.rc-47zxg" in namespace "gc-3807"
  Apr 15 06:38:47.834: INFO: Deleting pod "simpletest.rc-48n7d" in namespace "gc-3807"
  Apr 15 06:38:47.886: INFO: Deleting pod "simpletest.rc-4d5jh" in namespace "gc-3807"
  Apr 15 06:38:47.955: INFO: Deleting pod "simpletest.rc-4lzl2" in namespace "gc-3807"
  Apr 15 06:38:47.997: INFO: Deleting pod "simpletest.rc-56962" in namespace "gc-3807"
  Apr 15 06:38:48.085: INFO: Deleting pod "simpletest.rc-59qsw" in namespace "gc-3807"
  Apr 15 06:38:48.149: INFO: Deleting pod "simpletest.rc-5bkpf" in namespace "gc-3807"
  E0415 06:38:48.321389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:48.333: INFO: Deleting pod "simpletest.rc-5d8z8" in namespace "gc-3807"
  Apr 15 06:38:48.421: INFO: Deleting pod "simpletest.rc-5ds2v" in namespace "gc-3807"
  Apr 15 06:38:48.472: INFO: Deleting pod "simpletest.rc-5hzvg" in namespace "gc-3807"
  Apr 15 06:38:48.525: INFO: Deleting pod "simpletest.rc-5klw9" in namespace "gc-3807"
  Apr 15 06:38:48.574: INFO: Deleting pod "simpletest.rc-5x9ts" in namespace "gc-3807"
  Apr 15 06:38:48.638: INFO: Deleting pod "simpletest.rc-6jmgc" in namespace "gc-3807"
  Apr 15 06:38:48.769: INFO: Deleting pod "simpletest.rc-6sbnw" in namespace "gc-3807"
  Apr 15 06:38:48.830: INFO: Deleting pod "simpletest.rc-7pwl7" in namespace "gc-3807"
  Apr 15 06:38:48.912: INFO: Deleting pod "simpletest.rc-7sl9h" in namespace "gc-3807"
  Apr 15 06:38:49.051: INFO: Deleting pod "simpletest.rc-88mx8" in namespace "gc-3807"
  E0415 06:38:49.321606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:49.372: INFO: Deleting pod "simpletest.rc-8cx5j" in namespace "gc-3807"
  Apr 15 06:38:49.419: INFO: Deleting pod "simpletest.rc-8h78n" in namespace "gc-3807"
  Apr 15 06:38:49.461: INFO: Deleting pod "simpletest.rc-8vwch" in namespace "gc-3807"
  Apr 15 06:38:49.551: INFO: Deleting pod "simpletest.rc-9pvm5" in namespace "gc-3807"
  Apr 15 06:38:49.649: INFO: Deleting pod "simpletest.rc-9xg58" in namespace "gc-3807"
  Apr 15 06:38:49.777: INFO: Deleting pod "simpletest.rc-bgcdg" in namespace "gc-3807"
  Apr 15 06:38:49.841: INFO: Deleting pod "simpletest.rc-dd8t4" in namespace "gc-3807"
  Apr 15 06:38:49.906: INFO: Deleting pod "simpletest.rc-f58m4" in namespace "gc-3807"
  Apr 15 06:38:50.042: INFO: Deleting pod "simpletest.rc-ffl8g" in namespace "gc-3807"
  Apr 15 06:38:50.101: INFO: Deleting pod "simpletest.rc-fnkmn" in namespace "gc-3807"
  Apr 15 06:38:50.151: INFO: Deleting pod "simpletest.rc-ghv4s" in namespace "gc-3807"
  Apr 15 06:38:50.204: INFO: Deleting pod "simpletest.rc-gpp6q" in namespace "gc-3807"
  Apr 15 06:38:50.254: INFO: Deleting pod "simpletest.rc-gxqjb" in namespace "gc-3807"
  Apr 15 06:38:50.287: INFO: Deleting pod "simpletest.rc-h4sl6" in namespace "gc-3807"
  E0415 06:38:50.322866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:50.382: INFO: Deleting pod "simpletest.rc-h6m5c" in namespace "gc-3807"
  Apr 15 06:38:50.446: INFO: Deleting pod "simpletest.rc-hgt4w" in namespace "gc-3807"
  Apr 15 06:38:50.536: INFO: Deleting pod "simpletest.rc-hs66x" in namespace "gc-3807"
  Apr 15 06:38:50.648: INFO: Deleting pod "simpletest.rc-hzwjx" in namespace "gc-3807"
  Apr 15 06:38:50.792: INFO: Deleting pod "simpletest.rc-j4f7k" in namespace "gc-3807"
  Apr 15 06:38:50.881: INFO: Deleting pod "simpletest.rc-j5s48" in namespace "gc-3807"
  Apr 15 06:38:50.947: INFO: Deleting pod "simpletest.rc-j9ktp" in namespace "gc-3807"
  Apr 15 06:38:50.991: INFO: Deleting pod "simpletest.rc-jbhdr" in namespace "gc-3807"
  Apr 15 06:38:51.173: INFO: Deleting pod "simpletest.rc-jg7hp" in namespace "gc-3807"
  Apr 15 06:38:51.244: INFO: Deleting pod "simpletest.rc-jgx22" in namespace "gc-3807"
  E0415 06:38:51.323735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:51.356: INFO: Deleting pod "simpletest.rc-jnb2r" in namespace "gc-3807"
  Apr 15 06:38:51.415: INFO: Deleting pod "simpletest.rc-jpwwd" in namespace "gc-3807"
  Apr 15 06:38:51.582: INFO: Deleting pod "simpletest.rc-jzg68" in namespace "gc-3807"
  Apr 15 06:38:51.664: INFO: Deleting pod "simpletest.rc-k6hh7" in namespace "gc-3807"
  Apr 15 06:38:51.796: INFO: Deleting pod "simpletest.rc-k7tb6" in namespace "gc-3807"
  Apr 15 06:38:51.912: INFO: Deleting pod "simpletest.rc-kftjt" in namespace "gc-3807"
  Apr 15 06:38:51.966: INFO: Deleting pod "simpletest.rc-ktbj4" in namespace "gc-3807"
  Apr 15 06:38:52.043: INFO: Deleting pod "simpletest.rc-l6t99" in namespace "gc-3807"
  Apr 15 06:38:52.107: INFO: Deleting pod "simpletest.rc-lcm5x" in namespace "gc-3807"
  Apr 15 06:38:52.150: INFO: Deleting pod "simpletest.rc-lk8kw" in namespace "gc-3807"
  Apr 15 06:38:52.263: INFO: Deleting pod "simpletest.rc-lq28v" in namespace "gc-3807"
  E0415 06:38:52.324443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:52.338: INFO: Deleting pod "simpletest.rc-lsj2s" in namespace "gc-3807"
  Apr 15 06:38:52.399: INFO: Deleting pod "simpletest.rc-mcnrk" in namespace "gc-3807"
  Apr 15 06:38:52.455: INFO: Deleting pod "simpletest.rc-mgjcb" in namespace "gc-3807"
  Apr 15 06:38:52.537: INFO: Deleting pod "simpletest.rc-mmfn7" in namespace "gc-3807"
  Apr 15 06:38:52.601: INFO: Deleting pod "simpletest.rc-mwhdb" in namespace "gc-3807"
  Apr 15 06:38:52.703: INFO: Deleting pod "simpletest.rc-mwv66" in namespace "gc-3807"
  Apr 15 06:38:52.813: INFO: Deleting pod "simpletest.rc-mz9hf" in namespace "gc-3807"
  Apr 15 06:38:52.964: INFO: Deleting pod "simpletest.rc-n5jh6" in namespace "gc-3807"
  Apr 15 06:38:53.005: INFO: Deleting pod "simpletest.rc-nw85f" in namespace "gc-3807"
  Apr 15 06:38:53.205: INFO: Deleting pod "simpletest.rc-p4tsb" in namespace "gc-3807"
  Apr 15 06:38:53.300: INFO: Deleting pod "simpletest.rc-p7klt" in namespace "gc-3807"
  E0415 06:38:53.325138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:53.514: INFO: Deleting pod "simpletest.rc-q5rp7" in namespace "gc-3807"
  Apr 15 06:38:53.590: INFO: Deleting pod "simpletest.rc-qkjtp" in namespace "gc-3807"
  Apr 15 06:38:53.752: INFO: Deleting pod "simpletest.rc-qsh6h" in namespace "gc-3807"
  Apr 15 06:38:53.858: INFO: Deleting pod "simpletest.rc-qtn27" in namespace "gc-3807"
  Apr 15 06:38:53.938: INFO: Deleting pod "simpletest.rc-qxz9v" in namespace "gc-3807"
  Apr 15 06:38:54.009: INFO: Deleting pod "simpletest.rc-r59kk" in namespace "gc-3807"
  Apr 15 06:38:54.201: INFO: Deleting pod "simpletest.rc-r5jj2" in namespace "gc-3807"
  Apr 15 06:38:54.287: INFO: Deleting pod "simpletest.rc-r9rhx" in namespace "gc-3807"
  E0415 06:38:54.325193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:54.418: INFO: Deleting pod "simpletest.rc-rbs6p" in namespace "gc-3807"
  Apr 15 06:38:54.513: INFO: Deleting pod "simpletest.rc-s8s8z" in namespace "gc-3807"
  Apr 15 06:38:54.641: INFO: Deleting pod "simpletest.rc-srtj8" in namespace "gc-3807"
  Apr 15 06:38:54.715: INFO: Deleting pod "simpletest.rc-svpxv" in namespace "gc-3807"
  Apr 15 06:38:54.859: INFO: Deleting pod "simpletest.rc-tcj7q" in namespace "gc-3807"
  Apr 15 06:38:54.966: INFO: Deleting pod "simpletest.rc-tlw62" in namespace "gc-3807"
  Apr 15 06:38:54.994: INFO: Deleting pod "simpletest.rc-tmtnh" in namespace "gc-3807"
  Apr 15 06:38:55.054: INFO: Deleting pod "simpletest.rc-ttsfh" in namespace "gc-3807"
  Apr 15 06:38:55.285: INFO: Deleting pod "simpletest.rc-v2fqv" in namespace "gc-3807"
  E0415 06:38:55.325865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:55.531: INFO: Deleting pod "simpletest.rc-vbcvd" in namespace "gc-3807"
  Apr 15 06:38:55.708: INFO: Deleting pod "simpletest.rc-vdc4n" in namespace "gc-3807"
  Apr 15 06:38:55.858: INFO: Deleting pod "simpletest.rc-vkvqj" in namespace "gc-3807"
  Apr 15 06:38:55.984: INFO: Deleting pod "simpletest.rc-wljsn" in namespace "gc-3807"
  Apr 15 06:38:56.050: INFO: Deleting pod "simpletest.rc-wr6n5" in namespace "gc-3807"
  Apr 15 06:38:56.102: INFO: Deleting pod "simpletest.rc-wv2t2" in namespace "gc-3807"
  Apr 15 06:38:56.217: INFO: Deleting pod "simpletest.rc-wwb5q" in namespace "gc-3807"
  Apr 15 06:38:56.275: INFO: Deleting pod "simpletest.rc-wz489" in namespace "gc-3807"
  Apr 15 06:38:56.308: INFO: Deleting pod "simpletest.rc-x5sj7" in namespace "gc-3807"
  E0415 06:38:56.326832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:38:56.361: INFO: Deleting pod "simpletest.rc-xr2gm" in namespace "gc-3807"
  Apr 15 06:38:56.435: INFO: Deleting pod "simpletest.rc-xs426" in namespace "gc-3807"
  Apr 15 06:38:56.487: INFO: Deleting pod "simpletest.rc-zgght" in namespace "gc-3807"
  Apr 15 06:38:56.551: INFO: Deleting pod "simpletest.rc-zk7vb" in namespace "gc-3807"
  Apr 15 06:38:56.667: INFO: Deleting pod "simpletest.rc-zvf8c" in namespace "gc-3807"
  Apr 15 06:38:56.790: INFO: Deleting pod "simpletest.rc-zw5gp" in namespace "gc-3807"
  Apr 15 06:38:56.885: INFO: Deleting pod "simpletest.rc-zxjbx" in namespace "gc-3807"
  Apr 15 06:38:56.955: INFO: Deleting pod "simpletest.rc-zzcq8" in namespace "gc-3807"
  Apr 15 06:38:57.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3807" for this suite. @ 04/15/24 06:38:57.134
â€¢ [51.660 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 04/15/24 06:38:57.237
  Apr 15 06:38:57.237: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename events @ 04/15/24 06:38:57.251
  E0415 06:38:57.327317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:38:57.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:38:57.366
  STEP: Create set of events @ 04/15/24 06:38:57.373
  STEP: get a list of Events with a label in the current namespace @ 04/15/24 06:38:57.437
  STEP: delete a list of events @ 04/15/24 06:38:57.448
  Apr 15 06:38:57.448: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/15/24 06:38:57.591
  Apr 15 06:38:57.618: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-5916" for this suite. @ 04/15/24 06:38:57.63
â€¢ [0.442 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 04/15/24 06:38:57.682
  Apr 15 06:38:57.682: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:38:57.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:38:57.788
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:38:57.795
  STEP: Creating configMap with name cm-test-opt-del-6dd0a021-2d34-4133-af7c-1960eaa908f9 @ 04/15/24 06:38:57.824
  STEP: Creating configMap with name cm-test-opt-upd-69c403cc-282f-4c4f-8d3d-4e4f21d5e5bb @ 04/15/24 06:38:57.845
  STEP: Creating the pod @ 04/15/24 06:38:57.883
  E0415 06:38:58.328306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:38:59.329754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-6dd0a021-2d34-4133-af7c-1960eaa908f9 @ 04/15/24 06:39:00.039
  STEP: Updating configmap cm-test-opt-upd-69c403cc-282f-4c4f-8d3d-4e4f21d5e5bb @ 04/15/24 06:39:00.054
  STEP: Creating configMap with name cm-test-opt-create-6d9a41aa-0e05-4d34-8d04-59c3b04b7c08 @ 04/15/24 06:39:00.075
  STEP: waiting to observe update in volume @ 04/15/24 06:39:00.084
  E0415 06:39:00.329413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:01.330153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:02.331053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:03.331729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:04.331802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:05.331839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:06.332006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:07.332713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:08.333193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:09.333971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:10.335080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:11.335545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:12.336389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:13.336370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:14.336716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:15.337275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:16.337843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:17.338618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:18.339666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:19.339384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:20.339444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:21.339984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:22.340449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:23.341188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:24.341384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:25.341558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:26.342382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:27.342795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:28.342980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:29.343737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:30.344670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:31.346102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:32.345584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:33.345663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:34.345985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:35.346097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:36.346278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:37.346624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:38.346789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:39.346971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:40.348099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:41.349229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:42.350069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:43.350196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:44.350348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:45.350769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:46.351892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:47.351690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:48.351861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:49.352868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:50.353649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:51.353901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:52.354167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:53.354537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:54.354860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:55.355480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:56.355520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:57.355811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:58.356120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:39:59.356350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:00.357363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:01.358042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:02.358430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:03.358520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:04.358842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:05.359970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:06.360050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:07.360804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:08.360608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:09.361650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:10.361679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:11.362325      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:12.363591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:13.363654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:14.364336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:15.365132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:16.365435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:17.365575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:18.365847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:19.052: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7980" for this suite. @ 04/15/24 06:40:19.067
â€¢ [81.402 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 04/15/24 06:40:19.088
  Apr 15 06:40:19.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 06:40:19.093
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:40:19.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:40:19.138
  E0415 06:40:19.367318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:20.367955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:21.368712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:22.369120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:23.370156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:24.370630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:40:25.287
  Apr 15 06:40:25.296: INFO: Trying to get logs from node phiefi7ighaa-3 pod client-envvars-dd1ce1dd-c1f8-4d77-8bec-83beea8d3d1f container env3cont: <nil>
  STEP: delete the pod @ 04/15/24 06:40:25.317
  Apr 15 06:40:25.353: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8453" for this suite. @ 04/15/24 06:40:25.363
  E0415 06:40:25.372239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [6.289 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
test/e2e/kubectl/kubectl.go:396
  STEP: Creating a kubernetes client @ 04/15/24 06:40:25.379
  Apr 15 06:40:25.379: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:40:25.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:40:25.415
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:40:25.421
  STEP: creating all guestbook components @ 04/15/24 06:40:25.426
  Apr 15 06:40:25.427: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Apr 15 06:40:25.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 create -f -'
  Apr 15 06:40:26.177: INFO: stderr: ""
  Apr 15 06:40:26.177: INFO: stdout: "service/agnhost-replica created\n"
  Apr 15 06:40:26.177: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Apr 15 06:40:26.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 create -f -'
  E0415 06:40:26.372112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:26.726: INFO: stderr: ""
  Apr 15 06:40:26.727: INFO: stdout: "service/agnhost-primary created\n"
  Apr 15 06:40:26.727: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Apr 15 06:40:26.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 create -f -'
  Apr 15 06:40:27.224: INFO: stderr: ""
  Apr 15 06:40:27.224: INFO: stdout: "service/frontend created\n"
  Apr 15 06:40:27.224: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Apr 15 06:40:27.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 create -f -'
  E0415 06:40:27.372481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:27.704: INFO: stderr: ""
  Apr 15 06:40:27.704: INFO: stdout: "deployment.apps/frontend created\n"
  Apr 15 06:40:27.704: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 15 06:40:27.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 create -f -'
  Apr 15 06:40:28.238: INFO: stderr: ""
  Apr 15 06:40:28.238: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Apr 15 06:40:28.238: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.47
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 15 06:40:28.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 create -f -'
  E0415 06:40:28.373156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:29.142: INFO: stderr: ""
  Apr 15 06:40:29.142: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 04/15/24 06:40:29.142
  Apr 15 06:40:29.142: INFO: Waiting for all frontend pods to be Running.
  E0415 06:40:29.374909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:30.375720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:31.375885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:32.376122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:33.376476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:34.194: INFO: Waiting for frontend to serve content.
  Apr 15 06:40:34.230: INFO: Trying to add a new entry to the guestbook.
  Apr 15 06:40:34.259: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 04/15/24 06:40:34.293
  Apr 15 06:40:34.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 delete --grace-period=0 --force -f -'
  E0415 06:40:34.377713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:34.510: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 15 06:40:34.510: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 04/15/24 06:40:34.51
  Apr 15 06:40:34.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 delete --grace-period=0 --force -f -'
  Apr 15 06:40:34.714: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 15 06:40:34.714: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/15/24 06:40:34.714
  Apr 15 06:40:34.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 delete --grace-period=0 --force -f -'
  Apr 15 06:40:34.906: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 15 06:40:34.906: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/15/24 06:40:34.906
  Apr 15 06:40:34.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 delete --grace-period=0 --force -f -'
  Apr 15 06:40:35.090: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 15 06:40:35.090: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/15/24 06:40:35.09
  Apr 15 06:40:35.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 delete --grace-period=0 --force -f -'
  Apr 15 06:40:35.316: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 15 06:40:35.316: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/15/24 06:40:35.317
  Apr 15 06:40:35.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-1026 delete --grace-period=0 --force -f -'
  E0415 06:40:35.377802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:35.560: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 15 06:40:35.560: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Apr 15 06:40:35.560: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1026" for this suite. @ 04/15/24 06:40:35.573
â€¢ [10.224 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 04/15/24 06:40:35.665
  Apr 15 06:40:35.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 06:40:35.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:40:35.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:40:35.745
  STEP: Create a pod @ 04/15/24 06:40:35.753
  E0415 06:40:36.377970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:37.378526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 04/15/24 06:40:37.791
  Apr 15 06:40:37.806: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Apr 15 06:40:37.806: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2733" for this suite. @ 04/15/24 06:40:37.82
â€¢ [2.172 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 04/15/24 06:40:37.839
  Apr 15 06:40:37.839: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 06:40:37.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:40:37.866
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:40:37.873
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-8239 @ 04/15/24 06:40:37.879
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/15/24 06:40:37.909
  STEP: creating service externalsvc in namespace services-8239 @ 04/15/24 06:40:37.91
  STEP: creating replication controller externalsvc in namespace services-8239 @ 04/15/24 06:40:37.944
  I0415 06:40:37.959271      13 runners.go:197] Created replication controller with name: externalsvc, namespace: services-8239, replica count: 2
  E0415 06:40:38.379472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:39.379666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:40.380511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 06:40:41.013674      13 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 04/15/24 06:40:41.021
  Apr 15 06:40:41.059: INFO: Creating new exec pod
  E0415 06:40:41.381182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:42.381406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:43.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-8239 exec execpodqjwbk -- /bin/sh -x -c nslookup nodeport-service.services-8239.svc.cluster.local'
  E0415 06:40:43.382691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:43.540: INFO: stderr: "+ nslookup nodeport-service.services-8239.svc.cluster.local\n"
  Apr 15 06:40:43.540: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-8239.svc.cluster.local\tcanonical name = externalsvc.services-8239.svc.cluster.local.\nName:\texternalsvc.services-8239.svc.cluster.local\nAddress: 10.233.63.82\n\n"
  Apr 15 06:40:43.540: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-8239, will wait for the garbage collector to delete the pods @ 04/15/24 06:40:43.555
  Apr 15 06:40:43.630: INFO: Deleting ReplicationController externalsvc took: 17.412493ms
  Apr 15 06:40:43.731: INFO: Terminating ReplicationController externalsvc pods took: 101.173423ms
  E0415 06:40:44.383114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:45.384213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:46.384991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:46.580: INFO: Cleaning up the NodePort to ExternalName test service
  STEP: Destroying namespace "services-8239" for this suite. @ 04/15/24 06:40:46.617
â€¢ [8.802 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:609
  STEP: Creating a kubernetes client @ 04/15/24 06:40:46.642
  Apr 15 06:40:46.642: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename security-context-test @ 04/15/24 06:40:46.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:40:46.675
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:40:46.68
  E0415 06:40:47.388424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:48.385616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:49.385656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:50.386161      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:40:50.753: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9342" for this suite. @ 04/15/24 06:40:50.767
â€¢ [4.140 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 04/15/24 06:40:50.784
  Apr 15 06:40:50.784: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-runtime @ 04/15/24 06:40:50.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:40:50.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:40:50.838
  STEP: create the container @ 04/15/24 06:40:50.847
  W0415 06:40:50.865835      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 04/15/24 06:40:50.866
  E0415 06:40:51.386251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:52.386628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:53.386837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/15/24 06:40:53.902
  STEP: the container should be terminated @ 04/15/24 06:40:53.91
  STEP: the termination message should be set @ 04/15/24 06:40:53.91
  Apr 15 06:40:53.910: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/15/24 06:40:53.91
  Apr 15 06:40:53.929: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-532" for this suite. @ 04/15/24 06:40:53.946
â€¢ [3.175 seconds]
------------------------------
SS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 04/15/24 06:40:53.96
  Apr 15 06:40:53.960: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename certificates @ 04/15/24 06:40:53.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:40:54.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:40:54.019
  E0415 06:40:54.386794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:55.387469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting /apis @ 04/15/24 06:40:55.645
  STEP: getting /apis/certificates.k8s.io @ 04/15/24 06:40:55.652
  STEP: getting /apis/certificates.k8s.io/v1 @ 04/15/24 06:40:55.655
  STEP: creating @ 04/15/24 06:40:55.657
  STEP: getting @ 04/15/24 06:40:55.695
  STEP: listing @ 04/15/24 06:40:55.7
  STEP: watching @ 04/15/24 06:40:55.708
  Apr 15 06:40:55.708: INFO: starting watch
  STEP: patching @ 04/15/24 06:40:55.712
  STEP: updating @ 04/15/24 06:40:55.735
  Apr 15 06:40:55.759: INFO: waiting for watch events with expected annotations
  Apr 15 06:40:55.759: INFO: saw patched and updated annotations
  STEP: getting /approval @ 04/15/24 06:40:55.76
  STEP: patching /approval @ 04/15/24 06:40:55.771
  STEP: updating /approval @ 04/15/24 06:40:55.788
  STEP: getting /status @ 04/15/24 06:40:55.804
  STEP: patching /status @ 04/15/24 06:40:55.823
  STEP: updating /status @ 04/15/24 06:40:55.843
  STEP: deleting @ 04/15/24 06:40:55.862
  STEP: deleting a collection @ 04/15/24 06:40:55.894
  Apr 15 06:40:55.926: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-5673" for this suite. @ 04/15/24 06:40:55.937
â€¢ [1.993 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:87
  STEP: Creating a kubernetes client @ 04/15/24 06:40:55.957
  Apr 15 06:40:55.957: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:40:55.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:40:55.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:40:55.997
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 04/15/24 06:40:56.003
  E0415 06:40:56.387471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:57.387831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:58.388509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:40:59.389162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:41:00.066
  Apr 15 06:41:00.073: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-40890dbb-567b-483e-a50a-3968fac2fcbd container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:41:00.095
  Apr 15 06:41:00.150: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6138" for this suite. @ 04/15/24 06:41:00.164
â€¢ [4.253 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 04/15/24 06:41:00.217
  Apr 15 06:41:00.217: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 06:41:00.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:41:00.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:41:00.265
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5476 @ 04/15/24 06:41:00.271
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/15/24 06:41:00.305
  STEP: creating service externalsvc in namespace services-5476 @ 04/15/24 06:41:00.308
  STEP: creating replication controller externalsvc in namespace services-5476 @ 04/15/24 06:41:00.33
  I0415 06:41:00.354048      13 runners.go:197] Created replication controller with name: externalsvc, namespace: services-5476, replica count: 2
  E0415 06:41:00.389707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:01.390003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:02.390398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:03.390594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 06:41:03.410252      13 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 04/15/24 06:41:03.417
  Apr 15 06:41:03.451: INFO: Creating new exec pod
  E0415 06:41:04.391328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:05.391789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:05.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-5476 exec execpodpp8jc -- /bin/sh -x -c nslookup clusterip-service.services-5476.svc.cluster.local'
  Apr 15 06:41:05.992: INFO: stderr: "+ nslookup clusterip-service.services-5476.svc.cluster.local\n"
  Apr 15 06:41:05.992: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-5476.svc.cluster.local\tcanonical name = externalsvc.services-5476.svc.cluster.local.\nName:\texternalsvc.services-5476.svc.cluster.local\nAddress: 10.233.53.148\n\n"
  Apr 15 06:41:05.993: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-5476, will wait for the garbage collector to delete the pods @ 04/15/24 06:41:06.006
  Apr 15 06:41:06.077: INFO: Deleting ReplicationController externalsvc took: 14.631844ms
  Apr 15 06:41:06.179: INFO: Terminating ReplicationController externalsvc pods took: 101.185585ms
  E0415 06:41:06.391976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:07.393103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:08.393350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:09.332: INFO: Cleaning up the ClusterIP to ExternalName test service
  STEP: Destroying namespace "services-5476" for this suite. @ 04/15/24 06:41:09.365
â€¢ [9.171 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]
test/e2e/apps/deployment.go:488
  STEP: Creating a kubernetes client @ 04/15/24 06:41:09.391
  Apr 15 06:41:09.392: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:41:09.394043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename deployment @ 04/15/24 06:41:09.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:41:09.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:41:09.43
  STEP: creating a Deployment @ 04/15/24 06:41:09.444
  Apr 15 06:41:09.444: INFO: Creating simple deployment test-deployment-d4crd
  Apr 15 06:41:09.470: INFO: new replicaset for deployment "test-deployment-d4crd" is yet to be created
  E0415 06:41:10.394856      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:11.395408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 04/15/24 06:41:11.498
  Apr 15 06:41:11.514: INFO: Deployment test-deployment-d4crd has Conditions: [{Available True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d4crd-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 04/15/24 06:41:11.514
  Apr 15 06:41:11.537: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 41, 10, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 41, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 41, 10, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 41, 9, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-d4crd-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 04/15/24 06:41:11.537
  Apr 15 06:41:11.544: INFO: Observed &Deployment event: ADDED
  Apr 15 06:41:11.544: INFO: Observed Deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d4crd-5d576bd769"}
  Apr 15 06:41:11.544: INFO: Observed &Deployment event: MODIFIED
  Apr 15 06:41:11.544: INFO: Observed Deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d4crd-5d576bd769"}
  Apr 15 06:41:11.544: INFO: Observed Deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 15 06:41:11.545: INFO: Observed &Deployment event: MODIFIED
  Apr 15 06:41:11.546: INFO: Observed Deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 15 06:41:11.546: INFO: Observed Deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-d4crd-5d576bd769" is progressing.}
  Apr 15 06:41:11.546: INFO: Observed &Deployment event: MODIFIED
  Apr 15 06:41:11.546: INFO: Observed Deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 15 06:41:11.547: INFO: Observed Deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d4crd-5d576bd769" has successfully progressed.}
  Apr 15 06:41:11.547: INFO: Observed &Deployment event: MODIFIED
  Apr 15 06:41:11.547: INFO: Observed Deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 15 06:41:11.548: INFO: Observed Deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d4crd-5d576bd769" has successfully progressed.}
  Apr 15 06:41:11.549: INFO: Found Deployment test-deployment-d4crd in namespace deployment-2451 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 15 06:41:11.550: INFO: Deployment test-deployment-d4crd has an updated status
  STEP: patching the Statefulset Status @ 04/15/24 06:41:11.551
  Apr 15 06:41:11.552: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 15 06:41:11.569: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 04/15/24 06:41:11.569
  Apr 15 06:41:11.575: INFO: Observed &Deployment event: ADDED
  Apr 15 06:41:11.576: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d4crd-5d576bd769"}
  Apr 15 06:41:11.576: INFO: Observed &Deployment event: MODIFIED
  Apr 15 06:41:11.576: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d4crd-5d576bd769"}
  Apr 15 06:41:11.576: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 15 06:41:11.577: INFO: Observed &Deployment event: MODIFIED
  Apr 15 06:41:11.577: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 15 06:41:11.577: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:09 +0000 UTC 2024-04-15 06:41:09 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-d4crd-5d576bd769" is progressing.}
  Apr 15 06:41:11.578: INFO: Observed &Deployment event: MODIFIED
  Apr 15 06:41:11.578: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 15 06:41:11.578: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d4crd-5d576bd769" has successfully progressed.}
  Apr 15 06:41:11.578: INFO: Observed &Deployment event: MODIFIED
  Apr 15 06:41:11.579: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 15 06:41:11.580: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-15 06:41:10 +0000 UTC 2024-04-15 06:41:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d4crd-5d576bd769" has successfully progressed.}
  Apr 15 06:41:11.580: INFO: Observed deployment test-deployment-d4crd in namespace deployment-2451 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 15 06:41:11.580: INFO: Observed &Deployment event: MODIFIED
  Apr 15 06:41:11.582: INFO: Found deployment test-deployment-d4crd in namespace deployment-2451 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Apr 15 06:41:11.585: INFO: Deployment test-deployment-d4crd has a patched status
  Apr 15 06:41:11.594: INFO: Deployment "test-deployment-d4crd":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-d4crd",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2451",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "66a0e259-ed0b-4597-b9a5-1f96221377b6",
      ResourceVersion: (string) (len=6) "153719",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760069,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760069,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760071,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760071,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760071,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760071,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-d4crd-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 15 06:41:11.608: INFO: New ReplicaSet "test-deployment-d4crd-5d576bd769" of Deployment "test-deployment-d4crd":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-d4crd-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2451",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1de50380-37a9-4713-bb12-1fc156afd2bb",
      ResourceVersion: (string) (len=6) "153713",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760069,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
        (string) (len=3) "e2e": (string) (len=7) "testing"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-d4crd",
          UID: (types.UID) (len=36) "66a0e259-ed0b-4597-b9a5-1f96221377b6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760069,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 36 36 61  |k:{\"uid\":\"66a|
              00000120  30 65 32 35 39 2d 65 64  30 62 2d 34 35 39 37 2d  |0e259-ed0b-4597-|
              00000130  62 39 61 35 2d 31 66 39  36 32 32 31 33 37 37 62  |b9a5-1f96221377b|
              00000140  36 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |6\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:41:11.643: INFO: Pod "test-deployment-d4crd-5d576bd769-fkt6v" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-d4crd-5d576bd769-fkt6v",
      GenerateName: (string) (len=33) "test-deployment-d4crd-5d576bd769-",
      Namespace: (string) (len=15) "deployment-2451",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9c0b0d13-b6c0-4bd6-ab88-58347898ea31",
      ResourceVersion: (string) (len=6) "153712",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760069,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-d4crd-5d576bd769",
          UID: (types.UID) (len=36) "1de50380-37a9-4713-bb12-1fc156afd2bb",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760069,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 31 64 65 35 30 33 38  30 2d 33 37 61 39 2d 34  |"1de50380-37a9-4|
              000000a0  37 31 33 2d 62 62 31 32  2d 31 66 63 31 35 36 61  |713-bb12-1fc156a|
              000000b0  66 64 32 62 62 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |fd2bb\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 31 30 39 5c 22 7d  |10.233.66.109\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nsbc2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nsbc2",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760069,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760070,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760069,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.206",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.66.109",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.109"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760069,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760070,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://7c7c8911c56613eb23813dc149546c0affcb39c434e473f010660ecae1a3e58c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:41:11.655: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2451" for this suite. @ 04/15/24 06:41:11.667
â€¢ [2.289 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 04/15/24 06:41:11.688
  Apr 15 06:41:11.688: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:41:11.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:41:11.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:41:11.723
  STEP: Creating configMap with name configmap-test-volume-2db552ea-a6fb-4efc-a070-b71777d940af @ 04/15/24 06:41:11.73
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:41:11.744
  E0415 06:41:12.395704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:13.395773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:14.397004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:15.397608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:41:15.795
  Apr 15 06:41:15.804: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-4271f3de-6997-45e0-8ceb-f15fe74e57aa container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 06:41:15.826
  Apr 15 06:41:15.874: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4460" for this suite. @ 04/15/24 06:41:15.886
â€¢ [4.215 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 04/15/24 06:41:15.905
  Apr 15 06:41:15.905: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:41:15.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:41:15.939
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:41:15.945
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:41:15.951
  E0415 06:41:16.398032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:17.398664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:18.400252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:19.399142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:41:20.001
  Apr 15 06:41:20.009: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-7ad87f44-3fc9-4d2f-9437-a54e52062c60 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:41:20.032
  Apr 15 06:41:20.073: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1014" for this suite. @ 04/15/24 06:41:20.086
â€¢ [4.195 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
test/e2e/apps/statefulset.go:640
  STEP: Creating a kubernetes client @ 04/15/24 06:41:20.103
  Apr 15 06:41:20.103: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename statefulset @ 04/15/24 06:41:20.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:41:20.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:41:20.192
  STEP: Creating service test in namespace statefulset-8215 @ 04/15/24 06:41:20.197
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 04/15/24 06:41:20.224
  STEP: Creating stateful set ss in namespace statefulset-8215 @ 04/15/24 06:41:20.236
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8215 @ 04/15/24 06:41:20.268
  Apr 15 06:41:20.275: INFO: Found 0 stateful pods, waiting for 1
  E0415 06:41:20.400230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:21.400240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:22.401998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:23.401945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:24.402866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:25.403911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:26.403936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:27.404218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:28.404539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:29.405531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:30.285: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 04/15/24 06:41:30.285
  Apr 15 06:41:30.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-8215 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0415 06:41:30.406415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:30.636: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:41:30.636: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:41:30.636: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 15 06:41:30.645: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0415 06:41:31.406673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:32.407049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:33.426353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:34.410343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:35.411107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:36.412006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:37.412277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:38.412943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:39.413171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:40.413420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:40.678: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 15 06:41:40.678: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 15 06:41:40.729: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999586s
  E0415 06:41:41.413592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:41.745: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.985834647s
  E0415 06:41:42.414321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:42.753: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.970442562s
  E0415 06:41:43.415062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:43.763: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.962439843s
  E0415 06:41:44.418678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:44.779: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.950127831s
  E0415 06:41:45.418583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:45.791: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.936395668s
  E0415 06:41:46.418467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:46.809: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.923939023s
  E0415 06:41:47.420641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:47.819: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.904690406s
  E0415 06:41:48.420563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:48.832: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.896416358s
  E0415 06:41:49.421526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:41:49.840: INFO: Verifying statefulset ss doesn't scale past 1 for another 882.878413ms
  E0415 06:41:50.422749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8215 @ 04/15/24 06:41:50.842
  Apr 15 06:41:50.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-8215 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 15 06:41:51.340: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 15 06:41:51.340: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 15 06:41:51.340: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 15 06:41:51.347: INFO: Found 1 stateful pods, waiting for 3
  E0415 06:41:51.423263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:52.423330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:53.423713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:54.425629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:55.426552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:56.426786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:57.426976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:58.427297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:41:59.428471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:00.428522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:01.359: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 06:42:01.359: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 06:42:01.360: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 04/15/24 06:42:01.36
  STEP: Scale down will halt with unhealthy stateful pod @ 04/15/24 06:42:01.361
  Apr 15 06:42:01.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-8215 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0415 06:42:01.429222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:01.725: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:42:01.726: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:42:01.726: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 15 06:42:01.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-8215 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 15 06:42:02.047: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:42:02.047: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:42:02.047: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 15 06:42:02.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-8215 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 15 06:42:02.384: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:42:02.384: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:42:02.384: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 15 06:42:02.384: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 15 06:42:02.394: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 2
  E0415 06:42:02.430187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:03.431133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:04.431560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:05.432633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:06.433180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:07.433758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:08.433791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:09.434924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:10.435211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:11.436235      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:12.414: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 15 06:42:12.414: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 15 06:42:12.414: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  E0415 06:42:12.437015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:12.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999336s
  E0415 06:42:13.437187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:13.456: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991015411s
  E0415 06:42:14.437659      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:14.476: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979247204s
  E0415 06:42:15.437678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:15.487: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.96064497s
  E0415 06:42:16.437944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:16.501: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.948400478s
  E0415 06:42:17.439053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:17.517: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.935266345s
  E0415 06:42:18.439511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:18.533: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.919366955s
  E0415 06:42:19.439252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:19.545: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.902668705s
  E0415 06:42:20.439422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:20.562: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.891926985s
  E0415 06:42:21.440228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:21.574: INFO: Verifying statefulset ss doesn't scale past 3 for another 873.847178ms
  E0415 06:42:22.440711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8215 @ 04/15/24 06:42:22.575
  Apr 15 06:42:22.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-8215 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 15 06:42:22.952: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 15 06:42:22.952: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 15 06:42:22.952: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 15 06:42:22.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-8215 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 15 06:42:23.296: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 15 06:42:23.297: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 15 06:42:23.297: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 15 06:42:23.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-8215 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0415 06:42:23.441328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:23.673: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 15 06:42:23.673: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 15 06:42:23.673: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 15 06:42:23.673: INFO: Scaling statefulset ss to 0
  E0415 06:42:24.442131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:25.442536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:26.443406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:27.444633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:28.444301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:29.446035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:30.445464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:31.445463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:32.445543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:33.446675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 04/15/24 06:42:33.72
  Apr 15 06:42:33.721: INFO: Deleting all statefulset in ns statefulset-8215
  Apr 15 06:42:33.733: INFO: Scaling statefulset ss to 0
  Apr 15 06:42:33.788: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 15 06:42:33.797: INFO: Deleting statefulset ss
  Apr 15 06:42:33.845: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8215" for this suite. @ 04/15/24 06:42:33.864
â€¢ [73.778 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]
test/e2e/network/endpointslice.go:355
  STEP: Creating a kubernetes client @ 04/15/24 06:42:33.903
  Apr 15 06:42:33.903: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename endpointslice @ 04/15/24 06:42:33.911
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:42:33.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:42:33.946
  STEP: getting /apis @ 04/15/24 06:42:33.951
  STEP: getting /apis/discovery.k8s.io @ 04/15/24 06:42:33.962
  STEP: getting /apis/discovery.k8s.iov1 @ 04/15/24 06:42:33.964
  STEP: creating @ 04/15/24 06:42:33.967
  STEP: getting @ 04/15/24 06:42:34.002
  STEP: listing @ 04/15/24 06:42:34.008
  STEP: watching @ 04/15/24 06:42:34.016
  Apr 15 06:42:34.016: INFO: starting watch
  STEP: cluster-wide listing @ 04/15/24 06:42:34.018
  STEP: cluster-wide watching @ 04/15/24 06:42:34.026
  Apr 15 06:42:34.027: INFO: starting watch
  STEP: patching @ 04/15/24 06:42:34.03
  STEP: updating @ 04/15/24 06:42:34.042
  Apr 15 06:42:34.060: INFO: waiting for watch events with expected annotations
  Apr 15 06:42:34.061: INFO: saw patched and updated annotations
  STEP: deleting @ 04/15/24 06:42:34.063
  STEP: deleting a collection @ 04/15/24 06:42:34.089
  Apr 15 06:42:34.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7043" for this suite. @ 04/15/24 06:42:34.145
â€¢ [0.254 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
test/e2e/apimachinery/garbage_collector.go:713
  STEP: Creating a kubernetes client @ 04/15/24 06:42:34.16
  Apr 15 06:42:34.160: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename gc @ 04/15/24 06:42:34.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:42:34.194
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:42:34.2
  STEP: create the rc1 @ 04/15/24 06:42:34.216
  STEP: create the rc2 @ 04/15/24 06:42:34.231
  E0415 06:42:34.447099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:35.448316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:36.448352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:37.448633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:38.449641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:39.450278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 04/15/24 06:42:40.347
  E0415 06:42:40.456729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:41.458108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:42.460829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:43.460763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 04/15/24 06:42:44.311
  E0415 06:42:44.460848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for the rc to be deleted @ 04/15/24 06:42:44.466
  E0415 06:42:45.488245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:46.472246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:47.474359      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:48.486629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:49.475239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:49.559: INFO: 72 pods remaining
  Apr 15 06:42:49.560: INFO: 72 pods has nil DeletionTimestamp
  Apr 15 06:42:49.560: INFO: 
  E0415 06:42:50.475666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:51.475941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:52.476435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:53.476647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:42:54.477621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/15/24 06:42:54.531
  Apr 15 06:42:55.328: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 15 06:42:55.335: INFO: Deleting pod "simpletest-rc-to-be-deleted-22mdv" in namespace "gc-8938"
  E0415 06:42:55.478598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:55.658: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hh4s" in namespace "gc-8938"
  Apr 15 06:42:55.886: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ttj2" in namespace "gc-8938"
  Apr 15 06:42:55.946: INFO: Deleting pod "simpletest-rc-to-be-deleted-4fn8p" in namespace "gc-8938"
  Apr 15 06:42:55.989: INFO: Deleting pod "simpletest-rc-to-be-deleted-4lm6f" in namespace "gc-8938"
  Apr 15 06:42:56.114: INFO: Deleting pod "simpletest-rc-to-be-deleted-4lvdl" in namespace "gc-8938"
  Apr 15 06:42:56.279: INFO: Deleting pod "simpletest-rc-to-be-deleted-58mm8" in namespace "gc-8938"
  Apr 15 06:42:56.339: INFO: Deleting pod "simpletest-rc-to-be-deleted-665n9" in namespace "gc-8938"
  Apr 15 06:42:56.436: INFO: Deleting pod "simpletest-rc-to-be-deleted-6btxn" in namespace "gc-8938"
  E0415 06:42:56.479077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:56.487: INFO: Deleting pod "simpletest-rc-to-be-deleted-6fj9n" in namespace "gc-8938"
  Apr 15 06:42:56.564: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hxp5" in namespace "gc-8938"
  Apr 15 06:42:56.611: INFO: Deleting pod "simpletest-rc-to-be-deleted-6pxlw" in namespace "gc-8938"
  Apr 15 06:42:56.671: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rmdn" in namespace "gc-8938"
  Apr 15 06:42:56.736: INFO: Deleting pod "simpletest-rc-to-be-deleted-75rzf" in namespace "gc-8938"
  Apr 15 06:42:56.777: INFO: Deleting pod "simpletest-rc-to-be-deleted-75s8b" in namespace "gc-8938"
  Apr 15 06:42:56.837: INFO: Deleting pod "simpletest-rc-to-be-deleted-7p4cx" in namespace "gc-8938"
  Apr 15 06:42:56.897: INFO: Deleting pod "simpletest-rc-to-be-deleted-7qxsr" in namespace "gc-8938"
  Apr 15 06:42:56.978: INFO: Deleting pod "simpletest-rc-to-be-deleted-8fxvt" in namespace "gc-8938"
  Apr 15 06:42:57.119: INFO: Deleting pod "simpletest-rc-to-be-deleted-8t7s9" in namespace "gc-8938"
  Apr 15 06:42:57.252: INFO: Deleting pod "simpletest-rc-to-be-deleted-8zrmx" in namespace "gc-8938"
  Apr 15 06:42:57.318: INFO: Deleting pod "simpletest-rc-to-be-deleted-96jwz" in namespace "gc-8938"
  Apr 15 06:42:57.363: INFO: Deleting pod "simpletest-rc-to-be-deleted-9fml2" in namespace "gc-8938"
  Apr 15 06:42:57.416: INFO: Deleting pod "simpletest-rc-to-be-deleted-bkbv4" in namespace "gc-8938"
  E0415 06:42:57.480107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:57.492: INFO: Deleting pod "simpletest-rc-to-be-deleted-bq5w5" in namespace "gc-8938"
  Apr 15 06:42:57.625: INFO: Deleting pod "simpletest-rc-to-be-deleted-bsvbg" in namespace "gc-8938"
  Apr 15 06:42:57.677: INFO: Deleting pod "simpletest-rc-to-be-deleted-cf4kq" in namespace "gc-8938"
  Apr 15 06:42:57.750: INFO: Deleting pod "simpletest-rc-to-be-deleted-cgnwx" in namespace "gc-8938"
  Apr 15 06:42:57.882: INFO: Deleting pod "simpletest-rc-to-be-deleted-ck4m5" in namespace "gc-8938"
  Apr 15 06:42:57.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-cv6nq" in namespace "gc-8938"
  Apr 15 06:42:57.996: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5dt8" in namespace "gc-8938"
  Apr 15 06:42:58.060: INFO: Deleting pod "simpletest-rc-to-be-deleted-dtl5d" in namespace "gc-8938"
  Apr 15 06:42:58.192: INFO: Deleting pod "simpletest-rc-to-be-deleted-dv57w" in namespace "gc-8938"
  Apr 15 06:42:58.284: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzpnz" in namespace "gc-8938"
  Apr 15 06:42:58.407: INFO: Deleting pod "simpletest-rc-to-be-deleted-f55b4" in namespace "gc-8938"
  Apr 15 06:42:58.474: INFO: Deleting pod "simpletest-rc-to-be-deleted-f8rj5" in namespace "gc-8938"
  E0415 06:42:58.480763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:58.539: INFO: Deleting pod "simpletest-rc-to-be-deleted-fdgm8" in namespace "gc-8938"
  Apr 15 06:42:58.728: INFO: Deleting pod "simpletest-rc-to-be-deleted-g85ff" in namespace "gc-8938"
  Apr 15 06:42:58.842: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbd2j" in namespace "gc-8938"
  Apr 15 06:42:58.937: INFO: Deleting pod "simpletest-rc-to-be-deleted-h69h5" in namespace "gc-8938"
  Apr 15 06:42:59.029: INFO: Deleting pod "simpletest-rc-to-be-deleted-hb7v2" in namespace "gc-8938"
  Apr 15 06:42:59.116: INFO: Deleting pod "simpletest-rc-to-be-deleted-hblp4" in namespace "gc-8938"
  Apr 15 06:42:59.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-hflhb" in namespace "gc-8938"
  Apr 15 06:42:59.228: INFO: Deleting pod "simpletest-rc-to-be-deleted-hh2bh" in namespace "gc-8938"
  Apr 15 06:42:59.260: INFO: Deleting pod "simpletest-rc-to-be-deleted-hhnn5" in namespace "gc-8938"
  E0415 06:42:59.481596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:42:59.554: INFO: Deleting pod "simpletest-rc-to-be-deleted-hj9h7" in namespace "gc-8938"
  Apr 15 06:42:59.599: INFO: Deleting pod "simpletest-rc-to-be-deleted-hldlm" in namespace "gc-8938"
  Apr 15 06:42:59.712: INFO: Deleting pod "simpletest-rc-to-be-deleted-hlxkp" in namespace "gc-8938"
  Apr 15 06:42:59.794: INFO: Deleting pod "simpletest-rc-to-be-deleted-hrtrv" in namespace "gc-8938"
  Apr 15 06:43:00.006: INFO: Deleting pod "simpletest-rc-to-be-deleted-hzzqf" in namespace "gc-8938"
  Apr 15 06:43:00.111: INFO: Deleting pod "simpletest-rc-to-be-deleted-jsv4c" in namespace "gc-8938"
  Apr 15 06:43:00.378: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8938" for this suite. @ 04/15/24 06:43:00.42
  E0415 06:43:00.481839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [26.399 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]
test/e2e/apps/rc.go:424
  STEP: Creating a kubernetes client @ 04/15/24 06:43:00.559
  Apr 15 06:43:00.559: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replication-controller @ 04/15/24 06:43:00.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:43:00.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:43:00.662
  STEP: Creating ReplicationController "e2e-rc-7x6t2" @ 04/15/24 06:43:00.674
  Apr 15 06:43:00.696: INFO: Get Replication Controller "e2e-rc-7x6t2" to confirm replicas
  E0415 06:43:01.482023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:01.711: INFO: Get Replication Controller "e2e-rc-7x6t2" to confirm replicas
  Apr 15 06:43:01.725: INFO: Found 1 replicas for "e2e-rc-7x6t2" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-7x6t2" @ 04/15/24 06:43:01.725
  STEP: Updating a scale subresource @ 04/15/24 06:43:01.742
  STEP: Verifying replicas where modified for replication controller "e2e-rc-7x6t2" @ 04/15/24 06:43:01.792
  Apr 15 06:43:01.792: INFO: Get Replication Controller "e2e-rc-7x6t2" to confirm replicas
  E0415 06:43:02.482269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:02.804: INFO: Get Replication Controller "e2e-rc-7x6t2" to confirm replicas
  Apr 15 06:43:02.822: INFO: Found 2 replicas for "e2e-rc-7x6t2" replication controller
  Apr 15 06:43:02.823: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5234" for this suite. @ 04/15/24 06:43:02.846
â€¢ [2.324 seconds]
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 04/15/24 06:43:02.884
  Apr 15 06:43:02.884: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 06:43:02.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:43:02.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:43:02.996
  STEP: creating service nodeport-test with type=NodePort in namespace services-186 @ 04/15/24 06:43:03.001
  STEP: creating replication controller nodeport-test in namespace services-186 @ 04/15/24 06:43:03.087
  I0415 06:43:03.115772      13 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-186, replica count: 2
  E0415 06:43:03.482502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:04.482924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:05.484089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 06:43:06.168095      13 runners.go:197] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0415 06:43:06.484795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:07.485180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:08.485781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 06:43:09.168347      13 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 15 06:43:09.168: INFO: Creating new exec pod
  E0415 06:43:09.486197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:10.487309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:11.487509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:12.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  E0415 06:43:12.487939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:12.686: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 15 06:43:12.686: INFO: stdout: ""
  E0415 06:43:13.489178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:13.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Apr 15 06:43:14.034: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 15 06:43:14.034: INFO: stdout: ""
  E0415 06:43:14.489429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:14.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Apr 15 06:43:15.064: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 15 06:43:15.064: INFO: stdout: ""
  E0415 06:43:15.489662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:15.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Apr 15 06:43:15.996: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 15 06:43:15.996: INFO: stdout: ""
  E0415 06:43:16.490328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:16.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Apr 15 06:43:17.048: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 15 06:43:17.048: INFO: stdout: "nodeport-test-qknwb"
  Apr 15 06:43:17.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.61.224 80'
  Apr 15 06:43:17.358: INFO: stderr: "+ nc+ echo hostName\n -v -t -w 2 10.233.61.224 80\nConnection to 10.233.61.224 80 port [tcp/http] succeeded!\n"
  Apr 15 06:43:17.358: INFO: stdout: "nodeport-test-mhwxn"
  Apr 15 06:43:17.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.141 32482'
  E0415 06:43:17.492132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:17.612: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.141 32482\nConnection to 192.168.121.141 32482 port [tcp/*] succeeded!\n"
  Apr 15 06:43:17.612: INFO: stdout: ""
  E0415 06:43:18.492460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:18.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.141 32482'
  Apr 15 06:43:18.888: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.141 32482\nConnection to 192.168.121.141 32482 port [tcp/*] succeeded!\n"
  Apr 15 06:43:18.888: INFO: stdout: ""
  E0415 06:43:19.493335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:19.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.141 32482'
  Apr 15 06:43:19.959: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.141 32482\nConnection to 192.168.121.141 32482 port [tcp/*] succeeded!\n"
  Apr 15 06:43:19.959: INFO: stdout: ""
  E0415 06:43:20.494221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:20.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.141 32482'
  Apr 15 06:43:20.893: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.141 32482\nConnection to 192.168.121.141 32482 port [tcp/*] succeeded!\n"
  Apr 15 06:43:20.893: INFO: stdout: "nodeport-test-qknwb"
  Apr 15 06:43:20.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-186 exec execpod2bhxd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.206 32482'
  Apr 15 06:43:21.259: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.206 32482\nConnection to 192.168.121.206 32482 port [tcp/*] succeeded!\n"
  Apr 15 06:43:21.259: INFO: stdout: "nodeport-test-qknwb"
  Apr 15 06:43:21.260: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-186" for this suite. @ 04/15/24 06:43:21.272
â€¢ [18.403 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
test/e2e/apps/job.go:430
  STEP: Creating a kubernetes client @ 04/15/24 06:43:21.29
  Apr 15 06:43:21.290: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename job @ 04/15/24 06:43:21.292
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:43:21.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:43:21.329
  STEP: Creating a job @ 04/15/24 06:43:21.336
  STEP: Ensuring job reaches completions @ 04/15/24 06:43:21.354
  E0415 06:43:21.494580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:22.494990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:23.495713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:24.495950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:25.497110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:26.497199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:27.498112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:28.498472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:29.499801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:30.499779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:31.363: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6859" for this suite. @ 04/15/24 06:43:31.375
â€¢ [10.098 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:93
  STEP: Creating a kubernetes client @ 04/15/24 06:43:31.398
  Apr 15 06:43:31.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:43:31.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:43:31.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:43:31.436
  STEP: Creating configMap configmap-6254/configmap-test-99c9b14a-7ecf-4d48-b4f6-39639c0d289d @ 04/15/24 06:43:31.444
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:43:31.459
  E0415 06:43:31.500888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:32.501209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:33.501275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:34.501721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:35.502437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:43:35.512
  Apr 15 06:43:35.521: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-dc64a010-5541-4585-a381-d8ad7d4f4cd8 container env-test: <nil>
  STEP: delete the pod @ 04/15/24 06:43:35.565
  Apr 15 06:43:35.607: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6254" for this suite. @ 04/15/24 06:43:35.623
â€¢ [4.247 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 04/15/24 06:43:35.653
  Apr 15 06:43:35.653: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:43:35.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:43:35.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:43:35.7
  STEP: Creating projection with secret that has name projected-secret-test-cbe7d956-9660-4a34-b325-dad72f738b32 @ 04/15/24 06:43:35.707
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:43:35.718
  E0415 06:43:36.504065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:37.504305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:38.504724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:39.505526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:43:39.783
  Apr 15 06:43:39.790: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-secrets-13a966f8-fa27-42c9-964b-a88609da1145 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:43:39.807
  Apr 15 06:43:39.843: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7105" for this suite. @ 04/15/24 06:43:39.855
â€¢ [4.218 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2165
  STEP: Creating a kubernetes client @ 04/15/24 06:43:39.874
  Apr 15 06:43:39.874: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 06:43:39.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:43:39.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:43:39.913
  STEP: creating service in namespace services-6707 @ 04/15/24 06:43:39.919
  STEP: creating service affinity-clusterip in namespace services-6707 @ 04/15/24 06:43:39.919
  STEP: creating replication controller affinity-clusterip in namespace services-6707 @ 04/15/24 06:43:39.943
  I0415 06:43:39.971804      13 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-6707, replica count: 3
  E0415 06:43:40.506410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:41.506655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:42.507162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 06:43:43.023986      13 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 15 06:43:43.042: INFO: Creating new exec pod
  E0415 06:43:43.507793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:44.507712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:45.507935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:46.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-6707 exec execpod-affinityp88kh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Apr 15 06:43:46.415: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Apr 15 06:43:46.415: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 06:43:46.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-6707 exec execpod-affinityp88kh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.34.7 80'
  E0415 06:43:46.508475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:46.724: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.34.7 80\nConnection to 10.233.34.7 80 port [tcp/http] succeeded!\n"
  Apr 15 06:43:46.724: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 06:43:46.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-6707 exec execpod-affinityp88kh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.34.7:80/ ; done'
  Apr 15 06:43:47.356: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.34.7:80/\n"
  Apr 15 06:43:47.356: INFO: stdout: "\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8\naffinity-clusterip-rfcs8"
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Received response from host: affinity-clusterip-rfcs8
  Apr 15 06:43:47.357: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 06:43:47.370: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-6707, will wait for the garbage collector to delete the pods @ 04/15/24 06:43:47.413
  Apr 15 06:43:47.488: INFO: Deleting ReplicationController affinity-clusterip took: 15.950314ms
  E0415 06:43:47.508935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:47.589: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.053357ms
  E0415 06:43:48.510490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:49.510525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:50.511499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-6707" for this suite. @ 04/15/24 06:43:50.949
â€¢ [11.091 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 04/15/24 06:43:50.972
  Apr 15 06:43:50.972: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename field-validation @ 04/15/24 06:43:50.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:43:51.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:43:51.01
  Apr 15 06:43:51.015: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:43:51.511887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:52.512314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:53.512383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:43:54.415: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3108" for this suite. @ 04/15/24 06:43:54.47
â€¢ [3.515 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:370
  STEP: Creating a kubernetes client @ 04/15/24 06:43:54.488
  Apr 15 06:43:54.488: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename namespaces @ 04/15/24 06:43:54.491
  E0415 06:43:54.513005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:43:54.526
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:43:54.535
  STEP: Updating Namespace "namespaces-1935" @ 04/15/24 06:43:54.547
  Apr 15 06:43:54.572: INFO: Namespace "namespaces-1935" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"09b869e7-e058-491d-bad7-361809188490", "kubernetes.io/metadata.name":"namespaces-1935", "namespaces-1935":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Apr 15 06:43:54.573: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1935" for this suite. @ 04/15/24 06:43:54.587
â€¢ [0.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 04/15/24 06:43:54.617
  Apr 15 06:43:54.617: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename dns @ 04/15/24 06:43:54.62
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:43:54.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:43:54.662
  STEP: Creating a test externalName service @ 04/15/24 06:43:54.674
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-231.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local; sleep 1; done
   @ 04/15/24 06:43:54.691
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-231.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-231.svc.cluster.local; sleep 1; done
   @ 04/15/24 06:43:54.691
  STEP: creating a pod to probe DNS @ 04/15/24 06:43:54.691
  STEP: submitting the pod to kubernetes @ 04/15/24 06:43:54.692
  E0415 06:43:55.513402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:56.514122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/15/24 06:43:56.759
  STEP: looking for the results for each expected name from probers @ 04/15/24 06:43:56.768
  Apr 15 06:43:56.802: INFO: DNS probes using dns-test-32e9c726-2097-4e5b-bb59-63cd9f945ec9 succeeded

  STEP: changing the externalName to bar.example.com @ 04/15/24 06:43:56.802
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-231.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local; sleep 1; done
   @ 04/15/24 06:43:56.826
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-231.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-231.svc.cluster.local; sleep 1; done
   @ 04/15/24 06:43:56.826
  STEP: creating a second pod to probe DNS @ 04/15/24 06:43:56.826
  STEP: submitting the pod to kubernetes @ 04/15/24 06:43:56.826
  E0415 06:43:57.515000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:43:58.515764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/15/24 06:43:58.886
  STEP: looking for the results for each expected name from probers @ 04/15/24 06:43:58.896
  Apr 15 06:43:58.914: INFO: File wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:43:58.933: INFO: File jessie_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:43:58.933: INFO: Lookups using dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 failed for: [wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local jessie_udp@dns-test-service-3.dns-231.svc.cluster.local]

  Apr 15 06:43:58.957: INFO: Pod client logs for webserver: 
  Apr 15 06:43:58.976: INFO: Pod client logs for querier: 
  Apr 15 06:43:59.001: INFO: Pod client logs for jessie-querier: 
  E0415 06:43:59.515853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:00.516704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:01.517039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:02.517434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:03.517344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:04.015: INFO: File wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:44:04.024: INFO: File jessie_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:44:04.024: INFO: Lookups using dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 failed for: [wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local jessie_udp@dns-test-service-3.dns-231.svc.cluster.local]

  Apr 15 06:44:04.042: INFO: Pod client logs for webserver: 
  Apr 15 06:44:04.057: INFO: Pod client logs for querier: 
  Apr 15 06:44:04.074: INFO: Pod client logs for jessie-querier: 
  E0415 06:44:04.518311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:05.519858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:06.521286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:07.519703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:08.520181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:09.015: INFO: File wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:44:09.024: INFO: File jessie_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:44:09.025: INFO: Lookups using dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 failed for: [wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local jessie_udp@dns-test-service-3.dns-231.svc.cluster.local]

  Apr 15 06:44:09.040: INFO: Pod client logs for webserver: 
  Apr 15 06:44:09.065: INFO: Pod client logs for querier: 
  Apr 15 06:44:09.082: INFO: Pod client logs for jessie-querier: 
  E0415 06:44:09.521517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:10.522579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:11.522496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:12.522897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:13.523714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:14.013: INFO: File wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:44:14.029: INFO: File jessie_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:44:14.030: INFO: Lookups using dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 failed for: [wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local jessie_udp@dns-test-service-3.dns-231.svc.cluster.local]

  Apr 15 06:44:14.050: INFO: Pod client logs for webserver: 
  Apr 15 06:44:14.066: INFO: Pod client logs for querier: 
  Apr 15 06:44:14.086: INFO: Pod client logs for jessie-querier: 
  E0415 06:44:14.525064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:15.525253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:16.526699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:17.526932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:18.528567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:19.013: INFO: File wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:44:19.025: INFO: File jessie_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 15 06:44:19.027: INFO: Lookups using dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 failed for: [wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local jessie_udp@dns-test-service-3.dns-231.svc.cluster.local]

  Apr 15 06:44:19.043: INFO: Pod client logs for webserver: 
  Apr 15 06:44:19.058: INFO: Pod client logs for querier: 
  Apr 15 06:44:19.076: INFO: Pod client logs for jessie-querier: 
  E0415 06:44:19.529691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:20.529813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:21.530077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:22.530586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:23.531490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:24.022: INFO: File wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains '' instead of 'bar.example.com.'
  Apr 15 06:44:24.040: INFO: File jessie_udp@dns-test-service-3.dns-231.svc.cluster.local from pod  dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 contains '' instead of 'bar.example.com.'
  Apr 15 06:44:24.040: INFO: Lookups using dns-231/dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 failed for: [wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local jessie_udp@dns-test-service-3.dns-231.svc.cluster.local]

  Apr 15 06:44:24.062: INFO: Pod client logs for webserver: 
  Apr 15 06:44:24.083: INFO: Pod client logs for querier: 
  Apr 15 06:44:24.100: INFO: Pod client logs for jessie-querier: 
  E0415 06:44:24.532541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:25.533283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:26.533410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:27.533519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:28.534496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:29.022: INFO: DNS probes using dns-test-1c2bd7f8-3e7a-4597-9bb6-b82ce4337f07 succeeded

  STEP: changing the service to type=ClusterIP @ 04/15/24 06:44:29.022
  W0415 06:44:29.105278      13 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-231.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-231.svc.cluster.local; sleep 1; done
   @ 04/15/24 06:44:29.105
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-231.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-231.svc.cluster.local; sleep 1; done
   @ 04/15/24 06:44:29.105
  STEP: creating a third pod to probe DNS @ 04/15/24 06:44:29.105
  STEP: submitting the pod to kubernetes @ 04/15/24 06:44:29.116
  E0415 06:44:29.535188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:30.535450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/15/24 06:44:31.241
  STEP: looking for the results for each expected name from probers @ 04/15/24 06:44:31.248
  Apr 15 06:44:31.278: INFO: DNS probes using dns-test-60f2a69b-0fc8-42e7-b6f5-011d8c5bf1e5 succeeded

  Apr 15 06:44:31.279: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 06:44:31.294
  STEP: deleting the pod @ 04/15/24 06:44:31.375
  STEP: deleting the pod @ 04/15/24 06:44:31.411
  STEP: deleting the test externalName service @ 04/15/24 06:44:31.452
  STEP: Destroying namespace "dns-231" for this suite. @ 04/15/24 06:44:31.51
  E0415 06:44:31.537279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [36.931 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
test/e2e/apimachinery/resource_quota.go:806
  STEP: Creating a kubernetes client @ 04/15/24 06:44:31.627
  Apr 15 06:44:31.628: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 06:44:31.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:44:31.708
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:44:31.715
  STEP: Creating a ResourceQuota with best effort scope @ 04/15/24 06:44:31.725
  STEP: Ensuring ResourceQuota status is calculated @ 04/15/24 06:44:31.736
  E0415 06:44:32.537281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:33.537025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 04/15/24 06:44:33.744
  STEP: Ensuring ResourceQuota status is calculated @ 04/15/24 06:44:33.761
  E0415 06:44:34.537835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:35.538581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 04/15/24 06:44:35.77
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 04/15/24 06:44:35.805
  E0415 06:44:36.538671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:37.538984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 04/15/24 06:44:37.815
  E0415 06:44:38.539245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:39.539860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/15/24 06:44:39.825
  STEP: Ensuring resource quota status released the pod usage @ 04/15/24 06:44:39.861
  E0415 06:44:40.540746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:41.540944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 04/15/24 06:44:41.869
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 04/15/24 06:44:41.889
  E0415 06:44:42.541629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:43.541579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 04/15/24 06:44:43.898
  E0415 06:44:44.541731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:45.542005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/15/24 06:44:45.907
  STEP: Ensuring resource quota status released the pod usage @ 04/15/24 06:44:45.943
  E0415 06:44:46.542845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:47.542909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:47.953: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2024" for this suite. @ 04/15/24 06:44:47.963
â€¢ [16.348 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 04/15/24 06:44:47.988
  Apr 15 06:44:47.988: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:44:47.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:44:48.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:44:48.029
  STEP: Creating secret with name projected-secret-test-a5004dcb-591d-48f1-9a1f-dcacbdfa7642 @ 04/15/24 06:44:48.036
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:44:48.052
  E0415 06:44:48.544104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:49.547970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:50.548560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:51.549507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:44:52.113
  Apr 15 06:44:52.119: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-secrets-7ee560e6-b98c-426e-a633-45c06d7c8d9b container secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:44:52.151
  Apr 15 06:44:52.182: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4354" for this suite. @ 04/15/24 06:44:52.194
â€¢ [4.256 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 04/15/24 06:44:52.247
  Apr 15 06:44:52.247: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:44:52.25
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:44:52.277
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:44:52.284
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:44:52.29
  E0415 06:44:52.550101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:53.550873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:54.551699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:44:55.552349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:44:56.351
  Apr 15 06:44:56.359: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-9e2e1daf-f16f-4bc5-b106-1735272f6549 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:44:56.374
  Apr 15 06:44:56.410: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4613" for this suite. @ 04/15/24 06:44:56.422
â€¢ [4.195 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]
test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 04/15/24 06:44:56.445
  Apr 15 06:44:56.445: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename daemonsets @ 04/15/24 06:44:56.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:44:56.477
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:44:56.484
  STEP: Creating a simple DaemonSet "daemon-set" @ 04/15/24 06:44:56.535
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/15/24 06:44:56.547
  E0415 06:44:56.552526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:56.564: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:44:56.564: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:44:57.553233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:57.631: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:44:57.631: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:44:58.553641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:58.583: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 15 06:44:58.583: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 04/15/24 06:44:58.59
  Apr 15 06:44:58.657: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 15 06:44:58.657: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:44:59.553782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:44:59.692: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 15 06:44:59.692: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:45:00.554162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:00.678: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 15 06:45:00.678: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 04/15/24 06:45:00.678
  STEP: Deleting DaemonSet "daemon-set" @ 04/15/24 06:45:00.711
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7436, will wait for the garbage collector to delete the pods @ 04/15/24 06:45:00.712
  Apr 15 06:45:00.786: INFO: Deleting DaemonSet.extensions daemon-set took: 12.554961ms
  Apr 15 06:45:00.888: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.156902ms
  E0415 06:45:01.554149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:02.295: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:45:02.295: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 15 06:45:02.301: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"156920"},"items":null}

  Apr 15 06:45:02.310: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"156920"},"items":null}

  Apr 15 06:45:02.352: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7436" for this suite. @ 04/15/24 06:45:02.369
â€¢ [5.944 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]
test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 04/15/24 06:45:02.394
  Apr 15 06:45:02.394: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename field-validation @ 04/15/24 06:45:02.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:02.436
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:02.448
  Apr 15 06:45:02.460: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:45:02.554591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:03.554757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:04.555678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0415 06:45:05.272748      13 warnings.go:70] unknown field "alpha"
  W0415 06:45:05.273128      13 warnings.go:70] unknown field "beta"
  W0415 06:45:05.273374      13 warnings.go:70] unknown field "delta"
  W0415 06:45:05.273471      13 warnings.go:70] unknown field "epsilon"
  W0415 06:45:05.273484      13 warnings.go:70] unknown field "gamma"
  E0415 06:45:05.555441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:05.860: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1745" for this suite. @ 04/15/24 06:45:05.905
â€¢ [3.522 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 04/15/24 06:45:05.919
  Apr 15 06:45:05.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubelet-test @ 04/15/24 06:45:05.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:05.951
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:05.956
  E0415 06:45:06.555814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:07.556537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:08.556634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:09.556974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:10.005: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3005" for this suite. @ 04/15/24 06:45:10.015
â€¢ [4.110 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 04/15/24 06:45:10.036
  Apr 15 06:45:10.036: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename deployment @ 04/15/24 06:45:10.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:10.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:10.081
  Apr 15 06:45:10.087: INFO: Creating deployment "webserver-deployment"
  Apr 15 06:45:10.099: INFO: Waiting for observed generation 1
  E0415 06:45:10.557909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:11.558109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:12.205: INFO: Waiting for all required pods to come up
  Apr 15 06:45:12.246: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 04/15/24 06:45:12.246
  E0415 06:45:12.558570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:13.558934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:14.375: INFO: Waiting for deployment "webserver-deployment" to complete
  Apr 15 06:45:14.389: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Apr 15 06:45:14.412: INFO: Updating deployment webserver-deployment
  Apr 15 06:45:14.412: INFO: Waiting for observed generation 2
  E0415 06:45:14.559556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:15.560429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:16.432: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Apr 15 06:45:16.440: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Apr 15 06:45:16.454: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 15 06:45:16.477: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Apr 15 06:45:16.477: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Apr 15 06:45:16.484: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 15 06:45:16.500: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Apr 15 06:45:16.501: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Apr 15 06:45:16.529: INFO: Updating deployment webserver-deployment
  Apr 15 06:45:16.530: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Apr 15 06:45:16.547: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  E0415 06:45:16.561277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:16.562: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Apr 15 06:45:16.595: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "469726b9-e2a9-40a3-b576-bdf0b15b57ef",
      ResourceVersion: (string) (len=6) "157200",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 15 06:45:16.696: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8a072764-0c32-4a1d-bc82-9e71bb4b953f",
      ResourceVersion: (string) (len=6) "157204",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "469726b9-e2a9-40a3-b576-bdf0b15b57ef",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 36 39 37 32 36  62 39 2d 65 32 61 39 2d  |\"469726b9-e2a9-|
              00000120  34 30 61 33 2d 62 35 37  36 2d 62 64 66 30 62 31  |40a3-b576-bdf0b1|
              00000130  35 62 35 37 65 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5b57ef\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:45:16.698: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Apr 15 06:45:16.699: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
      ResourceVersion: (string) (len=6) "157201",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "469726b9-e2a9-40a3-b576-bdf0b15b57ef",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 36 39 37 32 36  62 39 2d 65 32 61 39 2d  |\"469726b9-e2a9-|
              00000120  34 30 61 33 2d 62 35 37  36 2d 62 64 66 30 62 31  |40a3-b576-bdf0b1|
              00000130  35 62 35 37 65 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |5b57ef\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:45:16.762: INFO: Pod "webserver-deployment-557759b7c7-4nfxs" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-4nfxs",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "06b4afce-4934-4224-b618-b7b9077d6c5b",
      ResourceVersion: (string) (len=6) "157122",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  35 2e 32 31 39 5c 22 7d  |10.233.65.219\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bnps5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bnps5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.65.219",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.219"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760312,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://297cc11659d53830eea3579c033945f19a1aec086164b67c80124e347efc7d9e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.766: INFO: Pod "webserver-deployment-557759b7c7-4wrkj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-4wrkj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c6c90c52-225c-408a-ae67-b80a0259e937",
      ResourceVersion: (string) (len=6) "157212",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-24ldh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-24ldh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.770: INFO: Pod "webserver-deployment-557759b7c7-5thnd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-5thnd",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2d539014-609b-4d8a-b4e7-00d13cdc8515",
      ResourceVersion: (string) (len=6) "157116",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  35 2e 32 32 30 5c 22 7d  |10.233.65.220\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2spc6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2spc6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.65.220",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.220"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760312,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://8909ce1da9eb08facb565897edb1c5f46596b751018e37a020c432a6f3a9e2fa",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.776: INFO: Pod "webserver-deployment-557759b7c7-6z26z" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-6z26z",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6fda935a-bdd7-4f1a-a5ef-8c714d993578",
      ResourceVersion: (string) (len=6) "157224",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7xdxt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7xdxt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.779: INFO: Pod "webserver-deployment-557759b7c7-7678w" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-7678w",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c8088508-08dc-4acd-911f-5b1e9c674a60",
      ResourceVersion: (string) (len=6) "157096",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  34 2e 31 38 38 5c 22 7d  |10.233.64.188\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-b6xkl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-b6xkl",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.141",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.64.188",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.64.188"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760311,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://92acfd64c830cc363a1e0e3c6a9ca7e947540ecdf69f09997cabb0dec8d6de55",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.788: INFO: Pod "webserver-deployment-557759b7c7-9lhrg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-9lhrg",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6ebcbc97-e0ed-4e6e-bc03-895096ec7a48",
      ResourceVersion: (string) (len=6) "157091",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  34 2e 31 39 30 5c 22 7d  |10.233.64.190\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4n6dp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4n6dp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.141",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.64.190",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.64.190"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760311,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://ae303151060acd330414558d967016afb4b671afecee95718d48c35e1cd33fc6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.797: INFO: Pod "webserver-deployment-557759b7c7-9wgm9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-9wgm9",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bd8b8a2c-4648-4637-b1b0-aa965ad50610",
      ResourceVersion: (string) (len=6) "157118",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  35 2e 32 32 31 5c 22 7d  |10.233.65.221\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gvpjb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gvpjb",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760313,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.65.221",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.65.221"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760312,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://222502329aaba0bf8255de15f216dce7bddda842f6b1847e9ff6bc50b60b456e",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.802: INFO: Pod "webserver-deployment-557759b7c7-9xl8n" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-9xl8n",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "93a0d79c-4b51-4e7b-bb30-eacc76ed38e6",
      ResourceVersion: (string) (len=6) "157077",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760311,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 31 36 36 5c 22 7d  |10.233.66.166\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qcrhh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qcrhh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760311,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760311,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.206",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.66.166",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.166"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760311,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://8ccc299593bf368fd996f7ed48d0a2f64c5ba9b9a7ba9c5929885a74a48e01a7",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.807: INFO: Pod "webserver-deployment-557759b7c7-frzqq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-frzqq",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "10094ca9-1d22-41bf-a53c-adfbc283e592",
      ResourceVersion: (string) (len=6) "157107",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 31 36 37 5c 22 7d  |10.233.66.167\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xklb8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xklb8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.206",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.66.167",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.167"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760311,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://5ff6687b55daf42a21ecbe087c3f71090a488a7824f7a3bf3495c01d968111ca",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.814: INFO: Pod "webserver-deployment-557759b7c7-gbctq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-gbctq",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f8380ef2-8b18-463b-a3c4-271cf523478f",
      ResourceVersion: (string) (len=6) "157216",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-s9k4k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-s9k4k",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.819: INFO: Pod "webserver-deployment-557759b7c7-gm8pz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-gm8pz",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e4c8c045-d497-48c3-a429-5796632d037a",
      ResourceVersion: (string) (len=6) "157218",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t8rpp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t8rpp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.823: INFO: Pod "webserver-deployment-557759b7c7-jtvdm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-jtvdm",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7bec4b21-2d08-4997-82f8-9f5a8249feb9",
      ResourceVersion: (string) (len=6) "157085",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  34 2e 31 38 39 5c 22 7d  |10.233.64.189\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lt5ps",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lt5ps",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760312,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760310,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.141",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.64.189",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.64.189"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760310,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760311,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://e96d501f08503d7c038076c725713de4dba8d800bb32828296dec2c7e189df54",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.828: INFO: Pod "webserver-deployment-557759b7c7-kxh6c" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-kxh6c",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c549f5f0-7d2d-4fd4-8dc1-f7c1d3f32ed1",
      ResourceVersion: (string) (len=6) "157222",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wlz75",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wlz75",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.834: INFO: Pod "webserver-deployment-557759b7c7-ll92z" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-ll92z",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8722015c-8152-4f6e-aaa8-a0cd8200f702",
      ResourceVersion: (string) (len=6) "157219",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-llpss",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-llpss",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.837: INFO: Pod "webserver-deployment-557759b7c7-nlksb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-nlksb",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "235af185-3fc9-4a26-85a6-112214205cf3",
      ResourceVersion: (string) (len=6) "157207",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "d013de89-ee37-4440-8982-58c2a9c0a62b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 30  31 33 64 65 38 39 2d 65  |d\":\"d013de89-e|
              00000090  65 33 37 2d 34 34 34 30  2d 38 39 38 32 2d 35 38  |e37-4440-8982-58|
              000000a0  63 32 61 39 63 30 61 36  32 62 5c 22 7d 22 3a 7b  |c2a9c0a62b\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jfmf8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jfmf8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.840: INFO: Pod "webserver-deployment-9b4f5bf69-5bqmc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-5bqmc",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cf811423-fa83-4910-a7b3-bfbbe88b0b6f",
      ResourceVersion: (string) (len=6) "157173",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "8a072764-0c32-4a1d-bc82-9e71bb4b953f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 61  30 37 32 37 36 34 2d 30  |d\":\"8a072764-0|
              00000090  63 33 32 2d 34 61 31 64  2d 62 63 38 32 2d 39 65  |c32-4a1d-bc82-9e|
              000000a0  37 31 62 62 34 62 39 35  33 66 5c 22 7d 22 3a 7b  |71bb4b953f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-k8gfg",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-k8gfg",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.206",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.846: INFO: Pod "webserver-deployment-9b4f5bf69-dml6k" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-dml6k",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3f08dfdd-4920-4a5b-826b-80052c36e451",
      ResourceVersion: (string) (len=6) "157174",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "8a072764-0c32-4a1d-bc82-9e71bb4b953f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 61  30 37 32 37 36 34 2d 30  |d\":\"8a072764-0|
              00000090  63 33 32 2d 34 61 31 64  2d 62 63 38 32 2d 39 65  |c32-4a1d-bc82-9e|
              000000a0  37 31 62 62 34 62 39 35  33 66 5c 22 7d 22 3a 7b  |71bb4b953f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-k8ftf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-k8ftf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.854: INFO: Pod "webserver-deployment-9b4f5bf69-lvh9q" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-lvh9q",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a7d7e44c-1db8-4fcf-800d-fca0fcaa25b9",
      ResourceVersion: (string) (len=6) "157145",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "8a072764-0c32-4a1d-bc82-9e71bb4b953f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 61  30 37 32 37 36 34 2d 30  |d\":\"8a072764-0|
              00000090  63 33 32 2d 34 61 31 64  2d 62 63 38 32 2d 39 65  |c32-4a1d-bc82-9e|
              000000a0  37 31 62 62 34 62 39 35  33 66 5c 22 7d 22 3a 7b  |71bb4b953f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tkqkr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tkqkr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.206",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.858: INFO: Pod "webserver-deployment-9b4f5bf69-png99" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-png99",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a9ed212f-f132-4918-b7b0-668eb9322bc4",
      ResourceVersion: (string) (len=6) "157220",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "8a072764-0c32-4a1d-bc82-9e71bb4b953f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 61  30 37 32 37 36 34 2d 30  |d\":\"8a072764-0|
              00000090  63 33 32 2d 34 61 31 64  2d 62 63 38 32 2d 39 65  |c32-4a1d-bc82-9e|
              000000a0  37 31 62 62 34 62 39 35  33 66 5c 22 7d 22 3a 7b  |71bb4b953f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xqgpv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xqgpv",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.861: INFO: Pod "webserver-deployment-9b4f5bf69-qlzzv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-qlzzv",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a6b6c111-9be3-4f49-b22d-2881a8abd57b",
      ResourceVersion: (string) (len=6) "157152",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "8a072764-0c32-4a1d-bc82-9e71bb4b953f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 61  30 37 32 37 36 34 2d 30  |d\":\"8a072764-0|
              00000090  63 33 32 2d 34 61 31 64  2d 62 63 38 32 2d 39 65  |c32-4a1d-bc82-9e|
              000000a0  37 31 62 62 34 62 39 35  33 66 5c 22 7d 22 3a 7b  |71bb4b953f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-c6kfk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-c6kfk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.865: INFO: Pod "webserver-deployment-9b4f5bf69-r2mdj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-r2mdj",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "59f1e0cf-b17d-4ccf-b11f-f55d412f0d42",
      ResourceVersion: (string) (len=6) "157221",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "8a072764-0c32-4a1d-bc82-9e71bb4b953f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 61  30 37 32 37 36 34 2d 30  |d\":\"8a072764-0|
              00000090  63 33 32 2d 34 61 31 64  2d 62 63 38 32 2d 39 65  |c32-4a1d-bc82-9e|
              000000a0  37 31 62 62 34 62 39 35  33 66 5c 22 7d 22 3a 7b  |71bb4b953f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wphxs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wphxs",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.869: INFO: Pod "webserver-deployment-9b4f5bf69-r2ng2" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-r2ng2",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0ad09937-534c-421b-af99-b80980704bb2",
      ResourceVersion: (string) (len=6) "157149",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "8a072764-0c32-4a1d-bc82-9e71bb4b953f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 61  30 37 32 37 36 34 2d 30  |d\":\"8a072764-0|
              00000090  63 33 32 2d 34 61 31 64  2d 62 63 38 32 2d 39 65  |c32-4a1d-bc82-9e|
              000000a0  37 31 62 62 34 62 39 35  33 66 5c 22 7d 22 3a 7b  |71bb4b953f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tv9ws",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tv9ws",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760314,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.141",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760314,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.873: INFO: Pod "webserver-deployment-9b4f5bf69-tskkb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-tskkb",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-2219",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7308eab3-105d-4c72-8e3d-143f9549bf3d",
      ResourceVersion: (string) (len=6) "157217",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760316,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "8a072764-0c32-4a1d-bc82-9e71bb4b953f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 61  30 37 32 37 36 34 2d 30  |d\":\"8a072764-0|
              00000090  63 33 32 2d 34 61 31 64  2d 62 63 38 32 2d 39 65  |c32-4a1d-bc82-9e|
              000000a0  37 31 62 62 34 62 39 35  33 66 5c 22 7d 22 3a 7b  |71bb4b953f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bm8jl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bm8jl",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-1",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760316,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:45:16.877: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2219" for this suite. @ 04/15/24 06:45:17.055
â€¢ [7.129 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 04/15/24 06:45:17.167
  Apr 15 06:45:17.168: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename field-validation @ 04/15/24 06:45:17.18
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:17.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:17.399
  STEP: apply creating a deployment @ 04/15/24 06:45:17.409
  Apr 15 06:45:17.412: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:45:17.561593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "field-validation-1357" for this suite. @ 04/15/24 06:45:17.612
â€¢ [0.519 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 04/15/24 06:45:17.702
  Apr 15 06:45:17.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename containers @ 04/15/24 06:45:17.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:17.816
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:17.825
  E0415 06:45:18.562121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:19.562699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:19.995: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-711" for this suite. @ 04/15/24 06:45:20.013
â€¢ [2.337 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 04/15/24 06:45:20.049
  Apr 15 06:45:20.050: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-runtime @ 04/15/24 06:45:20.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:20.081
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:20.087
  STEP: create the container @ 04/15/24 06:45:20.093
  W0415 06:45:20.110052      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/15/24 06:45:20.11
  E0415 06:45:20.563217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:21.564238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:22.565297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/15/24 06:45:23.179
  STEP: the container should be terminated @ 04/15/24 06:45:23.207
  STEP: the termination message should be set @ 04/15/24 06:45:23.207
  Apr 15 06:45:23.208: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/15/24 06:45:23.208
  Apr 15 06:45:23.486: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:45:23.565593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "container-runtime-8534" for this suite. @ 04/15/24 06:45:23.674
â€¢ [3.738 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 04/15/24 06:45:23.794
  Apr 15 06:45:23.794: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename dns @ 04/15/24 06:45:23.798
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:24.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:24.022
  STEP: Creating a test headless service @ 04/15/24 06:45:24.034
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2074.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2074.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2074.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2074.svc.cluster.local;sleep 1; done
   @ 04/15/24 06:45:24.082
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2074.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2074.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2074.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2074.svc.cluster.local;sleep 1; done
   @ 04/15/24 06:45:24.082
  STEP: creating a pod to probe DNS @ 04/15/24 06:45:24.082
  STEP: submitting the pod to kubernetes @ 04/15/24 06:45:24.082
  E0415 06:45:24.565830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:25.566330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:26.566927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:27.567283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/15/24 06:45:28.537
  STEP: looking for the results for each expected name from probers @ 04/15/24 06:45:28.55
  E0415 06:45:28.568007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:28.596: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-2074.svc.cluster.local from pod dns-2074/dns-test-718fcf96-a9cf-4b0a-9689-fd669f52dab4: the server could not find the requested resource (get pods dns-test-718fcf96-a9cf-4b0a-9689-fd669f52dab4)
  Apr 15 06:45:28.616: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local from pod dns-2074/dns-test-718fcf96-a9cf-4b0a-9689-fd669f52dab4: the server could not find the requested resource (get pods dns-test-718fcf96-a9cf-4b0a-9689-fd669f52dab4)
  Apr 15 06:45:28.624: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local from pod dns-2074/dns-test-718fcf96-a9cf-4b0a-9689-fd669f52dab4: the server could not find the requested resource (get pods dns-test-718fcf96-a9cf-4b0a-9689-fd669f52dab4)
  Apr 15 06:45:28.641: INFO: Lookups using dns-2074/dns-test-718fcf96-a9cf-4b0a-9689-fd669f52dab4 failed for: [wheezy_udp@dns-test-service-2.dns-2074.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2074.svc.cluster.local]

  Apr 15 06:45:28.658: INFO: Pod client logs for webserver: 
  Apr 15 06:45:28.671: INFO: Pod client logs for querier: 
  Apr 15 06:45:28.681: INFO: Pod client logs for jessie-querier: 
  E0415 06:45:29.568715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:30.569578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:31.569777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:32.570446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:33.570472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:33.749: INFO: DNS probes using dns-2074/dns-test-718fcf96-a9cf-4b0a-9689-fd669f52dab4 succeeded

  Apr 15 06:45:33.750: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 06:45:33.763
  STEP: deleting the test headless service @ 04/15/24 06:45:33.81
  STEP: Destroying namespace "dns-2074" for this suite. @ 04/15/24 06:45:33.865
â€¢ [10.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service  [Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 04/15/24 06:45:33.889
  Apr 15 06:45:33.889: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 06:45:33.899
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:33.927
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:33.936
  Apr 15 06:45:33.950: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-420" for this suite. @ 04/15/24 06:45:33.961
â€¢ [0.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 04/15/24 06:45:33.981
  Apr 15 06:45:33.981: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename dns @ 04/15/24 06:45:33.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:34.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:34.016
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8785.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8785.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 04/15/24 06:45:34.021
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8785.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8785.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 04/15/24 06:45:34.021
  STEP: creating a pod to probe /etc/hosts @ 04/15/24 06:45:34.022
  STEP: submitting the pod to kubernetes @ 04/15/24 06:45:34.022
  E0415 06:45:34.570682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:35.570886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/15/24 06:45:36.056
  STEP: looking for the results for each expected name from probers @ 04/15/24 06:45:36.065
  Apr 15 06:45:36.120: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-8785/dns-test-e559828f-ec04-4c17-86d5-5ffc8bbcdd26: the server could not find the requested resource (get pods dns-test-e559828f-ec04-4c17-86d5-5ffc8bbcdd26)
  Apr 15 06:45:36.121: INFO: Lookups using dns-8785/dns-test-e559828f-ec04-4c17-86d5-5ffc8bbcdd26 failed for: [jessie_hosts@dns-querier-1]

  Apr 15 06:45:36.141: INFO: Pod client logs for webserver: 
  Apr 15 06:45:36.159: INFO: Pod client logs for querier: 
  Apr 15 06:45:36.177: INFO: Pod client logs for jessie-querier: 
  E0415 06:45:36.571874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:37.572079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:38.572923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:39.573131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:40.573960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:41.214: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-8785/dns-test-e559828f-ec04-4c17-86d5-5ffc8bbcdd26: the server could not find the requested resource (get pods dns-test-e559828f-ec04-4c17-86d5-5ffc8bbcdd26)
  Apr 15 06:45:41.214: INFO: Lookups using dns-8785/dns-test-e559828f-ec04-4c17-86d5-5ffc8bbcdd26 failed for: [jessie_hosts@dns-querier-1]

  Apr 15 06:45:41.240: INFO: Pod client logs for webserver: 
  Apr 15 06:45:41.255: INFO: Pod client logs for querier: 
  Apr 15 06:45:41.274: INFO: Pod client logs for jessie-querier: 
  E0415 06:45:41.575015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:42.576038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:43.576513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:44.576461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:45.576742      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:46.211: INFO: DNS probes using dns-8785/dns-test-e559828f-ec04-4c17-86d5-5ffc8bbcdd26 succeeded

  Apr 15 06:45:46.211: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 06:45:46.222
  STEP: Destroying namespace "dns-8785" for this suite. @ 04/15/24 06:45:46.254
â€¢ [12.311 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 04/15/24 06:45:46.295
  Apr 15 06:45:46.295: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:45:46.3
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:46.333
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:46.341
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:45:46.346
  E0415 06:45:46.577493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:47.578623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:48.578159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:49.578412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:45:50.395
  Apr 15 06:45:50.406: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-f88e9313-2282-47ab-9253-3886d492b9dc container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:45:50.42
  Apr 15 06:45:50.463: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1797" for this suite. @ 04/15/24 06:45:50.474
â€¢ [4.196 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
test/e2e/apps/statefulset.go:901
  STEP: Creating a kubernetes client @ 04/15/24 06:45:50.498
  Apr 15 06:45:50.498: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename statefulset @ 04/15/24 06:45:50.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:45:50.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:45:50.546
  STEP: Creating service test in namespace statefulset-8547 @ 04/15/24 06:45:50.561
  STEP: Creating statefulset ss in namespace statefulset-8547 @ 04/15/24 06:45:50.581
  E0415 06:45:50.586605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:45:50.618: INFO: Found 0 stateful pods, waiting for 1
  E0415 06:45:51.586694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:52.586955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:53.587028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:54.587662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:55.588558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:56.588477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:57.588956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:58.589518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:45:59.590080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:00.590749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:00.626: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 04/15/24 06:46:00.642
  STEP: updating a scale subresource @ 04/15/24 06:46:00.652
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/15/24 06:46:00.672
  STEP: Patch a scale subresource @ 04/15/24 06:46:00.695
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/15/24 06:46:00.792
  Apr 15 06:46:00.833: INFO: Deleting all statefulset in ns statefulset-8547
  Apr 15 06:46:00.841: INFO: Scaling statefulset ss to 0
  E0415 06:46:01.591397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:02.591334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:03.592079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:04.592500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:05.592966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:06.593283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:07.593546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:08.593792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:09.594054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:10.594355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:10.929: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 15 06:46:10.941: INFO: Deleting statefulset ss
  Apr 15 06:46:10.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8547" for this suite. @ 04/15/24 06:46:11.021
â€¢ [20.540 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 04/15/24 06:46:11.076
  Apr 15 06:46:11.076: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 06:46:11.085
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:11.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:11.138
  STEP: creating the pod @ 04/15/24 06:46:11.147
  STEP: setting up watch @ 04/15/24 06:46:11.148
  STEP: submitting the pod to kubernetes @ 04/15/24 06:46:11.256
  STEP: verifying the pod is in kubernetes @ 04/15/24 06:46:11.278
  STEP: verifying pod creation was observed @ 04/15/24 06:46:11.297
  E0415 06:46:11.595406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:12.595636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/15/24 06:46:13.33
  STEP: verifying pod deletion was observed @ 04/15/24 06:46:13.343
  E0415 06:46:13.595699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:14.596286      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:15.597082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:16.145: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7792" for this suite. @ 04/15/24 06:46:16.186
â€¢ [5.184 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:217
  STEP: Creating a kubernetes client @ 04/15/24 06:46:16.274
  Apr 15 06:46:16.274: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:46:16.28
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:16.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:16.33
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/15/24 06:46:16.344
  E0415 06:46:16.597923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:17.597906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:18.598472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:19.598264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:46:20.407
  Apr 15 06:46:20.418: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-15d78a74-7fce-42fc-908d-43193aa61945 container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:46:20.448
  Apr 15 06:46:20.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4176" for this suite. @ 04/15/24 06:46:20.502
â€¢ [4.245 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 04/15/24 06:46:20.548
  Apr 15 06:46:20.548: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/15/24 06:46:20.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:20.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:20.596
  E0415 06:46:20.598584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:20.607: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:46:21.599119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:22.599448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/15/24 06:46:22.769
  Apr 15 06:46:22.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-7099 --namespace=crd-publish-openapi-7099 create -f -'
  E0415 06:46:23.600342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:24.291: INFO: stderr: ""
  Apr 15 06:46:24.291: INFO: stdout: "e2e-test-crd-publish-openapi-1478-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 15 06:46:24.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-7099 --namespace=crd-publish-openapi-7099 delete e2e-test-crd-publish-openapi-1478-crds test-cr'
  E0415 06:46:24.600127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:24.666: INFO: stderr: ""
  Apr 15 06:46:24.666: INFO: stdout: "e2e-test-crd-publish-openapi-1478-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Apr 15 06:46:24.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-7099 --namespace=crd-publish-openapi-7099 apply -f -'
  Apr 15 06:46:25.085: INFO: stderr: ""
  Apr 15 06:46:25.086: INFO: stdout: "e2e-test-crd-publish-openapi-1478-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 15 06:46:25.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-7099 --namespace=crd-publish-openapi-7099 delete e2e-test-crd-publish-openapi-1478-crds test-cr'
  Apr 15 06:46:25.310: INFO: stderr: ""
  Apr 15 06:46:25.310: INFO: stdout: "e2e-test-crd-publish-openapi-1478-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 04/15/24 06:46:25.31
  Apr 15 06:46:25.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-7099 explain e2e-test-crd-publish-openapi-1478-crds'
  E0415 06:46:25.601102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:26.470: INFO: stderr: ""
  Apr 15 06:46:26.470: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-1478-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0415 06:46:26.602279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:27.602958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:28.446: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7099" for this suite. @ 04/15/24 06:46:28.472
â€¢ [7.947 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 04/15/24 06:46:28.496
  Apr 15 06:46:28.496: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename var-expansion @ 04/15/24 06:46:28.501
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:28.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:28.547
  STEP: Creating a pod to test env composition @ 04/15/24 06:46:28.553
  E0415 06:46:28.603637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:29.604051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:30.603880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:31.608723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:32.606682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:46:32.61
  Apr 15 06:46:32.617: INFO: Trying to get logs from node phiefi7ighaa-3 pod var-expansion-9f634986-6de4-4823-9a47-efdab66777a7 container dapi-container: <nil>
  STEP: delete the pod @ 04/15/24 06:46:32.63
  Apr 15 06:46:32.659: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8935" for this suite. @ 04/15/24 06:46:32.672
â€¢ [4.191 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 04/15/24 06:46:32.692
  Apr 15 06:46:32.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename init-container @ 04/15/24 06:46:32.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:32.724
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:32.729
  STEP: creating the pod @ 04/15/24 06:46:32.735
  Apr 15 06:46:32.736: INFO: PodSpec: initContainers in spec.initContainers
  E0415 06:46:33.607585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:34.608550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:35.608574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:36.608817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:37.357: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7655" for this suite. @ 04/15/24 06:46:37.371
â€¢ [4.697 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]
test/e2e/kubectl/kubectl.go:996
  STEP: Creating a kubernetes client @ 04/15/24 06:46:37.404
  Apr 15 06:46:37.404: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:46:37.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:37.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:37.463
  STEP: create deployment with httpd image @ 04/15/24 06:46:37.47
  Apr 15 06:46:37.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-7344 create -f -'
  E0415 06:46:37.608692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:38.609988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:39.548: INFO: stderr: ""
  Apr 15 06:46:39.548: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 04/15/24 06:46:39.548
  Apr 15 06:46:39.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-7344 diff -f -'
  E0415 06:46:39.611324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:40.100: INFO: rc: 1
  Apr 15 06:46:40.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-7344 delete -f -'
  Apr 15 06:46:40.366: INFO: stderr: ""
  Apr 15 06:46:40.366: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Apr 15 06:46:40.366: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7344" for this suite. @ 04/15/24 06:46:40.384
â€¢ [3.000 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 04/15/24 06:46:40.405
  Apr 15 06:46:40.405: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:46:40.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:40.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:40.462
  STEP: Creating projection with secret that has name projected-secret-test-map-127d5768-2045-49fb-bbba-259a46cdf0d9 @ 04/15/24 06:46:40.47
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:46:40.483
  E0415 06:46:40.610949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:41.611484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:42.611580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:43.611537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:46:44.541
  Apr 15 06:46:44.553: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-secrets-9ba03c3d-4eb9-414f-82bd-775b18c97bec container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:46:44.569
  Apr 15 06:46:44.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:46:44.612485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "projected-6525" for this suite. @ 04/15/24 06:46:44.621
â€¢ [4.235 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 04/15/24 06:46:44.643
  Apr 15 06:46:44.644: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename disruption @ 04/15/24 06:46:44.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:44.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:44.696
  STEP: creating the pdb @ 04/15/24 06:46:44.704
  STEP: Waiting for the pdb to be processed @ 04/15/24 06:46:44.723
  E0415 06:46:45.613069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:46.613255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 04/15/24 06:46:46.749
  STEP: Waiting for the pdb to be processed @ 04/15/24 06:46:46.767
  E0415 06:46:47.613746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:48.614114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 04/15/24 06:46:48.787
  STEP: Waiting for the pdb to be processed @ 04/15/24 06:46:48.823
  STEP: Waiting for the pdb to be deleted @ 04/15/24 06:46:48.861
  Apr 15 06:46:48.872: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-4739" for this suite. @ 04/15/24 06:46:48.883
â€¢ [4.259 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]
test/e2e/common/node/runtimeclass.go:189
  STEP: Creating a kubernetes client @ 04/15/24 06:46:48.904
  Apr 15 06:46:48.904: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename runtimeclass @ 04/15/24 06:46:48.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:48.937
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:48.946
  STEP: getting /apis @ 04/15/24 06:46:48.953
  STEP: getting /apis/node.k8s.io @ 04/15/24 06:46:48.964
  STEP: getting /apis/node.k8s.io/v1 @ 04/15/24 06:46:48.967
  STEP: creating @ 04/15/24 06:46:48.971
  STEP: watching @ 04/15/24 06:46:49.019
  Apr 15 06:46:49.019: INFO: starting watch
  STEP: getting @ 04/15/24 06:46:49.04
  STEP: listing @ 04/15/24 06:46:49.056
  STEP: patching @ 04/15/24 06:46:49.067
  STEP: updating @ 04/15/24 06:46:49.078
  Apr 15 06:46:49.093: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 04/15/24 06:46:49.094
  STEP: deleting a collection @ 04/15/24 06:46:49.156
  Apr 15 06:46:49.203: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2616" for this suite. @ 04/15/24 06:46:49.216
â€¢ [0.329 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 04/15/24 06:46:49.248
  Apr 15 06:46:49.248: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename var-expansion @ 04/15/24 06:46:49.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:49.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:49.299
  E0415 06:46:49.614322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:50.614365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:51.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 06:46:51.361: INFO: Deleting pod "var-expansion-c3fe0ebb-bf4b-4be5-83ad-86e88528c9ff" in namespace "var-expansion-9277"
  Apr 15 06:46:51.377: INFO: Wait up to 5m0s for pod "var-expansion-c3fe0ebb-bf4b-4be5-83ad-86e88528c9ff" to be fully deleted
  E0415 06:46:51.615506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:52.615784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-9277" for this suite. @ 04/15/24 06:46:53.397
â€¢ [4.172 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 04/15/24 06:46:53.434
  Apr 15 06:46:53.434: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename deployment @ 04/15/24 06:46:53.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:46:53.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:46:53.506
  Apr 15 06:46:53.514: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Apr 15 06:46:53.545: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0415 06:46:53.616714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:54.616267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:55.616810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:56.617110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:46:57.617322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:58.566: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/15/24 06:46:58.566
  Apr 15 06:46:58.567: INFO: Creating deployment "test-rolling-update-deployment"
  Apr 15 06:46:58.594: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  E0415 06:46:58.617806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:46:58.626: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0415 06:46:59.618764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:00.619100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:00.646: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Apr 15 06:47:00.658: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Apr 15 06:47:00.690: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "45a88747-24bd-49b4-909b-f85d6b8a1b39",
      ResourceVersion: (string) (len=6) "158280",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760418,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760418,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760420,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760418,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760418,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760420,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760418,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-7ddb77f68b\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 15 06:47:00.719: INFO: New ReplicaSet "test-rolling-update-deployment-7ddb77f68b" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f4c395f1-4367-4996-8e7b-364f1df011b7",
      ResourceVersion: (string) (len=6) "158269",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760418,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "45a88747-24bd-49b4-909b-f85d6b8a1b39",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760418,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 35 61 38 38 37  34 37 2d 32 34 62 64 2d  |\"45a88747-24bd-|
              00000120  34 39 62 34 2d 39 30 39  62 2d 66 38 35 64 36 62  |49b4-909b-f85d6b|
              00000130  38 61 31 62 33 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |8a1b39\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760420,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:47:00.721: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Apr 15 06:47:00.721: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dfceea65-83df-48e4-a648-75da0d290b6c",
      ResourceVersion: (string) (len=6) "158279",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760413,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "45a88747-24bd-49b4-909b-f85d6b8a1b39",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760413,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760420,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 34 35 61 38 38 37 34  |"uid\":\"45a8874|
              000000b0  37 2d 32 34 62 64 2d 34  39 62 34 2d 39 30 39 62  |7-24bd-49b4-909b|
              000000c0  2d 66 38 35 64 36 62 38  61 31 62 33 39 5c 22 7d  |-f85d6b8a1b39\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760420,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:47:00.733: INFO: Pod "test-rolling-update-deployment-7ddb77f68b-zj565" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-7ddb77f68b-zj565",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-7ddb77f68b-",
      Namespace: (string) (len=15) "deployment-1288",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "85b9462d-1dc8-43ed-ad41-5458b17b3c2b",
      ResourceVersion: (string) (len=6) "158268",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760418,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7ddb77f68b"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-7ddb77f68b",
          UID: (types.UID) (len=36) "f4c395f1-4367-4996-8e7b-364f1df011b7",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760418,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 34  63 33 39 35 66 31 2d 34  |d\":\"f4c395f1-4|
              00000090  33 36 37 2d 34 39 39 36  2d 38 65 37 62 2d 33 36  |367-4996-8e7b-36|
              000000a0  34 66 31 64 66 30 31 31  62 37 5c 22 7d 22 3a 7b  |4f1df011b7\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760420,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 31 39 34 5c 22 7d  |10.233.66.194\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-z64jh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-z64jh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760418,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760420,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760420,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760418,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.206",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.66.194",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.194"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760418,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760419,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:c9997bf8d2e223d7d2a0078dcfb11a653e9b16cf09418829ec03e1d57ca9628a",
          ContainerID: (string) (len=72) "cri-o://7442be92a6cb7312f232e7fae57e1ee705c87a78936ed469b0c6fee330bc27b9",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:47:00.737: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1288" for this suite. @ 04/15/24 06:47:00.751
â€¢ [7.343 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
test/e2e/apimachinery/resource_quota.go:232
  STEP: Creating a kubernetes client @ 04/15/24 06:47:00.782
  Apr 15 06:47:00.782: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 06:47:00.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:00.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:00.831
  STEP: Counting existing ResourceQuota @ 04/15/24 06:47:00.84
  E0415 06:47:01.620374      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:02.621110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:03.622217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:04.624620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:05.623704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/15/24 06:47:05.851
  STEP: Ensuring resource quota status is calculated @ 04/15/24 06:47:05.877
  E0415 06:47:06.623352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:07.624663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 04/15/24 06:47:07.887
  STEP: Ensuring ResourceQuota status captures the pod usage @ 04/15/24 06:47:07.919
  E0415 06:47:08.625621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:09.626037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 04/15/24 06:47:09.928
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 04/15/24 06:47:09.933
  STEP: Ensuring a pod cannot update its resource requirements @ 04/15/24 06:47:09.938
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 04/15/24 06:47:09.948
  E0415 06:47:10.626236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:11.626928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/15/24 06:47:11.958
  STEP: Ensuring resource quota status released the pod usage @ 04/15/24 06:47:11.987
  E0415 06:47:12.627570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:13.627894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:13.995: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6413" for this suite. @ 04/15/24 06:47:14.008
â€¢ [13.247 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
test/e2e/apimachinery/resource_quota.go:395
  STEP: Creating a kubernetes client @ 04/15/24 06:47:14.033
  Apr 15 06:47:14.033: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 06:47:14.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:14.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:14.078
  STEP: Counting existing ResourceQuota @ 04/15/24 06:47:14.087
  E0415 06:47:14.628873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:15.629439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:16.630133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:17.630966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:18.630976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/15/24 06:47:19.098
  STEP: Ensuring resource quota status is calculated @ 04/15/24 06:47:19.119
  E0415 06:47:19.631088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:20.632292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 04/15/24 06:47:21.129
  STEP: Ensuring resource quota status captures replication controller creation @ 04/15/24 06:47:21.156
  E0415 06:47:21.632501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:22.633356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 04/15/24 06:47:23.166
  STEP: Ensuring resource quota status released usage @ 04/15/24 06:47:23.185
  E0415 06:47:23.634092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:24.634641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:25.196: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4759" for this suite. @ 04/15/24 06:47:25.209
â€¢ [11.197 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 04/15/24 06:47:25.234
  Apr 15 06:47:25.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:47:25.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:25.273
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:25.279
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:47:25.284
  E0415 06:47:25.635321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:26.635948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:27.635919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:28.636133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:47:29.35
  Apr 15 06:47:29.368: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-0ad191ed-60d2-42f9-a5cf-aedbcc0ba53b container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:47:29.387
  Apr 15 06:47:29.432: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1824" for this suite. @ 04/15/24 06:47:29.443
â€¢ [4.226 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 04/15/24 06:47:29.464
  Apr 15 06:47:29.464: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename field-validation @ 04/15/24 06:47:29.47
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:29.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:29.516
  Apr 15 06:47:29.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:47:29.637532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:30.638430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:31.638267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0415 06:47:32.280576      13 warnings.go:70] unknown field "alpha"
  W0415 06:47:32.280953      13 warnings.go:70] unknown field "beta"
  W0415 06:47:32.281268      13 warnings.go:70] unknown field "delta"
  W0415 06:47:32.281554      13 warnings.go:70] unknown field "epsilon"
  W0415 06:47:32.281824      13 warnings.go:70] unknown field "gamma"
  E0415 06:47:32.639082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:32.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4240" for this suite. @ 04/15/24 06:47:32.887
â€¢ [3.437 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 04/15/24 06:47:32.905
  Apr 15 06:47:32.905: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:47:32.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:32.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:32.943
  STEP: Creating configMap with name configmap-test-upd-ab57d420-6836-4520-b6a0-8eff36810670 @ 04/15/24 06:47:32.959
  STEP: Creating the pod @ 04/15/24 06:47:32.97
  E0415 06:47:33.639952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:34.640921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 04/15/24 06:47:35.012
  STEP: Waiting for pod with binary data @ 04/15/24 06:47:35.029
  Apr 15 06:47:35.047: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5858" for this suite. @ 04/15/24 06:47:35.058
â€¢ [2.168 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]
test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 04/15/24 06:47:35.075
  Apr 15 06:47:35.075: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename daemonsets @ 04/15/24 06:47:35.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:35.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:35.166
  STEP: Creating simple DaemonSet "daemon-set" @ 04/15/24 06:47:35.215
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/15/24 06:47:35.228
  Apr 15 06:47:35.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:47:35.245: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:47:35.641776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:36.265: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:47:36.265: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:47:36.642268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:37.270: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 15 06:47:37.270: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 04/15/24 06:47:37.277
  STEP: DeleteCollection of the DaemonSets @ 04/15/24 06:47:37.286
  STEP: Verify that ReplicaSets have been deleted @ 04/15/24 06:47:37.306
  Apr 15 06:47:37.362: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"158502"},"items":null}

  Apr 15 06:47:37.377: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"158502"},"items":[{"metadata":{"name":"daemon-set-8dt97","generateName":"daemon-set-","namespace":"daemonsets-6045","uid":"64815a2b-0bbc-441b-bdfe-6e3bcdd317cc","resourceVersion":"158500","creationTimestamp":"2024-04-15T06:47:35Z","deletionTimestamp":"2024-04-15T06:48:07Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"5d451d0d-cb8c-4eeb-816e-31ab7c8fa2e8","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-15T06:47:35Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d451d0d-cb8c-4eeb-816e-31ab7c8fa2e8\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-15T06:47:37Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.196\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-lfhgt","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-lfhgt","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"phiefi7ighaa-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["phiefi7ighaa-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:35Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:37Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:37Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:35Z"}],"hostIP":"192.168.121.141","podIP":"10.233.64.196","podIPs":[{"ip":"10.233.64.196"}],"startTime":"2024-04-15T06:47:35Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-15T06:47:36Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://1a7d6a46ae326aa70170de243e9d3e77d65fd03f06fc03cf72a85cd7b7f4e74f","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-qks5b","generateName":"daemon-set-","namespace":"daemonsets-6045","uid":"251bcc7d-e85f-403b-ac7a-a8ebd1efa42d","resourceVersion":"158502","creationTimestamp":"2024-04-15T06:47:35Z","deletionTimestamp":"2024-04-15T06:48:07Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"5d451d0d-cb8c-4eeb-816e-31ab7c8fa2e8","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-15T06:47:35Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d451d0d-cb8c-4eeb-816e-31ab7c8fa2e8\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-15T06:47:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.228\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-gpgr2","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-gpgr2","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"phiefi7ighaa-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["phiefi7ighaa-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:35Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:36Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:36Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:35Z"}],"hostIP":"192.168.121.17","podIP":"10.233.65.228","podIPs":[{"ip":"10.233.65.228"}],"startTime":"2024-04-15T06:47:35Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-15T06:47:36Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://f2411560f8fe61ae338f0eb9fbf546913694d85ac345da89fba9ee7030bc2b37","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-wtm8d","generateName":"daemon-set-","namespace":"daemonsets-6045","uid":"6c051ce1-417b-49b7-b1a9-9f53d661b928","resourceVersion":"158499","creationTimestamp":"2024-04-15T06:47:35Z","deletionTimestamp":"2024-04-15T06:48:07Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"5d451d0d-cb8c-4eeb-816e-31ab7c8fa2e8","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-15T06:47:35Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5d451d0d-cb8c-4eeb-816e-31ab7c8fa2e8\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-15T06:47:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.197\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-rnnfc","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-rnnfc","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"phiefi7ighaa-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["phiefi7ighaa-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:35Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:36Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:36Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-15T06:47:35Z"}],"hostIP":"192.168.121.206","podIP":"10.233.66.197","podIPs":[{"ip":"10.233.66.197"}],"startTime":"2024-04-15T06:47:35Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-15T06:47:36Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://0a68e7af65e3269e54ea2918d0cef5d0c5f086df6cb3a71de815cc39b73dd311","started":true}],"qosClass":"BestEffort"}}]}

  Apr 15 06:47:37.457: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6045" for this suite. @ 04/15/24 06:47:37.476
â€¢ [2.421 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 04/15/24 06:47:37.509
  Apr 15 06:47:37.509: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename proxy @ 04/15/24 06:47:37.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:37.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:37.578
  Apr 15 06:47:37.586: INFO: Creating pod...
  E0415 06:47:37.642966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:38.643480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:39.627: INFO: Creating service...
  E0415 06:47:39.644447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:39.662: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/pods/agnhost/proxy/some/path/with/DELETE
  Apr 15 06:47:39.689: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 15 06:47:39.689: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/pods/agnhost/proxy/some/path/with/GET
  Apr 15 06:47:39.706: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 15 06:47:39.708: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/pods/agnhost/proxy/some/path/with/HEAD
  Apr 15 06:47:39.718: INFO: http.Client request:HEAD | StatusCode:200
  Apr 15 06:47:39.718: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/pods/agnhost/proxy/some/path/with/OPTIONS
  Apr 15 06:47:39.726: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 15 06:47:39.726: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/pods/agnhost/proxy/some/path/with/PATCH
  Apr 15 06:47:39.734: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 15 06:47:39.734: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/pods/agnhost/proxy/some/path/with/POST
  Apr 15 06:47:39.744: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 15 06:47:39.745: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/pods/agnhost/proxy/some/path/with/PUT
  Apr 15 06:47:39.766: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 15 06:47:39.766: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/services/test-service/proxy/some/path/with/DELETE
  Apr 15 06:47:39.776: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 15 06:47:39.777: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/services/test-service/proxy/some/path/with/GET
  Apr 15 06:47:39.788: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 15 06:47:39.788: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/services/test-service/proxy/some/path/with/HEAD
  Apr 15 06:47:39.798: INFO: http.Client request:HEAD | StatusCode:200
  Apr 15 06:47:39.798: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/services/test-service/proxy/some/path/with/OPTIONS
  Apr 15 06:47:39.806: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 15 06:47:39.806: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/services/test-service/proxy/some/path/with/PATCH
  Apr 15 06:47:39.823: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 15 06:47:39.823: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/services/test-service/proxy/some/path/with/POST
  Apr 15 06:47:39.834: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 15 06:47:39.834: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7410/services/test-service/proxy/some/path/with/PUT
  Apr 15 06:47:39.844: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 15 06:47:39.844: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7410" for this suite. @ 04/15/24 06:47:39.855
â€¢ [2.361 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:169
  STEP: Creating a kubernetes client @ 04/15/24 06:47:39.878
  Apr 15 06:47:39.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename discovery @ 04/15/24 06:47:39.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:39.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:39.918
  STEP: Setting up server cert @ 04/15/24 06:47:39.928
  E0415 06:47:40.644486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:41.645484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Requesting APIResourceList from "/api/v1" @ 04/15/24 06:47:42.268
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 04/15/24 06:47:42.271
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 04/15/24 06:47:42.273
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 04/15/24 06:47:42.275
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 04/15/24 06:47:42.277
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 04/15/24 06:47:42.279
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 04/15/24 06:47:42.281
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 04/15/24 06:47:42.283
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 04/15/24 06:47:42.286
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 04/15/24 06:47:42.288
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 04/15/24 06:47:42.29
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 04/15/24 06:47:42.292
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 04/15/24 06:47:42.294
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 04/15/24 06:47:42.296
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 04/15/24 06:47:42.298
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 04/15/24 06:47:42.301
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 04/15/24 06:47:42.303
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 04/15/24 06:47:42.305
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 04/15/24 06:47:42.307
  Apr 15 06:47:42.309: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-4218" for this suite. @ 04/15/24 06:47:42.319
â€¢ [2.454 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]
test/e2e/kubectl/kubectl.go:1316
  STEP: Creating a kubernetes client @ 04/15/24 06:47:42.336
  Apr 15 06:47:42.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:47:42.34
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:42.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:42.381
  STEP: validating cluster-info @ 04/15/24 06:47:42.386
  Apr 15 06:47:42.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-9707 cluster-info'
  Apr 15 06:47:42.555: INFO: stderr: ""
  Apr 15 06:47:42.555: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Apr 15 06:47:42.555: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9707" for this suite. @ 04/15/24 06:47:42.566
â€¢ [0.243 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 04/15/24 06:47:42.581
  Apr 15 06:47:42.582: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 06:47:42.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:42.63
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:42.638
  STEP: Create set of pods @ 04/15/24 06:47:42.645
  E0415 06:47:42.646293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:42.671: INFO: created test-pod-1
  Apr 15 06:47:42.701: INFO: created test-pod-2
  Apr 15 06:47:42.724: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 04/15/24 06:47:42.724
  E0415 06:47:43.645976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:44.646850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 04/15/24 06:47:44.898
  Apr 15 06:47:44.918: INFO: Pod quantity 3 is different from expected quantity 0
  E0415 06:47:45.647080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:45.934: INFO: Pod quantity 3 is different from expected quantity 0
  E0415 06:47:46.649070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:46.928: INFO: Pod quantity 3 is different from expected quantity 0
  E0415 06:47:47.649616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:47.932: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3961" for this suite. @ 04/15/24 06:47:47.951
â€¢ [5.389 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
test/e2e/apimachinery/resource_quota.go:101
  STEP: Creating a kubernetes client @ 04/15/24 06:47:47.976
  Apr 15 06:47:47.976: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 06:47:47.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:48.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:48.031
  STEP: Counting existing ResourceQuota @ 04/15/24 06:47:48.041
  E0415 06:47:48.650670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:49.650338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:50.650544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:51.650944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:52.652076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/15/24 06:47:53.052
  STEP: Ensuring resource quota status is calculated @ 04/15/24 06:47:53.067
  E0415 06:47:53.653112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:54.653075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 04/15/24 06:47:55.075
  STEP: Creating a NodePort Service @ 04/15/24 06:47:55.113
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 04/15/24 06:47:55.161
  STEP: Ensuring resource quota status captures service creation @ 04/15/24 06:47:55.201
  E0415 06:47:55.654487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:56.655059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 04/15/24 06:47:57.212
  STEP: Ensuring resource quota status released usage @ 04/15/24 06:47:57.294
  E0415 06:47:57.655212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:47:58.655774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:47:59.357: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9161" for this suite. @ 04/15/24 06:47:59.376
â€¢ [11.416 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 04/15/24 06:47:59.396
  Apr 15 06:47:59.396: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 06:47:59.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:47:59.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:47:59.449
  STEP: Creating secret with name secret-test-adc718af-40d8-4cf5-bb07-096e8efc2ab8 @ 04/15/24 06:47:59.508
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:47:59.523
  E0415 06:47:59.656780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:00.657170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:01.658127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:02.658365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:48:03.604
  Apr 15 06:48:03.615: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-secrets-c35b5c5a-3be6-47e3-98a9-6619750f9639 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:48:03.634
  E0415 06:48:03.659046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:03.677: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7627" for this suite. @ 04/15/24 06:48:03.69
  STEP: Destroying namespace "secret-namespace-3454" for this suite. @ 04/15/24 06:48:03.705
â€¢ [4.329 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
test/e2e/apps/statefulset.go:750
  STEP: Creating a kubernetes client @ 04/15/24 06:48:03.727
  Apr 15 06:48:03.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename statefulset @ 04/15/24 06:48:03.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:48:03.757
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:48:03.763
  STEP: Creating service test in namespace statefulset-416 @ 04/15/24 06:48:03.769
  STEP: Creating stateful set ss in namespace statefulset-416 @ 04/15/24 06:48:03.782
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-416 @ 04/15/24 06:48:03.802
  Apr 15 06:48:03.815: INFO: Found 0 stateful pods, waiting for 1
  E0415 06:48:04.659970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:05.661212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:06.661492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:07.661896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:08.662096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:09.663384      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:10.663549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:11.663814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:12.663753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:13.663941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:13.827: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 04/15/24 06:48:13.828
  Apr 15 06:48:13.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-416 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 15 06:48:14.210: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:48:14.210: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:48:14.210: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 15 06:48:14.216: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E0415 06:48:14.664426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:15.664730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:16.664942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:17.666838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:18.665958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:19.666261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:20.667089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:21.667200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:22.667308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:23.667612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:24.230: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 15 06:48:24.231: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 15 06:48:24.286: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
  Apr 15 06:48:24.286: INFO: ss-0  phiefi7ighaa-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:03 +0000 UTC  }]
  Apr 15 06:48:24.287: INFO: 
  Apr 15 06:48:24.287: INFO: StatefulSet ss has not reached scale 3, at 1
  E0415 06:48:24.669083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:25.300: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98563929s
  E0415 06:48:25.669436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:26.311: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972751811s
  E0415 06:48:26.669869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:27.332: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.96196762s
  E0415 06:48:27.670334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:28.355: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.941287517s
  E0415 06:48:28.670732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:29.368: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.917317948s
  E0415 06:48:29.670600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:30.381: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.904204033s
  E0415 06:48:30.670963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:31.393: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.890888596s
  E0415 06:48:31.672119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:32.407: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.88035041s
  E0415 06:48:32.672341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:33.417: INFO: Verifying statefulset ss doesn't scale past 3 for another 865.26304ms
  E0415 06:48:33.672915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-416 @ 04/15/24 06:48:34.418
  Apr 15 06:48:34.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-416 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0415 06:48:34.672750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:34.745: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 15 06:48:34.745: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 15 06:48:34.745: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 15 06:48:34.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-416 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 15 06:48:35.068: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 15 06:48:35.068: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 15 06:48:35.068: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 15 06:48:35.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-416 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 15 06:48:35.378: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 15 06:48:35.378: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 15 06:48:35.378: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 15 06:48:35.388: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
  E0415 06:48:35.673558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:36.674611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:37.675406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:38.675837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:39.676339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:40.676569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:41.676639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:42.676937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:43.677270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:44.677562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:45.401: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 06:48:45.401: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 06:48:45.401: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 04/15/24 06:48:45.401
  Apr 15 06:48:45.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-416 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0415 06:48:45.678497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:45.737: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:48:45.737: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:48:45.738: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 15 06:48:45.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-416 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 15 06:48:46.050: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:48:46.050: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:48:46.050: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 15 06:48:46.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=statefulset-416 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 15 06:48:46.343: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 15 06:48:46.343: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 15 06:48:46.344: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 15 06:48:46.344: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Apr 15 06:48:46.366: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E0415 06:48:46.679644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:47.679867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:48.680399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:49.681084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:50.682132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:51.683804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:52.683739      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:53.684072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:54.684672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:48:55.685519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:56.392: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 15 06:48:56.392: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 15 06:48:56.392: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 15 06:48:56.436: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
  Apr 15 06:48:56.436: INFO: ss-0  phiefi7ighaa-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:03 +0000 UTC  }]
  Apr 15 06:48:56.436: INFO: ss-1  phiefi7ighaa-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:24 +0000 UTC  }]
  Apr 15 06:48:56.436: INFO: ss-2  phiefi7ighaa-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:24 +0000 UTC  }]
  Apr 15 06:48:56.436: INFO: 
  Apr 15 06:48:56.436: INFO: StatefulSet ss has not reached scale 0, at 3
  E0415 06:48:56.686234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:57.447: INFO: POD   NODE            PHASE      GRACE  CONDITIONS
  Apr 15 06:48:57.448: INFO: ss-1  phiefi7ighaa-2  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:24 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:24 +0000 UTC  }]
  Apr 15 06:48:57.449: INFO: ss-2  phiefi7ighaa-1  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:24 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:46 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-15 06:48:24 +0000 UTC  }]
  Apr 15 06:48:57.450: INFO: 
  Apr 15 06:48:57.451: INFO: StatefulSet ss has not reached scale 0, at 2
  E0415 06:48:57.687099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:58.459: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.973923116s
  E0415 06:48:58.687462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:48:59.467: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.966260642s
  E0415 06:48:59.688594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:00.475: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.958255961s
  E0415 06:49:00.688552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:01.495: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.948376548s
  E0415 06:49:01.689647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:02.513: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.929811851s
  E0415 06:49:02.690068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:03.522: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.912069053s
  E0415 06:49:03.690489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:04.531: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.903230002s
  E0415 06:49:04.691692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:05.541: INFO: Verifying statefulset ss doesn't scale past 0 for another 893.759806ms
  E0415 06:49:05.691403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-416 @ 04/15/24 06:49:06.542
  Apr 15 06:49:06.551: INFO: Scaling statefulset ss to 0
  Apr 15 06:49:06.573: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 15 06:49:06.580: INFO: Deleting all statefulset in ns statefulset-416
  Apr 15 06:49:06.588: INFO: Scaling statefulset ss to 0
  Apr 15 06:49:06.619: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 15 06:49:06.627: INFO: Deleting statefulset ss
  Apr 15 06:49:06.671: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-416" for this suite. @ 04/15/24 06:49:06.683
  E0415 06:49:06.691861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [62.975 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance]
test/e2e/common/node/podtemplates.go:176
  STEP: Creating a kubernetes client @ 04/15/24 06:49:06.71
  Apr 15 06:49:06.710: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename podtemplate @ 04/15/24 06:49:06.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:49:06.748
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:49:06.753
  STEP: Create a pod template @ 04/15/24 06:49:06.758
  STEP: Replace a pod template @ 04/15/24 06:49:06.784
  Apr 15 06:49:06.804: INFO: Found updated podtemplate annotation: "true"

  Apr 15 06:49:06.804: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-9463" for this suite. @ 04/15/24 06:49:06.818
â€¢ [0.122 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:141
  STEP: Creating a kubernetes client @ 04/15/24 06:49:06.832
  Apr 15 06:49:06.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-webhook @ 04/15/24 06:49:06.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:49:06.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:49:06.872
  STEP: Setting up server cert @ 04/15/24 06:49:06.877
  E0415 06:49:07.692483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/15/24 06:49:07.79
  STEP: Deploying the custom resource conversion webhook pod @ 04/15/24 06:49:07.808
  STEP: Wait for the deployment to be ready @ 04/15/24 06:49:07.841
  Apr 15 06:49:07.859: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0415 06:49:08.693352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:09.693580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:09.896: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 49, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 49, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 49, 8, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 49, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-686b5695cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:49:10.694627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:11.694886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 06:49:11.907
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:49:11.946
  E0415 06:49:12.695140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:12.947: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 15 06:49:12.961: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:49:13.696397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:14.696547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:15.696747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/15/24 06:49:15.776
  STEP: v2 custom resource should be converted @ 04/15/24 06:49:15.797
  Apr 15 06:49:15.817: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-4433" for this suite. @ 04/15/24 06:49:16.474
â€¢ [9.661 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 04/15/24 06:49:16.496
  Apr 15 06:49:16.496: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:49:16.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:49:16.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:49:16.55
  STEP: Creating configMap with name projected-configmap-test-volume-map-53c00624-5c05-415a-b5aa-e910e4fa0c98 @ 04/15/24 06:49:16.559
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:49:16.572
  E0415 06:49:16.697464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:17.698121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:18.699276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:19.700013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:49:20.622
  Apr 15 06:49:20.629: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-configmaps-92a4b40b-3eca-44db-ad38-21aebfc745c0 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 06:49:20.646
  Apr 15 06:49:20.680: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5553" for this suite. @ 04/15/24 06:49:20.689
  E0415 06:49:20.701956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [4.207 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:58
  STEP: Creating a kubernetes client @ 04/15/24 06:49:20.707
  Apr 15 06:49:20.707: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/15/24 06:49:20.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:49:20.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:49:20.744
  Apr 15 06:49:20.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:49:21.700753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:21.791: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9221" for this suite. @ 04/15/24 06:49:21.804
â€¢ [1.115 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 04/15/24 06:49:21.837
  Apr 15 06:49:21.837: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 06:49:21.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:49:21.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:49:21.875
  STEP: Creating secret with name secret-test-29c3355d-aaa8-475a-9d72-f474835a5661 @ 04/15/24 06:49:21.882
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:49:21.891
  E0415 06:49:22.701130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:23.701520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:24.701876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:25.703521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:49:25.94
  Apr 15 06:49:25.949: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-secrets-8bf9482b-3648-4247-b782-82f07607370b container secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:49:25.964
  Apr 15 06:49:25.993: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8504" for this suite. @ 04/15/24 06:49:26.002
â€¢ [4.178 seconds]
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:124
  STEP: Creating a kubernetes client @ 04/15/24 06:49:26.017
  Apr 15 06:49:26.017: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pod-network-test @ 04/15/24 06:49:26.024
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:49:26.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:49:26.067
  STEP: Performing setup for networking test in namespace pod-network-test-2364 @ 04/15/24 06:49:26.074
  STEP: creating a selector @ 04/15/24 06:49:26.074
  STEP: Creating the service pods in kubernetes @ 04/15/24 06:49:26.074
  Apr 15 06:49:26.074: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0415 06:49:26.703773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:27.705061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:28.705511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:29.705808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:30.707046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:31.706929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:32.707785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:33.708269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:34.709009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:35.708500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:36.709028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:37.710132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:38.710159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:39.711106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:40.711508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:41.712799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:42.713653      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:43.713600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:44.714614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:45.714942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:46.715055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:47.715768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/15/24 06:49:48.37
  E0415 06:49:48.716371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:49.716672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:50.446: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 15 06:49:50.447: INFO: Going to poll 10.233.64.198 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 15 06:49:50.455: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.198 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2364 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:49:50.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:49:50.457: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:49:50.457: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2364/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.198+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0415 06:49:50.717705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:51.621: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 15 06:49:51.622: INFO: Going to poll 10.233.65.231 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 15 06:49:51.631: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.231 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2364 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:49:51.631: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:49:51.634: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:49:51.634: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2364/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.231+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0415 06:49:51.718404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:52.719520      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:52.782: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 15 06:49:52.782: INFO: Going to poll 10.233.66.206 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Apr 15 06:49:52.792: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.206 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2364 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:49:52.792: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:49:52.794: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:49:52.794: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2364/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.206+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0415 06:49:53.720532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:49:54.012: INFO: Found all 1 expected endpoints: [netserver-2]
  Apr 15 06:49:54.012: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2364" for this suite. @ 04/15/24 06:49:54.029
â€¢ [28.033 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 04/15/24 06:49:54.054
  Apr 15 06:49:54.054: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:49:54.057
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:49:54.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:49:54.1
  STEP: Creating configMap with name configmap-test-upd-046557bb-964f-41ce-9eaf-8cf966a94b99 @ 04/15/24 06:49:54.123
  STEP: Creating the pod @ 04/15/24 06:49:54.138
  E0415 06:49:54.721326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:55.722231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-046557bb-964f-41ce-9eaf-8cf966a94b99 @ 04/15/24 06:49:56.218
  STEP: waiting to observe update in volume @ 04/15/24 06:49:56.23
  E0415 06:49:56.723416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:57.723509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:58.723826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:49:59.724584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:00.725698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:01.725353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:02.727147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:03.727095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:04.727263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:05.727468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:06.727918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:07.728830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:08.729776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:09.730504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:10.731479      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:11.732260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:12.732890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:13.733147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:14.733308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:15.734391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:16.735513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:17.735946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:18.736894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:19.736837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:20.738091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:21.738777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:22.739721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:23.740223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:24.740397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:25.740677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:26.741336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:27.742145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:28.743272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:29.743485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:30.744280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:31.745363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:32.746238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:33.746517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:34.747385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:35.747975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:36.748483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:37.748709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:38.749035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:39.749242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:40.749436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:41.749610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:42.749877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:43.750094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:44.750891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:45.751183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:46.752048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:47.752445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:48.753149      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:49.753513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:50.753688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:51.754350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:52.754538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:53.755697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:54.756528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:55.757502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:56.757766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:57.758462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:50:58.759140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:50:59.040: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2553" for this suite. @ 04/15/24 06:50:59.053
â€¢ [65.020 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
test/e2e/kubectl/kubectl.go:1707
  STEP: Creating a kubernetes client @ 04/15/24 06:50:59.085
  Apr 15 06:50:59.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:50:59.088
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:50:59.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:50:59.148
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/15/24 06:50:59.154
  Apr 15 06:50:59.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-2381 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Apr 15 06:50:59.453: INFO: stderr: ""
  Apr 15 06:50:59.453: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/15/24 06:50:59.453
  Apr 15 06:50:59.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-2381 delete pods e2e-test-httpd-pod'
  E0415 06:50:59.759880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:00.760392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:01.710: INFO: stderr: ""
  Apr 15 06:51:01.710: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 15 06:51:01.710: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2381" for this suite. @ 04/15/24 06:51:01.726
â€¢ [2.659 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]
test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 04/15/24 06:51:01.746
  Apr 15 06:51:01.746: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/15/24 06:51:01.749
  E0415 06:51:01.760466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:01.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:01.797
  STEP: Creating two CSIDrivers @ 04/15/24 06:51:01.807
  STEP: Getting "inline-driver-39f3a109-c8c1-4138-815c-1e7c9d023a6b" & "inline-driver-6dcc1c58-ffce-44af-8ec6-860068f53667" @ 04/15/24 06:51:01.851
  STEP: Patching the CSIDriver "inline-driver-6dcc1c58-ffce-44af-8ec6-860068f53667" @ 04/15/24 06:51:01.864
  STEP: Updating the CSIDriver "inline-driver-6dcc1c58-ffce-44af-8ec6-860068f53667" @ 04/15/24 06:51:01.882
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-1486" @ 04/15/24 06:51:01.898
  STEP: Deleting CSIDriver "inline-driver-39f3a109-c8c1-4138-815c-1e7c9d023a6b" @ 04/15/24 06:51:01.906
  STEP: Confirm deletion of CSIDriver "inline-driver-39f3a109-c8c1-4138-815c-1e7c9d023a6b" @ 04/15/24 06:51:01.921
  STEP: Deleting CSIDriver "inline-driver-6dcc1c58-ffce-44af-8ec6-860068f53667" via DeleteCollection @ 04/15/24 06:51:01.929
  STEP: Confirm deletion of CSIDriver "inline-driver-6dcc1c58-ffce-44af-8ec6-860068f53667" @ 04/15/24 06:51:01.945
  Apr 15 06:51:01.950: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-1486" for this suite. @ 04/15/24 06:51:01.962
â€¢ [0.229 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 04/15/24 06:51:01.976
  Apr 15 06:51:01.976: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:51:01.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:02.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:02.013
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:51:02.018
  E0415 06:51:02.762323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:03.766402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:04.764715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:05.765718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:51:06.075
  Apr 15 06:51:06.086: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-64f6dfbb-1dff-44a1-98cb-25daf0865dba container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:51:06.101
  Apr 15 06:51:06.134: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8063" for this suite. @ 04/15/24 06:51:06.152
â€¢ [4.195 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 04/15/24 06:51:06.173
  Apr 15 06:51:06.173: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/15/24 06:51:06.178
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:06.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:06.225
  STEP: creating a target pod @ 04/15/24 06:51:06.233
  E0415 06:51:06.766650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:07.766777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 04/15/24 06:51:08.283
  E0415 06:51:08.766888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:09.768342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 04/15/24 06:51:10.347
  Apr 15 06:51:10.347: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2077 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:51:10.348: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:51:10.352: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:51:10.352: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-2077/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Apr 15 06:51:10.503: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 04/15/24 06:51:10.519
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 04/15/24 06:51:10.529
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 04/15/24 06:51:10.555
  Apr 15 06:51:10.566: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-2077" for this suite. @ 04/15/24 06:51:10.579
â€¢ [4.423 seconds]
------------------------------
SSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 04/15/24 06:51:10.599
  Apr 15 06:51:10.599: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/15/24 06:51:10.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:10.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:10.657
  STEP: creating a target pod @ 04/15/24 06:51:10.667
  E0415 06:51:10.768495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:11.768471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 04/15/24 06:51:12.715
  E0415 06:51:12.768769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:13.769042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 04/15/24 06:51:14.76
  Apr 15 06:51:14.760: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4136 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:51:14.760: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:51:14.763: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:51:14.763: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-4136/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  E0415 06:51:14.769377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:14.894: INFO: Exec stderr: ""
  Apr 15 06:51:14.910: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-4136" for this suite. @ 04/15/24 06:51:14.922
â€¢ [4.344 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 04/15/24 06:51:14.948
  Apr 15 06:51:14.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename watch @ 04/15/24 06:51:14.953
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:14.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:14.994
  STEP: getting a starting resourceVersion @ 04/15/24 06:51:15.001
  STEP: starting a background goroutine to produce watch events @ 04/15/24 06:51:15.008
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 04/15/24 06:51:15.009
  E0415 06:51:15.770639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:16.769430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:17.767: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:51:17.769740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "watch-8063" for this suite. @ 04/15/24 06:51:17.818
â€¢ [2.922 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 04/15/24 06:51:17.885
  Apr 15 06:51:17.885: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:51:17.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:17.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:17.925
  STEP: Creating configMap with name configmap-test-volume-0d901a5a-d043-431f-bca2-1b3fe92c886b @ 04/15/24 06:51:17.929
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:51:17.942
  E0415 06:51:18.770466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:19.771377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:20.771867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:21.772488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:51:21.986
  Apr 15 06:51:21.994: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-48abf8e3-051a-4e05-a761-f944d4e248a0 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 06:51:22.01
  Apr 15 06:51:22.038: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8142" for this suite. @ 04/15/24 06:51:22.052
â€¢ [4.188 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:97
  STEP: Creating a kubernetes client @ 04/15/24 06:51:22.076
  Apr 15 06:51:22.076: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:51:22.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:22.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:22.132
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/15/24 06:51:22.14
  E0415 06:51:22.773594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:23.774386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:24.774551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:25.775270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:51:26.187
  Apr 15 06:51:26.202: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-20a5ed2a-99f8-4161-99fe-080d28de194a container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:51:26.217
  Apr 15 06:51:26.250: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4682" for this suite. @ 04/15/24 06:51:26.264
â€¢ [4.205 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:45
  STEP: Creating a kubernetes client @ 04/15/24 06:51:26.292
  Apr 15 06:51:26.293: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:51:26.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:26.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:26.329
  STEP: Creating configMap configmap-8996/configmap-test-1739049c-38b2-4e25-b0dc-eefb319bdc45 @ 04/15/24 06:51:26.336
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:51:26.349
  E0415 06:51:26.778657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:27.779415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:28.780423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:29.781183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:51:30.462
  Apr 15 06:51:30.468: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-48623d4e-64e8-442d-a9ee-255c8be4652d container env-test: <nil>
  STEP: delete the pod @ 04/15/24 06:51:30.486
  Apr 15 06:51:30.550: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8996" for this suite. @ 04/15/24 06:51:30.56
â€¢ [4.283 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 04/15/24 06:51:30.579
  Apr 15 06:51:30.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:51:30.583
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:30.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:30.621
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:51:30.628
  E0415 06:51:30.781869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:31.782791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:32.783416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:33.783642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:51:34.689
  Apr 15 06:51:34.695: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-fad9b014-c21f-4bf7-ba68-dbbcd0e5a90c container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:51:34.711
  Apr 15 06:51:34.756: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6642" for this suite. @ 04/15/24 06:51:34.768
â€¢ [4.203 seconds]
------------------------------
S  E0415 06:51:34.784325      13 retrywatcher.go:129] "Watch failed" err="context canceled"
SSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 04/15/24 06:51:34.786
  Apr 15 06:51:34.787: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:51:34.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:34.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:34.851
  STEP: Creating projection with secret that has name projected-secret-test-map-ff955340-6eae-40df-9f64-5f1f2c438fc6 @ 04/15/24 06:51:34.856
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:51:34.869
  E0415 06:51:35.784666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:36.784939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:37.784916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:38.785338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:51:38.915
  Apr 15 06:51:38.925: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-secrets-7329ef76-4b8f-4a09-b003-614031c7031b container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:51:38.942
  Apr 15 06:51:38.970: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5686" for this suite. @ 04/15/24 06:51:38.979
â€¢ [4.205 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 04/15/24 06:51:38.995
  Apr 15 06:51:38.995: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 06:51:38.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:39.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:39.037
  STEP: Setting up server cert @ 04/15/24 06:51:39.097
  E0415 06:51:39.785087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 06:51:39.926
  STEP: Deploying the webhook pod @ 04/15/24 06:51:39.94
  STEP: Wait for the deployment to be ready @ 04/15/24 06:51:39.967
  Apr 15 06:51:39.993: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 06:51:40.786086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:41.786581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:42.016: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:51:42.786618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:43.787297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:44.024: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:51:44.787625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:45.787702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:46.027: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:51:46.788443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:47.788896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:48.027: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:51:48.789168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:49.789343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:50.026: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 51, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 51, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:51:50.789891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:51.790540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 06:51:52.027
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 06:51:52.074
  E0415 06:51:52.791096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:53.075: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 04/15/24 06:51:53.09
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 04/15/24 06:51:53.157
  STEP: Creating a configMap that should not be mutated @ 04/15/24 06:51:53.171
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 04/15/24 06:51:53.193
  STEP: Creating a configMap that should be mutated @ 04/15/24 06:51:53.213
  Apr 15 06:51:53.265: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5442" for this suite. @ 04/15/24 06:51:53.427
  STEP: Destroying namespace "webhook-markers-579" for this suite. @ 04/15/24 06:51:53.448
â€¢ [14.479 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
test/e2e/apimachinery/garbage_collector.go:538
  STEP: Creating a kubernetes client @ 04/15/24 06:51:53.495
  Apr 15 06:51:53.495: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename gc @ 04/15/24 06:51:53.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:53.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:53.62
  STEP: create the deployment @ 04/15/24 06:51:53.626
  W0415 06:51:53.647916      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/15/24 06:51:53.648
  E0415 06:51:53.791425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 04/15/24 06:51:54.182
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 04/15/24 06:51:54.213
  E0415 06:51:54.791860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/15/24 06:51:54.839
  Apr 15 06:51:55.247: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 15 06:51:55.249: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5913" for this suite. @ 04/15/24 06:51:55.265
â€¢ [1.791 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:269
  STEP: Creating a kubernetes client @ 04/15/24 06:51:55.29
  Apr 15 06:51:55.290: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/15/24 06:51:55.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:55.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:55.377
  Apr 15 06:51:55.397: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 06:51:55.792412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:56.792806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:57.793372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:51:58.793417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:51:59.039: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2749" for this suite. @ 04/15/24 06:51:59.058
â€¢ [3.792 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
test/e2e/network/endpointslice.go:207
  STEP: Creating a kubernetes client @ 04/15/24 06:51:59.087
  Apr 15 06:51:59.087: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename endpointslice @ 04/15/24 06:51:59.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:51:59.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:51:59.134
  E0415 06:51:59.794372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:00.795400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:01.795598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:02.796038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:03.796482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 04/15/24 06:52:04.377
  E0415 06:52:04.796891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:05.798039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:06.797993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:07.798238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:08.799155      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 04/15/24 06:52:09.398
  E0415 06:52:09.799471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:10.799564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:11.800122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:12.800247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:13.801144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 04/15/24 06:52:14.426
  E0415 06:52:14.801532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:15.801773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:16.802038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:17.803060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:18.803357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 04/15/24 06:52:19.446
  Apr 15 06:52:19.501: INFO: EndpointSlice for Service endpointslice-208/example-named-port not found
  E0415 06:52:19.803420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:20.804574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:21.804682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:22.804897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:23.805183      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:24.805413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:25.806431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:26.806676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:27.806897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:28.807181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:52:29.521: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-208" for this suite. @ 04/15/24 06:52:29.532
â€¢ [30.460 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:137
  STEP: Creating a kubernetes client @ 04/15/24 06:52:29.552
  Apr 15 06:52:29.552: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 06:52:29.555
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:52:29.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:52:29.593
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/15/24 06:52:29.6
  E0415 06:52:29.807894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:30.808545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:31.809316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:32.811681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:52:33.646
  Apr 15 06:52:33.657: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-aeef2161-dec9-4faf-bb37-8fa9db75f392 container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:52:33.679
  Apr 15 06:52:33.716: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6604" for this suite. @ 04/15/24 06:52:33.73
â€¢ [4.197 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]
test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 04/15/24 06:52:33.753
  Apr 15 06:52:33.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename subpath @ 04/15/24 06:52:33.758
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:52:33.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:52:33.79
  STEP: Setting up data @ 04/15/24 06:52:33.795
  E0415 06:52:33.810786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating pod pod-subpath-test-downwardapi-6xcj @ 04/15/24 06:52:33.816
  STEP: Creating a pod to test atomic-volume-subpath @ 04/15/24 06:52:33.816
  E0415 06:52:34.812451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:35.811786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:36.812364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:37.813169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:38.813302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:39.814045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:40.814045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:41.814205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:42.814615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:43.815195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:44.816186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:45.816408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:46.816642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:47.816704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:48.817405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:49.818371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:50.819018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:51.819240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:52.819523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:53.820412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:54.821288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:55.822031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:56.822208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:57.823252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:52:57.955
  Apr 15 06:52:57.963: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-subpath-test-downwardapi-6xcj container test-container-subpath-downwardapi-6xcj: <nil>
  STEP: delete the pod @ 04/15/24 06:52:57.987
  STEP: Deleting pod pod-subpath-test-downwardapi-6xcj @ 04/15/24 06:52:58.018
  Apr 15 06:52:58.019: INFO: Deleting pod "pod-subpath-test-downwardapi-6xcj" in namespace "subpath-6343"
  Apr 15 06:52:58.026: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6343" for this suite. @ 04/15/24 06:52:58.036
â€¢ [24.297 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:129
  STEP: Creating a kubernetes client @ 04/15/24 06:52:58.058
  Apr 15 06:52:58.059: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename runtimeclass @ 04/15/24 06:52:58.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:52:58.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:52:58.101
  E0415 06:52:58.824090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:52:59.824209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:00.175: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8188" for this suite. @ 04/15/24 06:53:00.221
â€¢ [2.190 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 04/15/24 06:53:00.248
  Apr 15 06:53:00.248: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:53:00.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:53:00.33
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:53:00.338
  STEP: Creating configMap with name configmap-test-volume-map-4dde8ad9-d4e3-44a8-bb6b-ec97ab31324f @ 04/15/24 06:53:00.345
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:53:00.366
  E0415 06:53:00.826542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:01.826748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:02.827499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:03.828344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:53:04.42
  Apr 15 06:53:04.427: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-da076000-85af-4278-ad1d-65a92cdf6e5c container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 06:53:04.444
  Apr 15 06:53:04.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-140" for this suite. @ 04/15/24 06:53:04.5
â€¢ [4.270 seconds]
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]
test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 04/15/24 06:53:04.52
  Apr 15 06:53:04.520: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename daemonsets @ 04/15/24 06:53:04.523
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:53:04.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:53:04.56
  Apr 15 06:53:04.622: INFO: Create a RollingUpdate DaemonSet
  Apr 15 06:53:04.633: INFO: Check that daemon pods launch on every node of the cluster
  Apr 15 06:53:04.654: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:53:04.654: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:53:04.828756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:05.679: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:53:05.680: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:53:05.829917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:06.679: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 15 06:53:06.680: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 06:53:06.829995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:07.677: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 15 06:53:07.677: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  E0415 06:53:07.830439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:08.677: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Apr 15 06:53:08.677: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Apr 15 06:53:08.677: INFO: Update the DaemonSet to trigger a rollout
  Apr 15 06:53:08.697: INFO: Updating DaemonSet daemon-set
  E0415 06:53:08.831037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:09.744: INFO: Roll back the DaemonSet before rollout is complete
  Apr 15 06:53:09.772: INFO: Updating DaemonSet daemon-set
  Apr 15 06:53:09.772: INFO: Make sure DaemonSet rollback is complete
  Apr 15 06:53:09.782: INFO: Wrong image for pod: daemon-set-gmvcx. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Apr 15 06:53:09.782: INFO: Pod daemon-set-gmvcx is not available
  E0415 06:53:09.831325      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:10.832524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:11.833109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:12.834102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:13.834591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:14.835654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:15.816: INFO: Pod daemon-set-drsvf is not available
  E0415 06:53:15.835974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting DaemonSet "daemon-set" @ 04/15/24 06:53:15.849
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6082, will wait for the garbage collector to delete the pods @ 04/15/24 06:53:15.849
  Apr 15 06:53:15.921: INFO: Deleting DaemonSet.extensions daemon-set took: 12.920102ms
  Apr 15 06:53:16.123: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.663278ms
  E0415 06:53:16.836895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:17.631: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 06:53:17.631: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 15 06:53:17.638: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"160591"},"items":null}

  Apr 15 06:53:17.645: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"160591"},"items":null}

  Apr 15 06:53:17.683: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6082" for this suite. @ 04/15/24 06:53:17.691
â€¢ [13.185 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:95
  STEP: Creating a kubernetes client @ 04/15/24 06:53:17.706
  Apr 15 06:53:17.706: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pod-network-test @ 04/15/24 06:53:17.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:53:17.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:53:17.75
  STEP: Performing setup for networking test in namespace pod-network-test-9576 @ 04/15/24 06:53:17.756
  STEP: creating a selector @ 04/15/24 06:53:17.756
  STEP: Creating the service pods in kubernetes @ 04/15/24 06:53:17.756
  Apr 15 06:53:17.756: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0415 06:53:17.837417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:18.837410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:19.838302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:20.838321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:21.838463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:22.838768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:23.839591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:24.839303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:25.839444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:26.840030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:27.841148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:28.840786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:29.841844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/15/24 06:53:29.97
  E0415 06:53:30.841976      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:31.842700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:32.008: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Apr 15 06:53:32.009: INFO: Breadth first check of 10.233.64.200 on host 192.168.121.141...
  Apr 15 06:53:32.017: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.229:9080/dial?request=hostname&protocol=udp&host=10.233.64.200&port=8081&tries=1'] Namespace:pod-network-test-9576 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:53:32.017: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:53:32.019: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:53:32.019: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9576/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.229%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.200%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 15 06:53:32.228: INFO: Waiting for responses: map[]
  Apr 15 06:53:32.228: INFO: reached 10.233.64.200 after 0/1 tries
  Apr 15 06:53:32.228: INFO: Breadth first check of 10.233.65.234 on host 192.168.121.17...
  Apr 15 06:53:32.238: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.229:9080/dial?request=hostname&protocol=udp&host=10.233.65.234&port=8081&tries=1'] Namespace:pod-network-test-9576 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:53:32.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:53:32.241: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:53:32.241: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9576/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.229%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.234%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 15 06:53:32.385: INFO: Waiting for responses: map[]
  Apr 15 06:53:32.385: INFO: reached 10.233.65.234 after 0/1 tries
  Apr 15 06:53:32.386: INFO: Breadth first check of 10.233.66.228 on host 192.168.121.206...
  Apr 15 06:53:32.397: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.229:9080/dial?request=hostname&protocol=udp&host=10.233.66.228&port=8081&tries=1'] Namespace:pod-network-test-9576 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 06:53:32.397: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 06:53:32.400: INFO: ExecWithOptions: Clientset creation
  Apr 15 06:53:32.400: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9576/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.229%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.228%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 15 06:53:32.524: INFO: Waiting for responses: map[]
  Apr 15 06:53:32.524: INFO: reached 10.233.66.228 after 0/1 tries
  Apr 15 06:53:32.524: INFO: Going to retry 0 out of 3 pods....
  Apr 15 06:53:32.524: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9576" for this suite. @ 04/15/24 06:53:32.535
â€¢ [14.848 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
test/e2e/scheduling/limit_range.go:61
  STEP: Creating a kubernetes client @ 04/15/24 06:53:32.558
  Apr 15 06:53:32.558: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename limitrange @ 04/15/24 06:53:32.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:53:32.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:53:32.602
  STEP: Creating a LimitRange @ 04/15/24 06:53:32.615
  STEP: Setting up watch @ 04/15/24 06:53:32.615
  STEP: Submitting a LimitRange @ 04/15/24 06:53:32.725
  STEP: Verifying LimitRange creation was observed @ 04/15/24 06:53:32.748
  STEP: Fetching the LimitRange to ensure it has proper values @ 04/15/24 06:53:32.749
  Apr 15 06:53:32.757: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 15 06:53:32.757: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 04/15/24 06:53:32.757
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 04/15/24 06:53:32.773
  Apr 15 06:53:32.789: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 15 06:53:32.790: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 04/15/24 06:53:32.79
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 04/15/24 06:53:32.817
  Apr 15 06:53:32.826: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Apr 15 06:53:32.826: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 04/15/24 06:53:32.826
  STEP: Failing to create a Pod with more than max resources @ 04/15/24 06:53:32.833
  STEP: Updating a LimitRange @ 04/15/24 06:53:32.839
  E0415 06:53:32.843675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying LimitRange updating is effective @ 04/15/24 06:53:32.853
  E0415 06:53:33.844001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:34.845051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 04/15/24 06:53:34.863
  STEP: Failing to create a Pod with more than max resources @ 04/15/24 06:53:34.879
  STEP: Deleting a LimitRange @ 04/15/24 06:53:34.888
  STEP: Verifying the LimitRange was deleted @ 04/15/24 06:53:34.922
  E0415 06:53:35.845291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:36.845419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:37.845500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:38.845940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:39.846637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:39.931: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 04/15/24 06:53:39.932
  Apr 15 06:53:39.951: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-9546" for this suite. @ 04/15/24 06:53:39.963
â€¢ [7.421 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 04/15/24 06:53:39.98
  Apr 15 06:53:39.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename deployment @ 04/15/24 06:53:39.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:53:40.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:53:40.015
  Apr 15 06:53:40.042: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E0415 06:53:40.847042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:41.847869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:42.847700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:43.848485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:44.848535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:45.053: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/15/24 06:53:45.054
  Apr 15 06:53:45.054: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0415 06:53:45.849182      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:46.849196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:47.065: INFO: Creating deployment "test-rollover-deployment"
  Apr 15 06:53:47.089: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E0415 06:53:47.849669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:48.849831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:49.113: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Apr 15 06:53:49.129: INFO: Ensure that both replica sets have 1 created replica
  Apr 15 06:53:49.149: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Apr 15 06:53:49.176: INFO: Updating deployment test-rollover-deployment
  Apr 15 06:53:49.177: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0415 06:53:49.850742      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:50.851377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:51.195: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Apr 15 06:53:51.209: INFO: Make sure deployment "test-rollover-deployment" is complete
  Apr 15 06:53:51.223: INFO: all replica sets need to contain the pod-template-hash label
  Apr 15 06:53:51.223: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:53:51.851949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:52.852604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:53.244: INFO: all replica sets need to contain the pod-template-hash label
  Apr 15 06:53:53.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:53:53.855387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:54.856345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:55.241: INFO: all replica sets need to contain the pod-template-hash label
  Apr 15 06:53:55.241: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:53:55.860355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:56.857009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:57.247: INFO: all replica sets need to contain the pod-template-hash label
  Apr 15 06:53:57.247: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:53:57.858018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:53:58.858980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:53:59.247: INFO: all replica sets need to contain the pod-template-hash label
  Apr 15 06:53:59.248: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 53, 50, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 53, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-68774655d5\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:53:59.871044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:00.869975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:54:01.244: INFO: 
  Apr 15 06:54:01.245: INFO: Ensure that both old replica sets have no replicas
  Apr 15 06:54:01.289: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2221",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "295c89d8-bd8a-4ced-8d0c-c00d73638ca6",
      ResourceVersion: (string) (len=6) "160907",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760827,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760840,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760827,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760827,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760840,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760827,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-68774655d5\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 15 06:54:01.312: INFO: New ReplicaSet "test-rollover-deployment-68774655d5" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-68774655d5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2221",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5f4caf7d-7293-4f9b-9c88-2e4822981a5f",
      ResourceVersion: (string) (len=6) "160897",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760829,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "295c89d8-bd8a-4ced-8d0c-c00d73638ca6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 39 35 63 38 39  64 38 2d 62 64 38 61 2d  |\"295c89d8-bd8a-|
              00000120  34 63 65 64 2d 38 64 30  63 2d 63 30 30 64 37 33  |4ced-8d0c-c00d73|
              00000130  36 33 38 63 61 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |638ca6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760840,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:54:01.325: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Apr 15 06:54:01.325: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2221",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b89de074-9874-44bd-8b84-677b0827eb4c",
      ResourceVersion: (string) (len=6) "160905",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760820,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "295c89d8-bd8a-4ced-8d0c-c00d73638ca6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760820,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760840,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  32 39 35 63 38 39 64 38  2d 62 64 38 61 2d 34 63  |295c89d8-bd8a-4c|
              000000c0  65 64 2d 38 64 30 63 2d  63 30 30 64 37 33 36 33  |ed-8d0c-c00d7363|
              000000d0  38 63 61 36 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |8ca6\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760840,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:54:01.337: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2221",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6ec4b4fd-b17e-435a-a96b-1f78cc5d740c",
      ResourceVersion: (string) (len=6) "160862",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760827,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874",
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "295c89d8-bd8a-4ced-8d0c-c00d73638ca6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 32 39 35 63 38 39  64 38 2d 62 64 38 61 2d  |\"295c89d8-bd8a-|
              00000120  34 63 65 64 2d 38 64 30  63 2d 63 30 30 64 37 33  |4ced-8d0c-c00d73|
              00000130  36 33 38 63 61 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |638ca6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 06:54:01.357: INFO: Pod "test-rollover-deployment-68774655d5-f72wp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-68774655d5-f72wp",
      GenerateName: (string) (len=36) "test-rollover-deployment-68774655d5-",
      Namespace: (string) (len=15) "deployment-2221",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b60a83b0-d447-47e4-abd5-10200a365faa",
      ResourceVersion: (string) (len=6) "160875",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760829,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "68774655d5"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-68774655d5",
          UID: (types.UID) (len=36) "5f4caf7d-7293-4f9b-9c88-2e4822981a5f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 35 66  34 63 61 66 37 64 2d 37  |d\":\"5f4caf7d-7|
              00000090  32 39 33 2d 34 66 39 62  2d 39 63 38 38 2d 32 65  |293-4f9b-9c88-2e|
              000000a0  34 38 32 32 39 38 31 61  35 66 5c 22 7d 22 3a 7b  |4822981a5f\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760830,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 32 33 33 5c 22 7d  |10.233.66.233\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-djdsr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-djdsr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760830,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760830,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848760829,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.206",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "10.233.66.233",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "10.233.66.233"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848760829,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848760830,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.47",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:c9997bf8d2e223d7d2a0078dcfb11a653e9b16cf09418829ec03e1d57ca9628a",
          ContainerID: (string) (len=72) "cri-o://1dd9fca52b6c42d178760567e13722c161f8e2398401e7b091abb720fd94886d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 06:54:01.360: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2221" for this suite. @ 04/15/24 06:54:01.377
â€¢ [21.414 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 04/15/24 06:54:01.395
  Apr 15 06:54:01.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-preemption @ 04/15/24 06:54:01.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:54:01.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:54:01.451
  Apr 15 06:54:01.486: INFO: Waiting up to 1m0s for all nodes to be ready
  E0415 06:54:01.870114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:02.870897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:03.872002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:04.872304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:05.872994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:06.873524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:07.874336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:08.874668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:09.875582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:10.876385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:11.876338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:12.876986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:13.877601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:14.878285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:15.878731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:16.878555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:17.878753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:18.878963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:19.879831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:20.880451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:21.881224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:22.881410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:23.881664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:24.882113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:25.883397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:26.883599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:27.883993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:28.884523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:29.884633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:30.884914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:31.885926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:32.886283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:33.887324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:34.887687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:35.888076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:36.889066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:37.890009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:38.890328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:39.890174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:40.890467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:41.890715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:42.891267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:43.891990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:44.892754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:45.893246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:46.893201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:47.894307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:48.894492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:49.895482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:50.896422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:51.896750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:52.897144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:53.897624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:54.898019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:55.898621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:56.898633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:57.899469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:58.900521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:54:59.900788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:00.901039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:01.556: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/15/24 06:55:01.567
  Apr 15 06:55:01.624: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 15 06:55:01.641: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 15 06:55:01.767: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 15 06:55:01.800: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  E0415 06:55:01.901256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:02.051: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Apr 15 06:55:02.106: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/15/24 06:55:02.107
  E0415 06:55:02.902747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:03.902545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:04.903662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:05.903621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 04/15/24 06:55:06.245
  E0415 06:55:06.903951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:07.904539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:08.904759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:09.904851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:10.337: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1429" for this suite. @ 04/15/24 06:55:10.473
â€¢ [69.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 04/15/24 06:55:10.505
  Apr 15 06:55:10.505: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:55:10.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:10.542
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:10.548
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:55:10.553
  E0415 06:55:10.905741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:11.906589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:12.907441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:13.907321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:55:14.598
  Apr 15 06:55:14.606: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-5f713000-1515-4b88-87ab-a5027b1e5a18 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:55:14.643
  Apr 15 06:55:14.684: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-426" for this suite. @ 04/15/24 06:55:14.696
â€¢ [4.206 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:164
  STEP: Creating a kubernetes client @ 04/15/24 06:55:14.717
  Apr 15 06:55:14.717: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename security-context @ 04/15/24 06:55:14.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:14.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:14.767
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/15/24 06:55:14.774
  E0415 06:55:14.907991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:15.908542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:16.908533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:17.909163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:55:18.819
  Apr 15 06:55:18.825: INFO: Trying to get logs from node phiefi7ighaa-3 pod security-context-c216a800-68e2-4063-b287-b79ec69cdebb container test-container: <nil>
  STEP: delete the pod @ 04/15/24 06:55:18.837
  Apr 15 06:55:18.883: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-9823" for this suite. @ 04/15/24 06:55:18.895
  E0415 06:55:18.910218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [4.195 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 04/15/24 06:55:18.928
  Apr 15 06:55:18.928: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:55:18.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:18.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:18.972
  STEP: Creating projection with secret that has name projected-secret-test-41b0aa9c-367f-4d25-9f78-a1f825837588 @ 04/15/24 06:55:18.978
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:55:18.989
  E0415 06:55:19.910801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:20.910872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:21.911175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:22.911491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:55:23.051
  Apr 15 06:55:23.061: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-secrets-fac0848d-5b0c-4486-9dea-4b2ded8f52c2 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:55:23.075
  Apr 15 06:55:23.108: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6614" for this suite. @ 04/15/24 06:55:23.121
â€¢ [4.209 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:268
  STEP: Creating a kubernetes client @ 04/15/24 06:55:23.142
  Apr 15 06:55:23.143: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:55:23.145
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:23.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:23.189
  STEP: Creating a pod to test downward api env vars @ 04/15/24 06:55:23.195
  E0415 06:55:23.912382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:24.912057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:25.912550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:26.913106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:55:27.242
  Apr 15 06:55:27.250: INFO: Trying to get logs from node phiefi7ighaa-3 pod downward-api-2995f1f6-f692-4df9-ac51-c4dcd4b26eaf container dapi-container: <nil>
  STEP: delete the pod @ 04/15/24 06:55:27.271
  Apr 15 06:55:27.344: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9158" for this suite. @ 04/15/24 06:55:27.37
â€¢ [4.250 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2224
  STEP: Creating a kubernetes client @ 04/15/24 06:55:27.399
  Apr 15 06:55:27.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 06:55:27.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:27.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:27.44
  STEP: creating service in namespace services-1894 @ 04/15/24 06:55:27.448
  STEP: creating service affinity-nodeport-transition in namespace services-1894 @ 04/15/24 06:55:27.449
  STEP: creating replication controller affinity-nodeport-transition in namespace services-1894 @ 04/15/24 06:55:27.487
  I0415 06:55:27.505328      13 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-1894, replica count: 3
  E0415 06:55:27.913945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:28.914169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:29.914735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 06:55:30.558813      13 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 15 06:55:30.582: INFO: Creating new exec pod
  E0415 06:55:30.914974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:31.915076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:32.916237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:33.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1894 exec execpod-affinityhm6sr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  E0415 06:55:33.916089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:34.048: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Apr 15 06:55:34.049: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 06:55:34.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1894 exec execpod-affinityhm6sr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.56.62 80'
  Apr 15 06:55:34.386: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.56.62 80\nConnection to 10.233.56.62 80 port [tcp/http] succeeded!\n"
  Apr 15 06:55:34.386: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 06:55:34.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1894 exec execpod-affinityhm6sr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.206 31069'
  Apr 15 06:55:34.723: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.206 31069\nConnection to 192.168.121.206 31069 port [tcp/*] succeeded!\n"
  Apr 15 06:55:34.723: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 06:55:34.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1894 exec execpod-affinityhm6sr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.141 31069'
  E0415 06:55:34.916544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:34.974: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.141 31069\nConnection to 192.168.121.141 31069 port [tcp/*] succeeded!\n"
  Apr 15 06:55:34.974: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 06:55:34.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1894 exec execpod-affinityhm6sr -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.141:31069/ ; done'
  Apr 15 06:55:35.565: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n"
  Apr 15 06:55:35.565: INFO: stdout: "\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-cx5hg\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-cx5hg\naffinity-nodeport-transition-ppxbj\naffinity-nodeport-transition-cx5hg\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-ppxbj\naffinity-nodeport-transition-ppxbj\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-ppxbj\naffinity-nodeport-transition-ppxbj\naffinity-nodeport-transition-ppxbj\naffinity-nodeport-transition-k65tf"
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-cx5hg
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-cx5hg
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-ppxbj
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-cx5hg
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-ppxbj
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-ppxbj
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-ppxbj
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-ppxbj
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-ppxbj
  Apr 15 06:55:35.565: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:35.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1894 exec execpod-affinityhm6sr -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.141:31069/ ; done'
  E0415 06:55:35.917528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:36.110: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31069/\n"
  Apr 15 06:55:36.110: INFO: stdout: "\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf\naffinity-nodeport-transition-k65tf"
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.110: INFO: Received response from host: affinity-nodeport-transition-k65tf
  Apr 15 06:55:36.111: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 06:55:36.120: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-1894, will wait for the garbage collector to delete the pods @ 04/15/24 06:55:36.158
  Apr 15 06:55:36.261: INFO: Deleting ReplicationController affinity-nodeport-transition took: 46.941656ms
  Apr 15 06:55:36.363: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.924238ms
  E0415 06:55:36.918019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:37.919800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:38.920792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-1894" for this suite. @ 04/15/24 06:55:39.846
â€¢ [12.460 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs  [Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 04/15/24 06:55:39.866
  Apr 15 06:55:39.866: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl-logs @ 04/15/24 06:55:39.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:39.903
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:39.907
  STEP: creating an pod @ 04/15/24 06:55:39.913
  Apr 15 06:55:39.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-logs-2581 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.47 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  E0415 06:55:39.920935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:40.099: INFO: stderr: ""
  Apr 15 06:55:40.099: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 04/15/24 06:55:40.099
  Apr 15 06:55:40.099: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0415 06:55:40.921256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:41.921399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:42.122: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 04/15/24 06:55:42.122
  Apr 15 06:55:42.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-logs-2581 logs logs-generator logs-generator'
  Apr 15 06:55:42.344: INFO: stderr: ""
  Apr 15 06:55:42.344: INFO: stdout: "I0415 06:55:40.856417       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/7rm4 481\nI0415 06:55:41.055495       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/wv6m 467\nI0415 06:55:41.255018       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/wm2 332\nI0415 06:55:41.455652       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/d2s 405\nI0415 06:55:41.655199       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/55g 361\nI0415 06:55:41.855790       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/45zq 302\nI0415 06:55:42.055363       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/bgv 339\nI0415 06:55:42.254870       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/ndz2 223\n"
  STEP: limiting log lines @ 04/15/24 06:55:42.344
  Apr 15 06:55:42.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-logs-2581 logs logs-generator logs-generator --tail=1'
  Apr 15 06:55:42.511: INFO: stderr: ""
  Apr 15 06:55:42.511: INFO: stdout: "I0415 06:55:42.455819       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/w8l2 279\n"
  Apr 15 06:55:42.511: INFO: got output "I0415 06:55:42.455819       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/w8l2 279\n"
  STEP: limiting log bytes @ 04/15/24 06:55:42.511
  Apr 15 06:55:42.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-logs-2581 logs logs-generator logs-generator --limit-bytes=1'
  Apr 15 06:55:42.700: INFO: stderr: ""
  Apr 15 06:55:42.700: INFO: stdout: "I"
  Apr 15 06:55:42.700: INFO: got output "I"
  STEP: exposing timestamps @ 04/15/24 06:55:42.7
  Apr 15 06:55:42.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-logs-2581 logs logs-generator logs-generator --tail=1 --timestamps'
  Apr 15 06:55:42.891: INFO: stderr: ""
  Apr 15 06:55:42.891: INFO: stdout: "2024-04-15T06:55:42.855363256Z I0415 06:55:42.855269       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/8nk 522\n"
  Apr 15 06:55:42.891: INFO: got output "2024-04-15T06:55:42.855363256Z I0415 06:55:42.855269       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/8nk 522\n"
  STEP: restricting to a time range @ 04/15/24 06:55:42.891
  E0415 06:55:42.922372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:43.922666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:44.923626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:45.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-logs-2581 logs logs-generator logs-generator --since=1s'
  Apr 15 06:55:45.610: INFO: stderr: ""
  Apr 15 06:55:45.610: INFO: stdout: "I0415 06:55:44.655861       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/9k7 380\nI0415 06:55:44.855417       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/r2k 270\nI0415 06:55:45.054841       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/w2k 347\nI0415 06:55:45.255282       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/7w6 214\nI0415 06:55:45.456256       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/s4p 338\n"
  Apr 15 06:55:45.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-logs-2581 logs logs-generator logs-generator --since=24h'
  Apr 15 06:55:45.821: INFO: stderr: ""
  Apr 15 06:55:45.821: INFO: stdout: "I0415 06:55:40.856417       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/7rm4 481\nI0415 06:55:41.055495       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/wv6m 467\nI0415 06:55:41.255018       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/wm2 332\nI0415 06:55:41.455652       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/d2s 405\nI0415 06:55:41.655199       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/55g 361\nI0415 06:55:41.855790       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/45zq 302\nI0415 06:55:42.055363       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/bgv 339\nI0415 06:55:42.254870       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/ndz2 223\nI0415 06:55:42.455819       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/w8l2 279\nI0415 06:55:42.655699       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/svrv 330\nI0415 06:55:42.855269       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/8nk 522\nI0415 06:55:43.054845       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/qwrd 579\nI0415 06:55:43.255501       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/mpn 543\nI0415 06:55:43.454924       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/56rr 487\nI0415 06:55:43.655327       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/rpk 306\nI0415 06:55:43.855821       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/4wg 563\nI0415 06:55:44.055347       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/bh6 292\nI0415 06:55:44.255857       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/b69 280\nI0415 06:55:44.455328       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/w79 325\nI0415 06:55:44.655861       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/9k7 380\nI0415 06:55:44.855417       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/r2k 270\nI0415 06:55:45.054841       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/w2k 347\nI0415 06:55:45.255282       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/7w6 214\nI0415 06:55:45.456256       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/s4p 338\nI0415 06:55:45.654911       1 logs_generator.go:76] 24 POST /api/v1/namespaces/ns/pods/v62f 571\n"
  Apr 15 06:55:45.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-logs-2581 delete pod logs-generator'
  E0415 06:55:45.924759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:46.643: INFO: stderr: ""
  Apr 15 06:55:46.644: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Apr 15 06:55:46.644: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-2581" for this suite. @ 04/15/24 06:55:46.656
â€¢ [6.806 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 04/15/24 06:55:46.674
  Apr 15 06:55:46.674: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename init-container @ 04/15/24 06:55:46.677
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:46.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:46.718
  STEP: creating the pod @ 04/15/24 06:55:46.723
  Apr 15 06:55:46.724: INFO: PodSpec: initContainers in spec.initContainers
  E0415 06:55:46.925075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:47.925302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:48.925346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:49.926264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:50.332: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1953" for this suite. @ 04/15/24 06:55:50.344
â€¢ [3.686 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 04/15/24 06:55:50.363
  Apr 15 06:55:50.363: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:55:50.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:50.401
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:50.406
  STEP: Creating configMap with name projected-configmap-test-volume-c454267d-6829-4968-9ec5-af1b87fe2d55 @ 04/15/24 06:55:50.412
  STEP: Creating a pod to test consume configMaps @ 04/15/24 06:55:50.422
  E0415 06:55:50.926611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:51.926974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:55:52.468
  Apr 15 06:55:52.480: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-configmaps-44cf9f1a-1fe6-410f-9db6-468b60966610 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:55:52.503
  Apr 15 06:55:52.553: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8818" for this suite. @ 04/15/24 06:55:52.564
â€¢ [2.217 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 04/15/24 06:55:52.585
  Apr 15 06:55:52.586: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename proxy @ 04/15/24 06:55:52.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:52.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:52.648
  STEP: starting an echo server on multiple ports @ 04/15/24 06:55:52.692
  STEP: creating replication controller proxy-service-bfqzp in namespace proxy-6706 @ 04/15/24 06:55:52.692
  I0415 06:55:52.715616      13 runners.go:197] Created replication controller with name: proxy-service-bfqzp, namespace: proxy-6706, replica count: 1
  E0415 06:55:52.927930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 06:55:53.768330      13 runners.go:197] proxy-service-bfqzp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0415 06:55:53.927905      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 06:55:54.769413      13 runners.go:197] proxy-service-bfqzp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 15 06:55:54.775: INFO: setup took 2.116746715s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 04/15/24 06:55:54.775
  Apr 15 06:55:54.802: INFO: (0) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 26.126412ms)
  Apr 15 06:55:54.803: INFO: (0) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 27.300227ms)
  Apr 15 06:55:54.803: INFO: (0) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 27.19068ms)
  Apr 15 06:55:54.803: INFO: (0) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 27.34881ms)
  Apr 15 06:55:54.810: INFO: (0) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 33.739817ms)
  Apr 15 06:55:54.810: INFO: (0) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 35.023919ms)
  Apr 15 06:55:54.810: INFO: (0) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 34.025914ms)
  Apr 15 06:55:54.810: INFO: (0) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 33.130416ms)
  Apr 15 06:55:54.812: INFO: (0) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 35.917373ms)
  Apr 15 06:55:54.812: INFO: (0) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 36.338532ms)
  Apr 15 06:55:54.813: INFO: (0) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 36.896288ms)
  Apr 15 06:55:54.815: INFO: (0) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 38.240827ms)
  Apr 15 06:55:54.815: INFO: (0) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 37.679856ms)
  Apr 15 06:55:54.815: INFO: (0) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 39.083958ms)
  Apr 15 06:55:54.815: INFO: (0) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 38.148827ms)
  Apr 15 06:55:54.815: INFO: (0) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 38.848747ms)
  Apr 15 06:55:54.831: INFO: (1) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 13.25225ms)
  Apr 15 06:55:54.831: INFO: (1) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 12.884778ms)
  Apr 15 06:55:54.838: INFO: (1) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 20.85477ms)
  Apr 15 06:55:54.839: INFO: (1) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 21.907567ms)
  Apr 15 06:55:54.839: INFO: (1) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 20.008567ms)
  Apr 15 06:55:54.843: INFO: (1) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 24.31697ms)
  Apr 15 06:55:54.847: INFO: (1) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 29.707344ms)
  Apr 15 06:55:54.849: INFO: (1) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 30.049088ms)
  Apr 15 06:55:54.849: INFO: (1) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 28.639761ms)
  Apr 15 06:55:54.849: INFO: (1) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 27.787965ms)
  Apr 15 06:55:54.850: INFO: (1) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 29.586579ms)
  Apr 15 06:55:54.851: INFO: (1) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 30.687885ms)
  Apr 15 06:55:54.851: INFO: (1) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 33.119186ms)
  Apr 15 06:55:54.852: INFO: (1) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 32.044073ms)
  Apr 15 06:55:54.852: INFO: (1) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 32.309407ms)
  Apr 15 06:55:54.852: INFO: (1) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 31.307893ms)
  Apr 15 06:55:54.866: INFO: (2) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 12.33212ms)
  Apr 15 06:55:54.866: INFO: (2) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 12.267478ms)
  Apr 15 06:55:54.869: INFO: (2) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 14.870176ms)
  Apr 15 06:55:54.869: INFO: (2) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 14.767808ms)
  Apr 15 06:55:54.869: INFO: (2) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 15.485967ms)
  Apr 15 06:55:54.894: INFO: (2) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 40.12391ms)
  Apr 15 06:55:54.894: INFO: (2) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 40.710662ms)
  Apr 15 06:55:54.894: INFO: (2) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 41.099849ms)
  Apr 15 06:55:54.894: INFO: (2) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 41.113204ms)
  Apr 15 06:55:54.894: INFO: (2) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 40.988694ms)
  Apr 15 06:55:54.895: INFO: (2) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 40.779167ms)
  Apr 15 06:55:54.895: INFO: (2) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 40.976013ms)
  Apr 15 06:55:54.896: INFO: (2) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 41.659846ms)
  Apr 15 06:55:54.897: INFO: (2) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 42.904499ms)
  Apr 15 06:55:54.898: INFO: (2) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 43.165815ms)
  Apr 15 06:55:54.901: INFO: (2) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 46.276046ms)
  Apr 15 06:55:54.914: INFO: (3) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 13.528927ms)
  Apr 15 06:55:54.914: INFO: (3) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 12.974933ms)
  Apr 15 06:55:54.920: INFO: (3) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 17.644455ms)
  Apr 15 06:55:54.920: INFO: (3) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 18.053034ms)
  Apr 15 06:55:54.922: INFO: (3) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 19.752815ms)
  Apr 15 06:55:54.922: INFO: (3) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 19.360233ms)
  Apr 15 06:55:54.923: INFO: (3) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 20.348874ms)
  Apr 15 06:55:54.924: INFO: (3) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 21.689194ms)
  Apr 15 06:55:54.925: INFO: (3) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 22.71713ms)
  Apr 15 06:55:54.926: INFO: (3) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 22.742293ms)
  Apr 15 06:55:54.926: INFO: (3) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 24.788437ms)
  E0415 06:55:54.931252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:55:54.932: INFO: (3) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 31.051474ms)
  Apr 15 06:55:54.932: INFO: (3) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 30.591894ms)
  Apr 15 06:55:54.932: INFO: (3) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 29.279768ms)
  Apr 15 06:55:54.931: INFO: (3) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 30.184949ms)
  Apr 15 06:55:54.940: INFO: (3) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 36.479878ms)
  Apr 15 06:55:54.954: INFO: (4) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 13.103036ms)
  Apr 15 06:55:54.954: INFO: (4) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 13.441389ms)
  Apr 15 06:55:54.961: INFO: (4) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 19.580701ms)
  Apr 15 06:55:54.964: INFO: (4) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 21.917362ms)
  Apr 15 06:55:54.964: INFO: (4) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 23.725396ms)
  Apr 15 06:55:54.965: INFO: (4) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 22.810996ms)
  Apr 15 06:55:54.965: INFO: (4) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 23.29368ms)
  Apr 15 06:55:54.965: INFO: (4) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 23.523163ms)
  Apr 15 06:55:54.969: INFO: (4) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 28.731217ms)
  Apr 15 06:55:54.969: INFO: (4) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 27.801771ms)
  Apr 15 06:55:54.969: INFO: (4) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 28.174446ms)
  Apr 15 06:55:54.969: INFO: (4) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 28.525262ms)
  Apr 15 06:55:54.974: INFO: (4) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 33.002273ms)
  Apr 15 06:55:54.974: INFO: (4) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 32.518365ms)
  Apr 15 06:55:54.975: INFO: (4) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 32.935778ms)
  Apr 15 06:55:54.976: INFO: (4) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 34.98394ms)
  Apr 15 06:55:54.989: INFO: (5) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 12.964509ms)
  Apr 15 06:55:54.991: INFO: (5) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 13.325361ms)
  Apr 15 06:55:54.993: INFO: (5) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 14.793537ms)
  Apr 15 06:55:54.994: INFO: (5) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 17.217614ms)
  Apr 15 06:55:54.997: INFO: (5) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 17.344699ms)
  Apr 15 06:55:54.997: INFO: (5) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 18.15443ms)
  Apr 15 06:55:55.001: INFO: (5) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 21.623091ms)
  Apr 15 06:55:55.002: INFO: (5) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 23.894091ms)
  Apr 15 06:55:55.003: INFO: (5) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 23.800271ms)
  Apr 15 06:55:55.005: INFO: (5) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 27.164538ms)
  Apr 15 06:55:55.007: INFO: (5) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 30.130205ms)
  Apr 15 06:55:55.007: INFO: (5) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 30.063943ms)
  Apr 15 06:55:55.007: INFO: (5) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 28.540293ms)
  Apr 15 06:55:55.007: INFO: (5) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 28.47878ms)
  Apr 15 06:55:55.008: INFO: (5) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 30.479918ms)
  Apr 15 06:55:55.008: INFO: (5) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 28.607262ms)
  Apr 15 06:55:55.026: INFO: (6) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 17.406097ms)
  Apr 15 06:55:55.027: INFO: (6) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 16.179375ms)
  Apr 15 06:55:55.027: INFO: (6) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 17.707115ms)
  Apr 15 06:55:55.039: INFO: (6) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 28.620668ms)
  Apr 15 06:55:55.039: INFO: (6) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 28.340649ms)
  Apr 15 06:55:55.039: INFO: (6) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 28.441371ms)
  Apr 15 06:55:55.041: INFO: (6) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 30.030146ms)
  Apr 15 06:55:55.041: INFO: (6) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 31.315231ms)
  Apr 15 06:55:55.041: INFO: (6) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 30.223596ms)
  Apr 15 06:55:55.042: INFO: (6) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 31.249358ms)
  Apr 15 06:55:55.042: INFO: (6) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 31.278216ms)
  Apr 15 06:55:55.044: INFO: (6) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 33.793626ms)
  Apr 15 06:55:55.044: INFO: (6) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 33.91903ms)
  Apr 15 06:55:55.044: INFO: (6) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 34.84392ms)
  Apr 15 06:55:55.045: INFO: (6) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 34.227106ms)
  Apr 15 06:55:55.047: INFO: (6) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 36.43181ms)
  Apr 15 06:55:55.059: INFO: (7) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 11.131302ms)
  Apr 15 06:55:55.067: INFO: (7) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 19.824658ms)
  Apr 15 06:55:55.068: INFO: (7) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 20.854672ms)
  Apr 15 06:55:55.068: INFO: (7) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 20.138714ms)
  Apr 15 06:55:55.069: INFO: (7) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 20.385137ms)
  Apr 15 06:55:55.071: INFO: (7) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 23.170342ms)
  Apr 15 06:55:55.075: INFO: (7) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 27.238313ms)
  Apr 15 06:55:55.077: INFO: (7) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 28.726255ms)
  Apr 15 06:55:55.077: INFO: (7) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 29.219296ms)
  Apr 15 06:55:55.080: INFO: (7) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 31.034454ms)
  Apr 15 06:55:55.081: INFO: (7) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 32.585579ms)
  Apr 15 06:55:55.083: INFO: (7) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 34.254437ms)
  Apr 15 06:55:55.084: INFO: (7) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 34.947368ms)
  Apr 15 06:55:55.084: INFO: (7) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 35.159086ms)
  Apr 15 06:55:55.084: INFO: (7) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 35.738775ms)
  Apr 15 06:55:55.087: INFO: (7) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 38.30987ms)
  Apr 15 06:55:55.111: INFO: (8) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 22.973776ms)
  Apr 15 06:55:55.111: INFO: (8) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 22.758926ms)
  Apr 15 06:55:55.115: INFO: (8) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 27.808161ms)
  Apr 15 06:55:55.116: INFO: (8) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 29.136212ms)
  Apr 15 06:55:55.117: INFO: (8) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 30.004744ms)
  Apr 15 06:55:55.118: INFO: (8) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 29.93663ms)
  Apr 15 06:55:55.120: INFO: (8) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 31.645522ms)
  Apr 15 06:55:55.122: INFO: (8) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 34.630646ms)
  Apr 15 06:55:55.123: INFO: (8) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 34.881712ms)
  Apr 15 06:55:55.124: INFO: (8) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 37.201259ms)
  Apr 15 06:55:55.124: INFO: (8) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 36.202478ms)
  Apr 15 06:55:55.125: INFO: (8) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 37.383056ms)
  Apr 15 06:55:55.126: INFO: (8) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 37.813478ms)
  Apr 15 06:55:55.127: INFO: (8) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 38.367976ms)
  Apr 15 06:55:55.133: INFO: (8) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 44.478505ms)
  Apr 15 06:55:55.134: INFO: (8) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 46.108703ms)
  Apr 15 06:55:55.152: INFO: (9) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 17.082647ms)
  Apr 15 06:55:55.158: INFO: (9) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 22.83331ms)
  Apr 15 06:55:55.158: INFO: (9) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 23.437018ms)
  Apr 15 06:55:55.161: INFO: (9) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 24.899015ms)
  Apr 15 06:55:55.161: INFO: (9) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 26.376025ms)
  Apr 15 06:55:55.166: INFO: (9) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 30.513901ms)
  Apr 15 06:55:55.167: INFO: (9) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 30.943647ms)
  Apr 15 06:55:55.168: INFO: (9) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 32.59834ms)
  Apr 15 06:55:55.170: INFO: (9) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 34.94076ms)
  Apr 15 06:55:55.170: INFO: (9) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 35.342318ms)
  Apr 15 06:55:55.170: INFO: (9) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 34.664576ms)
  Apr 15 06:55:55.170: INFO: (9) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 34.898744ms)
  Apr 15 06:55:55.172: INFO: (9) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 36.906666ms)
  Apr 15 06:55:55.172: INFO: (9) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 36.545179ms)
  Apr 15 06:55:55.172: INFO: (9) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 36.955989ms)
  Apr 15 06:55:55.174: INFO: (9) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 37.962489ms)
  Apr 15 06:55:55.186: INFO: (10) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 12.347982ms)
  Apr 15 06:55:55.187: INFO: (10) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 12.28141ms)
  Apr 15 06:55:55.196: INFO: (10) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 20.976975ms)
  Apr 15 06:55:55.198: INFO: (10) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 23.218265ms)
  Apr 15 06:55:55.200: INFO: (10) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 25.889742ms)
  Apr 15 06:55:55.200: INFO: (10) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 25.703734ms)
  Apr 15 06:55:55.201: INFO: (10) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 25.934124ms)
  Apr 15 06:55:55.202: INFO: (10) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 26.802808ms)
  Apr 15 06:55:55.202: INFO: (10) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 26.887721ms)
  Apr 15 06:55:55.203: INFO: (10) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 29.37299ms)
  Apr 15 06:55:55.206: INFO: (10) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 31.381402ms)
  Apr 15 06:55:55.206: INFO: (10) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 31.325453ms)
  Apr 15 06:55:55.206: INFO: (10) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 31.730123ms)
  Apr 15 06:55:55.206: INFO: (10) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 31.192721ms)
  Apr 15 06:55:55.208: INFO: (10) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 33.64605ms)
  Apr 15 06:55:55.208: INFO: (10) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 33.166582ms)
  Apr 15 06:55:55.234: INFO: (11) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 23.990509ms)
  Apr 15 06:55:55.234: INFO: (11) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 24.597542ms)
  Apr 15 06:55:55.234: INFO: (11) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 25.434207ms)
  Apr 15 06:55:55.234: INFO: (11) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 25.311565ms)
  Apr 15 06:55:55.234: INFO: (11) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 24.465334ms)
  Apr 15 06:55:55.235: INFO: (11) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 24.560513ms)
  Apr 15 06:55:55.235: INFO: (11) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 26.214484ms)
  Apr 15 06:55:55.237: INFO: (11) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 26.915944ms)
  Apr 15 06:55:55.237: INFO: (11) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 27.531041ms)
  Apr 15 06:55:55.238: INFO: (11) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 27.913216ms)
  Apr 15 06:55:55.239: INFO: (11) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 29.577583ms)
  Apr 15 06:55:55.240: INFO: (11) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 30.161421ms)
  Apr 15 06:55:55.242: INFO: (11) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 31.540326ms)
  Apr 15 06:55:55.243: INFO: (11) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 32.336752ms)
  Apr 15 06:55:55.248: INFO: (11) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 38.532401ms)
  Apr 15 06:55:55.250: INFO: (11) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 39.133216ms)
  Apr 15 06:55:55.265: INFO: (12) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 15.201053ms)
  Apr 15 06:55:55.275: INFO: (12) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 24.771021ms)
  Apr 15 06:55:55.275: INFO: (12) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 24.694466ms)
  Apr 15 06:55:55.276: INFO: (12) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 26.147832ms)
  Apr 15 06:55:55.285: INFO: (12) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 34.721945ms)
  Apr 15 06:55:55.286: INFO: (12) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 35.491507ms)
  Apr 15 06:55:55.287: INFO: (12) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 36.251549ms)
  Apr 15 06:55:55.288: INFO: (12) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 37.479339ms)
  Apr 15 06:55:55.289: INFO: (12) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 38.0287ms)
  Apr 15 06:55:55.289: INFO: (12) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 38.179105ms)
  Apr 15 06:55:55.290: INFO: (12) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 38.686753ms)
  Apr 15 06:55:55.294: INFO: (12) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 43.318371ms)
  Apr 15 06:55:55.294: INFO: (12) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 43.574897ms)
  Apr 15 06:55:55.295: INFO: (12) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 43.412027ms)
  Apr 15 06:55:55.295: INFO: (12) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 44.608968ms)
  Apr 15 06:55:55.296: INFO: (12) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 44.971339ms)
  Apr 15 06:55:55.354: INFO: (13) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 57.143866ms)
  Apr 15 06:55:55.355: INFO: (13) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 57.223066ms)
  Apr 15 06:55:55.355: INFO: (13) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 57.981984ms)
  Apr 15 06:55:55.362: INFO: (13) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 65.282154ms)
  Apr 15 06:55:55.366: INFO: (13) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 68.259951ms)
  Apr 15 06:55:55.366: INFO: (13) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 69.794939ms)
  Apr 15 06:55:55.367: INFO: (13) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 69.110465ms)
  Apr 15 06:55:55.367: INFO: (13) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 69.558523ms)
  Apr 15 06:55:55.369: INFO: (13) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 70.856387ms)
  Apr 15 06:55:55.375: INFO: (13) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 77.955684ms)
  Apr 15 06:55:55.375: INFO: (13) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 78.289588ms)
  Apr 15 06:55:55.375: INFO: (13) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 78.703491ms)
  Apr 15 06:55:55.375: INFO: (13) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 77.185075ms)
  Apr 15 06:55:55.376: INFO: (13) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 78.394414ms)
  Apr 15 06:55:55.376: INFO: (13) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 78.489559ms)
  Apr 15 06:55:55.381: INFO: (13) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 82.861175ms)
  Apr 15 06:55:55.399: INFO: (14) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 17.737995ms)
  Apr 15 06:55:55.401: INFO: (14) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 18.78515ms)
  Apr 15 06:55:55.405: INFO: (14) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 22.963961ms)
  Apr 15 06:55:55.407: INFO: (14) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 25.510324ms)
  Apr 15 06:55:55.408: INFO: (14) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 26.416283ms)
  Apr 15 06:55:55.409: INFO: (14) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 26.762792ms)
  Apr 15 06:55:55.409: INFO: (14) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 26.797906ms)
  Apr 15 06:55:55.409: INFO: (14) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 27.059296ms)
  Apr 15 06:55:55.417: INFO: (14) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 34.416047ms)
  Apr 15 06:55:55.418: INFO: (14) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 34.866452ms)
  Apr 15 06:55:55.418: INFO: (14) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 35.178755ms)
  Apr 15 06:55:55.418: INFO: (14) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 36.254809ms)
  Apr 15 06:55:55.418: INFO: (14) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 36.098319ms)
  Apr 15 06:55:55.420: INFO: (14) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 37.75623ms)
  Apr 15 06:55:55.423: INFO: (14) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 40.559871ms)
  Apr 15 06:55:55.425: INFO: (14) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 42.812281ms)
  Apr 15 06:55:55.446: INFO: (15) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 19.910335ms)
  Apr 15 06:55:55.446: INFO: (15) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 20.030309ms)
  Apr 15 06:55:55.448: INFO: (15) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 22.791118ms)
  Apr 15 06:55:55.456: INFO: (15) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 30.01182ms)
  Apr 15 06:55:55.456: INFO: (15) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 29.714171ms)
  Apr 15 06:55:55.458: INFO: (15) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 32.120576ms)
  Apr 15 06:55:55.459: INFO: (15) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 32.028666ms)
  Apr 15 06:55:55.461: INFO: (15) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 34.164197ms)
  Apr 15 06:55:55.461: INFO: (15) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 35.6302ms)
  Apr 15 06:55:55.462: INFO: (15) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 36.415648ms)
  Apr 15 06:55:55.462: INFO: (15) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 35.17553ms)
  Apr 15 06:55:55.467: INFO: (15) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 41.011264ms)
  Apr 15 06:55:55.467: INFO: (15) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 40.357657ms)
  Apr 15 06:55:55.468: INFO: (15) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 41.093189ms)
  Apr 15 06:55:55.469: INFO: (15) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 42.213088ms)
  Apr 15 06:55:55.476: INFO: (15) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 50.084925ms)
  Apr 15 06:55:55.498: INFO: (16) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 20.927732ms)
  Apr 15 06:55:55.498: INFO: (16) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 20.737934ms)
  Apr 15 06:55:55.501: INFO: (16) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 22.53725ms)
  Apr 15 06:55:55.501: INFO: (16) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 23.096497ms)
  Apr 15 06:55:55.504: INFO: (16) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 25.703105ms)
  Apr 15 06:55:55.505: INFO: (16) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 28.424229ms)
  Apr 15 06:55:55.505: INFO: (16) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 28.733736ms)
  Apr 15 06:55:55.507: INFO: (16) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 28.850093ms)
  Apr 15 06:55:55.508: INFO: (16) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 30.477325ms)
  Apr 15 06:55:55.508: INFO: (16) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 30.703152ms)
  Apr 15 06:55:55.512: INFO: (16) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 33.936848ms)
  Apr 15 06:55:55.512: INFO: (16) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 34.482286ms)
  Apr 15 06:55:55.516: INFO: (16) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 38.222471ms)
  Apr 15 06:55:55.517: INFO: (16) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 39.434254ms)
  Apr 15 06:55:55.517: INFO: (16) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 38.77958ms)
  Apr 15 06:55:55.517: INFO: (16) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 39.543977ms)
  Apr 15 06:55:55.538: INFO: (17) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 19.093128ms)
  Apr 15 06:55:55.538: INFO: (17) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 20.873772ms)
  Apr 15 06:55:55.542: INFO: (17) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 22.544134ms)
  Apr 15 06:55:55.544: INFO: (17) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 24.007377ms)
  Apr 15 06:55:55.553: INFO: (17) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 33.602244ms)
  Apr 15 06:55:55.554: INFO: (17) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 33.003978ms)
  Apr 15 06:55:55.554: INFO: (17) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 33.257312ms)
  Apr 15 06:55:55.554: INFO: (17) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 35.208809ms)
  Apr 15 06:55:55.558: INFO: (17) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 39.488876ms)
  Apr 15 06:55:55.558: INFO: (17) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 37.860857ms)
  Apr 15 06:55:55.558: INFO: (17) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 37.103466ms)
  Apr 15 06:55:55.558: INFO: (17) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 36.978538ms)
  Apr 15 06:55:55.558: INFO: (17) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 37.882238ms)
  Apr 15 06:55:55.558: INFO: (17) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 38.761507ms)
  Apr 15 06:55:55.563: INFO: (17) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 43.224288ms)
  Apr 15 06:55:55.564: INFO: (17) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 44.51647ms)
  Apr 15 06:55:55.587: INFO: (18) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 21.821301ms)
  Apr 15 06:55:55.594: INFO: (18) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 29.067427ms)
  Apr 15 06:55:55.594: INFO: (18) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 28.383761ms)
  Apr 15 06:55:55.595: INFO: (18) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 28.818933ms)
  Apr 15 06:55:55.596: INFO: (18) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 30.018541ms)
  Apr 15 06:55:55.596: INFO: (18) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 30.707341ms)
  Apr 15 06:55:55.598: INFO: (18) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 32.503611ms)
  Apr 15 06:55:55.607: INFO: (18) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 41.293039ms)
  Apr 15 06:55:55.609: INFO: (18) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 43.165017ms)
  Apr 15 06:55:55.609: INFO: (18) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 44.635118ms)
  Apr 15 06:55:55.609: INFO: (18) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 42.996454ms)
  Apr 15 06:55:55.609: INFO: (18) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 44.43633ms)
  Apr 15 06:55:55.609: INFO: (18) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 43.591149ms)
  Apr 15 06:55:55.611: INFO: (18) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 45.189972ms)
  Apr 15 06:55:55.615: INFO: (18) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 48.597831ms)
  Apr 15 06:55:55.618: INFO: (18) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 51.458664ms)
  Apr 15 06:55:55.627: INFO: (19) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 9.201611ms)
  Apr 15 06:55:55.639: INFO: (19) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">test<... (200; 20.498638ms)
  Apr 15 06:55:55.640: INFO: (19) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 21.941625ms)
  Apr 15 06:55:55.640: INFO: (19) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:443/proxy/tlsrewritem... (200; 21.93881ms)
  Apr 15 06:55:55.642: INFO: (19) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc/proxy/rewriteme">test</a> (200; 23.07078ms)
  Apr 15 06:55:55.642: INFO: (19) /api/v1/namespaces/proxy-6706/pods/proxy-service-bfqzp-2pfjc:162/proxy/: bar (200; 23.294906ms)
  Apr 15 06:55:55.645: INFO: (19) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:462/proxy/: tls qux (200; 27.150894ms)
  Apr 15 06:55:55.646: INFO: (19) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname2/proxy/: bar (200; 28.326006ms)
  Apr 15 06:55:55.647: INFO: (19) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname2/proxy/: bar (200; 28.656079ms)
  Apr 15 06:55:55.647: INFO: (19) /api/v1/namespaces/proxy-6706/services/http:proxy-service-bfqzp:portname1/proxy/: foo (200; 29.412519ms)
  Apr 15 06:55:55.652: INFO: (19) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/: <a href="/api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:1080/proxy/rewriteme">... (200; 32.863926ms)
  Apr 15 06:55:55.653: INFO: (19) /api/v1/namespaces/proxy-6706/services/proxy-service-bfqzp:portname1/proxy/: foo (200; 34.412701ms)
  Apr 15 06:55:55.655: INFO: (19) /api/v1/namespaces/proxy-6706/pods/http:proxy-service-bfqzp-2pfjc:160/proxy/: foo (200; 36.474194ms)
  Apr 15 06:55:55.657: INFO: (19) /api/v1/namespaces/proxy-6706/pods/https:proxy-service-bfqzp-2pfjc:460/proxy/: tls baz (200; 37.936279ms)
  Apr 15 06:55:55.658: INFO: (19) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname1/proxy/: tls baz (200; 38.954282ms)
  Apr 15 06:55:55.659: INFO: (19) /api/v1/namespaces/proxy-6706/services/https:proxy-service-bfqzp:tlsportname2/proxy/: tls qux (200; 40.4936ms)
  Apr 15 06:55:55.660: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController proxy-service-bfqzp in namespace proxy-6706, will wait for the garbage collector to delete the pods @ 04/15/24 06:55:55.679
  Apr 15 06:55:55.753: INFO: Deleting ReplicationController proxy-service-bfqzp took: 14.179514ms
  Apr 15 06:55:55.856: INFO: Terminating ReplicationController proxy-service-bfqzp pods took: 102.899971ms
  E0415 06:55:55.932326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:56.932561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:57.932777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "proxy-6706" for this suite. @ 04/15/24 06:55:58.457
â€¢ [5.889 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 04/15/24 06:55:58.479
  Apr 15 06:55:58.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:55:58.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:55:58.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:55:58.523
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 06:55:58.527
  E0415 06:55:58.933776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:55:59.934187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:00.934665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:01.935304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:56:02.591
  Apr 15 06:56:02.600: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-5d060dd7-ce72-4f60-9f55-4d95f6bcd6e7 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 06:56:02.616
  Apr 15 06:56:02.664: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3676" for this suite. @ 04/15/24 06:56:02.681
â€¢ [4.222 seconds]
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 04/15/24 06:56:02.702
  Apr 15 06:56:02.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 06:56:02.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:02.735
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:02.746
  Apr 15 06:56:02.842: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8737" for this suite. @ 04/15/24 06:56:02.852
â€¢ [0.163 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:218
  STEP: Creating a kubernetes client @ 04/15/24 06:56:02.866
  Apr 15 06:56:02.866: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 06:56:02.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:02.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:02.905
  STEP: Creating a pod to test downward api env vars @ 04/15/24 06:56:02.911
  E0415 06:56:02.935729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:03.935921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:04.936410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:05.936533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:06.937803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:56:06.971
  Apr 15 06:56:06.979: INFO: Trying to get logs from node phiefi7ighaa-3 pod downward-api-c70ef7aa-10f9-4bb7-b76a-e6c57de55555 container dapi-container: <nil>
  STEP: delete the pod @ 04/15/24 06:56:06.995
  Apr 15 06:56:07.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1580" for this suite. @ 04/15/24 06:56:07.043
â€¢ [4.192 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
test/e2e/kubectl/kubectl.go:830
  STEP: Creating a kubernetes client @ 04/15/24 06:56:07.065
  Apr 15 06:56:07.065: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 06:56:07.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:07.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:07.116
  STEP: validating api versions @ 04/15/24 06:56:07.123
  Apr 15 06:56:07.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-6357 api-versions'
  Apr 15 06:56:07.320: INFO: stderr: ""
  Apr 15 06:56:07.320: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Apr 15 06:56:07.320: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6357" for this suite. @ 04/15/24 06:56:07.342
â€¢ [0.296 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]
test/e2e/common/node/secrets.go:140
  STEP: Creating a kubernetes client @ 04/15/24 06:56:07.363
  Apr 15 06:56:07.363: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 06:56:07.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:07.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:07.416
  STEP: Creating projection with secret that has name secret-emptykey-test-2dd38873-b6ac-4ef0-918f-4e9f44f87fbc @ 04/15/24 06:56:07.423
  Apr 15 06:56:07.431: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3806" for this suite. @ 04/15/24 06:56:07.443
â€¢ [0.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]
test/e2e/common/node/configmap.go:169
  STEP: Creating a kubernetes client @ 04/15/24 06:56:07.473
  Apr 15 06:56:07.473: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 06:56:07.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:07.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:07.522
  STEP: creating a ConfigMap @ 04/15/24 06:56:07.532
  STEP: fetching the ConfigMap @ 04/15/24 06:56:07.545
  STEP: patching the ConfigMap @ 04/15/24 06:56:07.552
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 04/15/24 06:56:07.563
  STEP: deleting the ConfigMap by collection with a label selector @ 04/15/24 06:56:07.574
  STEP: listing all ConfigMaps in test namespace @ 04/15/24 06:56:07.596
  Apr 15 06:56:07.604: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2982" for this suite. @ 04/15/24 06:56:07.614
â€¢ [0.162 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]
test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 04/15/24 06:56:07.641
  Apr 15 06:56:07.641: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-pred @ 04/15/24 06:56:07.644
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:07.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:07.694
  Apr 15 06:56:07.700: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 15 06:56:07.733: INFO: Waiting for terminating namespaces to be deleted...
  Apr 15 06:56:07.747: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-1 before test
  Apr 15 06:56:07.759: INFO: coredns-5dd5756b68-6h4pb from kube-system started at 2024-04-15 06:16:14 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.760: INFO: 	Container coredns ready: true, restart count 0
  Apr 15 06:56:07.760: INFO: kube-addon-manager-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.760: INFO: 	Container kube-addon-manager ready: true, restart count 4
  Apr 15 06:56:07.760: INFO: kube-apiserver-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.761: INFO: 	Container kube-apiserver ready: true, restart count 4
  Apr 15 06:56:07.761: INFO: kube-controller-manager-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.761: INFO: 	Container kube-controller-manager ready: true, restart count 4
  Apr 15 06:56:07.761: INFO: kube-flannel-ds-wkm7k from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.762: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 06:56:07.762: INFO: kube-proxy-qgvqr from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.762: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 06:56:07.762: INFO: kube-scheduler-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.762: INFO: 	Container kube-scheduler ready: true, restart count 4
  Apr 15 06:56:07.763: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-f9ld5 from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (2 container statuses recorded)
  Apr 15 06:56:07.763: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:56:07.763: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 15 06:56:07.763: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-2 before test
  Apr 15 06:56:07.782: INFO: kube-addon-manager-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.782: INFO: 	Container kube-addon-manager ready: true, restart count 4
  Apr 15 06:56:07.782: INFO: kube-apiserver-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.782: INFO: 	Container kube-apiserver ready: true, restart count 4
  Apr 15 06:56:07.782: INFO: kube-controller-manager-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.782: INFO: 	Container kube-controller-manager ready: true, restart count 4
  Apr 15 06:56:07.783: INFO: kube-flannel-ds-5txx7 from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.783: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 06:56:07.783: INFO: kube-proxy-rkzlb from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.783: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 06:56:07.783: INFO: kube-scheduler-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.783: INFO: 	Container kube-scheduler ready: true, restart count 4
  Apr 15 06:56:07.783: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-jn669 from sonobuoy started at 2024-04-15 06:16:23 +0000 UTC (2 container statuses recorded)
  Apr 15 06:56:07.783: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:56:07.783: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 15 06:56:07.783: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-3 before test
  Apr 15 06:56:07.800: INFO: coredns-5dd5756b68-hggvw from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.801: INFO: 	Container coredns ready: true, restart count 0
  Apr 15 06:56:07.801: INFO: kube-flannel-ds-q9jkx from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.802: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 06:56:07.802: INFO: kube-proxy-rw79s from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.802: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 06:56:07.803: INFO: sonobuoy from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (1 container statuses recorded)
  Apr 15 06:56:07.803: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 15 06:56:07.803: INFO: sonobuoy-e2e-job-c84246e43b2d459a from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (2 container statuses recorded)
  Apr 15 06:56:07.804: INFO: 	Container e2e ready: true, restart count 0
  Apr 15 06:56:07.804: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:56:07.804: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-5gbvc from sonobuoy started at 2024-04-15 06:16:23 +0000 UTC (2 container statuses recorded)
  Apr 15 06:56:07.805: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 06:56:07.805: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node phiefi7ighaa-1 @ 04/15/24 06:56:07.898
  E0415 06:56:07.938700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the node has the label node phiefi7ighaa-2 @ 04/15/24 06:56:07.954
  STEP: verifying the node has the label node phiefi7ighaa-3 @ 04/15/24 06:56:07.983
  Apr 15 06:56:08.030: INFO: Pod coredns-5dd5756b68-6h4pb requesting resource cpu=100m on Node phiefi7ighaa-1
  Apr 15 06:56:08.031: INFO: Pod coredns-5dd5756b68-hggvw requesting resource cpu=100m on Node phiefi7ighaa-3
  Apr 15 06:56:08.031: INFO: Pod kube-addon-manager-phiefi7ighaa-1 requesting resource cpu=5m on Node phiefi7ighaa-1
  Apr 15 06:56:08.031: INFO: Pod kube-addon-manager-phiefi7ighaa-2 requesting resource cpu=5m on Node phiefi7ighaa-2
  Apr 15 06:56:08.031: INFO: Pod kube-apiserver-phiefi7ighaa-1 requesting resource cpu=250m on Node phiefi7ighaa-1
  Apr 15 06:56:08.031: INFO: Pod kube-apiserver-phiefi7ighaa-2 requesting resource cpu=250m on Node phiefi7ighaa-2
  Apr 15 06:56:08.031: INFO: Pod kube-controller-manager-phiefi7ighaa-1 requesting resource cpu=200m on Node phiefi7ighaa-1
  Apr 15 06:56:08.031: INFO: Pod kube-controller-manager-phiefi7ighaa-2 requesting resource cpu=200m on Node phiefi7ighaa-2
  Apr 15 06:56:08.031: INFO: Pod kube-flannel-ds-5txx7 requesting resource cpu=100m on Node phiefi7ighaa-2
  Apr 15 06:56:08.031: INFO: Pod kube-flannel-ds-q9jkx requesting resource cpu=100m on Node phiefi7ighaa-3
  Apr 15 06:56:08.031: INFO: Pod kube-flannel-ds-wkm7k requesting resource cpu=100m on Node phiefi7ighaa-1
  Apr 15 06:56:08.031: INFO: Pod kube-proxy-qgvqr requesting resource cpu=0m on Node phiefi7ighaa-1
  Apr 15 06:56:08.031: INFO: Pod kube-proxy-rkzlb requesting resource cpu=0m on Node phiefi7ighaa-2
  Apr 15 06:56:08.031: INFO: Pod kube-proxy-rw79s requesting resource cpu=0m on Node phiefi7ighaa-3
  Apr 15 06:56:08.031: INFO: Pod kube-scheduler-phiefi7ighaa-1 requesting resource cpu=100m on Node phiefi7ighaa-1
  Apr 15 06:56:08.031: INFO: Pod kube-scheduler-phiefi7ighaa-2 requesting resource cpu=100m on Node phiefi7ighaa-2
  Apr 15 06:56:08.031: INFO: Pod sonobuoy requesting resource cpu=0m on Node phiefi7ighaa-3
  Apr 15 06:56:08.031: INFO: Pod sonobuoy-e2e-job-c84246e43b2d459a requesting resource cpu=0m on Node phiefi7ighaa-3
  Apr 15 06:56:08.031: INFO: Pod sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-5gbvc requesting resource cpu=0m on Node phiefi7ighaa-3
  Apr 15 06:56:08.031: INFO: Pod sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-f9ld5 requesting resource cpu=0m on Node phiefi7ighaa-1
  Apr 15 06:56:08.032: INFO: Pod sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-jn669 requesting resource cpu=0m on Node phiefi7ighaa-2
  STEP: Starting Pods to consume most of the cluster CPU. @ 04/15/24 06:56:08.032
  Apr 15 06:56:08.032: INFO: Creating a pod which consumes cpu=591m on Node phiefi7ighaa-1
  Apr 15 06:56:08.072: INFO: Creating a pod which consumes cpu=661m on Node phiefi7ighaa-2
  Apr 15 06:56:08.092: INFO: Creating a pod which consumes cpu=980m on Node phiefi7ighaa-3
  E0415 06:56:08.940655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:09.941826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 04/15/24 06:56:10.186
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1d824263-19d4-450e-a779-a2d6aa043f06.17c661bbf3940180], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3810/filler-pod-1d824263-19d4-450e-a779-a2d6aa043f06 to phiefi7ighaa-2] @ 04/15/24 06:56:10.198
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1d824263-19d4-450e-a779-a2d6aa043f06.17c661bc2041bd43], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/15/24 06:56:10.203
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1d824263-19d4-450e-a779-a2d6aa043f06.17c661bc2c89f350], Reason = [Created], Message = [Created container filler-pod-1d824263-19d4-450e-a779-a2d6aa043f06] @ 04/15/24 06:56:10.203
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-1d824263-19d4-450e-a779-a2d6aa043f06.17c661bc2e79e755], Reason = [Started], Message = [Started container filler-pod-1d824263-19d4-450e-a779-a2d6aa043f06] @ 04/15/24 06:56:10.204
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-2e30f780-c448-4f97-bea5-224af2be4efb.17c661bbf0e9065e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3810/filler-pod-2e30f780-c448-4f97-bea5-224af2be4efb to phiefi7ighaa-1] @ 04/15/24 06:56:10.211
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-2e30f780-c448-4f97-bea5-224af2be4efb.17c661bc17f9f7dc], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/15/24 06:56:10.211
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-2e30f780-c448-4f97-bea5-224af2be4efb.17c661bc27332354], Reason = [Created], Message = [Created container filler-pod-2e30f780-c448-4f97-bea5-224af2be4efb] @ 04/15/24 06:56:10.211
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-2e30f780-c448-4f97-bea5-224af2be4efb.17c661bc2d7ddaa3], Reason = [Started], Message = [Started container filler-pod-2e30f780-c448-4f97-bea5-224af2be4efb] @ 04/15/24 06:56:10.211
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3465f4c2-1562-4037-aec2-797c1ccc9458.17c661bbf4aac162], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3810/filler-pod-3465f4c2-1562-4037-aec2-797c1ccc9458 to phiefi7ighaa-3] @ 04/15/24 06:56:10.212
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3465f4c2-1562-4037-aec2-797c1ccc9458.17c661bc19806867], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/15/24 06:56:10.212
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3465f4c2-1562-4037-aec2-797c1ccc9458.17c661bc2329c855], Reason = [Created], Message = [Created container filler-pod-3465f4c2-1562-4037-aec2-797c1ccc9458] @ 04/15/24 06:56:10.216
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-3465f4c2-1562-4037-aec2-797c1ccc9458.17c661bc27a32815], Reason = [Started], Message = [Started container filler-pod-3465f4c2-1562-4037-aec2-797c1ccc9458] @ 04/15/24 06:56:10.216
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17c661bc6f60e141], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..] @ 04/15/24 06:56:10.217
  E0415 06:56:10.942702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node phiefi7ighaa-3 @ 04/15/24 06:56:11.222
  STEP: verifying the node doesn't have the label node @ 04/15/24 06:56:11.252
  STEP: removing the label node off the node phiefi7ighaa-1 @ 04/15/24 06:56:11.26
  STEP: verifying the node doesn't have the label node @ 04/15/24 06:56:11.323
  STEP: removing the label node off the node phiefi7ighaa-2 @ 04/15/24 06:56:11.334
  STEP: verifying the node doesn't have the label node @ 04/15/24 06:56:11.363
  Apr 15 06:56:11.375: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3810" for this suite. @ 04/15/24 06:56:11.385
â€¢ [3.774 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 04/15/24 06:56:11.417
  Apr 15 06:56:11.417: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 06:56:11.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:11.463
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:11.469
  STEP: Creating configMap with name cm-test-opt-del-0560ddfa-8cd2-4944-8baf-f0a3353e4f8b @ 04/15/24 06:56:11.493
  STEP: Creating configMap with name cm-test-opt-upd-db8c271b-69ed-43ae-af49-0c97d7ad7400 @ 04/15/24 06:56:11.508
  STEP: Creating the pod @ 04/15/24 06:56:11.518
  E0415 06:56:11.944342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:12.944560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-0560ddfa-8cd2-4944-8baf-f0a3353e4f8b @ 04/15/24 06:56:13.626
  STEP: Updating configmap cm-test-opt-upd-db8c271b-69ed-43ae-af49-0c97d7ad7400 @ 04/15/24 06:56:13.642
  STEP: Creating configMap with name cm-test-opt-create-19daaa45-95eb-4ee4-8840-c51e519d2d1b @ 04/15/24 06:56:13.657
  STEP: waiting to observe update in volume @ 04/15/24 06:56:13.67
  E0415 06:56:13.946201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:14.946367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:15.947010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:16.947485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:17.752: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1186" for this suite. @ 04/15/24 06:56:17.77
â€¢ [6.370 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods  [Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 04/15/24 06:56:17.788
  Apr 15 06:56:17.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 06:56:17.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:17.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:17.908
  STEP: creating service multi-endpoint-test in namespace services-7020 @ 04/15/24 06:56:17.928
  E0415 06:56:17.948291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7020 to expose endpoints map[] @ 04/15/24 06:56:17.987
  Apr 15 06:56:18.014: INFO: successfully validated that service multi-endpoint-test in namespace services-7020 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-7020 @ 04/15/24 06:56:18.015
  E0415 06:56:18.948424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:19.949180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7020 to expose endpoints map[pod1:[100]] @ 04/15/24 06:56:20.07
  Apr 15 06:56:20.092: INFO: successfully validated that service multi-endpoint-test in namespace services-7020 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-7020 @ 04/15/24 06:56:20.093
  E0415 06:56:20.949808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:21.949741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7020 to expose endpoints map[pod1:[100] pod2:[101]] @ 04/15/24 06:56:22.127
  Apr 15 06:56:22.165: INFO: successfully validated that service multi-endpoint-test in namespace services-7020 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 04/15/24 06:56:22.165
  Apr 15 06:56:22.165: INFO: Creating new exec pod
  E0415 06:56:22.950352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:23.950924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:24.951761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:25.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-7020 exec execpod4xh87 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Apr 15 06:56:25.551: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Apr 15 06:56:25.551: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 06:56:25.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-7020 exec execpod4xh87 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.12.201 80'
  Apr 15 06:56:25.844: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.12.201 80\nConnection to 10.233.12.201 80 port [tcp/http] succeeded!\n"
  Apr 15 06:56:25.844: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 06:56:25.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-7020 exec execpod4xh87 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  E0415 06:56:25.952436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:26.167: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Apr 15 06:56:26.167: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 06:56:26.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-7020 exec execpod4xh87 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.12.201 81'
  Apr 15 06:56:26.435: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.12.201 81\nConnection to 10.233.12.201 81 port [tcp/*] succeeded!\n"
  Apr 15 06:56:26.435: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-7020 @ 04/15/24 06:56:26.435
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7020 to expose endpoints map[pod2:[101]] @ 04/15/24 06:56:26.497
  Apr 15 06:56:26.539: INFO: successfully validated that service multi-endpoint-test in namespace services-7020 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-7020 @ 04/15/24 06:56:26.539
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7020 to expose endpoints map[] @ 04/15/24 06:56:26.595
  E0415 06:56:26.955020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:27.654: INFO: successfully validated that service multi-endpoint-test in namespace services-7020 exposes endpoints map[]
  Apr 15 06:56:27.655: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7020" for this suite. @ 04/15/24 06:56:27.72
â€¢ [9.967 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
test/e2e/apimachinery/aggregator.go:96
  STEP: Creating a kubernetes client @ 04/15/24 06:56:27.76
  Apr 15 06:56:27.760: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename aggregator @ 04/15/24 06:56:27.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:27.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:27.804
  Apr 15 06:56:27.810: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Registering the sample API server. @ 04/15/24 06:56:27.813
  E0415 06:56:27.955929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:28.956198      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:29.029: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Apr 15 06:56:29.174: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0415 06:56:29.956669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:30.960524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:31.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:31.964120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:32.962476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:33.468: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:33.963406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:34.963844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:35.455: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:35.965062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:36.965099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:37.455: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:37.965426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:38.965723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:39.456: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:39.966028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:40.967282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:41.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:41.967962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:42.968011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:43.461: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:43.969032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:44.968498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:45.457: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:45.969247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:46.969375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:47.455: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:47.969613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:48.969591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:49.455: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:49.970468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:50.970954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:51.457: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5769b9d9dd\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 06:56:51.972189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:52.972537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:53.622: INFO: Waited 139.362969ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 04/15/24 06:56:53.728
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 04/15/24 06:56:53.736
  STEP: List APIServices @ 04/15/24 06:56:53.75
  Apr 15 06:56:53.765: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 04/15/24 06:56:53.765
  Apr 15 06:56:53.796: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 04/15/24 06:56:53.796
  Apr 15 06:56:53.816: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2024, time.April, 15, 6, 56, 53, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 04/15/24 06:56:53.816
  Apr 15 06:56:53.826: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2024-04-15 06:56:53 +0000 UTC Passed all checks passed}
  Apr 15 06:56:53.826: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 15 06:56:53.826: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 04/15/24 06:56:53.827
  Apr 15 06:56:53.853: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete APIService "dynamic-flunder-2144733443" @ 04/15/24 06:56:53.854
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 04/15/24 06:56:53.889
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 04/15/24 06:56:53.907
  STEP: Patch APIService Status @ 04/15/24 06:56:53.916
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 04/15/24 06:56:53.932
  Apr 15 06:56:53.945: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2024-04-15 06:56:53 +0000 UTC Passed all checks passed}
  Apr 15 06:56:53.948: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 15 06:56:53.948: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Apr 15 06:56:53.949: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "e2e-apiservice=patched" @ 04/15/24 06:56:53.949
  STEP: Confirm that the generated APIService has been deleted @ 04/15/24 06:56:53.961
  Apr 15 06:56:53.961: INFO: Requesting list of APIServices to confirm quantity
  E0415 06:56:53.973098      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:56:53.975: INFO: Found 0 APIService with label "e2e-apiservice=patched"
  Apr 15 06:56:53.976: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Apr 15 06:56:54.227: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-890" for this suite. @ 04/15/24 06:56:54.36
â€¢ [26.630 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 04/15/24 06:56:54.403
  Apr 15 06:56:54.403: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename cronjob @ 04/15/24 06:56:54.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:56:54.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:56:54.472
  STEP: Creating a ReplaceConcurrent cronjob @ 04/15/24 06:56:54.479
  STEP: Ensuring a job is scheduled @ 04/15/24 06:56:54.493
  E0415 06:56:54.973740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:55.974116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:56.975032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:57.975271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:58.975473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:56:59.976585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/15/24 06:57:00.502
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/15/24 06:57:00.51
  STEP: Ensuring the job is replaced with a new one @ 04/15/24 06:57:00.52
  E0415 06:57:00.976112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:01.976256      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:02.977148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:03.977526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:04.977832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:05.978213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:06.978398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:07.979185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:08.979902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:09.980725      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:10.980316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:11.981176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:12.981809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:13.981812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:14.982900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:15.982975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:16.983466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:17.983878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:18.984208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:19.985348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:20.986349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:21.986726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:22.986805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:23.987165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:24.987879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:25.987964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:26.988339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:27.989078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:28.989392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:29.989801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:30.990260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:31.990196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:32.991071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:33.991984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:34.993224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:35.993413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:36.994245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:37.994470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:38.994964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:39.995110      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:40.995996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:41.996563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:42.997131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:43.997332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:44.997735      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:45.997835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:46.998311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:47.998452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:48.999412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:49.999897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:51.001350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:52.001536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:53.002798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:54.003075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:55.003822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:56.004254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:57.004985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:58.005502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:57:59.005313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:00.006425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 04/15/24 06:58:00.542
  Apr 15 06:58:00.563: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4714" for this suite. @ 04/15/24 06:58:00.588
â€¢ [66.204 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 04/15/24 06:58:00.609
  Apr 15 06:58:00.610: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-preemption @ 04/15/24 06:58:00.615
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:58:00.666
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:58:00.673
  Apr 15 06:58:00.709: INFO: Waiting up to 1m0s for all nodes to be ready
  E0415 06:58:01.007099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:02.007356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:03.007536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:04.008312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:05.009412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:06.009537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:07.009639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:08.009791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:09.010517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:10.010858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:11.010955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:12.011686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:13.012554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:14.012783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:15.013508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:16.014268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:17.014497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:18.015510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:19.016525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:20.016787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:21.016979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:22.017301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:23.018188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:24.018375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:25.019488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:26.020410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:27.022111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:28.022751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:29.023486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:30.024582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:31.024753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:32.025798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:33.026359      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:34.027292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:35.027425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:36.027971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:37.029240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:38.030079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:39.030997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:40.032002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:41.032303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:42.033236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:43.034561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:44.035311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:45.036088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:46.036364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:47.036748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:48.037033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:49.037299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:50.038184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:51.038436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:52.038828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:53.039095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:54.040585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:55.041100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:56.070750      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:57.049187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:58.050607      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:58:59.050744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:00.051881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:00.780: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/15/24 06:59:00.798
  Apr 15 06:59:00.798: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/15/24 06:59:00.806
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:59:00.892
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:59:00.901
  Apr 15 06:59:00.961: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Apr 15 06:59:00.973: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Apr 15 06:59:01.033: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 06:59:01.058267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:01.135: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2824" for this suite. @ 04/15/24 06:59:01.283
  STEP: Destroying namespace "sched-preemption-2448" for this suite. @ 04/15/24 06:59:01.299
â€¢ [60.707 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]
test/e2e/auth/service_accounts.go:740
  STEP: Creating a kubernetes client @ 04/15/24 06:59:01.33
  Apr 15 06:59:01.331: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename svcaccounts @ 04/15/24 06:59:01.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:59:01.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:59:01.386
  Apr 15 06:59:01.418: INFO: Got root ca configmap in namespace "svcaccounts-1192"
  Apr 15 06:59:01.438: INFO: Deleted root ca configmap in namespace "svcaccounts-1192"
  STEP: waiting for a new root ca configmap created @ 04/15/24 06:59:01.939
  Apr 15 06:59:01.958: INFO: Recreated root ca configmap in namespace "svcaccounts-1192"
  Apr 15 06:59:01.980: INFO: Updated root ca configmap in namespace "svcaccounts-1192"
  E0415 06:59:02.058524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for the root ca configmap reconciled @ 04/15/24 06:59:02.481
  Apr 15 06:59:02.490: INFO: Reconciled root ca configmap in namespace "svcaccounts-1192"
  Apr 15 06:59:02.490: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1192" for this suite. @ 04/15/24 06:59:02.502
â€¢ [1.190 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance]
test/e2e/common/node/secrets.go:154
  STEP: Creating a kubernetes client @ 04/15/24 06:59:02.522
  Apr 15 06:59:02.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 06:59:02.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:59:02.569
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:59:02.577
  STEP: creating a secret @ 04/15/24 06:59:02.591
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 04/15/24 06:59:02.616
  STEP: patching the secret @ 04/15/24 06:59:02.633
  STEP: deleting the secret using a LabelSelector @ 04/15/24 06:59:02.681
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 04/15/24 06:59:02.709
  Apr 15 06:59:02.719: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8883" for this suite. @ 04/15/24 06:59:02.733
â€¢ [0.269 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 04/15/24 06:59:02.8
  Apr 15 06:59:02.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 06:59:02.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:59:02.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:59:02.873
  STEP: Creating secret with name secret-test-map-0114e6d6-6034-49fc-9357-aa58bf004a18 @ 04/15/24 06:59:02.881
  STEP: Creating a pod to test consume secrets @ 04/15/24 06:59:02.905
  E0415 06:59:03.059141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:04.060116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:05.060242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:06.061223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 06:59:06.99
  Apr 15 06:59:07.003: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-secrets-d57d311c-3848-43e0-9b81-b81ebb6f5ad8 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 06:59:07.05
  E0415 06:59:07.061924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:07.084: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1964" for this suite. @ 04/15/24 06:59:07.096
â€¢ [4.312 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 04/15/24 06:59:07.118
  Apr 15 06:59:07.119: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 06:59:07.122
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 06:59:07.164
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 06:59:07.17
  STEP: Creating pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094 @ 04/15/24 06:59:07.181
  E0415 06:59:08.062377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:09.062641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/15/24 06:59:09.219
  Apr 15 06:59:09.228: INFO: Initial restart count of pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d is 0
  Apr 15 06:59:09.235: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:10.062971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:11.063335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:11.243: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:12.063762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:13.064041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:13.251: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:14.064365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:15.064879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:15.260: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:16.065301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:17.065765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:17.270: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:18.066951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:19.067728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:19.283: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:20.067880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:21.068825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:21.293: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:22.069152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:23.069889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:23.306: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:24.069907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:25.070624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:25.324: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:26.070868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:27.071526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:27.352: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:28.071694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:29.071953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:29.362: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:30.072588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:31.073383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:31.376: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:32.074129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:33.075049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:33.385: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:34.075211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:35.075451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:35.394: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:36.075636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:37.075785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:37.404: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:38.075841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:39.075982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:39.411: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:40.076565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:41.076855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:41.419: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:42.077083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:43.077376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:43.435: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:44.077478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:45.078584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:45.443: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:46.079505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:47.080258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:47.452: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:48.081142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:49.081386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:49.460: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:50.081514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:51.082195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:51.471: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:52.082276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:53.082523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:53.481: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:54.082695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:55.082866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:55.490: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:56.083063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:57.083490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:57.500: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 06:59:58.083632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 06:59:59.084116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 06:59:59.514: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:00.084990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:01.085122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:01.526: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:02.085347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:03.086498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:03.536: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:04.086585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:05.087655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:05.545: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:06.087859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:07.087990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:07.554: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:08.088037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:09.088705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:09.566: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:10.088806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:11.089548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:11.576: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:12.089602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:13.089969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:13.586: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:14.090160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:15.091002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:15.599: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:16.091069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:17.091347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:17.610: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:18.091614      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:19.092575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:19.621: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:20.092794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:21.093738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:21.630: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:22.094465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:23.095065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:23.640: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:24.096029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:25.096353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:25.651: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:26.097075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:27.097871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:27.659: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:28.098037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:29.098915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:29.668: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:30.099729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:31.100862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:31.677: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:32.101477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:33.101713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:33.688: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:34.102215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:35.103218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:35.698: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:36.103352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:37.104134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:37.707: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:38.104316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:39.104509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:39.719: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:40.104605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:41.104796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:41.729: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:42.105480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:43.106469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:43.739: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:44.107373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:45.108301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:45.749: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:46.109220      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:47.109359      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:47.762: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:48.109955      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:49.110293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:49.774: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:50.111284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:51.111606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:51.783: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:52.111785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:53.111967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:53.798: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:54.112104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:55.113229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:55.807: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:56.114038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:57.114243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:57.821: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:00:58.115175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:00:59.115568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:00:59.832: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:00.116784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:01.116727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:01.842: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:02.117707      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:03.118199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:03.854: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:04.118912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:05.119716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:05.863: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:06.120552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:07.120702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:07.870: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:08.121420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:09.122213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:09.879: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:10.122696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:11.122908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:11.889: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:12.123762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:13.125179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:13.904: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:14.128518      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:15.129320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:15.914: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:16.130357      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:17.131016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:17.925: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:18.132806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:19.132733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:19.935: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:20.133341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:21.133592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:21.946: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:22.133814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:23.134713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:23.958: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:24.134353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:25.134455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:25.972: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:26.134939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:27.135797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:27.982: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:28.136399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:29.136797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:29.995: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:30.137869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:31.138038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:32.005: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:32.139954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:33.139179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:34.015: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:34.140083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:35.141136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:36.024: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:36.141402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:37.141213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:38.034: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:38.141817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:39.142600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:40.043: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:40.143013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:41.143194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:42.051: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:42.144248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:43.144062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:44.062: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:44.145067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:45.145696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:46.074: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:46.146503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:47.146831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:48.085: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:48.147174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:49.147808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:50.098: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:50.148541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:51.148887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:52.113: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:52.149457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:53.149799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:54.122: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:54.150244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:55.150213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:56.142: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:56.150746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:57.150983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:01:58.159180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:01:58.159: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:01:59.159434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:00.160463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:00.168: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:01.161690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:02.161936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:02.178: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:03.162417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:04.163191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:04.190: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:05.163478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:06.164360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:06.201: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:07.164717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:08.165721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:08.213: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:09.166171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:10.166302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:10.223: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:11.166699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:12.167464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:12.232: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:13.167612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:14.168223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:14.243: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:15.168314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:16.170250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:16.256: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:17.170079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:18.170736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:18.265: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:19.170609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:20.171103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:20.276: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:21.171469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:22.171410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:22.293: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:23.171675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:24.172041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:24.307: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:25.172450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:26.173496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:26.318: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:27.174561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:28.174459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:28.331: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:29.175077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:30.175066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:30.342: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:31.175259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:32.175912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:32.353: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:33.176562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:34.177030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:34.368: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:35.178128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:36.178503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:36.379: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:37.178718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:38.179265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:38.388: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:39.179402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:40.180465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:40.399: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:41.180678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:42.180747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:42.411: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:43.181101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:44.181221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:44.425: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:45.181587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:46.182012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:46.434: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:47.182275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:48.182470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:48.445: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:49.183049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:50.183331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:50.455: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:51.183798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:52.183728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:52.467: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:53.184573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:54.184354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:54.476: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:55.185038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:56.185337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:56.485: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:57.185939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:02:58.186208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:02:58.496: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:02:59.186266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:00.187777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:03:00.508: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:03:01.187935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:02.188226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:03:02.517: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:03:03.190988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:04.194275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:03:04.534: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:03:05.189739      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:06.189977      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:03:06.544: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:03:07.190226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:08.191176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:03:08.553: INFO: Get pod test-webserver-e55a7576-769e-48b7-a318-c5d72107216d in namespace container-probe-4094
  E0415 07:03:09.192724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:10.192814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:03:10.555: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:03:10.571
  STEP: Destroying namespace "container-probe-4094" for this suite. @ 04/15/24 07:03:10.613
â€¢ [243.541 seconds]
------------------------------
SS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 04/15/24 07:03:10.663
  Apr 15 07:03:10.663: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename conformance-tests @ 04/15/24 07:03:10.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:03:10.743
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:03:10.751
  STEP: Getting node addresses @ 04/15/24 07:03:10.762
  Apr 15 07:03:10.763: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Apr 15 07:03:10.782: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-3162" for this suite. @ 04/15/24 07:03:10.8
â€¢ [0.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:486
  STEP: Creating a kubernetes client @ 04/15/24 07:03:10.829
  Apr 15 07:03:10.829: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename security-context-test @ 04/15/24 07:03:10.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:03:10.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:03:10.874
  E0415 07:03:11.193983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:12.196313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:13.196691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:14.197321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:03:14.956: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8431" for this suite. @ 04/15/24 07:03:14.976
â€¢ [4.164 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 04/15/24 07:03:14.998
  Apr 15 07:03:14.998: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename dns @ 04/15/24 07:03:15.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:03:15.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:03:15.05
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 04/15/24 07:03:15.056
  Apr 15 07:03:15.075: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8374  a2011fdd-b3ca-4168-8aac-49cbeaac3bef 162925 0 2024-04-15 07:03:15 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-04-15 07:03:15 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x68t4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.47,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x68t4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0415 07:03:15.197913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:16.198311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 04/15/24 07:03:17.147
  Apr 15 07:03:17.147: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8374 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:03:17.147: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:03:17.151: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:03:17.151: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-8374/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0415 07:03:17.199364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS server is configured on pod... @ 04/15/24 07:03:17.364
  Apr 15 07:03:17.365: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8374 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:03:17.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:03:17.369: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:03:17.370: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-8374/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 15 07:03:17.520: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 07:03:17.534: INFO: Deleting pod test-dns-nameservers...
  STEP: Destroying namespace "dns-8374" for this suite. @ 04/15/24 07:03:17.582
â€¢ [2.611 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance]
test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 04/15/24 07:03:17.684
  Apr 15 07:03:17.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename job @ 04/15/24 07:03:17.687
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:03:17.719
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:03:17.726
  STEP: Creating a job @ 04/15/24 07:03:17.737
  STEP: Ensuring active pods == parallelism @ 04/15/24 07:03:17.753
  E0415 07:03:18.199530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:19.199539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 04/15/24 07:03:19.766
  STEP: deleting Job.batch foo in namespace job-898, will wait for the garbage collector to delete the pods @ 04/15/24 07:03:19.767
  Apr 15 07:03:19.850: INFO: Deleting Job.batch foo took: 20.238518ms
  Apr 15 07:03:19.951: INFO: Terminating Job.batch foo pods took: 101.324608ms
  E0415 07:03:20.200426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:21.200567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:22.201762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:23.202675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:24.203122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:25.204229      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:26.205077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:27.205813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:28.206731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:29.207322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:30.207593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:31.208034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:32.208394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:33.209009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:34.209765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:35.210240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:36.211331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:37.212322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:38.212436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:39.213341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:40.213568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:41.214350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:42.214627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:43.215434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:44.215808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:45.216871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:46.217448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:47.218038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:48.218420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:49.218878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:50.219263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:51.219616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 04/15/24 07:03:51.753
  Apr 15 07:03:51.762: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-898" for this suite. @ 04/15/24 07:03:51.773
â€¢ [34.107 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]
test/e2e/apps/statefulset.go:961
  STEP: Creating a kubernetes client @ 04/15/24 07:03:51.797
  Apr 15 07:03:51.797: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename statefulset @ 04/15/24 07:03:51.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:03:51.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:03:51.848
  STEP: Creating service test in namespace statefulset-8412 @ 04/15/24 07:03:51.853
  Apr 15 07:03:51.902: INFO: Found 0 stateful pods, waiting for 1
  E0415 07:03:52.220211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:53.220885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:54.221030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:55.221512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:56.222387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:57.222282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:58.222471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:03:59.222794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:00.222919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:01.223140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:04:01.910: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 04/15/24 07:04:01.922
  W0415 07:04:01.950850      13 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 15 07:04:01.973: INFO: Found 1 stateful pods, waiting for 2
  E0415 07:04:02.223986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:03.223969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:04.224482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:05.225695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:06.225889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:07.226154      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:08.227165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:09.227534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:10.228362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:11.228554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:04:11.988: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 07:04:11.988: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 04/15/24 07:04:12.006
  STEP: Delete all of the StatefulSets @ 04/15/24 07:04:12.018
  STEP: Verify that StatefulSets have been deleted @ 04/15/24 07:04:12.037
  Apr 15 07:04:12.045: INFO: Deleting all statefulset in ns statefulset-8412
  Apr 15 07:04:12.069: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8412" for this suite. @ 04/15/24 07:04:12.101
â€¢ [20.344 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
test/e2e/apps/statefulset.go:331
  STEP: Creating a kubernetes client @ 04/15/24 07:04:12.156
  Apr 15 07:04:12.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename statefulset @ 04/15/24 07:04:12.198
  E0415 07:04:12.229028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:04:12.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:04:12.294
  STEP: Creating service test in namespace statefulset-560 @ 04/15/24 07:04:12.301
  STEP: Creating a new StatefulSet @ 04/15/24 07:04:12.328
  Apr 15 07:04:12.392: INFO: Found 0 stateful pods, waiting for 3
  E0415 07:04:13.230834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:14.230815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:15.231488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:16.232500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:17.232687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:18.233742      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:19.233552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:20.233852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:21.234158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:22.234364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:04:22.407: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 07:04:22.407: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 07:04:22.408: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/15/24 07:04:22.431
  Apr 15 07:04:22.464: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/15/24 07:04:22.464
  E0415 07:04:23.234849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:24.235506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:25.235238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:26.235288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:27.235495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:28.235935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:29.236137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:30.237189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:31.237549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:32.237693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 04/15/24 07:04:32.502
  STEP: Performing a canary update @ 04/15/24 07:04:32.502
  Apr 15 07:04:32.537: INFO: Updating stateful set ss2
  Apr 15 07:04:32.559: INFO: Waiting for Pod statefulset-560/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0415 07:04:33.238598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:34.239728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:35.239824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:36.240346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:37.241028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:38.241177      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:39.241778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:40.242985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:41.243264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:42.243350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 04/15/24 07:04:42.587
  Apr 15 07:04:42.743: INFO: Found 1 stateful pods, waiting for 3
  E0415 07:04:43.243805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:44.244628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:45.245639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:46.246043      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:47.246076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:48.246637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:49.246867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:50.247740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:51.248082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:52.248204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:04:52.754: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 07:04:52.755: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 15 07:04:52.755: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 04/15/24 07:04:52.776
  Apr 15 07:04:52.814: INFO: Updating stateful set ss2
  Apr 15 07:04:52.831: INFO: Waiting for Pod statefulset-560/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0415 07:04:53.248734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:54.249064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:55.250057      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:56.250999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:57.251050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:58.251123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:04:59.251849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:00.252671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:01.252626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:02.253032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:02.890: INFO: Updating stateful set ss2
  Apr 15 07:05:02.915: INFO: Waiting for StatefulSet statefulset-560/ss2 to complete update
  Apr 15 07:05:02.916: INFO: Waiting for Pod statefulset-560/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0415 07:05:03.253886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:04.257174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:05.255252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:06.255962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:07.256472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:08.256470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:09.257285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:10.257493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:11.257636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:12.257857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:12.937: INFO: Deleting all statefulset in ns statefulset-560
  Apr 15 07:05:12.947: INFO: Scaling statefulset ss2 to 0
  E0415 07:05:13.258771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:14.258863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:15.260078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:16.260605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:17.261689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:18.261973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:19.262602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:20.263377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:21.264232      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:22.264863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:22.990: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 15 07:05:22.999: INFO: Deleting statefulset ss2
  Apr 15 07:05:23.031: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-560" for this suite. @ 04/15/24 07:05:23.054
â€¢ [70.925 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 04/15/24 07:05:23.088
  Apr 15 07:05:23.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 07:05:23.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:05:23.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:05:23.163
  STEP: Creating pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019 @ 04/15/24 07:05:23.171
  E0415 07:05:23.265754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:24.266740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/15/24 07:05:25.218
  Apr 15 07:05:25.226: INFO: Initial restart count of pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae is 0
  Apr 15 07:05:25.235: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:25.266893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:26.267075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:27.245: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:27.268446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:28.268506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:29.255: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:29.268677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:30.268806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:31.269764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:31.278: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:32.270000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:33.272245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:33.287: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:34.272121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:35.273606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:35.311: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:36.273150      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:37.273375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:37.323: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:38.273426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:39.273697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:39.345: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:40.274048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:41.274242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:41.358: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:42.274738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:43.275744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:43.370: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  E0415 07:05:44.275021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:45.275807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:45.379: INFO: Get pod liveness-ccded694-d20b-4fd4-878c-b116a79f33ae in namespace container-probe-1019
  Apr 15 07:05:45.379: INFO: Restart count of pod container-probe-1019/liveness-ccded694-d20b-4fd4-878c-b116a79f33ae is now 1 (20.150921605s elapsed)
  Apr 15 07:05:45.380: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:05:45.39
  STEP: Destroying namespace "container-probe-1019" for this suite. @ 04/15/24 07:05:45.425
â€¢ [22.355 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 04/15/24 07:05:45.446
  Apr 15 07:05:45.446: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 07:05:45.45
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:05:45.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:05:45.494
  STEP: Creating pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349 @ 04/15/24 07:05:45.5
  E0415 07:05:46.275796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:47.276525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/15/24 07:05:47.548
  Apr 15 07:05:47.555: INFO: Initial restart count of pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf is 0
  Apr 15 07:05:47.563: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:05:48.276932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:49.277958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:49.574: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:05:50.278644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:51.278782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:51.585: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:05:52.278920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:53.279181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:53.598: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:05:54.279324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:55.280364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:55.608: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:05:56.281208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:57.281851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:57.619: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:05:58.281940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:05:59.282168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:05:59.630: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:00.282465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:01.283403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:01.637: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:02.283517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:03.284559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:03.649: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:04.284629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:05.285747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:05.665: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:06.285880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:07.287038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:07.676: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:08.287845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:09.289081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:09.685: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:10.289746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:11.290086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:11.697: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:12.291047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:13.291793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:13.709: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:14.291927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:15.292722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:15.723: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:16.293681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:17.294427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:17.743: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:18.294987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:19.296711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:19.754: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:20.296983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:21.297638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:21.765: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:22.298799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:23.298792      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:23.774: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:24.299860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:25.299880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:25.785: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:26.300757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:27.301642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:27.793: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:28.301878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:29.302051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:29.802: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:30.302867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:31.303209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:31.811: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:32.303570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:33.303737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:33.821: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:34.304085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:35.304480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:35.832: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:36.304983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:37.305883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:37.842: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:38.306365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:39.306808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:39.851: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:40.306815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:41.307216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:41.861: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:42.307700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:43.308308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:43.872: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:44.308808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:45.309552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:45.881: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:46.310503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:47.310860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:47.893: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:48.311561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:49.312388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:49.905: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:50.312502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:51.313398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:51.918: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:52.313106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:53.313500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:53.930: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:54.315001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:55.314620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:55.941: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:56.315797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:57.316085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:57.950: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:06:58.316842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:06:59.317272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:06:59.960: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:00.317287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:01.317307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:01.971: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:02.318641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:03.319167      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:03.982: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:04.319331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:05.321747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:05.993: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:06.320378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:07.321190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:08.002: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:08.321472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:09.322321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:10.012: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:10.323470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:11.323691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:12.021: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:12.324640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:13.325064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:14.030: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:14.325244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:15.325461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:16.040: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:16.325620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:17.326085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:18.049: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:18.327581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:19.327319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:20.068: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:20.328840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:21.328934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:22.077: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:22.329638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:23.330509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:24.088: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:24.331514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:25.331953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:26.098: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:26.332952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:27.333062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:28.111: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:28.334374      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:29.334375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:30.121: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:30.335733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:31.335764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:32.134: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:32.336630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:33.337148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:34.144: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:34.337114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:35.338386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:36.152: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:36.338849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:37.339693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:38.162: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:38.340307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:39.341010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:40.174: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:40.340617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:41.341440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:42.184: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:42.342549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:43.343105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:44.197: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:44.343510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:45.343600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:46.209: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:46.344250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:47.344809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:48.220: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:48.344912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:49.345247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:50.231: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:50.346553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:51.346891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:52.244: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:52.346916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:53.347368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:54.253: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:54.347728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:55.348638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:56.265: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:56.349840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:57.349829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:07:58.275: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:07:58.350152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:07:59.350400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:00.287: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:00.351447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:01.351842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:02.295: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:02.352806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:03.352620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:04.310: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:04.353664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:05.354523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:06.321: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:06.355014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:07.355871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:08.331: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:08.356093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:09.356416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:10.342: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:10.356831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:11.357887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:12.351: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:12.358508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:13.359333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:14.359546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:14.360: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:15.360602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:16.362077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:16.370: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:17.362629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:18.362909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:18.381: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:19.363372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:20.363581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:20.391: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:21.364511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:22.364993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:22.402: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:23.365189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:24.366075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:24.416: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:25.366532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:26.366773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:26.428: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:27.367733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:28.368527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:28.439: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:29.368555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:30.368847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:30.450: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:31.369189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:32.370085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:32.461: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:33.370253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:34.371119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:34.474: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:35.371207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:36.371630      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:36.484: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:37.371688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:38.372504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:38.493: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:39.372642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:40.373011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:40.503: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:41.373356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:42.373528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:42.514: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:43.373889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:44.374111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:44.526: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:45.374923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:46.375339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:46.538: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:47.375355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:48.375647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:48.549: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:49.375744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:50.375967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:50.560: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:51.376493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:52.377441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:52.571: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:53.377426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:54.378130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:54.593: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:55.378072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:56.378450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:56.607: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:57.378928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:08:58.378981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:08:58.618: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:08:59.379820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:00.380366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:00.631: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:01.381541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:02.381131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:02.642: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:03.381591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:04.382135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:04.653: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:05.382186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:06.382966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:06.667: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:07.384071      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:08.384483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:08.682: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:09.385672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:10.386021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:10.698: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:11.386091      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:12.386316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:12.710: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:13.386726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:14.387146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:14.723: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:15.388218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:16.388495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:16.734: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:17.388851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:18.388993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:18.744: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:19.389618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:20.389705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:20.754: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:21.389873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:22.390349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:22.766: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:23.391582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:24.391888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:24.793: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:25.392424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:26.392708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:26.806: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:27.394076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:28.394123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:28.821: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:29.394546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:30.394507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:30.829: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:31.394633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:32.394915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:32.844: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:33.396087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:34.396658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:34.856: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:35.397085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:36.397265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:36.866: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:37.397409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:38.398406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:38.875: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:39.399178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:40.399929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:40.884: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:41.399909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:42.400206      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:42.894: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:43.401374      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:44.401907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:44.904: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:45.403376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:46.403124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:46.913: INFO: Get pod test-grpc-33c256e0-195a-4a25-b789-9c34296e19cf in namespace container-probe-4349
  E0415 07:09:47.403549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:48.403863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:48.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:09:48.934
  STEP: Destroying namespace "container-probe-4349" for this suite. @ 04/15/24 07:09:48.975
â€¢ [243.550 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 04/15/24 07:09:49.001
  Apr 15 07:09:49.001: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/15/24 07:09:49.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:09:49.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:09:49.078
  STEP: set up a multi version CRD @ 04/15/24 07:09:49.092
  Apr 15 07:09:49.095: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:09:49.405081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:50.405326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:51.405873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:52.406499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:53.407029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 04/15/24 07:09:54.253
  STEP: check the unserved version gets removed @ 04/15/24 07:09:54.293
  E0415 07:09:54.407445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:55.408055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/15/24 07:09:55.874
  E0415 07:09:56.408323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:57.409555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:09:58.409921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:09:59.311: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5177" for this suite. @ 04/15/24 07:09:59.383
  E0415 07:09:59.410030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [10.434 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance]
test/e2e/network/service.go:3326
  STEP: Creating a kubernetes client @ 04/15/24 07:09:59.439
  Apr 15 07:09:59.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 07:09:59.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:09:59.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:09:59.49
  STEP: creating a Service @ 04/15/24 07:09:59.504
  STEP: watching for the Service to be added @ 04/15/24 07:09:59.529
  Apr 15 07:09:59.533: INFO: Found Service test-service-n7jpt in namespace services-9112 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
  Apr 15 07:09:59.535: INFO: Service test-service-n7jpt created
  STEP: Getting /status @ 04/15/24 07:09:59.537
  Apr 15 07:09:59.549: INFO: Service test-service-n7jpt has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 04/15/24 07:09:59.55
  STEP: watching for the Service to be patched @ 04/15/24 07:09:59.564
  Apr 15 07:09:59.576: INFO: observed Service test-service-n7jpt in namespace services-9112 with annotations: map[] & LoadBalancer: {[]}
  Apr 15 07:09:59.576: INFO: Found Service test-service-n7jpt in namespace services-9112 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
  Apr 15 07:09:59.577: INFO: Service test-service-n7jpt has service status patched
  STEP: updating the ServiceStatus @ 04/15/24 07:09:59.578
  Apr 15 07:09:59.600: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 04/15/24 07:09:59.601
  Apr 15 07:09:59.605: INFO: Observed Service test-service-n7jpt in namespace services-9112 with annotations: map[] & Conditions: {[]}
  Apr 15 07:09:59.606: INFO: Observed event: &Service{ObjectMeta:{test-service-n7jpt  services-9112  d30c2fb5-9441-443a-9de2-4b1e1f1f6df9 164229 0 2024-04-15 07:09:59 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-04-15 07:09:59 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-04-15 07:09:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.51.5,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.51.5],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Apr 15 07:09:59.607: INFO: Found Service test-service-n7jpt in namespace services-9112 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 15 07:09:59.608: INFO: Service test-service-n7jpt has service status updated
  STEP: patching the service @ 04/15/24 07:09:59.608
  STEP: watching for the Service to be patched @ 04/15/24 07:09:59.643
  Apr 15 07:09:59.651: INFO: observed Service test-service-n7jpt in namespace services-9112 with labels: map[test-service-static:true]
  Apr 15 07:09:59.653: INFO: observed Service test-service-n7jpt in namespace services-9112 with labels: map[test-service-static:true]
  Apr 15 07:09:59.653: INFO: observed Service test-service-n7jpt in namespace services-9112 with labels: map[test-service-static:true]
  Apr 15 07:09:59.653: INFO: Found Service test-service-n7jpt in namespace services-9112 with labels: map[test-service:patched test-service-static:true]
  Apr 15 07:09:59.653: INFO: Service test-service-n7jpt patched
  STEP: deleting the service @ 04/15/24 07:09:59.654
  STEP: watching for the Service to be deleted @ 04/15/24 07:09:59.689
  Apr 15 07:09:59.697: INFO: Observed event: ADDED
  Apr 15 07:09:59.697: INFO: Observed event: MODIFIED
  Apr 15 07:09:59.697: INFO: Observed event: MODIFIED
  Apr 15 07:09:59.697: INFO: Observed event: MODIFIED
  Apr 15 07:09:59.697: INFO: Found Service test-service-n7jpt in namespace services-9112 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Apr 15 07:09:59.697: INFO: Service test-service-n7jpt deleted
  Apr 15 07:09:59.697: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9112" for this suite. @ 04/15/24 07:09:59.72
â€¢ [0.304 seconds]
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance]
test/e2e/apps/job.go:713
  STEP: Creating a kubernetes client @ 04/15/24 07:09:59.744
  Apr 15 07:09:59.744: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename job @ 04/15/24 07:09:59.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:09:59.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:09:59.792
  STEP: Creating a suspended job @ 04/15/24 07:09:59.803
  STEP: Patching the Job @ 04/15/24 07:09:59.815
  STEP: Watching for Job to be patched @ 04/15/24 07:09:59.839
  Apr 15 07:09:59.842: INFO: Event ADDED observed for Job e2e-dr6ff in namespace job-8918 with labels: map[e2e-job-label:e2e-dr6ff] and annotations: map[]
  Apr 15 07:09:59.843: INFO: Event MODIFIED found for Job e2e-dr6ff in namespace job-8918 with labels: map[e2e-dr6ff:patched e2e-job-label:e2e-dr6ff] and annotations: map[]
  STEP: Updating the job @ 04/15/24 07:09:59.843
  STEP: Watching for Job to be updated @ 04/15/24 07:09:59.868
  Apr 15 07:09:59.874: INFO: Event MODIFIED found for Job e2e-dr6ff in namespace job-8918 with labels: map[e2e-dr6ff:patched e2e-job-label:e2e-dr6ff] and annotations: map[updated:true]
  Apr 15 07:09:59.874: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 04/15/24 07:09:59.875
  Apr 15 07:09:59.883: INFO: Job: e2e-dr6ff as labels: map[e2e-dr6ff:patched e2e-job-label:e2e-dr6ff]
  STEP: Waiting for job to complete @ 04/15/24 07:09:59.883
  E0415 07:10:00.410265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:01.410573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:02.410996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:03.411859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:04.411826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:05.412064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:06.412373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:07.413276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 04/15/24 07:10:07.894
  STEP: Watching for Job to be deleted @ 04/15/24 07:10:07.917
  Apr 15 07:10:07.922: INFO: Event MODIFIED observed for Job e2e-dr6ff in namespace job-8918 with labels: map[e2e-dr6ff:patched e2e-job-label:e2e-dr6ff] and annotations: map[updated:true]
  Apr 15 07:10:07.922: INFO: Event MODIFIED observed for Job e2e-dr6ff in namespace job-8918 with labels: map[e2e-dr6ff:patched e2e-job-label:e2e-dr6ff] and annotations: map[updated:true]
  Apr 15 07:10:07.923: INFO: Event MODIFIED observed for Job e2e-dr6ff in namespace job-8918 with labels: map[e2e-dr6ff:patched e2e-job-label:e2e-dr6ff] and annotations: map[updated:true]
  Apr 15 07:10:07.923: INFO: Event MODIFIED observed for Job e2e-dr6ff in namespace job-8918 with labels: map[e2e-dr6ff:patched e2e-job-label:e2e-dr6ff] and annotations: map[updated:true]
  Apr 15 07:10:07.923: INFO: Event MODIFIED observed for Job e2e-dr6ff in namespace job-8918 with labels: map[e2e-dr6ff:patched e2e-job-label:e2e-dr6ff] and annotations: map[updated:true]
  Apr 15 07:10:07.923: INFO: Event DELETED found for Job e2e-dr6ff in namespace job-8918 with labels: map[e2e-dr6ff:patched e2e-job-label:e2e-dr6ff] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 04/15/24 07:10:07.924
  Apr 15 07:10:07.938: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8918" for this suite. @ 04/15/24 07:10:07.96
â€¢ [8.252 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 04/15/24 07:10:07.999
  Apr 15 07:10:07.999: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename disruption @ 04/15/24 07:10:08.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:10:08.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:10:08.058
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:10:08.075
  E0415 07:10:08.413731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:09.413884      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 04/15/24 07:10:10.096
  STEP: Waiting for all pods to be running @ 04/15/24 07:10:10.125
  Apr 15 07:10:10.139: INFO: running pods: 0 < 1
  E0415 07:10:10.414647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:11.415809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/15/24 07:10:12.15
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:10:12.215
  STEP: Patching PodDisruptionBudget status @ 04/15/24 07:10:12.258
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:10:12.311
  Apr 15 07:10:12.323: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9261" for this suite. @ 04/15/24 07:10:12.341
â€¢ [4.363 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:354
  STEP: Creating a kubernetes client @ 04/15/24 07:10:12.366
  Apr 15 07:10:12.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 07:10:12.369
  E0415 07:10:12.417156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:10:12.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:10:12.443
  STEP: creating a replication controller @ 04/15/24 07:10:12.455
  Apr 15 07:10:12.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 create -f -'
  Apr 15 07:10:13.194: INFO: stderr: ""
  Apr 15 07:10:13.194: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/15/24 07:10:13.194
  Apr 15 07:10:13.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0415 07:10:13.417391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:13.424: INFO: stderr: ""
  Apr 15 07:10:13.424: INFO: stdout: "update-demo-nautilus-lz6rx update-demo-nautilus-sjxwg "
  Apr 15 07:10:13.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-lz6rx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 15 07:10:13.672: INFO: stderr: ""
  Apr 15 07:10:13.672: INFO: stdout: ""
  Apr 15 07:10:13.672: INFO: update-demo-nautilus-lz6rx is created but not running
  E0415 07:10:14.417654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:15.418793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:16.419065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:17.419152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:18.419398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:18.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 15 07:10:18.888: INFO: stderr: ""
  Apr 15 07:10:18.889: INFO: stdout: "update-demo-nautilus-lz6rx update-demo-nautilus-sjxwg "
  Apr 15 07:10:18.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-lz6rx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 15 07:10:19.112: INFO: stderr: ""
  Apr 15 07:10:19.112: INFO: stdout: "true"
  Apr 15 07:10:19.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-lz6rx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 15 07:10:19.351: INFO: stderr: ""
  Apr 15 07:10:19.351: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 15 07:10:19.351: INFO: validating pod update-demo-nautilus-lz6rx
  Apr 15 07:10:19.371: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 15 07:10:19.373: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 15 07:10:19.374: INFO: update-demo-nautilus-lz6rx is verified up and running
  Apr 15 07:10:19.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-sjxwg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0415 07:10:19.420975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:19.531: INFO: stderr: ""
  Apr 15 07:10:19.531: INFO: stdout: "true"
  Apr 15 07:10:19.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-sjxwg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 15 07:10:19.773: INFO: stderr: ""
  Apr 15 07:10:19.773: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 15 07:10:19.773: INFO: validating pod update-demo-nautilus-sjxwg
  Apr 15 07:10:19.799: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 15 07:10:19.799: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 15 07:10:19.799: INFO: update-demo-nautilus-sjxwg is verified up and running
  STEP: scaling down the replication controller @ 04/15/24 07:10:19.8
  Apr 15 07:10:19.826: INFO: scanned /root for discovery docs: <nil>
  Apr 15 07:10:19.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0415 07:10:20.421507      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:21.088: INFO: stderr: ""
  Apr 15 07:10:21.088: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/15/24 07:10:21.088
  Apr 15 07:10:21.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 15 07:10:21.288: INFO: stderr: ""
  Apr 15 07:10:21.288: INFO: stdout: "update-demo-nautilus-sjxwg "
  Apr 15 07:10:21.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-sjxwg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0415 07:10:21.425577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:21.477: INFO: stderr: ""
  Apr 15 07:10:21.477: INFO: stdout: "true"
  Apr 15 07:10:21.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-sjxwg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 15 07:10:21.688: INFO: stderr: ""
  Apr 15 07:10:21.688: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 15 07:10:21.688: INFO: validating pod update-demo-nautilus-sjxwg
  Apr 15 07:10:21.699: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 15 07:10:21.699: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 15 07:10:21.699: INFO: update-demo-nautilus-sjxwg is verified up and running
  STEP: scaling up the replication controller @ 04/15/24 07:10:21.699
  Apr 15 07:10:21.714: INFO: scanned /root for discovery docs: <nil>
  Apr 15 07:10:21.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0415 07:10:22.423214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:22.939: INFO: stderr: ""
  Apr 15 07:10:22.940: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/15/24 07:10:22.94
  Apr 15 07:10:22.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 15 07:10:23.124: INFO: stderr: ""
  Apr 15 07:10:23.124: INFO: stdout: "update-demo-nautilus-nd766 update-demo-nautilus-sjxwg "
  Apr 15 07:10:23.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-nd766 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 15 07:10:23.347: INFO: stderr: ""
  Apr 15 07:10:23.347: INFO: stdout: ""
  Apr 15 07:10:23.347: INFO: update-demo-nautilus-nd766 is created but not running
  E0415 07:10:23.423868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:24.424303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:25.424658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:26.424829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:27.425090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:28.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0415 07:10:28.426333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:28.560: INFO: stderr: ""
  Apr 15 07:10:28.560: INFO: stdout: "update-demo-nautilus-nd766 update-demo-nautilus-sjxwg "
  Apr 15 07:10:28.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-nd766 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 15 07:10:28.809: INFO: stderr: ""
  Apr 15 07:10:28.809: INFO: stdout: "true"
  Apr 15 07:10:28.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-nd766 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 15 07:10:29.001: INFO: stderr: ""
  Apr 15 07:10:29.001: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 15 07:10:29.001: INFO: validating pod update-demo-nautilus-nd766
  Apr 15 07:10:29.028: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 15 07:10:29.028: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 15 07:10:29.028: INFO: update-demo-nautilus-nd766 is verified up and running
  Apr 15 07:10:29.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-sjxwg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 15 07:10:29.205: INFO: stderr: ""
  Apr 15 07:10:29.205: INFO: stdout: "true"
  Apr 15 07:10:29.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods update-demo-nautilus-sjxwg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 15 07:10:29.360: INFO: stderr: ""
  Apr 15 07:10:29.360: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 15 07:10:29.361: INFO: validating pod update-demo-nautilus-sjxwg
  Apr 15 07:10:29.372: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 15 07:10:29.372: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 15 07:10:29.372: INFO: update-demo-nautilus-sjxwg is verified up and running
  STEP: using delete to clean up resources @ 04/15/24 07:10:29.372
  Apr 15 07:10:29.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 delete --grace-period=0 --force -f -'
  E0415 07:10:29.426469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:29.537: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 15 07:10:29.538: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 15 07:10:29.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get rc,svc -l name=update-demo --no-headers'
  Apr 15 07:10:29.811: INFO: stderr: "No resources found in kubectl-3159 namespace.\n"
  Apr 15 07:10:29.811: INFO: stdout: ""
  Apr 15 07:10:29.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-3159 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 15 07:10:30.046: INFO: stderr: ""
  Apr 15 07:10:30.046: INFO: stdout: ""
  Apr 15 07:10:30.047: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3159" for this suite. @ 04/15/24 07:10:30.072
â€¢ [17.725 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance]
test/e2e/apps/job.go:642
  STEP: Creating a kubernetes client @ 04/15/24 07:10:30.095
  Apr 15 07:10:30.095: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename job @ 04/15/24 07:10:30.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:10:30.148
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:10:30.156
  STEP: Creating a job @ 04/15/24 07:10:30.174
  STEP: Ensure pods equal to parallelism count is attached to the job @ 04/15/24 07:10:30.193
  E0415 07:10:30.427788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:31.428053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 04/15/24 07:10:32.203
  STEP: updating /status @ 04/15/24 07:10:32.222
  STEP: get /status @ 04/15/24 07:10:32.245
  Apr 15 07:10:32.254: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-9341" for this suite. @ 04/15/24 07:10:32.268
â€¢ [2.190 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2187
  STEP: Creating a kubernetes client @ 04/15/24 07:10:32.289
  Apr 15 07:10:32.289: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 07:10:32.293
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:10:32.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:10:32.334
  STEP: creating service in namespace services-1580 @ 04/15/24 07:10:32.341
  STEP: creating service affinity-clusterip-transition in namespace services-1580 @ 04/15/24 07:10:32.341
  STEP: creating replication controller affinity-clusterip-transition in namespace services-1580 @ 04/15/24 07:10:32.384
  I0415 07:10:32.402437      13 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-1580, replica count: 3
  E0415 07:10:32.428515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:33.429031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:34.429241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:35.430219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 07:10:35.454613      13 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 15 07:10:35.474: INFO: Creating new exec pod
  E0415 07:10:36.430303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:37.430784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:38.430952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:38.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1580 exec execpod-affinity7xt7n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Apr 15 07:10:38.966: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Apr 15 07:10:38.966: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 07:10:38.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1580 exec execpod-affinity7xt7n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.9.53 80'
  Apr 15 07:10:39.296: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.9.53 80\nConnection to 10.233.9.53 80 port [tcp/http] succeeded!\n"
  Apr 15 07:10:39.296: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 07:10:39.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1580 exec execpod-affinity7xt7n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.9.53:80/ ; done'
  E0415 07:10:39.431829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:39.967: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n"
  Apr 15 07:10:39.968: INFO: stdout: "\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-h8fvk\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-h8fvk\naffinity-clusterip-transition-h8fvk\naffinity-clusterip-transition-x57gl\naffinity-clusterip-transition-h8fvk\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-x57gl\naffinity-clusterip-transition-h8fvk\naffinity-clusterip-transition-h8fvk\naffinity-clusterip-transition-h8fvk\naffinity-clusterip-transition-x57gl\naffinity-clusterip-transition-h8fvk\naffinity-clusterip-transition-x57gl"
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-h8fvk
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-h8fvk
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-h8fvk
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-x57gl
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-h8fvk
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-x57gl
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-h8fvk
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-h8fvk
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-h8fvk
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-x57gl
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-h8fvk
  Apr 15 07:10:39.968: INFO: Received response from host: affinity-clusterip-transition-x57gl
  Apr 15 07:10:39.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-1580 exec execpod-affinity7xt7n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.9.53:80/ ; done'
  E0415 07:10:40.432495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:40.556: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.53:80/\n"
  Apr 15 07:10:40.556: INFO: stdout: "\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4\naffinity-clusterip-transition-g8ts4"
  Apr 15 07:10:40.556: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.556: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.556: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.556: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.556: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.556: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.556: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.556: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.556: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.557: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.557: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.557: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.557: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.557: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.557: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.557: INFO: Received response from host: affinity-clusterip-transition-g8ts4
  Apr 15 07:10:40.557: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 07:10:40.570: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-1580, will wait for the garbage collector to delete the pods @ 04/15/24 07:10:40.603
  Apr 15 07:10:40.675: INFO: Deleting ReplicationController affinity-clusterip-transition took: 14.744919ms
  Apr 15 07:10:40.775: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.65218ms
  E0415 07:10:41.433103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:42.434026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:43.434745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-1580" for this suite. @ 04/15/24 07:10:43.932
â€¢ [11.659 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 04/15/24 07:10:43.955
  Apr 15 07:10:43.955: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 07:10:43.959
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:10:43.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:10:43.998
  STEP: Setting up server cert @ 04/15/24 07:10:44.053
  E0415 07:10:44.435169      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 07:10:44.631
  STEP: Deploying the webhook pod @ 04/15/24 07:10:44.651
  STEP: Wait for the deployment to be ready @ 04/15/24 07:10:44.676
  Apr 15 07:10:44.692: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0415 07:10:45.435777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:46.436565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 07:10:46.726
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 07:10:46.745
  E0415 07:10:47.436802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:10:47.746: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/15/24 07:10:47.766
  STEP: create a pod that should be denied by the webhook @ 04/15/24 07:10:47.81
  STEP: create a pod that causes the webhook to hang @ 04/15/24 07:10:47.845
  E0415 07:10:48.437328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:49.437494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:50.437458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:51.437602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:52.438023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:53.439125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:54.439715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:55.440087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:56.440523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:57.440720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 04/15/24 07:10:57.865
  STEP: create a configmap that should be admitted by the webhook @ 04/15/24 07:10:57.926
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/15/24 07:10:57.946
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/15/24 07:10:57.965
  STEP: create a namespace that bypass the webhook @ 04/15/24 07:10:57.976
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 04/15/24 07:10:58.008
  Apr 15 07:10:58.029: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3288" for this suite. @ 04/15/24 07:10:58.181
  STEP: Destroying namespace "webhook-markers-4349" for this suite. @ 04/15/24 07:10:58.21
  STEP: Destroying namespace "exempted-namespace-3825" for this suite. @ 04/15/24 07:10:58.257
â€¢ [14.317 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2202
  STEP: Creating a kubernetes client @ 04/15/24 07:10:58.277
  Apr 15 07:10:58.278: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 07:10:58.29
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:10:58.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:10:58.328
  STEP: creating service in namespace services-9661 @ 04/15/24 07:10:58.335
  STEP: creating service affinity-nodeport in namespace services-9661 @ 04/15/24 07:10:58.335
  STEP: creating replication controller affinity-nodeport in namespace services-9661 @ 04/15/24 07:10:58.382
  I0415 07:10:58.407198      13 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-9661, replica count: 3
  E0415 07:10:58.441586      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:10:59.442535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:00.442994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:01.443461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 07:11:01.459147      13 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 15 07:11:01.486: INFO: Creating new exec pod
  E0415 07:11:02.443768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:03.444350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:04.444583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:04.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-9661 exec execpod-affinityh8rs6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Apr 15 07:11:04.858: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Apr 15 07:11:04.858: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 07:11:04.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-9661 exec execpod-affinityh8rs6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.16.237 80'
  Apr 15 07:11:05.243: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.16.237 80\nConnection to 10.233.16.237 80 port [tcp/http] succeeded!\n"
  Apr 15 07:11:05.243: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 07:11:05.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-9661 exec execpod-affinityh8rs6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.206 31300'
  E0415 07:11:05.448981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:05.590: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.206 31300\nConnection to 192.168.121.206 31300 port [tcp/*] succeeded!\n"
  Apr 15 07:11:05.590: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 07:11:05.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-9661 exec execpod-affinityh8rs6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.141 31300'
  Apr 15 07:11:06.125: INFO: stderr: "+ nc -v -t -w 2 192.168.121.141 31300\n+ echo hostName\nConnection to 192.168.121.141 31300 port [tcp/*] succeeded!\n"
  Apr 15 07:11:06.125: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 07:11:06.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-9661 exec execpod-affinityh8rs6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.141:31300/ ; done'
  E0415 07:11:06.446542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:06.821: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.141:31300/\n"
  Apr 15 07:11:06.821: INFO: stdout: "\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj\naffinity-nodeport-b9jfj"
  Apr 15 07:11:06.821: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.821: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.821: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.821: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.821: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.821: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.821: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.821: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.821: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.822: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.822: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.822: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.822: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.822: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.822: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.822: INFO: Received response from host: affinity-nodeport-b9jfj
  Apr 15 07:11:06.822: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 07:11:06.834: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-9661, will wait for the garbage collector to delete the pods @ 04/15/24 07:11:06.892
  Apr 15 07:11:06.964: INFO: Deleting ReplicationController affinity-nodeport took: 14.38482ms
  Apr 15 07:11:07.065: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.625203ms
  E0415 07:11:07.446833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:08.447327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:09.448412      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-9661" for this suite. @ 04/15/24 07:11:10.14
â€¢ [11.874 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 04/15/24 07:11:10.155
  Apr 15 07:11:10.156: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 07:11:10.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:11:10.202
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:11:10.207
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 07:11:10.213
  E0415 07:11:10.449398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:11.450028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:12.451017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:13.451745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:11:14.255
  Apr 15 07:11:14.261: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-f25b6db0-519f-44fc-9a70-b774d505b244 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 07:11:14.294
  Apr 15 07:11:14.325: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3205" for this suite. @ 04/15/24 07:11:14.349
â€¢ [4.211 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
test/e2e/auth/service_accounts.go:161
  STEP: Creating a kubernetes client @ 04/15/24 07:11:14.368
  Apr 15 07:11:14.368: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename svcaccounts @ 04/15/24 07:11:14.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:11:14.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:11:14.408
  Apr 15 07:11:14.447: INFO: created pod pod-service-account-defaultsa
  Apr 15 07:11:14.447: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  E0415 07:11:14.452370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:14.459: INFO: created pod pod-service-account-mountsa
  Apr 15 07:11:14.459: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Apr 15 07:11:14.477: INFO: created pod pod-service-account-nomountsa
  Apr 15 07:11:14.477: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Apr 15 07:11:14.489: INFO: created pod pod-service-account-defaultsa-mountspec
  Apr 15 07:11:14.490: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Apr 15 07:11:14.521: INFO: created pod pod-service-account-mountsa-mountspec
  Apr 15 07:11:14.521: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Apr 15 07:11:14.535: INFO: created pod pod-service-account-nomountsa-mountspec
  Apr 15 07:11:14.536: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Apr 15 07:11:14.546: INFO: created pod pod-service-account-defaultsa-nomountspec
  Apr 15 07:11:14.546: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Apr 15 07:11:14.558: INFO: created pod pod-service-account-mountsa-nomountspec
  Apr 15 07:11:14.558: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Apr 15 07:11:14.597: INFO: created pod pod-service-account-nomountsa-nomountspec
  Apr 15 07:11:14.597: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Apr 15 07:11:14.597: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7887" for this suite. @ 04/15/24 07:11:14.618
â€¢ [0.285 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]
test/e2e/apimachinery/namespace.go:303
  STEP: Creating a kubernetes client @ 04/15/24 07:11:14.66
  Apr 15 07:11:14.660: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename namespaces @ 04/15/24 07:11:14.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:11:14.737
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:11:14.742
  STEP: Read namespace status @ 04/15/24 07:11:14.747
  Apr 15 07:11:14.777: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 04/15/24 07:11:14.777
  Apr 15 07:11:14.799: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 04/15/24 07:11:14.799
  Apr 15 07:11:14.825: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Apr 15 07:11:14.825: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3622" for this suite. @ 04/15/24 07:11:14.887
â€¢ [0.245 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 04/15/24 07:11:14.906
  Apr 15 07:11:14.906: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-runtime @ 04/15/24 07:11:14.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:11:14.974
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:11:14.979
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 04/15/24 07:11:15.007
  E0415 07:11:15.452395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:16.453310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:17.453499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:18.454021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:19.454173      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:20.455209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:21.455590      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:22.456402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:23.457613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:24.457764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:25.458812      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:26.459493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:27.459863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:28.461585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:29.461990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:30.461935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:31.462774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 04/15/24 07:11:32.256
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 04/15/24 07:11:32.266
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 04/15/24 07:11:32.281
  STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] @ 04/15/24 07:11:32.281
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 04/15/24 07:11:32.334
  E0415 07:11:32.463687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:33.465204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 04/15/24 07:11:34.382
  E0415 07:11:34.465833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:35.465902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 04/15/24 07:11:36.414
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 04/15/24 07:11:36.432
  STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] @ 04/15/24 07:11:36.432
  E0415 07:11:36.466807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 04/15/24 07:11:36.481
  E0415 07:11:37.467370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 04/15/24 07:11:37.5
  E0415 07:11:38.467523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:39.467551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 04/15/24 07:11:39.523
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 04/15/24 07:11:39.539
  STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] @ 04/15/24 07:11:39.54
  Apr 15 07:11:39.576: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6402" for this suite. @ 04/15/24 07:11:39.615
â€¢ [24.727 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]
test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 04/15/24 07:11:39.642
  Apr 15 07:11:39.642: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename field-validation @ 04/15/24 07:11:39.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:11:39.695
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:11:39.704
  Apr 15 07:11:39.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:11:40.468367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:41.468919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0415 07:11:42.461162      13 warnings.go:70] unknown field "alpha"
  W0415 07:11:42.461219      13 warnings.go:70] unknown field "beta"
  W0415 07:11:42.461230      13 warnings.go:70] unknown field "delta"
  W0415 07:11:42.461241      13 warnings.go:70] unknown field "epsilon"
  W0415 07:11:42.461252      13 warnings.go:70] unknown field "gamma"
  E0415 07:11:42.468796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:43.023: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7231" for this suite. @ 04/15/24 07:11:43.056
â€¢ [3.426 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 04/15/24 07:11:43.072
  Apr 15 07:11:43.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/15/24 07:11:43.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:11:43.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:11:43.123
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 04/15/24 07:11:43.129
  Apr 15 07:11:43.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:11:43.469143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:44.471121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:45.274: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:11:45.471809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:46.471916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:47.472453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:48.473514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:49.473433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:50.474180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:51.474284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:11:52.474909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:52.690: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8589" for this suite. @ 04/15/24 07:11:52.711
â€¢ [9.653 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]
test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 04/15/24 07:11:52.744
  Apr 15 07:11:52.744: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename daemonsets @ 04/15/24 07:11:52.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:11:52.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:11:52.787
  Apr 15 07:11:52.855: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 04/15/24 07:11:52.871
  Apr 15 07:11:52.884: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 07:11:52.885: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 04/15/24 07:11:52.885
  Apr 15 07:11:52.952: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 07:11:52.952: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  E0415 07:11:53.475900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:53.961: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 07:11:53.961: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  E0415 07:11:54.476499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:54.961: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 07:11:54.961: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  E0415 07:11:55.477074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:55.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 07:11:55.962: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  E0415 07:11:56.476893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:56.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 15 07:11:56.962: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 04/15/24 07:11:56.97
  Apr 15 07:11:57.010: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 15 07:11:57.010: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  E0415 07:11:57.477329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:58.017: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 07:11:58.018: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 04/15/24 07:11:58.018
  Apr 15 07:11:58.041: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 07:11:58.041: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  E0415 07:11:58.478458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:11:59.064: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 07:11:59.064: INFO: Node phiefi7ighaa-2 is running 0 daemon pod, expected 1
  E0415 07:11:59.478798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:12:00.056: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 15 07:12:00.056: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/15/24 07:12:00.073
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7965, will wait for the garbage collector to delete the pods @ 04/15/24 07:12:00.073
  Apr 15 07:12:00.171: INFO: Deleting DaemonSet.extensions daemon-set took: 41.544188ms
  Apr 15 07:12:00.272: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.837764ms
  E0415 07:12:00.479342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:01.480283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:12:01.489: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 15 07:12:01.489: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 15 07:12:01.496: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"165344"},"items":null}

  Apr 15 07:12:01.503: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"165344"},"items":null}

  Apr 15 07:12:01.563: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7965" for this suite. @ 04/15/24 07:12:01.571
â€¢ [8.845 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:197
  STEP: Creating a kubernetes client @ 04/15/24 07:12:01.589
  Apr 15 07:12:01.589: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 07:12:01.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:12:01.634
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:12:01.639
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/15/24 07:12:01.644
  E0415 07:12:02.480456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:03.480662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:04.481425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:05.481498      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:12:05.691
  Apr 15 07:12:05.696: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-804c20ed-bd1e-4338-8294-9b848241bca0 container test-container: <nil>
  STEP: delete the pod @ 04/15/24 07:12:05.711
  Apr 15 07:12:05.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1319" for this suite. @ 04/15/24 07:12:05.752
â€¢ [4.176 seconds]
------------------------------
S
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 04/15/24 07:12:05.766
  Apr 15 07:12:05.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 04/15/24 07:12:05.769
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:12:05.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:12:05.81
  STEP: Setting up the test @ 04/15/24 07:12:05.815
  STEP: Creating hostNetwork=false pod @ 04/15/24 07:12:05.816
  E0415 07:12:06.481647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:07.484962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:08.484948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:09.485847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 04/15/24 07:12:09.869
  E0415 07:12:10.486082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:11.486331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 04/15/24 07:12:11.913
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 04/15/24 07:12:11.913
  Apr 15 07:12:11.914: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:11.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:12:11.917: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:11.918: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 15 07:12:12.104: INFO: Exec stderr: ""
  Apr 15 07:12:12.106: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:12.106: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:12:12.109: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:12.109: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 15 07:12:12.304: INFO: Exec stderr: ""
  Apr 15 07:12:12.305: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:12.305: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:12:12.307: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:12.308: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 15 07:12:12.485: INFO: Exec stderr: ""
  Apr 15 07:12:12.486: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:12.486: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:12:12.486721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:12:12.489: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:12.489: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 15 07:12:12.593: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 04/15/24 07:12:12.594
  Apr 15 07:12:12.594: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:12.594: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:12:12.596: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:12.596: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 15 07:12:12.718: INFO: Exec stderr: ""
  Apr 15 07:12:12.719: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:12.720: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:12:12.721: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:12.722: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 15 07:12:12.851: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 04/15/24 07:12:12.852
  Apr 15 07:12:12.852: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:12.852: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:12:12.858: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:12.858: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 15 07:12:13.001: INFO: Exec stderr: ""
  Apr 15 07:12:13.002: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:13.002: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:12:13.005: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:13.005: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 15 07:12:13.117: INFO: Exec stderr: ""
  Apr 15 07:12:13.117: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:13.117: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:12:13.122: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:13.122: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 15 07:12:13.270: INFO: Exec stderr: ""
  Apr 15 07:12:13.270: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6399 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:12:13.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:12:13.272: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:12:13.272: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6399/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 15 07:12:13.453: INFO: Exec stderr: ""
  Apr 15 07:12:13.453: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-6399" for this suite. @ 04/15/24 07:12:13.468
  E0415 07:12:13.486954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [7.721 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
test/e2e/apps/replica_set.go:131
  STEP: Creating a kubernetes client @ 04/15/24 07:12:13.489
  Apr 15 07:12:13.489: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replicaset @ 04/15/24 07:12:13.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:12:13.526
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:12:13.534
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 04/15/24 07:12:13.541
  E0415 07:12:14.487585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:15.487760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 04/15/24 07:12:15.588
  STEP: Then the orphan pod is adopted @ 04/15/24 07:12:15.603
  E0415 07:12:16.488452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 04/15/24 07:12:16.622
  Apr 15 07:12:16.629: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/15/24 07:12:16.653
  E0415 07:12:17.488657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:12:17.674: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8364" for this suite. @ 04/15/24 07:12:17.691
â€¢ [4.218 seconds]
------------------------------
S
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 04/15/24 07:12:17.709
  Apr 15 07:12:17.710: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename proxy @ 04/15/24 07:12:17.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:12:17.758
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:12:17.773
  Apr 15 07:12:17.781: INFO: Creating pod...
  E0415 07:12:18.490125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:19.490534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:12:19.833: INFO: Creating service...
  Apr 15 07:12:19.856: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/pods/agnhost/proxy?method=DELETE
  Apr 15 07:12:19.881: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 15 07:12:19.881: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/pods/agnhost/proxy?method=OPTIONS
  Apr 15 07:12:19.892: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 15 07:12:19.892: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/pods/agnhost/proxy?method=PATCH
  Apr 15 07:12:19.900: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 15 07:12:19.900: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/pods/agnhost/proxy?method=POST
  Apr 15 07:12:19.909: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 15 07:12:19.909: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/pods/agnhost/proxy?method=PUT
  Apr 15 07:12:19.919: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 15 07:12:19.920: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/services/e2e-proxy-test-service/proxy?method=DELETE
  Apr 15 07:12:19.931: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 15 07:12:19.931: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Apr 15 07:12:19.944: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 15 07:12:19.945: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/services/e2e-proxy-test-service/proxy?method=PATCH
  Apr 15 07:12:19.958: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 15 07:12:19.958: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/services/e2e-proxy-test-service/proxy?method=POST
  Apr 15 07:12:19.971: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 15 07:12:19.971: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/services/e2e-proxy-test-service/proxy?method=PUT
  Apr 15 07:12:19.983: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 15 07:12:19.984: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/pods/agnhost/proxy?method=GET
  Apr 15 07:12:19.990: INFO: http.Client request:GET StatusCode:301
  Apr 15 07:12:19.991: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/services/e2e-proxy-test-service/proxy?method=GET
  Apr 15 07:12:20.003: INFO: http.Client request:GET StatusCode:301
  Apr 15 07:12:20.003: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/pods/agnhost/proxy?method=HEAD
  Apr 15 07:12:20.010: INFO: http.Client request:HEAD StatusCode:301
  Apr 15 07:12:20.010: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-7044/services/e2e-proxy-test-service/proxy?method=HEAD
  Apr 15 07:12:20.028: INFO: http.Client request:HEAD StatusCode:301
  Apr 15 07:12:20.028: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-7044" for this suite. @ 04/15/24 07:12:20.04
â€¢ [2.345 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:167
  STEP: Creating a kubernetes client @ 04/15/24 07:12:20.071
  Apr 15 07:12:20.071: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 07:12:20.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:12:20.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:12:20.123
  STEP: Creating a pod to test downward api env vars @ 04/15/24 07:12:20.135
  E0415 07:12:20.491467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:21.491928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:22.492453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:23.492776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:12:24.214
  Apr 15 07:12:24.221: INFO: Trying to get logs from node phiefi7ighaa-3 pod downward-api-0e887fb3-86c1-465e-a37b-693f1ea0b086 container dapi-container: <nil>
  STEP: delete the pod @ 04/15/24 07:12:24.243
  Apr 15 07:12:24.281: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4506" for this suite. @ 04/15/24 07:12:24.295
â€¢ [4.242 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 04/15/24 07:12:24.315
  Apr 15 07:12:24.315: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 07:12:24.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:12:24.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:12:24.367
  STEP: Creating secret with name s-test-opt-del-7dea337c-65e8-4633-9c3a-541ab289372c @ 04/15/24 07:12:24.394
  STEP: Creating secret with name s-test-opt-upd-5e7a76e6-aac5-4d92-8ab0-2ba87fbbb801 @ 04/15/24 07:12:24.42
  STEP: Creating the pod @ 04/15/24 07:12:24.451
  E0415 07:12:24.492671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:25.493831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:26.494733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:27.495129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:28.495337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-7dea337c-65e8-4633-9c3a-541ab289372c @ 04/15/24 07:12:28.593
  STEP: Updating secret s-test-opt-upd-5e7a76e6-aac5-4d92-8ab0-2ba87fbbb801 @ 04/15/24 07:12:28.624
  STEP: Creating secret with name s-test-opt-create-904efd8f-e596-4e1c-8406-fec9ccf318fd @ 04/15/24 07:12:28.642
  STEP: waiting to observe update in volume @ 04/15/24 07:12:28.661
  E0415 07:12:29.496291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:30.496347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:31.496401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:32.496828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:33.497689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:34.497495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:35.497944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:36.498417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:37.498868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:38.499593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:39.499717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:40.500416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:41.501116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:42.501305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:43.501483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:44.521814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:45.508028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:46.508231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:47.508641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:48.509390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:49.510618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:50.510741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:51.511531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:52.511738      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:53.512247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:54.512540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:55.513017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:56.515070      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:57.516732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:58.517217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:12:59.518824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:00.518969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:01.519130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:02.519194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:03.519158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:04.520255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:05.521125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:06.522000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:07.522797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:08.523369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:09.523627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:10.524064      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:11.525163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:12.525591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:13.526580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:14.527296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:15.527936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:16.528745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:17.528658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:18.529766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:19.530483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:20.530689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:21.531835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:22.531478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:23.532326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:24.532456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:25.532973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:26.532828      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:27.533324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:28.533583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:29.533672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:30.534187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:31.533938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:32.534455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:33.534820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:34.534992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:35.536346      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:36.536416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:37.537104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:38.537330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:39.537684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:40.538892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:41.539613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:42.540696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:43.541060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:44.541733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:45.541403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:46.542419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:47.542171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:48.542369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:49.542636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:50.542740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:51.543449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:52.554583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:53.554541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:54.555093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:55.555916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:56.556648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:57.557354      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:58.558370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:13:59.558553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:13:59.807: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9493" for this suite. @ 04/15/24 07:13:59.823
â€¢ [95.524 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
test/e2e/kubectl/kubectl.go:1674
  STEP: Creating a kubernetes client @ 04/15/24 07:13:59.841
  Apr 15 07:13:59.841: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 07:13:59.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:13:59.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:13:59.907
  Apr 15 07:13:59.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-553 version'
  Apr 15 07:14:00.160: INFO: stderr: ""
  Apr 15 07:14:00.160: INFO: stdout: "Client Version: v1.28.8\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.28.8\n"
  Apr 15 07:14:00.162: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-553" for this suite. @ 04/15/24 07:14:00.175
â€¢ [0.370 seconds]
------------------------------
SSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]
test/e2e/instrumentation/core_events.go:57
  STEP: Creating a kubernetes client @ 04/15/24 07:14:00.213
  Apr 15 07:14:00.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename events @ 04/15/24 07:14:00.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:00.253
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:00.261
  STEP: creating a test event @ 04/15/24 07:14:00.266
  STEP: listing all events in all namespaces @ 04/15/24 07:14:00.281
  STEP: patching the test event @ 04/15/24 07:14:00.296
  STEP: fetching the test event @ 04/15/24 07:14:00.309
  STEP: updating the test event @ 04/15/24 07:14:00.319
  STEP: getting the test event @ 04/15/24 07:14:00.342
  STEP: deleting the test event @ 04/15/24 07:14:00.351
  STEP: listing all events in all namespaces @ 04/15/24 07:14:00.366
  Apr 15 07:14:00.379: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8189" for this suite. @ 04/15/24 07:14:00.388
â€¢ [0.187 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:528
  STEP: Creating a kubernetes client @ 04/15/24 07:14:00.412
  Apr 15 07:14:00.412: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename security-context-test @ 04/15/24 07:14:00.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:00.447
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:00.452
  E0415 07:14:00.559376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:01.559595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:02.559766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:03.560917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:04.560885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:14:04.563: INFO: Got logs for pod "busybox-privileged-false-bee14c0a-e91c-48d0-93e1-48d7022eac13": "ip: RTNETLINK answers: Operation not permitted\n"
  Apr 15 07:14:04.563: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9953" for this suite. @ 04/15/24 07:14:04.575
â€¢ [4.179 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:55
  STEP: Creating a kubernetes client @ 04/15/24 07:14:04.596
  Apr 15 07:14:04.596: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename runtimeclass @ 04/15/24 07:14:04.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:04.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:04.66
  Apr 15 07:14:04.699: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8219" for this suite. @ 04/15/24 07:14:04.71
â€¢ [0.132 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:129
  STEP: Creating a kubernetes client @ 04/15/24 07:14:04.74
  Apr 15 07:14:04.740: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename security-context @ 04/15/24 07:14:04.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:04.78
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:04.787
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/15/24 07:14:04.794
  E0415 07:14:05.562079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:06.562580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:07.562386      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:08.562758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:14:08.862
  Apr 15 07:14:08.883: INFO: Trying to get logs from node phiefi7ighaa-2 pod security-context-45617c96-358f-44e0-af7f-d717be5f66fd container test-container: <nil>
  STEP: delete the pod @ 04/15/24 07:14:08.917
  Apr 15 07:14:08.954: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6301" for this suite. @ 04/15/24 07:14:08.966
â€¢ [4.239 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
test/e2e/apimachinery/garbage_collector.go:817
  STEP: Creating a kubernetes client @ 04/15/24 07:14:08.981
  Apr 15 07:14:08.981: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename gc @ 04/15/24 07:14:08.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:09.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:09.032
  Apr 15 07:14:09.205: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6886e9ab-09be-4721-874d-8aa9a5957c8b", Controller:(*bool)(0xc005451e5a), BlockOwnerDeletion:(*bool)(0xc005451e5b)}}
  Apr 15 07:14:09.221: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3022fb48-7bd7-4c54-9857-f2a2fdf5bca1", Controller:(*bool)(0xc0043c4112), BlockOwnerDeletion:(*bool)(0xc0043c4113)}}
  Apr 15 07:14:09.237: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"904e7eee-393e-47e9-944d-a6da6e5b4fd8", Controller:(*bool)(0xc00474d612), BlockOwnerDeletion:(*bool)(0xc00474d613)}}
  E0415 07:14:09.563250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:10.564264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:11.564897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:12.565334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:13.565504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:14:14.265: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1700" for this suite. @ 04/15/24 07:14:14.281
â€¢ [5.322 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 04/15/24 07:14:14.311
  Apr 15 07:14:14.311: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 07:14:14.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:14.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:14.372
  STEP: Creating configMap with name configmap-test-volume-ae79ca31-6e6a-42a9-b525-2ce61cff0944 @ 04/15/24 07:14:14.381
  STEP: Creating a pod to test consume configMaps @ 04/15/24 07:14:14.392
  E0415 07:14:14.566881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:15.566619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:16.567377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:17.567628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:14:18.447
  Apr 15 07:14:18.455: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-dd11c409-0256-42af-bd49-e53df09f9530 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 07:14:18.472
  Apr 15 07:14:18.521: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8540" for this suite. @ 04/15/24 07:14:18.546
â€¢ [4.255 seconds]
------------------------------
S  E0415 07:14:18.567835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
SSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod  [Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 04/15/24 07:14:18.572
  Apr 15 07:14:18.573: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename prestop @ 04/15/24 07:14:18.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:18.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:18.64
  STEP: Creating server pod server in namespace prestop-3807 @ 04/15/24 07:14:18.646
  STEP: Waiting for pods to come up. @ 04/15/24 07:14:18.676
  E0415 07:14:19.568611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:20.569581      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-3807 @ 04/15/24 07:14:20.7
  E0415 07:14:21.570077      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:22.571004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 04/15/24 07:14:22.726
  E0415 07:14:23.571189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:24.571276      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:25.575089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:26.572811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:27.572941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:14:27.757: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  Apr 15 07:14:27.761: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Deleting the server pod @ 04/15/24 07:14:27.775
  STEP: Destroying namespace "prestop-3807" for this suite. @ 04/15/24 07:14:27.807
â€¢ [9.261 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 04/15/24 07:14:27.849
  Apr 15 07:14:27.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/15/24 07:14:27.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:27.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:27.916
  STEP: Creating 50 configmaps @ 04/15/24 07:14:27.922
  E0415 07:14:28.573841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 04/15/24 07:14:28.606
  Apr 15 07:14:28.664: INFO: Pod name wrapped-volume-race-f46836e8-1396-439e-bb0e-9f3ad9153381: Found 0 pods out of 5
  E0415 07:14:29.574209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:30.574800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:31.575165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:32.575194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:33.575644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:14:33.687: INFO: Pod name wrapped-volume-race-f46836e8-1396-439e-bb0e-9f3ad9153381: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/15/24 07:14:33.688
  STEP: Creating RC which spawns configmap-volume pods @ 04/15/24 07:14:33.747
  Apr 15 07:14:33.851: INFO: Pod name wrapped-volume-race-ed0ba57c-3a79-4354-9993-5bebcc3eac30: Found 1 pods out of 5
  E0415 07:14:34.576393      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:35.576946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:36.577013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:37.577133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:38.577308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:14:38.878: INFO: Pod name wrapped-volume-race-ed0ba57c-3a79-4354-9993-5bebcc3eac30: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/15/24 07:14:38.878
  STEP: Creating RC which spawns configmap-volume pods @ 04/15/24 07:14:38.942
  Apr 15 07:14:38.978: INFO: Pod name wrapped-volume-race-d835efc4-329b-44f9-9769-fb43c5fe6a8a: Found 0 pods out of 5
  E0415 07:14:39.577732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:40.577785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:41.578409      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:42.578779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:43.578791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:14:43.999: INFO: Pod name wrapped-volume-race-d835efc4-329b-44f9-9769-fb43c5fe6a8a: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/15/24 07:14:44
  Apr 15 07:14:44.047: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController wrapped-volume-race-d835efc4-329b-44f9-9769-fb43c5fe6a8a in namespace emptydir-wrapper-5766, will wait for the garbage collector to delete the pods @ 04/15/24 07:14:44.058
  Apr 15 07:14:44.145: INFO: Deleting ReplicationController wrapped-volume-race-d835efc4-329b-44f9-9769-fb43c5fe6a8a took: 27.089999ms
  Apr 15 07:14:44.346: INFO: Terminating ReplicationController wrapped-volume-race-d835efc4-329b-44f9-9769-fb43c5fe6a8a pods took: 201.291303ms
  E0415 07:14:44.579544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:45.580538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:46.581022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-ed0ba57c-3a79-4354-9993-5bebcc3eac30 in namespace emptydir-wrapper-5766, will wait for the garbage collector to delete the pods @ 04/15/24 07:14:47.448
  Apr 15 07:14:47.526: INFO: Deleting ReplicationController wrapped-volume-race-ed0ba57c-3a79-4354-9993-5bebcc3eac30 took: 16.442172ms
  E0415 07:14:47.581336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:14:47.727: INFO: Terminating ReplicationController wrapped-volume-race-ed0ba57c-3a79-4354-9993-5bebcc3eac30 pods took: 200.936219ms
  E0415 07:14:48.584674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:49.583422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-f46836e8-1396-439e-bb0e-9f3ad9153381 in namespace emptydir-wrapper-5766, will wait for the garbage collector to delete the pods @ 04/15/24 07:14:50.531
  E0415 07:14:50.584366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:14:50.614: INFO: Deleting ReplicationController wrapped-volume-race-f46836e8-1396-439e-bb0e-9f3ad9153381 took: 18.687721ms
  Apr 15 07:14:50.816: INFO: Terminating ReplicationController wrapped-volume-race-f46836e8-1396-439e-bb0e-9f3ad9153381 pods took: 201.116981ms
  E0415 07:14:51.584791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:52.585916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 04/15/24 07:14:53.317
  E0415 07:14:53.585841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "emptydir-wrapper-5766" for this suite. @ 04/15/24 07:14:54.071
â€¢ [26.233 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 04/15/24 07:14:54.086
  Apr 15 07:14:54.086: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename disruption @ 04/15/24 07:14:54.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:54.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:54.133
  STEP: Creating a kubernetes client @ 04/15/24 07:14:54.14
  Apr 15 07:14:54.140: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename disruption-2 @ 04/15/24 07:14:54.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:54.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:54.193
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:14:54.21
  E0415 07:14:54.586935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:55.586990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:14:56.247
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:14:56.283
  STEP: listing a collection of PDBs across all namespaces @ 04/15/24 07:14:56.292
  STEP: listing a collection of PDBs in namespace disruption-4405 @ 04/15/24 07:14:56.301
  STEP: deleting a collection of PDBs @ 04/15/24 07:14:56.31
  STEP: Waiting for the PDB collection to be deleted @ 04/15/24 07:14:56.339
  Apr 15 07:14:56.344: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 07:14:56.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-3481" for this suite. @ 04/15/24 07:14:56.363
  STEP: Destroying namespace "disruption-4405" for this suite. @ 04/15/24 07:14:56.378
â€¢ [2.309 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 04/15/24 07:14:56.398
  Apr 15 07:14:56.399: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename containers @ 04/15/24 07:14:56.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:56.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:56.447
  STEP: Creating a pod to test override arguments @ 04/15/24 07:14:56.456
  E0415 07:14:56.587523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:14:57.587698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:14:58.512
  Apr 15 07:14:58.520: INFO: Trying to get logs from node phiefi7ighaa-3 pod client-containers-d2df9f2c-e379-4e07-8896-f9c780b474a4 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 07:14:58.541
  Apr 15 07:14:58.576: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 07:14:58.587724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "containers-995" for this suite. @ 04/15/24 07:14:58.589
â€¢ [2.213 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 04/15/24 07:14:58.632
  Apr 15 07:14:58.633: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename deployment @ 04/15/24 07:14:58.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:14:58.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:14:58.677
  Apr 15 07:14:58.684: INFO: Creating simple deployment test-new-deployment
  Apr 15 07:14:58.722: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E0415 07:14:59.588565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:00.589180      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 04/15/24 07:15:00.755
  STEP: updating a scale subresource @ 04/15/24 07:15:00.765
  STEP: verifying the deployment Spec.Replicas was modified @ 04/15/24 07:15:00.78
  STEP: Patch a scale subresource @ 04/15/24 07:15:00.79
  Apr 15 07:15:00.925: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9972",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8b645ae6-05ee-44c4-ae9a-a326083a6ed6",
      ResourceVersion: (string) (len=6) "166595",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848762098,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Apr 15 07:15:00.956: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9972",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9bd22785-0770-4936-8fe6-29a290bbd7fc",
      ResourceVersion: (string) (len=6) "166600",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848762098,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "4",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "5",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "8b645ae6-05ee-44c4-ae9a-a326083a6ed6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 38 62 36 34 35 61  65 36 2d 30 35 65 65 2d  |\"8b645ae6-05ee-|
              00000120  34 34 63 34 2d 61 65 39  61 2d 61 33 32 36 30 38  |44c4-ae9a-a32608|
              00000130  33 61 36 65 64 36 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |3a6ed6\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(4),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Apr 15 07:15:00.993: INFO: Pod "test-new-deployment-557759b7c7-mj8js" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-mj8js",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-9972",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "55476262-290d-4ef7-9aef-157eba31482c",
      ResourceVersion: (string) (len=6) "166575",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848762098,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "9bd22785-0770-4936-8fe6-29a290bbd7fc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 62  64 32 32 37 38 35 2d 30  |d\":\"9bd22785-0|
              00000090  37 37 30 2d 34 39 33 36  2d 38 66 65 36 2d 32 39  |770-4936-8fe6-29|
              000000a0  61 32 39 30 62 62 64 37  66 63 5c 22 7d 22 3a 7b  |a290bbd7fc\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 30 2e 32 33 33 2e 36  36 2e 34 32 5c 22 7d 22  |10.233.66.42\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6f6gf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6f6gf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-3",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762098,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=15) "192.168.121.206",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "10.233.66.42",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.233.66.42"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848762098,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63848762099,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=72) "cri-o://d8438ea800cd05ee3feff598de4be0b082953fb0b0d9f4ac5db31bb7d89ed34c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 07:15:00.998: INFO: Pod "test-new-deployment-557759b7c7-rmqsd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-rmqsd",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-9972",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "072cc373-ca8c-42d6-8482-4cc6de7fa015",
      ResourceVersion: (string) (len=6) "166601",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848762100,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "9bd22785-0770-4936-8fe6-29a290bbd7fc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 62  64 32 32 37 38 35 2d 30  |d\":\"9bd22785-0|
              00000090  37 37 30 2d 34 39 33 36  2d 38 66 65 36 2d 32 39  |770-4936-8fe6-29|
              000000a0  61 32 39 30 62 62 64 37  66 63 5c 22 7d 22 3a 7b  |a290bbd7fc\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xdbgp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xdbgp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "phiefi7ighaa-2",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=14) "192.168.121.17",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848762100,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 07:15:01.006: INFO: Pod "test-new-deployment-557759b7c7-t5tcs" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-t5tcs",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-9972",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "75c82889-61ca-4b04-b927-c81da7a6db9a",
      ResourceVersion: (string) (len=6) "166606",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63848762100,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "9bd22785-0770-4936-8fe6-29a290bbd7fc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63848762100,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 62  64 32 32 37 38 35 2d 30  |d\":\"9bd22785-0|
              00000090  37 37 30 2d 34 39 33 36  2d 38 66 65 36 2d 32 39  |770-4936-8fe6-29|
              000000a0  61 32 39 30 62 62 64 37  66 63 5c 22 7d 22 3a 7b  |a290bbd7fc\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jvbzt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jvbzt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Apr 15 07:15:01.010: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9972" for this suite. @ 04/15/24 07:15:01.025
â€¢ [2.411 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 04/15/24 07:15:01.045
  Apr 15 07:15:01.045: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 07:15:01.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:15:01.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:15:01.178
  STEP: Creating secret with name secret-test-ae7c8da9-2521-425f-aeae-a4b3caa28b68 @ 04/15/24 07:15:01.19
  STEP: Creating a pod to test consume secrets @ 04/15/24 07:15:01.201
  E0415 07:15:01.589417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:02.589781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:03.590440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:04.591341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:15:05.249
  Apr 15 07:15:05.257: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-secrets-c0a03c54-c2e4-4d3c-85c6-54f41f78335f container secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 07:15:05.278
  Apr 15 07:15:05.319: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4544" for this suite. @ 04/15/24 07:15:05.332
â€¢ [4.309 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:145
  STEP: Creating a kubernetes client @ 04/15/24 07:15:05.361
  Apr 15 07:15:05.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/15/24 07:15:05.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:15:05.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:15:05.411
  Apr 15 07:15:05.417: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:15:05.592419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:15:06.046: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7244" for this suite. @ 04/15/24 07:15:06.06
â€¢ [0.720 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 04/15/24 07:15:06.082
  Apr 15 07:15:06.083: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename cronjob @ 04/15/24 07:15:06.085
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:15:06.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:15:06.139
  STEP: Creating a cronjob @ 04/15/24 07:15:06.15
  STEP: Ensuring more than one job is running at a time @ 04/15/24 07:15:06.168
  E0415 07:15:06.592934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:07.596014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:08.595891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:09.596826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:10.596975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:11.597186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:12.597616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:13.597953      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:14.598426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:15.598502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:16.598677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:17.599156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:18.599422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:19.599890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:20.600722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:21.602380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:22.602753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:23.603776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:24.604336      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:25.604505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:26.604657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:27.605597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:28.606179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:29.606866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:30.607438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:31.608114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:32.608404      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:33.608411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:34.609172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:35.610014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:36.610923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:37.611079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:38.611871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:39.612116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:40.612448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:41.613143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:42.613334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:43.613830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:44.614505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:45.614913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:46.615203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:47.615201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:48.616329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:49.617428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:50.618446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:51.619084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:52.620006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:53.620130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:54.620321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:55.623261      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:56.621705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:57.622538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:58.622935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:15:59.623784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:00.624136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:01.625480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:02.625749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:03.626259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:04.627872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:05.627352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:06.628438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:07.628999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:08.629474      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:09.629603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:10.631046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:11.631107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:12.632066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:13.633562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:14.633089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:15.634200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:16.635621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:17.635046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:18.635413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:19.635675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:20.635990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:21.636088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:22.636326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:23.636340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:24.636756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:25.637112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:26.637296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:27.638051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:28.639061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:29.639236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:30.640631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:31.641421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:32.641201      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:33.641599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:34.641923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:35.642248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:36.643457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:37.644267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:38.644424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:39.645054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:40.645340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:41.645734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:42.646801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:43.647163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:44.648275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:45.648415      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:46.648525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:47.648831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:48.649104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:49.649626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:50.650965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:51.651037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:52.651216      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:53.652304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:54.653337      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:55.653619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:56.653767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:57.654186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:58.654516      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:16:59.654537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 04/15/24 07:17:00.177
  STEP: Removing cronjob @ 04/15/24 07:17:00.195
  Apr 15 07:17:00.221: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3875" for this suite. @ 04/15/24 07:17:00.245
â€¢ [114.189 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 04/15/24 07:17:00.286
  Apr 15 07:17:00.286: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/15/24 07:17:00.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:00.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:00.391
  Apr 15 07:17:00.404: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:17:00.655521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:01.656028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 04/15/24 07:17:02.066
  Apr 15 07:17:02.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 --namespace=crd-publish-openapi-6485 create -f -'
  E0415 07:17:02.656618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:03.551: INFO: stderr: ""
  Apr 15 07:17:03.551: INFO: stdout: "e2e-test-crd-publish-openapi-5533-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 15 07:17:03.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 --namespace=crd-publish-openapi-6485 delete e2e-test-crd-publish-openapi-5533-crds test-foo'
  E0415 07:17:03.657526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:03.782: INFO: stderr: ""
  Apr 15 07:17:03.782: INFO: stdout: "e2e-test-crd-publish-openapi-5533-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Apr 15 07:17:03.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 --namespace=crd-publish-openapi-6485 apply -f -'
  Apr 15 07:17:04.279: INFO: stderr: ""
  Apr 15 07:17:04.279: INFO: stdout: "e2e-test-crd-publish-openapi-5533-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 15 07:17:04.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 --namespace=crd-publish-openapi-6485 delete e2e-test-crd-publish-openapi-5533-crds test-foo'
  Apr 15 07:17:04.450: INFO: stderr: ""
  Apr 15 07:17:04.450: INFO: stdout: "e2e-test-crd-publish-openapi-5533-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 04/15/24 07:17:04.45
  Apr 15 07:17:04.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 --namespace=crd-publish-openapi-6485 create -f -'
  E0415 07:17:04.657949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:04.833: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 04/15/24 07:17:04.833
  Apr 15 07:17:04.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 --namespace=crd-publish-openapi-6485 create -f -'
  Apr 15 07:17:05.213: INFO: rc: 1
  Apr 15 07:17:05.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 --namespace=crd-publish-openapi-6485 apply -f -'
  Apr 15 07:17:05.598: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 04/15/24 07:17:05.599
  Apr 15 07:17:05.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 --namespace=crd-publish-openapi-6485 create -f -'
  E0415 07:17:05.658980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:05.971: INFO: rc: 1
  Apr 15 07:17:05.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 --namespace=crd-publish-openapi-6485 apply -f -'
  Apr 15 07:17:06.323: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 04/15/24 07:17:06.323
  Apr 15 07:17:06.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 explain e2e-test-crd-publish-openapi-5533-crds'
  E0415 07:17:06.659321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:06.690: INFO: stderr: ""
  Apr 15 07:17:06.690: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5533-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 04/15/24 07:17:06.691
  Apr 15 07:17:06.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 explain e2e-test-crd-publish-openapi-5533-crds.metadata'
  Apr 15 07:17:07.015: INFO: stderr: ""
  Apr 15 07:17:07.015: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5533-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Apr 15 07:17:07.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 explain e2e-test-crd-publish-openapi-5533-crds.spec'
  Apr 15 07:17:07.333: INFO: stderr: ""
  Apr 15 07:17:07.333: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5533-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Apr 15 07:17:07.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 explain e2e-test-crd-publish-openapi-5533-crds.spec.bars'
  E0415 07:17:07.660085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:07.673: INFO: stderr: ""
  Apr 15 07:17:07.673: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5533-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 04/15/24 07:17:07.674
  Apr 15 07:17:07.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-6485 explain e2e-test-crd-publish-openapi-5533-crds.spec.bars2'
  Apr 15 07:17:08.020: INFO: rc: 1
  E0415 07:17:08.660632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:09.661295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:09.851: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6485" for this suite. @ 04/15/24 07:17:09.871
â€¢ [9.596 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance]
test/e2e/apimachinery/server_version.go:40
  STEP: Creating a kubernetes client @ 04/15/24 07:17:09.887
  Apr 15 07:17:09.888: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename server-version @ 04/15/24 07:17:09.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:09.915
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:09.92
  STEP: Request ServerVersion @ 04/15/24 07:17:09.923
  STEP: Confirm major version @ 04/15/24 07:17:09.925
  Apr 15 07:17:09.925: INFO: Major version: 1
  STEP: Confirm minor version @ 04/15/24 07:17:09.925
  Apr 15 07:17:09.925: INFO: cleanMinorVersion: 28
  Apr 15 07:17:09.925: INFO: Minor version: 28
  Apr 15 07:17:09.925: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-7916" for this suite. @ 04/15/24 07:17:09.934
â€¢ [0.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 04/15/24 07:17:09.956
  Apr 15 07:17:09.956: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/15/24 07:17:09.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:09.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:09.99
  Apr 15 07:17:09.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:17:10.662164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:11.663398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/15/24 07:17:12.001
  Apr 15 07:17:12.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-2958 --namespace=crd-publish-openapi-2958 create -f -'
  E0415 07:17:12.663508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:13.030: INFO: stderr: ""
  Apr 15 07:17:13.030: INFO: stdout: "e2e-test-crd-publish-openapi-3772-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 15 07:17:13.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-2958 --namespace=crd-publish-openapi-2958 delete e2e-test-crd-publish-openapi-3772-crds test-cr'
  Apr 15 07:17:13.198: INFO: stderr: ""
  Apr 15 07:17:13.198: INFO: stdout: "e2e-test-crd-publish-openapi-3772-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Apr 15 07:17:13.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-2958 --namespace=crd-publish-openapi-2958 apply -f -'
  E0415 07:17:13.664103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:14.063: INFO: stderr: ""
  Apr 15 07:17:14.063: INFO: stdout: "e2e-test-crd-publish-openapi-3772-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 15 07:17:14.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-2958 --namespace=crd-publish-openapi-2958 delete e2e-test-crd-publish-openapi-3772-crds test-cr'
  Apr 15 07:17:14.229: INFO: stderr: ""
  Apr 15 07:17:14.229: INFO: stdout: "e2e-test-crd-publish-openapi-3772-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/15/24 07:17:14.229
  Apr 15 07:17:14.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-2958 explain e2e-test-crd-publish-openapi-3772-crds'
  Apr 15 07:17:14.572: INFO: stderr: ""
  Apr 15 07:17:14.573: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-3772-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0415 07:17:14.665358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:15.665954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:16.357: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2958" for this suite. @ 04/15/24 07:17:16.381
â€¢ [6.442 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:479
  STEP: Creating a kubernetes client @ 04/15/24 07:17:16.408
  Apr 15 07:17:16.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename gc @ 04/15/24 07:17:16.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:16.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:16.444
  STEP: create the deployment @ 04/15/24 07:17:16.451
  W0415 07:17:16.461750      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/15/24 07:17:16.462
  STEP: delete the deployment @ 04/15/24 07:17:16.475
  STEP: wait for all rs to be garbage collected @ 04/15/24 07:17:16.525
  STEP: expected 0 rs, got 1 rs @ 04/15/24 07:17:16.543
  STEP: expected 0 pods, got 2 pods @ 04/15/24 07:17:16.556
  E0415 07:17:16.666994      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/15/24 07:17:17.111
  Apr 15 07:17:17.343: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 15 07:17:17.353: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8099" for this suite. @ 04/15/24 07:17:17.365
â€¢ [0.973 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]
test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 04/15/24 07:17:17.382
  Apr 15 07:17:17.383: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename subpath @ 04/15/24 07:17:17.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:17.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:17.419
  STEP: Setting up data @ 04/15/24 07:17:17.426
  STEP: Creating pod pod-subpath-test-secret-djkv @ 04/15/24 07:17:17.448
  STEP: Creating a pod to test atomic-volume-subpath @ 04/15/24 07:17:17.448
  E0415 07:17:17.667484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:18.668529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:19.669896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:20.669967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:21.670585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:22.670762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:23.671122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:24.672030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:25.673051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:26.673391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:27.674102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:28.674197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:29.675217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:30.675171      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:31.676348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:32.676355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:33.677310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:34.678295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:35.678859      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:36.679391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:37.679292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:38.679703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:39.680419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:40.680504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:17:41.593
  Apr 15 07:17:41.601: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-subpath-test-secret-djkv container test-container-subpath-secret-djkv: <nil>
  STEP: delete the pod @ 04/15/24 07:17:41.645
  E0415 07:17:41.680727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pod pod-subpath-test-secret-djkv @ 04/15/24 07:17:41.688
  Apr 15 07:17:41.688: INFO: Deleting pod "pod-subpath-test-secret-djkv" in namespace "subpath-4691"
  Apr 15 07:17:41.694: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4691" for this suite. @ 04/15/24 07:17:41.703
â€¢ [24.333 seconds]
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:347
  STEP: Creating a kubernetes client @ 04/15/24 07:17:41.717
  Apr 15 07:17:41.717: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename security-context-test @ 04/15/24 07:17:41.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:41.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:41.756
  E0415 07:17:42.681778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:43.681904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:44.682611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:45.682775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:45.811: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-514" for this suite. @ 04/15/24 07:17:45.824
â€¢ [4.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 04/15/24 07:17:45.84
  Apr 15 07:17:45.840: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 07:17:45.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:45.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:45.876
  STEP: Creating configMap with name configmap-test-volume-37704950-060e-4344-a03a-3454f886301d @ 04/15/24 07:17:45.882
  STEP: Creating a pod to test consume configMaps @ 04/15/24 07:17:45.891
  E0415 07:17:46.683502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:47.684226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:48.684549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:49.684727      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:17:49.924
  Apr 15 07:17:49.932: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-be6baac3-1a6f-4564-bfbf-1bc957e95b35 container configmap-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 07:17:49.947
  Apr 15 07:17:49.978: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5919" for this suite. @ 04/15/24 07:17:49.988
â€¢ [4.162 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
test/e2e/common/node/configmap.go:138
  STEP: Creating a kubernetes client @ 04/15/24 07:17:50.002
  Apr 15 07:17:50.002: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 07:17:50.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:50.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:50.059
  STEP: Creating configMap that has name configmap-test-emptyKey-8e501541-3d24-4079-b238-82cb144a4fb7 @ 04/15/24 07:17:50.063
  Apr 15 07:17:50.070: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-358" for this suite. @ 04/15/24 07:17:50.089
â€¢ [0.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 04/15/24 07:17:50.106
  Apr 15 07:17:50.107: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename field-validation @ 04/15/24 07:17:50.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:50.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:50.157
  Apr 15 07:17:50.169: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  W0415 07:17:50.171548      13 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0046071d0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0415 07:17:50.685819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:51.686638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:52.687564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  W0415 07:17:52.894676      13 warnings.go:70] unknown field "alpha"
  W0415 07:17:52.894725      13 warnings.go:70] unknown field "beta"
  W0415 07:17:52.894742      13 warnings.go:70] unknown field "delta"
  W0415 07:17:52.894757      13 warnings.go:70] unknown field "epsilon"
  W0415 07:17:52.894792      13 warnings.go:70] unknown field "gamma"
  Apr 15 07:17:53.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9701" for this suite. @ 04/15/24 07:17:53.492
â€¢ [3.400 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]
test/e2e/apps/controller_revision.go:124
  STEP: Creating a kubernetes client @ 04/15/24 07:17:53.507
  Apr 15 07:17:53.507: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename controllerrevisions @ 04/15/24 07:17:53.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:53.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:53.54
  STEP: Creating DaemonSet "e2e-2t27g-daemon-set" @ 04/15/24 07:17:53.58
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/15/24 07:17:53.597
  Apr 15 07:17:53.621: INFO: Number of nodes with available pods controlled by daemonset e2e-2t27g-daemon-set: 0
  Apr 15 07:17:53.621: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 07:17:53.688817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:54.662: INFO: Number of nodes with available pods controlled by daemonset e2e-2t27g-daemon-set: 0
  Apr 15 07:17:54.662: INFO: Node phiefi7ighaa-1 is running 0 daemon pod, expected 1
  E0415 07:17:54.691989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:55.641: INFO: Number of nodes with available pods controlled by daemonset e2e-2t27g-daemon-set: 3
  Apr 15 07:17:55.641: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-2t27g-daemon-set
  STEP: Confirm DaemonSet "e2e-2t27g-daemon-set" successfully created with "daemonset-name=e2e-2t27g-daemon-set" label @ 04/15/24 07:17:55.658
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-2t27g-daemon-set" @ 04/15/24 07:17:55.675
  Apr 15 07:17:55.682: INFO: Located ControllerRevision: "e2e-2t27g-daemon-set-7c77c5b789"
  E0415 07:17:55.692034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching ControllerRevision "e2e-2t27g-daemon-set-7c77c5b789" @ 04/15/24 07:17:55.692
  Apr 15 07:17:55.719: INFO: e2e-2t27g-daemon-set-7c77c5b789 has been patched
  STEP: Create a new ControllerRevision @ 04/15/24 07:17:55.719
  Apr 15 07:17:55.728: INFO: Created ControllerRevision: e2e-2t27g-daemon-set-6b4f755445
  STEP: Confirm that there are two ControllerRevisions @ 04/15/24 07:17:55.729
  Apr 15 07:17:55.729: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 15 07:17:55.737: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-2t27g-daemon-set-7c77c5b789" @ 04/15/24 07:17:55.738
  STEP: Confirm that there is only one ControllerRevision @ 04/15/24 07:17:55.751
  Apr 15 07:17:55.751: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 15 07:17:55.757: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-2t27g-daemon-set-6b4f755445" @ 04/15/24 07:17:55.764
  Apr 15 07:17:55.780: INFO: e2e-2t27g-daemon-set-6b4f755445 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 04/15/24 07:17:55.781
  W0415 07:17:55.799005      13 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 04/15/24 07:17:55.799
  Apr 15 07:17:55.799: INFO: Requesting list of ControllerRevisions to confirm quantity
  E0415 07:17:56.692317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:56.815: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 15 07:17:56.823: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-2t27g-daemon-set-6b4f755445=updated" @ 04/15/24 07:17:56.823
  STEP: Confirm that there is only one ControllerRevision @ 04/15/24 07:17:56.84
  Apr 15 07:17:56.840: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 15 07:17:56.847: INFO: Found 1 ControllerRevisions
  Apr 15 07:17:56.854: INFO: ControllerRevision "e2e-2t27g-daemon-set-6df79cb65b" has revision 3
  STEP: Deleting DaemonSet "e2e-2t27g-daemon-set" @ 04/15/24 07:17:56.86
  STEP: deleting DaemonSet.extensions e2e-2t27g-daemon-set in namespace controllerrevisions-4869, will wait for the garbage collector to delete the pods @ 04/15/24 07:17:56.86
  Apr 15 07:17:56.938: INFO: Deleting DaemonSet.extensions e2e-2t27g-daemon-set took: 19.765806ms
  Apr 15 07:17:57.039: INFO: Terminating DaemonSet.extensions e2e-2t27g-daemon-set pods took: 101.458101ms
  E0415 07:17:57.693044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:17:58.693773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:17:58.950: INFO: Number of nodes with available pods controlled by daemonset e2e-2t27g-daemon-set: 0
  Apr 15 07:17:58.950: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-2t27g-daemon-set
  Apr 15 07:17:58.957: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"167356"},"items":null}

  Apr 15 07:17:58.962: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"167356"},"items":null}

  Apr 15 07:17:58.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-4869" for this suite. @ 04/15/24 07:17:59.005
â€¢ [5.516 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
test/e2e/network/endpointslice.go:104
  STEP: Creating a kubernetes client @ 04/15/24 07:17:59.031
  Apr 15 07:17:59.031: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename endpointslice @ 04/15/24 07:17:59.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:59.081
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:59.086
  Apr 15 07:17:59.197: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7806" for this suite. @ 04/15/24 07:17:59.206
â€¢ [0.188 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:107
  STEP: Creating a kubernetes client @ 04/15/24 07:17:59.222
  Apr 15 07:17:59.222: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 07:17:59.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:17:59.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:17:59.261
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/15/24 07:17:59.27
  E0415 07:17:59.695533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:00.695863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:01.696700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:02.697125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:18:03.344
  Apr 15 07:18:03.352: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-8096e9aa-ef58-4847-8c14-28703c0df33f container test-container: <nil>
  STEP: delete the pod @ 04/15/24 07:18:03.37
  Apr 15 07:18:03.399: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6877" for this suite. @ 04/15/24 07:18:03.408
â€¢ [4.202 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 04/15/24 07:18:03.429
  Apr 15 07:18:03.429: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename watch @ 04/15/24 07:18:03.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:18:03.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:18:03.473
  STEP: creating a watch on configmaps with a certain label @ 04/15/24 07:18:03.479
  STEP: creating a new configmap @ 04/15/24 07:18:03.483
  STEP: modifying the configmap once @ 04/15/24 07:18:03.497
  STEP: changing the label value of the configmap @ 04/15/24 07:18:03.514
  STEP: Expecting to observe a delete notification for the watched object @ 04/15/24 07:18:03.529
  Apr 15 07:18:03.530: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8085  585001d5-fd3d-4792-b99b-3d14a59c9768 167399 0 2024-04-15 07:18:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-15 07:18:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:18:03.530: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8085  585001d5-fd3d-4792-b99b-3d14a59c9768 167400 0 2024-04-15 07:18:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-15 07:18:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:18:03.530: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8085  585001d5-fd3d-4792-b99b-3d14a59c9768 167401 0 2024-04-15 07:18:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-15 07:18:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 04/15/24 07:18:03.53
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 04/15/24 07:18:03.548
  E0415 07:18:03.697810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:04.697896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:05.697930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:06.698107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:07.699210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:08.699956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:09.700743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:10.701394      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:11.702364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:12.703227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 04/15/24 07:18:13.55
  STEP: modifying the configmap a third time @ 04/15/24 07:18:13.575
  STEP: deleting the configmap @ 04/15/24 07:18:13.599
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 04/15/24 07:18:13.619
  Apr 15 07:18:13.620: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8085  585001d5-fd3d-4792-b99b-3d14a59c9768 167461 0 2024-04-15 07:18:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-15 07:18:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:18:13.621: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8085  585001d5-fd3d-4792-b99b-3d14a59c9768 167462 0 2024-04-15 07:18:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-15 07:18:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:18:13.621: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8085  585001d5-fd3d-4792-b99b-3d14a59c9768 167463 0 2024-04-15 07:18:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-15 07:18:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:18:13.621: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8085" for this suite. @ 04/15/24 07:18:13.636
â€¢ [10.228 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 04/15/24 07:18:13.666
  Apr 15 07:18:13.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 07:18:13.671
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:18:13.702
  E0415 07:18:13.703305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:18:13.709
  STEP: Creating pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170 @ 04/15/24 07:18:13.715
  E0415 07:18:14.703909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:15.704389      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/15/24 07:18:15.746
  Apr 15 07:18:15.753: INFO: Initial restart count of pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 is 0
  Apr 15 07:18:15.761: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:16.704783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:17.705076      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:17.771: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:18.705672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:19.705838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:19.783: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:20.706069      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:21.706736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:21.796: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:22.707811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:23.707958      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:23.811: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:24.708869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:25.709127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:25.818: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:26.709980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:27.709971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:27.830: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:28.710111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:29.710983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:29.840: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:30.711869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:31.712129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:31.849: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:32.712475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:33.712654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:33.858: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:34.713036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:35.712996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:35.867: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:36.713242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:37.713283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:37.879: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:38.714017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:39.714141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:39.889: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:40.714700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:41.715222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:41.897: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:42.714894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:43.715957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:43.910: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:44.716796      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:45.717640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:45.918: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:46.717848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:47.718649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:47.926: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:48.718788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:49.719089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:49.939: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:50.719335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:51.721321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:51.947: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:52.720712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:53.721364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:53.963: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:54.721778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:55.721844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:55.973: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:56.722241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:57.722775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:57.982: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:18:58.723311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:18:59.723347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:18:59.997: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:00.724675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:01.725014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:02.006: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:02.725068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:03.725460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:04.018: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:04.726783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:05.726756      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:06.029: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:06.727134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:07.727270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:08.041: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:08.727667      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:09.727894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:10.054: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:10.729175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:11.729361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:12.066: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:12.729467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:13.729730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:14.078: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:14.730314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:15.730559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:16.100: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:16.731460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:17.731136      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:18.110: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  E0415 07:19:18.731364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:19.732086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:20.126: INFO: Get pod test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 in namespace container-probe-1170
  Apr 15 07:19:20.126: INFO: Restart count of pod container-probe-1170/test-grpc-dd771e2f-b438-4146-a7c0-a6e49bbe9085 is now 1 (1m4.373500784s elapsed)
  Apr 15 07:19:20.127: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:19:20.161
  STEP: Destroying namespace "container-probe-1170" for this suite. @ 04/15/24 07:19:20.228
â€¢ [66.576 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 04/15/24 07:19:20.247
  Apr 15 07:19:20.247: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename watch @ 04/15/24 07:19:20.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:19:20.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:19:20.307
  STEP: creating a watch on configmaps with label A @ 04/15/24 07:19:20.316
  STEP: creating a watch on configmaps with label B @ 04/15/24 07:19:20.319
  STEP: creating a watch on configmaps with label A or B @ 04/15/24 07:19:20.322
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 04/15/24 07:19:20.326
  Apr 15 07:19:20.339: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2094  a536ad6a-80ed-4fcb-a1b6-ed6f1907a4d5 167606 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:19:20.340: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2094  a536ad6a-80ed-4fcb-a1b6-ed6f1907a4d5 167606 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 04/15/24 07:19:20.341
  Apr 15 07:19:20.359: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2094  a536ad6a-80ed-4fcb-a1b6-ed6f1907a4d5 167607 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:19:20.359: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2094  a536ad6a-80ed-4fcb-a1b6-ed6f1907a4d5 167607 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 04/15/24 07:19:20.36
  Apr 15 07:19:20.380: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2094  a536ad6a-80ed-4fcb-a1b6-ed6f1907a4d5 167608 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:19:20.381: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2094  a536ad6a-80ed-4fcb-a1b6-ed6f1907a4d5 167608 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 04/15/24 07:19:20.382
  Apr 15 07:19:20.398: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2094  a536ad6a-80ed-4fcb-a1b6-ed6f1907a4d5 167609 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:19:20.398: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2094  a536ad6a-80ed-4fcb-a1b6-ed6f1907a4d5 167609 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 04/15/24 07:19:20.399
  Apr 15 07:19:20.410: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2094  0a96d1c5-011e-4e9d-8019-06de0488c540 167610 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:19:20.411: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2094  0a96d1c5-011e-4e9d-8019-06de0488c540 167610 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0415 07:19:20.733615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:21.734448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:22.735365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:23.735805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:24.736572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:25.737591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:26.737897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:27.738244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:28.738839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:29.739347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 04/15/24 07:19:30.411
  Apr 15 07:19:30.431: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2094  0a96d1c5-011e-4e9d-8019-06de0488c540 167638 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 15 07:19:30.432: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2094  0a96d1c5-011e-4e9d-8019-06de0488c540 167638 0 2024-04-15 07:19:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-15 07:19:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E0415 07:19:30.740351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:31.741047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:32.741635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:33.741744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:34.742461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:35.742617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:36.742805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:37.742996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:38.743204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:39.743416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:19:40.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2094" for this suite. @ 04/15/24 07:19:40.446
â€¢ [20.213 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 04/15/24 07:19:40.462
  Apr 15 07:19:40.462: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 07:19:40.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:19:40.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:19:40.498
  STEP: Creating configMap with name projected-configmap-test-volume-ec29249b-8f0f-41fc-8252-6bd46b814a0a @ 04/15/24 07:19:40.51
  STEP: Creating a pod to test consume configMaps @ 04/15/24 07:19:40.521
  E0415 07:19:40.743547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:41.744853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:42.745131      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:43.745398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:19:44.574
  Apr 15 07:19:44.584: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-configmaps-4068a0d1-08c0-49f9-8cb3-6a9773843b45 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 07:19:44.62
  Apr 15 07:19:44.651: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9534" for this suite. @ 04/15/24 07:19:44.661
â€¢ [4.215 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 04/15/24 07:19:44.681
  Apr 15 07:19:44.682: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 07:19:44.685
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:19:44.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:19:44.723
  STEP: creating the pod @ 04/15/24 07:19:44.728
  STEP: submitting the pod to kubernetes @ 04/15/24 07:19:44.729
  E0415 07:19:44.745748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:45.746548      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:46.746800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/15/24 07:19:46.773
  STEP: updating the pod @ 04/15/24 07:19:46.781
  Apr 15 07:19:47.338: INFO: Successfully updated pod "pod-update-d5eee679-532e-4c06-84ea-35c0b1ed03c3"
  STEP: verifying the updated pod is in kubernetes @ 04/15/24 07:19:47.363
  Apr 15 07:19:47.370: INFO: Pod update OK
  Apr 15 07:19:47.371: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8169" for this suite. @ 04/15/24 07:19:47.382
â€¢ [2.713 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 04/15/24 07:19:47.4
  Apr 15 07:19:47.401: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename events @ 04/15/24 07:19:47.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:19:47.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:19:47.493
  STEP: creating a test event @ 04/15/24 07:19:47.499
  STEP: listing events in all namespaces @ 04/15/24 07:19:47.522
  STEP: listing events in test namespace @ 04/15/24 07:19:47.531
  STEP: listing events with field selection filtering on source @ 04/15/24 07:19:47.538
  STEP: listing events with field selection filtering on reportingController @ 04/15/24 07:19:47.545
  STEP: getting the test event @ 04/15/24 07:19:47.551
  STEP: patching the test event @ 04/15/24 07:19:47.558
  STEP: getting the test event @ 04/15/24 07:19:47.587
  STEP: updating the test event @ 04/15/24 07:19:47.595
  STEP: getting the test event @ 04/15/24 07:19:47.613
  STEP: deleting the test event @ 04/15/24 07:19:47.621
  STEP: listing events in all namespaces @ 04/15/24 07:19:47.64
  STEP: listing events in test namespace @ 04/15/24 07:19:47.649
  Apr 15 07:19:47.661: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4941" for this suite. @ 04/15/24 07:19:47.676
â€¢ [0.288 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 04/15/24 07:19:47.732
  Apr 15 07:19:47.732: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 07:19:47.735
  E0415 07:19:47.747551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:19:47.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:19:47.769
  Apr 15 07:19:47.851: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8477" for this suite. @ 04/15/24 07:19:47.871
â€¢ [0.165 seconds]
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 04/15/24 07:19:47.899
  Apr 15 07:19:47.899: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-pred @ 04/15/24 07:19:47.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:19:47.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:19:47.937
  Apr 15 07:19:47.942: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 15 07:19:47.964: INFO: Waiting for terminating namespaces to be deleted...
  Apr 15 07:19:47.971: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-1 before test
  Apr 15 07:19:47.994: INFO: coredns-5dd5756b68-6h4pb from kube-system started at 2024-04-15 06:16:14 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:47.994: INFO: 	Container coredns ready: true, restart count 0
  Apr 15 07:19:47.994: INFO: kube-addon-manager-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:47.994: INFO: 	Container kube-addon-manager ready: true, restart count 4
  Apr 15 07:19:47.994: INFO: kube-apiserver-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:47.994: INFO: 	Container kube-apiserver ready: true, restart count 4
  Apr 15 07:19:47.994: INFO: kube-controller-manager-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:47.994: INFO: 	Container kube-controller-manager ready: true, restart count 4
  Apr 15 07:19:47.994: INFO: kube-flannel-ds-wkm7k from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:47.994: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 07:19:47.994: INFO: kube-proxy-qgvqr from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:47.994: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 07:19:47.994: INFO: kube-scheduler-phiefi7ighaa-1 from kube-system started at 2024-04-15 06:11:59 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:47.994: INFO: 	Container kube-scheduler ready: true, restart count 4
  Apr 15 07:19:47.994: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-f9ld5 from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (2 container statuses recorded)
  Apr 15 07:19:47.994: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 07:19:47.994: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 15 07:19:47.994: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-2 before test
  Apr 15 07:19:48.014: INFO: kube-addon-manager-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.014: INFO: 	Container kube-addon-manager ready: true, restart count 4
  Apr 15 07:19:48.014: INFO: kube-apiserver-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.014: INFO: 	Container kube-apiserver ready: true, restart count 4
  Apr 15 07:19:48.014: INFO: kube-controller-manager-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.014: INFO: 	Container kube-controller-manager ready: true, restart count 4
  Apr 15 07:19:48.014: INFO: kube-flannel-ds-5txx7 from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.014: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 07:19:48.014: INFO: kube-proxy-rkzlb from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.014: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 07:19:48.014: INFO: kube-scheduler-phiefi7ighaa-2 from kube-system started at 2024-04-15 06:07:11 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.014: INFO: 	Container kube-scheduler ready: true, restart count 4
  Apr 15 07:19:48.014: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-jn669 from sonobuoy started at 2024-04-15 06:16:23 +0000 UTC (2 container statuses recorded)
  Apr 15 07:19:48.014: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 07:19:48.014: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 15 07:19:48.014: INFO: 
  Logging pods the apiserver thinks is on node phiefi7ighaa-3 before test
  Apr 15 07:19:48.030: INFO: coredns-5dd5756b68-hggvw from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.031: INFO: 	Container coredns ready: true, restart count 0
  Apr 15 07:19:48.031: INFO: kube-flannel-ds-q9jkx from kube-system started at 2024-04-15 06:16:16 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.032: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 15 07:19:48.032: INFO: kube-proxy-rw79s from kube-system started at 2024-04-15 06:16:15 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.033: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 15 07:19:48.033: INFO: pod-update-d5eee679-532e-4c06-84ea-35c0b1ed03c3 from pods-8169 started at 2024-04-15 07:19:44 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.034: INFO: 	Container pause ready: true, restart count 0
  Apr 15 07:19:48.034: INFO: sonobuoy from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (1 container statuses recorded)
  Apr 15 07:19:48.034: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 15 07:19:48.035: INFO: sonobuoy-e2e-job-c84246e43b2d459a from sonobuoy started at 2024-04-15 06:16:22 +0000 UTC (2 container statuses recorded)
  Apr 15 07:19:48.035: INFO: 	Container e2e ready: true, restart count 0
  Apr 15 07:19:48.035: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 07:19:48.036: INFO: sonobuoy-systemd-logs-daemon-set-d7e2fd7d68fd4182-5gbvc from sonobuoy started at 2024-04-15 06:16:23 +0000 UTC (2 container statuses recorded)
  Apr 15 07:19:48.036: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 15 07:19:48.036: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/15/24 07:19:48.037
  E0415 07:19:48.748054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:49.748105      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/15/24 07:19:50.09
  STEP: Trying to apply a random label on the found node. @ 04/15/24 07:19:50.133
  STEP: verifying the node has the label kubernetes.io/e2e-262b6a20-c49a-49a1-9ec3-33ca36e0e576 95 @ 04/15/24 07:19:50.163
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 04/15/24 07:19:50.181
  E0415 07:19:50.748283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:51.748564      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.206 on the node which pod4 resides and expect not scheduled @ 04/15/24 07:19:52.231
  E0415 07:19:52.749627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:53.750014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:54.750417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:55.750631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:56.750718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:57.751095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:58.750987      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:19:59.751605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:00.752629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:01.752865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:02.753611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:03.753898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:04.754737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:05.754866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:06.755647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:07.756577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:08.756822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:09.756969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:10.757217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:11.757690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:12.758542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:13.759143      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:14.759889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:15.760323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:16.765673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:17.761753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:18.762138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:19.762527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:20.763372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:21.763822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:22.763923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:23.764133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:24.764547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:25.764600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:26.764931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:27.765045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:28.765992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:29.766561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:30.766458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:31.766654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:32.766913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:33.767089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:34.767263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:35.767521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:36.768041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:37.770482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:38.770944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:39.771041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:40.771834      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:41.771433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:42.771513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:43.771743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:44.772832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:45.773067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:46.773549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:47.774157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:48.774331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:49.774549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:50.775405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:51.776310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:52.776489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:53.776709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:54.777401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:55.778159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:56.779274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:57.779648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:58.780426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:20:59.780543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:00.781217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:01.786146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:02.785661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:03.786646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:04.787311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:05.787501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:06.788554      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:07.788724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:08.789633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:09.789923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:10.789926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:11.798061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:12.794142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:13.795352      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:14.795633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:15.796018      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:16.797378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:17.797376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:18.798092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:19.800005      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:20.799957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:21.800584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:22.801100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:23.801279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:24.801175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:25.801430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:26.802665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:27.803232      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:28.804604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:29.804809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:30.804954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:31.805310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:32.805862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:33.806601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:34.808041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:35.809833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:36.809968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:37.810891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:38.811870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:39.812804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:40.812885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:41.813604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:42.814407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:43.814269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:44.814936      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:45.815082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:46.815342      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:47.815790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:48.816034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:49.817017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:50.817174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:51.817291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:52.817688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:53.818691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:54.818794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:55.818815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:56.819099      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:57.819861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:58.820511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:21:59.821023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:00.821432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:01.821851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:02.822485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:03.823074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:04.823841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:05.824390      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:06.824505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:07.825130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:08.825654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:09.826333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:10.827186      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:11.827264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:12.827990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:13.828574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:14.828501      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:15.829160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:16.829779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:17.830638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:18.831044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:19.831930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:20.832641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:21.833798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:22.834003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:23.834843      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:24.835907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:25.836986      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:26.837879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:27.838298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:28.839291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:29.840130      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:30.841532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:31.841061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:32.841176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:33.841741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:34.841942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:35.842329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:36.842950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:37.843417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:38.844036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:39.844840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:40.845011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:41.845622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:42.846168      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:43.846952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:44.847461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:45.847457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:46.847556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:47.849259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:48.848718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:49.848580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:50.849640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:51.849774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:52.850080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:53.850526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:54.851297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:55.852551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:56.852588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:57.856599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:58.854555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:22:59.855492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:00.856238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:01.856632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:02.857514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:03.857717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:04.858599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:05.860013      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:06.860829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:07.861539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:08.862126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:09.862597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:10.862584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:11.863532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:12.864010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:13.864242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:14.864760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:15.864677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:16.865280      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:17.866243      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:18.867019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:19.867488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:20.867705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:21.868572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:22.869279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:23.870200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:24.869886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:25.870713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:26.870979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:27.871242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:28.871699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:29.871857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:30.872557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:31.873291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:32.873703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:33.874063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:34.874736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:35.875968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:36.876036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:37.876567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:38.876534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:39.877407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:40.878277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:41.879625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:42.879546      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:43.879732      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:44.880039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:45.880788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:46.881373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:47.882309      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:48.882951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:49.883308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:50.883729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:51.884271      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:52.884866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:53.885101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:54.885258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:55.886365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:56.886327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:57.887215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:58.887860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:23:59.888758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:00.888910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:01.889365      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:02.889315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:03.889705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:04.890175      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:05.890269      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:06.891011      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:07.892058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:08.892132      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:09.892506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:10.892492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:11.893134      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:12.893619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:13.894116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:14.894528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:15.895496      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:16.907145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:17.897305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:18.897344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:19.897544      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:20.897827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:21.898666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:22.899193      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:23.899767      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:24.900335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:25.901184      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:26.901265      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:27.902534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:28.902980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:29.903480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:30.903878      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:31.904640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:32.905367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:33.905050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:34.906027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:35.906855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:36.907254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:37.907672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:38.907949      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:39.908591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:40.908488      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:41.908751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:42.909159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:43.910049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:44.910414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:45.911537      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:46.911686      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:47.912789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:48.913624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:49.914030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:50.915104      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:24:51.915965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-262b6a20-c49a-49a1-9ec3-33ca36e0e576 off the node phiefi7ighaa-3 @ 04/15/24 07:24:52.251
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-262b6a20-c49a-49a1-9ec3-33ca36e0e576 @ 04/15/24 07:24:52.286
  Apr 15 07:24:52.316: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6679" for this suite. @ 04/15/24 07:24:52.335
â€¢ [304.460 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high  [Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 04/15/24 07:24:52.367
  Apr 15 07:24:52.367: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename svc-latency @ 04/15/24 07:24:52.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:24:52.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:24:52.434
  Apr 15 07:24:52.442: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-7752 @ 04/15/24 07:24:52.446
  I0415 07:24:52.464060      13 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7752, replica count: 1
  E0415 07:24:52.916625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 07:24:53.522907      13 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0415 07:24:53.917960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 07:24:54.524126      13 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 15 07:24:54.676: INFO: Created: latency-svc-r8wl9
  Apr 15 07:24:54.686: INFO: Got endpoints: latency-svc-r8wl9 [60.663505ms]
  Apr 15 07:24:54.731: INFO: Created: latency-svc-66kzj
  Apr 15 07:24:54.751: INFO: Got endpoints: latency-svc-66kzj [62.872961ms]
  Apr 15 07:24:54.764: INFO: Created: latency-svc-d2jss
  Apr 15 07:24:54.785: INFO: Created: latency-svc-tjmn7
  Apr 15 07:24:54.800: INFO: Got endpoints: latency-svc-d2jss [111.325462ms]
  Apr 15 07:24:54.807: INFO: Got endpoints: latency-svc-tjmn7 [116.711281ms]
  Apr 15 07:24:54.824: INFO: Created: latency-svc-h4xx2
  Apr 15 07:24:54.864: INFO: Created: latency-svc-n9pfs
  Apr 15 07:24:54.886: INFO: Got endpoints: latency-svc-h4xx2 [195.872567ms]
  Apr 15 07:24:54.905: INFO: Got endpoints: latency-svc-n9pfs [215.907379ms]
  Apr 15 07:24:54.915: INFO: Created: latency-svc-cfh6c
  E0415 07:24:54.918026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:24:54.938: INFO: Created: latency-svc-6rlq4
  Apr 15 07:24:54.947: INFO: Got endpoints: latency-svc-cfh6c [254.132414ms]
  Apr 15 07:24:54.976: INFO: Got endpoints: latency-svc-6rlq4 [282.98916ms]
  Apr 15 07:24:54.986: INFO: Created: latency-svc-zg279
  Apr 15 07:24:55.001: INFO: Got endpoints: latency-svc-zg279 [307.319494ms]
  Apr 15 07:24:55.025: INFO: Created: latency-svc-sfsh5
  Apr 15 07:24:55.062: INFO: Got endpoints: latency-svc-sfsh5 [368.117343ms]
  Apr 15 07:24:55.075: INFO: Created: latency-svc-hqvmg
  Apr 15 07:24:55.102: INFO: Got endpoints: latency-svc-hqvmg [406.980805ms]
  Apr 15 07:24:55.103: INFO: Created: latency-svc-qc8t4
  Apr 15 07:24:55.124: INFO: Got endpoints: latency-svc-qc8t4 [428.194258ms]
  Apr 15 07:24:55.142: INFO: Created: latency-svc-xmrhd
  Apr 15 07:24:55.153: INFO: Created: latency-svc-z6fpf
  Apr 15 07:24:55.160: INFO: Got endpoints: latency-svc-xmrhd [469.1938ms]
  Apr 15 07:24:55.172: INFO: Got endpoints: latency-svc-z6fpf [475.813501ms]
  Apr 15 07:24:55.183: INFO: Created: latency-svc-vb2w2
  Apr 15 07:24:55.202: INFO: Created: latency-svc-4kxc2
  Apr 15 07:24:55.214: INFO: Got endpoints: latency-svc-vb2w2 [516.465934ms]
  Apr 15 07:24:55.220: INFO: Got endpoints: latency-svc-4kxc2 [522.427132ms]
  Apr 15 07:24:55.227: INFO: Created: latency-svc-c4qdb
  Apr 15 07:24:55.232: INFO: Got endpoints: latency-svc-c4qdb [480.914886ms]
  Apr 15 07:24:55.244: INFO: Created: latency-svc-qgvds
  Apr 15 07:24:55.254: INFO: Created: latency-svc-pnpks
  Apr 15 07:24:55.275: INFO: Created: latency-svc-244hj
  Apr 15 07:24:55.275: INFO: Got endpoints: latency-svc-qgvds [467.202974ms]
  Apr 15 07:24:55.308: INFO: Got endpoints: latency-svc-pnpks [508.228733ms]
  Apr 15 07:24:55.311: INFO: Got endpoints: latency-svc-244hj [424.892984ms]
  Apr 15 07:24:55.353: INFO: Created: latency-svc-jxx8f
  Apr 15 07:24:55.386: INFO: Got endpoints: latency-svc-jxx8f [481.196364ms]
  Apr 15 07:24:55.400: INFO: Created: latency-svc-22nhr
  Apr 15 07:24:55.415: INFO: Got endpoints: latency-svc-22nhr [468.243014ms]
  Apr 15 07:24:55.434: INFO: Created: latency-svc-twp4j
  Apr 15 07:24:55.435: INFO: Got endpoints: latency-svc-twp4j [458.703387ms]
  Apr 15 07:24:55.446: INFO: Created: latency-svc-4j49f
  Apr 15 07:24:55.473: INFO: Created: latency-svc-877cw
  Apr 15 07:24:55.492: INFO: Created: latency-svc-qwrd8
  Apr 15 07:24:55.500: INFO: Got endpoints: latency-svc-4j49f [498.407563ms]
  Apr 15 07:24:55.505: INFO: Got endpoints: latency-svc-877cw [442.212305ms]
  Apr 15 07:24:55.515: INFO: Got endpoints: latency-svc-qwrd8 [413.223419ms]
  Apr 15 07:24:55.535: INFO: Created: latency-svc-hv4db
  Apr 15 07:24:55.552: INFO: Got endpoints: latency-svc-hv4db [427.97899ms]
  Apr 15 07:24:55.694: INFO: Created: latency-svc-2htd4
  Apr 15 07:24:55.709: INFO: Created: latency-svc-jnqv5
  Apr 15 07:24:55.709: INFO: Created: latency-svc-9qtz9
  Apr 15 07:24:55.718: INFO: Created: latency-svc-7nr56
  Apr 15 07:24:55.721: INFO: Created: latency-svc-vltb4
  Apr 15 07:24:55.722: INFO: Created: latency-svc-g6tq4
  Apr 15 07:24:55.724: INFO: Created: latency-svc-ch7s7
  Apr 15 07:24:55.724: INFO: Created: latency-svc-jt29f
  Apr 15 07:24:55.725: INFO: Created: latency-svc-wpttq
  Apr 15 07:24:55.725: INFO: Created: latency-svc-hdkz9
  Apr 15 07:24:55.740: INFO: Got endpoints: latency-svc-2htd4 [566.676197ms]
  Apr 15 07:24:55.745: INFO: Created: latency-svc-brv2p
  Apr 15 07:24:55.758: INFO: Created: latency-svc-nhssn
  Apr 15 07:24:55.759: INFO: Created: latency-svc-vtcrb
  Apr 15 07:24:55.760: INFO: Created: latency-svc-j5jw2
  Apr 15 07:24:55.762: INFO: Created: latency-svc-v744x
  Apr 15 07:24:55.773: INFO: Got endpoints: latency-svc-9qtz9 [559.741395ms]
  Apr 15 07:24:55.774: INFO: Got endpoints: latency-svc-jnqv5 [358.561709ms]
  Apr 15 07:24:55.833: INFO: Got endpoints: latency-svc-brv2p [524.2497ms]
  Apr 15 07:24:55.834: INFO: Got endpoints: latency-svc-vltb4 [559.01137ms]
  Apr 15 07:24:55.834: INFO: Got endpoints: latency-svc-hdkz9 [334.519445ms]
  Apr 15 07:24:55.847: INFO: Created: latency-svc-97w8d
  Apr 15 07:24:55.869: INFO: Got endpoints: latency-svc-v744x [557.99751ms]
  Apr 15 07:24:55.869: INFO: Got endpoints: latency-svc-wpttq [482.281429ms]
  Apr 15 07:24:55.888: INFO: Created: latency-svc-gcvwd
  Apr 15 07:24:55.913: INFO: Got endpoints: latency-svc-ch7s7 [752.719972ms]
  Apr 15 07:24:55.914: INFO: Got endpoints: latency-svc-vtcrb [408.6639ms]
  Apr 15 07:24:55.914: INFO: Got endpoints: latency-svc-j5jw2 [478.413506ms]
  E0415 07:24:55.918425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:24:55.923: INFO: Got endpoints: latency-svc-nhssn [703.398111ms]
  Apr 15 07:24:55.947: INFO: Created: latency-svc-kfbk5
  Apr 15 07:24:55.958: INFO: Got endpoints: latency-svc-g6tq4 [405.408706ms]
  Apr 15 07:24:55.968: INFO: Got endpoints: latency-svc-jt29f [452.234314ms]
  Apr 15 07:24:55.969: INFO: Got endpoints: latency-svc-7nr56 [736.085441ms]
  Apr 15 07:24:55.987: INFO: Got endpoints: latency-svc-gcvwd [213.696782ms]
  Apr 15 07:24:55.987: INFO: Got endpoints: latency-svc-97w8d [246.363192ms]
  Apr 15 07:24:56.008: INFO: Got endpoints: latency-svc-kfbk5 [233.940688ms]
  Apr 15 07:24:56.194: INFO: Created: latency-svc-9bjf2
  Apr 15 07:24:56.219: INFO: Created: latency-svc-h89f5
  Apr 15 07:24:56.219: INFO: Created: latency-svc-9655r
  Apr 15 07:24:56.221: INFO: Created: latency-svc-dr5z8
  Apr 15 07:24:56.221: INFO: Created: latency-svc-87lzv
  Apr 15 07:24:56.221: INFO: Created: latency-svc-sj92d
  Apr 15 07:24:56.228: INFO: Created: latency-svc-8v55z
  Apr 15 07:24:56.248: INFO: Got endpoints: latency-svc-sj92d [333.45551ms]
  Apr 15 07:24:56.249: INFO: Got endpoints: latency-svc-h89f5 [280.300959ms]
  Apr 15 07:24:56.249: INFO: Got endpoints: latency-svc-9bjf2 [377.747097ms]
  Apr 15 07:24:56.269: INFO: Created: latency-svc-pd44d
  Apr 15 07:24:56.270: INFO: Created: latency-svc-n9wpc
  Apr 15 07:24:56.272: INFO: Created: latency-svc-j2f5b
  Apr 15 07:24:56.273: INFO: Created: latency-svc-tskbb
  Apr 15 07:24:56.274: INFO: Created: latency-svc-fnlg8
  Apr 15 07:24:56.275: INFO: Created: latency-svc-9wlgs
  Apr 15 07:24:56.276: INFO: Created: latency-svc-f478t
  Apr 15 07:24:56.277: INFO: Created: latency-svc-dxdsv
  Apr 15 07:24:56.294: INFO: Got endpoints: latency-svc-87lzv [335.337196ms]
  Apr 15 07:24:56.295: INFO: Got endpoints: latency-svc-9wlgs [450.418045ms]
  Apr 15 07:24:56.317: INFO: Got endpoints: latency-svc-n9wpc [329.600793ms]
  Apr 15 07:24:56.325: INFO: Created: latency-svc-4k9h9
  Apr 15 07:24:56.328: INFO: Got endpoints: latency-svc-8v55z [488.22475ms]
  Apr 15 07:24:56.338: INFO: Got endpoints: latency-svc-dr5z8 [423.96315ms]
  Apr 15 07:24:56.339: INFO: Got endpoints: latency-svc-pd44d [352.051421ms]
  Apr 15 07:24:56.399: INFO: Got endpoints: latency-svc-9655r [429.941659ms]
  Apr 15 07:24:56.400: INFO: Got endpoints: latency-svc-tskbb [391.463384ms]
  Apr 15 07:24:56.434: INFO: Created: latency-svc-4v5tn
  Apr 15 07:24:56.455: INFO: Got endpoints: latency-svc-fnlg8 [620.003859ms]
  Apr 15 07:24:56.456: INFO: Got endpoints: latency-svc-f478t [524.951965ms]
  Apr 15 07:24:56.456: INFO: Got endpoints: latency-svc-dxdsv [540.988288ms]
  Apr 15 07:24:56.471: INFO: Created: latency-svc-89j8b
  Apr 15 07:24:56.472: INFO: Got endpoints: latency-svc-j2f5b [599.074495ms]
  Apr 15 07:24:56.473: INFO: Got endpoints: latency-svc-4k9h9 [224.559168ms]
  Apr 15 07:24:56.522: INFO: Created: latency-svc-6wzkh
  Apr 15 07:24:56.534: INFO: Got endpoints: latency-svc-89j8b [285.049032ms]
  Apr 15 07:24:56.535: INFO: Got endpoints: latency-svc-4v5tn [285.213806ms]
  Apr 15 07:24:56.572: INFO: Got endpoints: latency-svc-6wzkh [277.605432ms]
  Apr 15 07:24:56.577: INFO: Created: latency-svc-sbgxs
  Apr 15 07:24:56.590: INFO: Got endpoints: latency-svc-sbgxs [295.852596ms]
  Apr 15 07:24:56.783: INFO: Created: latency-svc-h648z
  Apr 15 07:24:56.783: INFO: Created: latency-svc-mr5w4
  Apr 15 07:24:56.784: INFO: Created: latency-svc-j7z4n
  Apr 15 07:24:56.786: INFO: Created: latency-svc-w274b
  Apr 15 07:24:56.788: INFO: Created: latency-svc-kk8n2
  Apr 15 07:24:56.794: INFO: Created: latency-svc-rprkq
  Apr 15 07:24:56.794: INFO: Created: latency-svc-jl474
  Apr 15 07:24:56.795: INFO: Created: latency-svc-djzt5
  Apr 15 07:24:56.795: INFO: Created: latency-svc-xn2vk
  Apr 15 07:24:56.802: INFO: Created: latency-svc-tppj7
  Apr 15 07:24:56.803: INFO: Created: latency-svc-n7sbb
  Apr 15 07:24:56.803: INFO: Created: latency-svc-f8hkd
  Apr 15 07:24:56.804: INFO: Created: latency-svc-xjznw
  Apr 15 07:24:56.804: INFO: Created: latency-svc-mfqqv
  Apr 15 07:24:56.805: INFO: Got endpoints: latency-svc-h648z [214.561871ms]
  Apr 15 07:24:56.826: INFO: Created: latency-svc-ddrt8
  Apr 15 07:24:56.844: INFO: Got endpoints: latency-svc-mr5w4 [388.371911ms]
  Apr 15 07:24:56.855: INFO: Got endpoints: latency-svc-j7z4n [516.164919ms]
  Apr 15 07:24:56.860: INFO: Created: latency-svc-7pr29
  Apr 15 07:24:56.911: INFO: Got endpoints: latency-svc-w274b [510.78974ms]
  Apr 15 07:24:56.911: INFO: Got endpoints: latency-svc-jl474 [593.282637ms]
  E0415 07:24:56.920515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:24:56.926: INFO: Created: latency-svc-k2x6g
  Apr 15 07:24:56.927: INFO: Created: latency-svc-4jd9r
  Apr 15 07:24:56.948: INFO: Got endpoints: latency-svc-djzt5 [474.857899ms]
  Apr 15 07:24:56.949: INFO: Got endpoints: latency-svc-xn2vk [608.763188ms]
  Apr 15 07:24:56.949: INFO: Got endpoints: latency-svc-rprkq [376.010692ms]
  Apr 15 07:24:56.972: INFO: Created: latency-svc-6ltxp
  Apr 15 07:24:56.974: INFO: Got endpoints: latency-svc-xjznw [516.859377ms]
  Apr 15 07:24:56.975: INFO: Got endpoints: latency-svc-mfqqv [645.891304ms]
  Apr 15 07:24:57.000: INFO: Created: latency-svc-5bzhb
  Apr 15 07:24:57.002: INFO: Got endpoints: latency-svc-tppj7 [603.034895ms]
  Apr 15 07:24:57.018: INFO: Created: latency-svc-q6crx
  Apr 15 07:24:57.068: INFO: Got endpoints: latency-svc-f8hkd [611.845607ms]
  Apr 15 07:24:57.095: INFO: Got endpoints: latency-svc-kk8n2 [622.032463ms]
  Apr 15 07:24:57.142: INFO: Got endpoints: latency-svc-n7sbb [607.867564ms]
  Apr 15 07:24:57.174: INFO: Created: latency-svc-pzf7l
  Apr 15 07:24:57.175: INFO: Created: latency-svc-slspk
  Apr 15 07:24:57.185: INFO: Created: latency-svc-7wxxw
  Apr 15 07:24:57.195: INFO: Created: latency-svc-jkm89
  Apr 15 07:24:57.197: INFO: Created: latency-svc-d5lfp
  Apr 15 07:24:57.205: INFO: Created: latency-svc-zbp7z
  Apr 15 07:24:57.205: INFO: Created: latency-svc-dxkh9
  Apr 15 07:24:57.207: INFO: Got endpoints: latency-svc-ddrt8 [671.448941ms]
  Apr 15 07:24:57.208: INFO: Created: latency-svc-tp2pf
  Apr 15 07:24:57.229: INFO: Created: latency-svc-tn6pm
  Apr 15 07:24:57.250: INFO: Got endpoints: latency-svc-7pr29 [444.136719ms]
  Apr 15 07:24:57.273: INFO: Created: latency-svc-c8t2h
  Apr 15 07:24:57.292: INFO: Got endpoints: latency-svc-4jd9r [447.155813ms]
  Apr 15 07:24:57.314: INFO: Created: latency-svc-gdghn
  Apr 15 07:24:57.345: INFO: Got endpoints: latency-svc-k2x6g [489.32731ms]
  Apr 15 07:24:57.368: INFO: Created: latency-svc-5q8r7
  Apr 15 07:24:57.399: INFO: Got endpoints: latency-svc-6ltxp [487.690866ms]
  Apr 15 07:24:57.418: INFO: Created: latency-svc-gkb7n
  Apr 15 07:24:57.442: INFO: Got endpoints: latency-svc-5bzhb [530.137575ms]
  Apr 15 07:24:57.470: INFO: Created: latency-svc-7tzzc
  Apr 15 07:24:57.497: INFO: Got endpoints: latency-svc-q6crx [548.746128ms]
  Apr 15 07:24:57.520: INFO: Created: latency-svc-cxl97
  Apr 15 07:24:57.546: INFO: Got endpoints: latency-svc-pzf7l [543.942173ms]
  Apr 15 07:24:57.574: INFO: Created: latency-svc-mmhkj
  Apr 15 07:24:57.594: INFO: Got endpoints: latency-svc-slspk [645.13173ms]
  Apr 15 07:24:57.620: INFO: Created: latency-svc-h8t75
  Apr 15 07:24:57.644: INFO: Got endpoints: latency-svc-7wxxw [695.166884ms]
  Apr 15 07:24:57.707: INFO: Got endpoints: latency-svc-d5lfp [612.164505ms]
  Apr 15 07:24:57.724: INFO: Created: latency-svc-s5txb
  Apr 15 07:24:57.748: INFO: Got endpoints: latency-svc-jkm89 [773.585203ms]
  Apr 15 07:24:57.761: INFO: Created: latency-svc-75lbr
  Apr 15 07:24:57.795: INFO: Created: latency-svc-pps67
  Apr 15 07:24:57.802: INFO: Got endpoints: latency-svc-zbp7z [827.372339ms]
  Apr 15 07:24:57.845: INFO: Created: latency-svc-g292c
  Apr 15 07:24:57.852: INFO: Got endpoints: latency-svc-dxkh9 [710.061349ms]
  Apr 15 07:24:57.877: INFO: Created: latency-svc-vscwr
  Apr 15 07:24:57.898: INFO: Got endpoints: latency-svc-tp2pf [829.699923ms]
  E0415 07:24:57.922717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:24:57.932: INFO: Created: latency-svc-7lz4m
  Apr 15 07:24:57.948: INFO: Got endpoints: latency-svc-tn6pm [741.423436ms]
  Apr 15 07:24:57.973: INFO: Created: latency-svc-4hv4w
  Apr 15 07:24:57.990: INFO: Got endpoints: latency-svc-c8t2h [740.373304ms]
  Apr 15 07:24:58.010: INFO: Created: latency-svc-bkctl
  Apr 15 07:24:58.043: INFO: Got endpoints: latency-svc-gdghn [751.26018ms]
  Apr 15 07:24:58.077: INFO: Created: latency-svc-rm4vn
  Apr 15 07:24:58.092: INFO: Got endpoints: latency-svc-5q8r7 [747.273245ms]
  Apr 15 07:24:58.111: INFO: Created: latency-svc-r6nfp
  Apr 15 07:24:58.144: INFO: Got endpoints: latency-svc-gkb7n [745.55786ms]
  Apr 15 07:24:58.169: INFO: Created: latency-svc-gxv4j
  Apr 15 07:24:58.198: INFO: Got endpoints: latency-svc-7tzzc [756.558378ms]
  Apr 15 07:24:58.254: INFO: Got endpoints: latency-svc-cxl97 [756.581239ms]
  Apr 15 07:24:58.261: INFO: Created: latency-svc-rv5ml
  Apr 15 07:24:58.289: INFO: Created: latency-svc-g4swd
  Apr 15 07:24:58.299: INFO: Got endpoints: latency-svc-mmhkj [751.804226ms]
  Apr 15 07:24:58.323: INFO: Created: latency-svc-27k87
  Apr 15 07:24:58.342: INFO: Got endpoints: latency-svc-h8t75 [747.984461ms]
  Apr 15 07:24:58.365: INFO: Created: latency-svc-92v9c
  Apr 15 07:24:58.395: INFO: Got endpoints: latency-svc-s5txb [750.107717ms]
  Apr 15 07:24:58.413: INFO: Created: latency-svc-sbtwv
  Apr 15 07:24:58.448: INFO: Got endpoints: latency-svc-75lbr [740.792339ms]
  Apr 15 07:24:58.480: INFO: Created: latency-svc-6kd5n
  Apr 15 07:24:58.495: INFO: Got endpoints: latency-svc-pps67 [746.427721ms]
  Apr 15 07:24:58.522: INFO: Created: latency-svc-lhh29
  Apr 15 07:24:58.544: INFO: Got endpoints: latency-svc-g292c [739.312536ms]
  Apr 15 07:24:58.567: INFO: Created: latency-svc-4fwgt
  Apr 15 07:24:58.596: INFO: Got endpoints: latency-svc-vscwr [743.698285ms]
  Apr 15 07:24:58.621: INFO: Created: latency-svc-7cjtc
  Apr 15 07:24:58.642: INFO: Got endpoints: latency-svc-7lz4m [743.668907ms]
  Apr 15 07:24:58.668: INFO: Created: latency-svc-56qpk
  Apr 15 07:24:58.698: INFO: Got endpoints: latency-svc-4hv4w [749.209857ms]
  Apr 15 07:24:58.722: INFO: Created: latency-svc-px9l8
  Apr 15 07:24:58.748: INFO: Got endpoints: latency-svc-bkctl [757.914607ms]
  Apr 15 07:24:58.775: INFO: Created: latency-svc-tp59h
  Apr 15 07:24:58.795: INFO: Got endpoints: latency-svc-rm4vn [752.355317ms]
  Apr 15 07:24:58.815: INFO: Created: latency-svc-cgtkf
  Apr 15 07:24:58.843: INFO: Got endpoints: latency-svc-r6nfp [750.152737ms]
  Apr 15 07:24:58.866: INFO: Created: latency-svc-k8ll5
  Apr 15 07:24:58.893: INFO: Got endpoints: latency-svc-gxv4j [748.481004ms]
  Apr 15 07:24:58.916: INFO: Created: latency-svc-46rrb
  E0415 07:24:58.922761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:24:58.942: INFO: Got endpoints: latency-svc-rv5ml [742.962719ms]
  Apr 15 07:24:58.968: INFO: Created: latency-svc-n9dff
  Apr 15 07:24:59.001: INFO: Got endpoints: latency-svc-g4swd [747.139455ms]
  Apr 15 07:24:59.029: INFO: Created: latency-svc-zcgsc
  Apr 15 07:24:59.049: INFO: Got endpoints: latency-svc-27k87 [750.436718ms]
  Apr 15 07:24:59.081: INFO: Created: latency-svc-jwcjp
  Apr 15 07:24:59.094: INFO: Got endpoints: latency-svc-92v9c [752.330611ms]
  Apr 15 07:24:59.119: INFO: Created: latency-svc-7z4h6
  Apr 15 07:24:59.145: INFO: Got endpoints: latency-svc-sbtwv [749.96223ms]
  Apr 15 07:24:59.173: INFO: Created: latency-svc-wtf8p
  Apr 15 07:24:59.192: INFO: Got endpoints: latency-svc-6kd5n [743.981733ms]
  Apr 15 07:24:59.217: INFO: Created: latency-svc-j7wr7
  Apr 15 07:24:59.241: INFO: Got endpoints: latency-svc-lhh29 [746.237058ms]
  Apr 15 07:24:59.273: INFO: Created: latency-svc-5vrrh
  Apr 15 07:24:59.293: INFO: Got endpoints: latency-svc-4fwgt [748.60129ms]
  Apr 15 07:24:59.326: INFO: Created: latency-svc-xzlj6
  Apr 15 07:24:59.345: INFO: Got endpoints: latency-svc-7cjtc [748.865736ms]
  Apr 15 07:24:59.376: INFO: Created: latency-svc-rnphf
  Apr 15 07:24:59.401: INFO: Got endpoints: latency-svc-56qpk [757.936519ms]
  Apr 15 07:24:59.427: INFO: Created: latency-svc-fwf4p
  Apr 15 07:24:59.444: INFO: Got endpoints: latency-svc-px9l8 [746.547638ms]
  Apr 15 07:24:59.471: INFO: Created: latency-svc-xmzr9
  Apr 15 07:24:59.497: INFO: Got endpoints: latency-svc-tp59h [746.897567ms]
  Apr 15 07:24:59.523: INFO: Created: latency-svc-qnrpc
  Apr 15 07:24:59.543: INFO: Got endpoints: latency-svc-cgtkf [747.483186ms]
  Apr 15 07:24:59.570: INFO: Created: latency-svc-7kbft
  Apr 15 07:24:59.592: INFO: Got endpoints: latency-svc-k8ll5 [748.39222ms]
  Apr 15 07:24:59.618: INFO: Created: latency-svc-9qn42
  Apr 15 07:24:59.643: INFO: Got endpoints: latency-svc-46rrb [748.900045ms]
  Apr 15 07:24:59.702: INFO: Got endpoints: latency-svc-n9dff [760.487734ms]
  Apr 15 07:24:59.718: INFO: Created: latency-svc-2r8vm
  Apr 15 07:24:59.725: INFO: Created: latency-svc-8mskf
  Apr 15 07:24:59.747: INFO: Got endpoints: latency-svc-zcgsc [745.915943ms]
  Apr 15 07:24:59.770: INFO: Created: latency-svc-w4fpf
  Apr 15 07:24:59.794: INFO: Got endpoints: latency-svc-jwcjp [745.041085ms]
  Apr 15 07:24:59.819: INFO: Created: latency-svc-srt7v
  Apr 15 07:24:59.847: INFO: Got endpoints: latency-svc-7z4h6 [752.577869ms]
  Apr 15 07:24:59.868: INFO: Created: latency-svc-xxlmg
  Apr 15 07:24:59.900: INFO: Got endpoints: latency-svc-wtf8p [755.058485ms]
  Apr 15 07:24:59.920: INFO: Created: latency-svc-4jjgk
  E0415 07:24:59.922680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:24:59.952: INFO: Got endpoints: latency-svc-j7wr7 [758.527003ms]
  Apr 15 07:24:59.974: INFO: Created: latency-svc-kjrhp
  Apr 15 07:24:59.993: INFO: Got endpoints: latency-svc-5vrrh [751.882923ms]
  Apr 15 07:25:00.018: INFO: Created: latency-svc-h8sg8
  Apr 15 07:25:00.048: INFO: Got endpoints: latency-svc-xzlj6 [754.102806ms]
  Apr 15 07:25:00.075: INFO: Created: latency-svc-xsh52
  Apr 15 07:25:00.093: INFO: Got endpoints: latency-svc-rnphf [746.856429ms]
  Apr 15 07:25:00.123: INFO: Created: latency-svc-2zdss
  Apr 15 07:25:00.146: INFO: Got endpoints: latency-svc-fwf4p [744.155044ms]
  Apr 15 07:25:00.179: INFO: Created: latency-svc-krhql
  Apr 15 07:25:00.212: INFO: Got endpoints: latency-svc-xmzr9 [767.036879ms]
  Apr 15 07:25:00.249: INFO: Created: latency-svc-ntbtv
  Apr 15 07:25:00.257: INFO: Got endpoints: latency-svc-qnrpc [759.501864ms]
  Apr 15 07:25:00.279: INFO: Created: latency-svc-qf4nt
  Apr 15 07:25:00.297: INFO: Got endpoints: latency-svc-7kbft [753.105069ms]
  Apr 15 07:25:00.351: INFO: Created: latency-svc-dr6r2
  Apr 15 07:25:00.360: INFO: Got endpoints: latency-svc-9qn42 [768.513101ms]
  Apr 15 07:25:00.385: INFO: Created: latency-svc-wpkld
  Apr 15 07:25:00.419: INFO: Got endpoints: latency-svc-2r8vm [775.979486ms]
  Apr 15 07:25:00.449: INFO: Created: latency-svc-2bh9p
  Apr 15 07:25:00.460: INFO: Got endpoints: latency-svc-8mskf [757.70488ms]
  Apr 15 07:25:00.482: INFO: Created: latency-svc-d8rzb
  Apr 15 07:25:00.496: INFO: Got endpoints: latency-svc-w4fpf [748.49867ms]
  Apr 15 07:25:00.521: INFO: Created: latency-svc-f9jq5
  Apr 15 07:25:00.550: INFO: Got endpoints: latency-svc-srt7v [755.705554ms]
  Apr 15 07:25:00.571: INFO: Created: latency-svc-fzxxz
  Apr 15 07:25:00.599: INFO: Got endpoints: latency-svc-xxlmg [750.681331ms]
  Apr 15 07:25:00.664: INFO: Created: latency-svc-sxrt5
  Apr 15 07:25:00.676: INFO: Got endpoints: latency-svc-4jjgk [776.587893ms]
  Apr 15 07:25:00.694: INFO: Got endpoints: latency-svc-kjrhp [742.43187ms]
  Apr 15 07:25:00.711: INFO: Created: latency-svc-jtrsp
  Apr 15 07:25:00.729: INFO: Created: latency-svc-mlxk5
  Apr 15 07:25:00.747: INFO: Got endpoints: latency-svc-h8sg8 [753.948121ms]
  Apr 15 07:25:00.777: INFO: Created: latency-svc-p8qt4
  Apr 15 07:25:00.800: INFO: Got endpoints: latency-svc-xsh52 [751.492266ms]
  Apr 15 07:25:00.826: INFO: Created: latency-svc-pv9p5
  Apr 15 07:25:00.846: INFO: Got endpoints: latency-svc-2zdss [753.245108ms]
  Apr 15 07:25:00.873: INFO: Created: latency-svc-7jn6k
  Apr 15 07:25:00.894: INFO: Got endpoints: latency-svc-krhql [747.844353ms]
  Apr 15 07:25:00.917: INFO: Created: latency-svc-btmkr
  E0415 07:25:00.923929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:25:00.946: INFO: Got endpoints: latency-svc-ntbtv [733.777541ms]
  Apr 15 07:25:00.975: INFO: Created: latency-svc-p2r6h
  Apr 15 07:25:01.004: INFO: Got endpoints: latency-svc-qf4nt [746.677711ms]
  Apr 15 07:25:01.024: INFO: Created: latency-svc-kbj76
  Apr 15 07:25:01.058: INFO: Got endpoints: latency-svc-dr6r2 [759.497899ms]
  Apr 15 07:25:01.092: INFO: Got endpoints: latency-svc-wpkld [731.251636ms]
  Apr 15 07:25:01.103: INFO: Created: latency-svc-ggj7v
  Apr 15 07:25:01.118: INFO: Created: latency-svc-p2jx2
  Apr 15 07:25:01.156: INFO: Got endpoints: latency-svc-2bh9p [736.932748ms]
  Apr 15 07:25:01.175: INFO: Created: latency-svc-rvmvr
  Apr 15 07:25:01.194: INFO: Got endpoints: latency-svc-d8rzb [733.229295ms]
  Apr 15 07:25:01.217: INFO: Created: latency-svc-52b75
  Apr 15 07:25:01.242: INFO: Got endpoints: latency-svc-f9jq5 [745.564252ms]
  Apr 15 07:25:01.263: INFO: Created: latency-svc-z8dsp
  Apr 15 07:25:01.296: INFO: Got endpoints: latency-svc-fzxxz [745.795951ms]
  Apr 15 07:25:01.316: INFO: Created: latency-svc-b9qsz
  Apr 15 07:25:01.344: INFO: Got endpoints: latency-svc-sxrt5 [744.877893ms]
  Apr 15 07:25:01.366: INFO: Created: latency-svc-t4t89
  Apr 15 07:25:01.402: INFO: Got endpoints: latency-svc-jtrsp [724.735193ms]
  Apr 15 07:25:01.428: INFO: Created: latency-svc-9ccm6
  Apr 15 07:25:01.447: INFO: Got endpoints: latency-svc-mlxk5 [752.095465ms]
  Apr 15 07:25:01.473: INFO: Created: latency-svc-ltnpr
  Apr 15 07:25:01.495: INFO: Got endpoints: latency-svc-p8qt4 [746.739168ms]
  Apr 15 07:25:01.518: INFO: Created: latency-svc-cj6h4
  Apr 15 07:25:01.546: INFO: Got endpoints: latency-svc-pv9p5 [745.920737ms]
  Apr 15 07:25:01.569: INFO: Created: latency-svc-lz99w
  Apr 15 07:25:01.593: INFO: Got endpoints: latency-svc-7jn6k [746.534624ms]
  Apr 15 07:25:01.614: INFO: Created: latency-svc-gkrvg
  Apr 15 07:25:01.644: INFO: Got endpoints: latency-svc-btmkr [750.085182ms]
  Apr 15 07:25:01.670: INFO: Created: latency-svc-lzfjw
  Apr 15 07:25:01.698: INFO: Got endpoints: latency-svc-p2r6h [750.880011ms]
  Apr 15 07:25:01.724: INFO: Created: latency-svc-8lvn9
  Apr 15 07:25:01.750: INFO: Got endpoints: latency-svc-kbj76 [745.748106ms]
  Apr 15 07:25:01.776: INFO: Created: latency-svc-nd7kw
  Apr 15 07:25:01.799: INFO: Got endpoints: latency-svc-ggj7v [738.891584ms]
  Apr 15 07:25:01.820: INFO: Created: latency-svc-fbsgm
  Apr 15 07:25:01.847: INFO: Got endpoints: latency-svc-p2jx2 [754.903446ms]
  Apr 15 07:25:01.872: INFO: Created: latency-svc-nxn2f
  Apr 15 07:25:01.894: INFO: Got endpoints: latency-svc-rvmvr [737.421483ms]
  Apr 15 07:25:01.920: INFO: Created: latency-svc-5b7g8
  E0415 07:25:01.924561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:25:01.946: INFO: Got endpoints: latency-svc-52b75 [751.400978ms]
  Apr 15 07:25:01.969: INFO: Created: latency-svc-2k2n2
  Apr 15 07:25:01.993: INFO: Got endpoints: latency-svc-z8dsp [751.379669ms]
  Apr 15 07:25:02.015: INFO: Created: latency-svc-cnm6l
  Apr 15 07:25:02.048: INFO: Got endpoints: latency-svc-b9qsz [751.514681ms]
  Apr 15 07:25:02.068: INFO: Created: latency-svc-xs8cv
  Apr 15 07:25:02.100: INFO: Got endpoints: latency-svc-t4t89 [755.004503ms]
  Apr 15 07:25:02.130: INFO: Created: latency-svc-hqbw6
  Apr 15 07:25:02.147: INFO: Got endpoints: latency-svc-9ccm6 [745.714756ms]
  Apr 15 07:25:02.176: INFO: Created: latency-svc-vz52p
  Apr 15 07:25:02.194: INFO: Got endpoints: latency-svc-ltnpr [746.132127ms]
  Apr 15 07:25:02.219: INFO: Created: latency-svc-mt2l9
  Apr 15 07:25:02.244: INFO: Got endpoints: latency-svc-cj6h4 [748.97875ms]
  Apr 15 07:25:02.266: INFO: Created: latency-svc-sfdbg
  Apr 15 07:25:02.296: INFO: Got endpoints: latency-svc-lz99w [749.821954ms]
  Apr 15 07:25:02.320: INFO: Created: latency-svc-qsswl
  Apr 15 07:25:02.346: INFO: Got endpoints: latency-svc-gkrvg [752.138241ms]
  Apr 15 07:25:02.368: INFO: Created: latency-svc-sfttt
  Apr 15 07:25:02.394: INFO: Got endpoints: latency-svc-lzfjw [748.941386ms]
  Apr 15 07:25:02.413: INFO: Created: latency-svc-tc7p7
  Apr 15 07:25:02.449: INFO: Got endpoints: latency-svc-8lvn9 [750.655484ms]
  Apr 15 07:25:02.470: INFO: Created: latency-svc-rwlgx
  Apr 15 07:25:02.498: INFO: Got endpoints: latency-svc-nd7kw [747.819285ms]
  Apr 15 07:25:02.517: INFO: Created: latency-svc-wfzlj
  Apr 15 07:25:02.549: INFO: Got endpoints: latency-svc-fbsgm [750.280488ms]
  Apr 15 07:25:02.599: INFO: Got endpoints: latency-svc-nxn2f [751.825871ms]
  Apr 15 07:25:02.652: INFO: Got endpoints: latency-svc-5b7g8 [757.34852ms]
  Apr 15 07:25:02.696: INFO: Got endpoints: latency-svc-2k2n2 [750.193508ms]
  Apr 15 07:25:02.745: INFO: Got endpoints: latency-svc-cnm6l [751.39696ms]
  Apr 15 07:25:02.808: INFO: Got endpoints: latency-svc-xs8cv [759.444533ms]
  Apr 15 07:25:02.843: INFO: Got endpoints: latency-svc-hqbw6 [743.323315ms]
  Apr 15 07:25:02.896: INFO: Got endpoints: latency-svc-vz52p [748.920438ms]
  E0415 07:25:02.924894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:25:02.956: INFO: Got endpoints: latency-svc-mt2l9 [761.50589ms]
  Apr 15 07:25:03.005: INFO: Got endpoints: latency-svc-sfdbg [760.830459ms]
  Apr 15 07:25:03.053: INFO: Got endpoints: latency-svc-qsswl [755.751471ms]
  Apr 15 07:25:03.097: INFO: Got endpoints: latency-svc-sfttt [751.68707ms]
  Apr 15 07:25:03.145: INFO: Got endpoints: latency-svc-tc7p7 [751.471667ms]
  Apr 15 07:25:03.194: INFO: Got endpoints: latency-svc-rwlgx [745.0463ms]
  Apr 15 07:25:03.248: INFO: Got endpoints: latency-svc-wfzlj [749.670313ms]
  Apr 15 07:25:03.248: INFO: Latencies: [62.872961ms 111.325462ms 116.711281ms 195.872567ms 213.696782ms 214.561871ms 215.907379ms 224.559168ms 233.940688ms 246.363192ms 254.132414ms 277.605432ms 280.300959ms 282.98916ms 285.049032ms 285.213806ms 295.852596ms 307.319494ms 329.600793ms 333.45551ms 334.519445ms 335.337196ms 352.051421ms 358.561709ms 368.117343ms 376.010692ms 377.747097ms 388.371911ms 391.463384ms 405.408706ms 406.980805ms 408.6639ms 413.223419ms 423.96315ms 424.892984ms 427.97899ms 428.194258ms 429.941659ms 442.212305ms 444.136719ms 447.155813ms 450.418045ms 452.234314ms 458.703387ms 467.202974ms 468.243014ms 469.1938ms 474.857899ms 475.813501ms 478.413506ms 480.914886ms 481.196364ms 482.281429ms 487.690866ms 488.22475ms 489.32731ms 498.407563ms 508.228733ms 510.78974ms 516.164919ms 516.465934ms 516.859377ms 522.427132ms 524.2497ms 524.951965ms 530.137575ms 540.988288ms 543.942173ms 548.746128ms 557.99751ms 559.01137ms 559.741395ms 566.676197ms 593.282637ms 599.074495ms 603.034895ms 607.867564ms 608.763188ms 611.845607ms 612.164505ms 620.003859ms 622.032463ms 645.13173ms 645.891304ms 671.448941ms 695.166884ms 703.398111ms 710.061349ms 724.735193ms 731.251636ms 733.229295ms 733.777541ms 736.085441ms 736.932748ms 737.421483ms 738.891584ms 739.312536ms 740.373304ms 740.792339ms 741.423436ms 742.43187ms 742.962719ms 743.323315ms 743.668907ms 743.698285ms 743.981733ms 744.155044ms 744.877893ms 745.041085ms 745.0463ms 745.55786ms 745.564252ms 745.714756ms 745.748106ms 745.795951ms 745.915943ms 745.920737ms 746.132127ms 746.237058ms 746.427721ms 746.534624ms 746.547638ms 746.677711ms 746.739168ms 746.856429ms 746.897567ms 747.139455ms 747.273245ms 747.483186ms 747.819285ms 747.844353ms 747.984461ms 748.39222ms 748.481004ms 748.49867ms 748.60129ms 748.865736ms 748.900045ms 748.920438ms 748.941386ms 748.97875ms 749.209857ms 749.670313ms 749.821954ms 749.96223ms 750.085182ms 750.107717ms 750.152737ms 750.193508ms 750.280488ms 750.436718ms 750.655484ms 750.681331ms 750.880011ms 751.26018ms 751.379669ms 751.39696ms 751.400978ms 751.471667ms 751.492266ms 751.514681ms 751.68707ms 751.804226ms 751.825871ms 751.882923ms 752.095465ms 752.138241ms 752.330611ms 752.355317ms 752.577869ms 752.719972ms 753.105069ms 753.245108ms 753.948121ms 754.102806ms 754.903446ms 755.004503ms 755.058485ms 755.705554ms 755.751471ms 756.558378ms 756.581239ms 757.34852ms 757.70488ms 757.914607ms 757.936519ms 758.527003ms 759.444533ms 759.497899ms 759.501864ms 760.487734ms 760.830459ms 761.50589ms 767.036879ms 768.513101ms 773.585203ms 775.979486ms 776.587893ms 827.372339ms 829.699923ms]
  Apr 15 07:25:03.250: INFO: 50 %ile: 742.43187ms
  Apr 15 07:25:03.250: INFO: 90 %ile: 756.558378ms
  Apr 15 07:25:03.250: INFO: 99 %ile: 827.372339ms
  Apr 15 07:25:03.251: INFO: Total sample count: 200
  Apr 15 07:25:03.251: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-7752" for this suite. @ 04/15/24 07:25:03.266
â€¢ [10.914 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 04/15/24 07:25:03.282
  Apr 15 07:25:03.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename var-expansion @ 04/15/24 07:25:03.285
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:25:03.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:25:03.358
  STEP: creating the pod with failed condition @ 04/15/24 07:25:03.375
  E0415 07:25:03.926307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:04.927185      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:05.927997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:06.928991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:07.929690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:08.930194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:09.930894      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:10.932573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:11.933673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:12.933998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:13.935234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:14.936687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:15.937481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:16.937650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:17.937837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:18.938963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:19.939678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:20.940017      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:21.940291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:22.940560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:23.941275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:24.941566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:25.942339      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:26.942571      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:27.942906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:28.943847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:29.944547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:30.944901      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:31.945274      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:32.946314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:33.949572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:34.949654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:35.950406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:36.950560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:37.951383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:38.951623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:39.951788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:40.954603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:41.954246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:42.955063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:43.955883      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:44.956740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:45.957398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:46.957668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:47.958612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:48.959775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:49.959470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:50.961121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:51.960664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:52.960467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:53.961231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:54.961306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:55.962472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:56.962461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:57.963407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:58.963484      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:25:59.963861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:00.964996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:01.964992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:02.965869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:03.966123      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:04.966786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:05.968214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:06.968704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:07.968895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:08.969364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:09.970041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:10.970731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:11.971067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:12.971218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:13.972233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:14.973113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:15.973922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:16.973978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:17.974761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:18.975194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:19.975633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:20.975426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:21.975565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:22.975915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:23.976709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:24.977628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:25.978223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:26.978926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:27.979616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:28.980038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:29.980509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:30.980599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:31.981116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:32.981504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:33.981823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:34.982914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:35.982929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:36.982920      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:37.983270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:38.983779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:39.984082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:40.984679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:41.984657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:42.985583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:43.986239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:44.986430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:45.987157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:46.987291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:47.987456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:48.987585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:49.988319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:50.988754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:51.989749      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:52.990004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:53.990152      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:54.991503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:55.992670      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:56.993009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:57.992997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:58.993217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:26:59.994035      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:00.994116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:01.994391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:02.994519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 04/15/24 07:27:03.407
  Apr 15 07:27:03.939: INFO: Successfully updated pod "var-expansion-b74e36b7-1102-44c2-9c92-59ec3505bd81"
  STEP: waiting for pod running @ 04/15/24 07:27:03.939
  E0415 07:27:03.995307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:04.995683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/15/24 07:27:05.966
  Apr 15 07:27:05.967: INFO: Deleting pod "var-expansion-b74e36b7-1102-44c2-9c92-59ec3505bd81" in namespace "var-expansion-1781"
  Apr 15 07:27:05.985: INFO: Wait up to 5m0s for pod "var-expansion-b74e36b7-1102-44c2-9c92-59ec3505bd81" to be fully deleted
  E0415 07:27:05.997841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:06.997761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:07.998476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:08.998814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:09.999024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:11.000052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:12.000550      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:13.000526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:14.001971      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:15.001797      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:16.002592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:17.003066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:18.002919      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:19.003292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:20.003591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:21.004555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:22.005006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:23.005406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:24.005572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:25.006146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:26.006842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:27.006681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:28.009002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:29.007923      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:30.008711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:31.008528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:32.009755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:33.010031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:34.010356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:35.010320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:36.011195      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:37.012588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:38.012644      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:27:38.197: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1781" for this suite. @ 04/15/24 07:27:38.212
â€¢ [154.946 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 04/15/24 07:27:38.259
  Apr 15 07:27:38.259: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 07:27:38.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:27:38.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:27:38.311
  STEP: Creating the pod @ 04/15/24 07:27:38.318
  E0415 07:27:39.013694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:40.014613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:27:40.962: INFO: Successfully updated pod "annotationupdate632bf185-9eb5-45dc-b85c-26341fd9896b"
  E0415 07:27:41.015596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:42.016934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:27:42.996: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8633" for this suite. @ 04/15/24 07:27:43.009
  E0415 07:27:43.016774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
â€¢ [4.765 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:272
  STEP: Creating a kubernetes client @ 04/15/24 07:27:43.028
  Apr 15 07:27:43.028: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename namespaces @ 04/15/24 07:27:43.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:27:43.064
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:27:43.07
  STEP: creating a Namespace @ 04/15/24 07:27:43.077
  STEP: patching the Namespace @ 04/15/24 07:27:43.109
  STEP: get the Namespace and ensuring it has the label @ 04/15/24 07:27:43.123
  Apr 15 07:27:43.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6107" for this suite. @ 04/15/24 07:27:43.149
  STEP: Destroying namespace "nspatchtest-015b2b97-927b-4c71-9b55-7ea4ff1a6ea8-5758" for this suite. @ 04/15/24 07:27:43.161
â€¢ [0.149 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]
test/e2e/apps/statefulset.go:1030
  STEP: Creating a kubernetes client @ 04/15/24 07:27:43.179
  Apr 15 07:27:43.179: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename statefulset @ 04/15/24 07:27:43.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:27:43.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:27:43.22
  STEP: Creating service test in namespace statefulset-3523 @ 04/15/24 07:27:43.224
  STEP: Creating statefulset ss in namespace statefulset-3523 @ 04/15/24 07:27:43.246
  Apr 15 07:27:43.285: INFO: Found 0 stateful pods, waiting for 1
  E0415 07:27:44.017801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:45.018622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:46.019669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:47.020772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:48.021677      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:49.022424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:50.023813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:51.023693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:52.024454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:53.024478      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:27:53.300: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 04/15/24 07:27:53.317
  STEP: Getting /status @ 04/15/24 07:27:53.342
  Apr 15 07:27:53.353: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 04/15/24 07:27:53.354
  Apr 15 07:27:53.374: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 04/15/24 07:27:53.375
  Apr 15 07:27:53.381: INFO: Observed &StatefulSet event: ADDED
  Apr 15 07:27:53.382: INFO: Found Statefulset ss in namespace statefulset-3523 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 15 07:27:53.382: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 04/15/24 07:27:53.382
  Apr 15 07:27:53.382: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 15 07:27:53.399: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 04/15/24 07:27:53.399
  Apr 15 07:27:53.403: INFO: Observed &StatefulSet event: ADDED
  Apr 15 07:27:53.403: INFO: Deleting all statefulset in ns statefulset-3523
  Apr 15 07:27:53.410: INFO: Scaling statefulset ss to 0
  E0415 07:27:54.024669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:55.024900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:56.025821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:57.026508      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:58.026928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:27:59.027376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:00.027529      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:01.027736      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:02.028210      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:03.028542      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:03.454: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 15 07:28:03.463: INFO: Deleting statefulset ss
  Apr 15 07:28:03.493: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3523" for this suite. @ 04/15/24 07:28:03.509
â€¢ [20.345 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 04/15/24 07:28:03.531
  Apr 15 07:28:03.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename var-expansion @ 04/15/24 07:28:03.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:03.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:03.578
  STEP: Creating a pod to test substitution in volume subpath @ 04/15/24 07:28:03.584
  E0415 07:28:04.029202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:05.029316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:06.030207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:07.036489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:28:07.641
  Apr 15 07:28:07.647: INFO: Trying to get logs from node phiefi7ighaa-3 pod var-expansion-bb2b7d30-b61b-4a01-82bc-1676493387df container dapi-container: <nil>
  STEP: delete the pod @ 04/15/24 07:28:07.667
  Apr 15 07:28:07.700: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1173" for this suite. @ 04/15/24 07:28:07.712
â€¢ [4.199 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 04/15/24 07:28:07.731
  Apr 15 07:28:07.732: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 07:28:07.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:07.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:07.768
  STEP: Creating secret with name secret-test-6140dd8f-2547-411a-a7f3-daf7e9eb1551 @ 04/15/24 07:28:07.773
  STEP: Creating a pod to test consume secrets @ 04/15/24 07:28:07.783
  E0415 07:28:08.037539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:09.038678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:10.039002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:11.039867      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:28:11.842
  Apr 15 07:28:11.851: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-secrets-e07db367-ff80-478a-a09b-938a3f40bf7e container secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 07:28:11.865
  Apr 15 07:28:11.893: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8621" for this suite. @ 04/15/24 07:28:11.905
â€¢ [4.191 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 04/15/24 07:28:11.927
  Apr 15 07:28:11.928: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 07:28:11.931
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:11.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:11.974
  STEP: Creating configMap with name projected-configmap-test-volume-2478827f-9b56-40e4-b2d9-3fb7902d1f24 @ 04/15/24 07:28:11.985
  STEP: Creating a pod to test consume configMaps @ 04/15/24 07:28:11.997
  E0415 07:28:12.040453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:13.042985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:14.043055      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:15.043608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:16.044314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:28:16.049
  Apr 15 07:28:16.058: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-configmaps-7a9f5ffc-523c-4ef5-821c-6b19e9732fc5 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 07:28:16.074
  Apr 15 07:28:16.106: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8368" for this suite. @ 04/15/24 07:28:16.117
â€¢ [4.221 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 04/15/24 07:28:16.153
  Apr 15 07:28:16.153: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename init-container @ 04/15/24 07:28:16.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:16.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:16.233
  STEP: creating the pod @ 04/15/24 07:28:16.242
  Apr 15 07:28:16.242: INFO: PodSpec: initContainers in spec.initContainers
  E0415 07:28:17.044701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:18.045006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:19.045662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:20.045909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:20.174: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2316" for this suite. @ 04/15/24 07:28:20.188
â€¢ [4.050 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 04/15/24 07:28:20.206
  Apr 15 07:28:20.206: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 07:28:20.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:20.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:20.248
  STEP: Setting up server cert @ 04/15/24 07:28:20.318
  E0415 07:28:21.046338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:22.047388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 07:28:22.375
  STEP: Deploying the webhook pod @ 04/15/24 07:28:22.4
  STEP: Wait for the deployment to be ready @ 04/15/24 07:28:22.435
  Apr 15 07:28:22.475: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 07:28:23.047804      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:24.048253      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 07:28:24.508
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 07:28:24.547
  E0415 07:28:25.048239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:25.548: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 04/15/24 07:28:25.564
  STEP: create a namespace for the webhook @ 04/15/24 07:28:25.614
  STEP: create a configmap should be unconditionally rejected by the webhook @ 04/15/24 07:28:25.664
  Apr 15 07:28:25.687: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6827" for this suite. @ 04/15/24 07:28:25.857
  STEP: Destroying namespace "webhook-markers-2384" for this suite. @ 04/15/24 07:28:25.884
  STEP: Destroying namespace "fail-closed-namespace-1578" for this suite. @ 04/15/24 07:28:25.907
â€¢ [5.721 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 04/15/24 07:28:25.928
  Apr 15 07:28:25.928: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 07:28:25.935
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:25.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:25.985
  STEP: Creating configMap with name configmap-projected-all-test-volume-91843e92-d8bf-418c-9716-f6906094bc82 @ 04/15/24 07:28:25.994
  STEP: Creating secret with name secret-projected-all-test-volume-ede92b4d-b2f5-4d9f-89c4-6e4da97c9ffa @ 04/15/24 07:28:26.005
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 04/15/24 07:28:26.015
  E0415 07:28:26.048763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:27.049101      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:28.049405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:29.049893      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:30.049935      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:28:30.083
  Apr 15 07:28:30.090: INFO: Trying to get logs from node phiefi7ighaa-3 pod projected-volume-ba2b5876-5337-4046-8764-e29561edbe1f container projected-all-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 07:28:30.106
  Apr 15 07:28:30.138: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5923" for this suite. @ 04/15/24 07:28:30.15
â€¢ [4.235 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 04/15/24 07:28:30.183
  Apr 15 07:28:30.183: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 07:28:30.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:30.214
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:30.22
  STEP: Setting up server cert @ 04/15/24 07:28:30.264
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 07:28:30.722
  STEP: Deploying the webhook pod @ 04/15/24 07:28:30.733
  STEP: Wait for the deployment to be ready @ 04/15/24 07:28:30.753
  Apr 15 07:28:30.770: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 07:28:31.051001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:32.051574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 07:28:32.795
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 07:28:32.815
  E0415 07:28:33.052778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:33.816: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/15/24 07:28:33.943
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/15/24 07:28:34.018
  E0415 07:28:34.053532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the collection of validation webhooks @ 04/15/24 07:28:34.071
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/15/24 07:28:34.182
  Apr 15 07:28:34.201: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1985" for this suite. @ 04/15/24 07:28:34.319
  STEP: Destroying namespace "webhook-markers-5188" for this suite. @ 04/15/24 07:28:34.335
â€¢ [4.169 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance]
test/e2e/network/service.go:3552
  STEP: Creating a kubernetes client @ 04/15/24 07:28:34.359
  Apr 15 07:28:34.359: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 07:28:34.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:34.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:34.394
  STEP: creating a collection of services @ 04/15/24 07:28:34.399
  Apr 15 07:28:34.400: INFO: Creating e2e-svc-a-wlnlg
  Apr 15 07:28:34.417: INFO: Creating e2e-svc-b-7x7ww
  Apr 15 07:28:34.444: INFO: Creating e2e-svc-c-4xdkt
  STEP: deleting service collection @ 04/15/24 07:28:34.479
  Apr 15 07:28:34.546: INFO: Collection of services has been deleted
  Apr 15 07:28:34.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4976" for this suite. @ 04/15/24 07:28:34.556
â€¢ [0.218 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 04/15/24 07:28:34.581
  Apr 15 07:28:34.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubelet-test @ 04/15/24 07:28:34.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:34.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:34.626
  E0415 07:28:35.054463      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:36.054141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:36.689: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1721" for this suite. @ 04/15/24 07:28:36.71
â€¢ [2.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:45
  STEP: Creating a kubernetes client @ 04/15/24 07:28:36.761
  Apr 15 07:28:36.761: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 07:28:36.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:36.786
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:36.79
  STEP: Creating a pod to test downward api env vars @ 04/15/24 07:28:36.796
  E0415 07:28:37.054602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:38.055107      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:39.055267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:40.055908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:28:40.845
  Apr 15 07:28:40.853: INFO: Trying to get logs from node phiefi7ighaa-3 pod downward-api-90954efb-d2bc-45a0-b54d-579a0bc81ec3 container dapi-container: <nil>
  STEP: delete the pod @ 04/15/24 07:28:40.876
  Apr 15 07:28:40.910: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1929" for this suite. @ 04/15/24 07:28:40.92
â€¢ [4.183 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]
test/e2e/apps/replica_set.go:176
  STEP: Creating a kubernetes client @ 04/15/24 07:28:40.951
  Apr 15 07:28:40.951: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replicaset @ 04/15/24 07:28:40.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:40.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:40.991
  STEP: Create a Replicaset @ 04/15/24 07:28:41.003
  STEP: Verify that the required pods have come up. @ 04/15/24 07:28:41.013
  Apr 15 07:28:41.021: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0415 07:28:41.056430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:42.056855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:43.056930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:44.057852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:45.057397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:46.030: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/15/24 07:28:46.03
  STEP: Getting /status @ 04/15/24 07:28:46.03
  Apr 15 07:28:46.043: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 04/15/24 07:28:46.043
  E0415 07:28:46.058129      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:46.068: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 04/15/24 07:28:46.069
  Apr 15 07:28:46.075: INFO: Observed &ReplicaSet event: ADDED
  Apr 15 07:28:46.076: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 15 07:28:46.076: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 15 07:28:46.077: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 15 07:28:46.078: INFO: Found replicaset test-rs in namespace replicaset-5994 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 15 07:28:46.079: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 04/15/24 07:28:46.08
  Apr 15 07:28:46.080: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 15 07:28:46.107: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 04/15/24 07:28:46.107
  Apr 15 07:28:46.112: INFO: Observed &ReplicaSet event: ADDED
  Apr 15 07:28:46.113: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 15 07:28:46.113: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 15 07:28:46.115: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 15 07:28:46.116: INFO: Observed replicaset test-rs in namespace replicaset-5994 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 15 07:28:46.118: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 15 07:28:46.118: INFO: Found replicaset test-rs in namespace replicaset-5994 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Apr 15 07:28:46.118: INFO: Replicaset test-rs has a patched status
  Apr 15 07:28:46.118: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5994" for this suite. @ 04/15/24 07:28:46.132
â€¢ [5.203 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 04/15/24 07:28:46.156
  Apr 15 07:28:46.156: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 07:28:46.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:46.191
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:46.204
  STEP: Creating secret with name s-test-opt-del-4b582c7f-5498-4100-8a30-bb6ae780de04 @ 04/15/24 07:28:46.224
  STEP: Creating secret with name s-test-opt-upd-b46baa14-3712-42d9-b044-a98eb8c9128e @ 04/15/24 07:28:46.235
  STEP: Creating the pod @ 04/15/24 07:28:46.245
  E0415 07:28:47.059115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:48.060140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-4b582c7f-5498-4100-8a30-bb6ae780de04 @ 04/15/24 07:28:48.341
  STEP: Updating secret s-test-opt-upd-b46baa14-3712-42d9-b044-a98eb8c9128e @ 04/15/24 07:28:48.354
  STEP: Creating secret with name s-test-opt-create-27aa3374-ee0e-4789-80aa-73805eb85e1d @ 04/15/24 07:28:48.365
  STEP: waiting to observe update in volume @ 04/15/24 07:28:48.375
  E0415 07:28:49.060084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:50.061156      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:51.061791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:52.061948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:52.452: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-36" for this suite. @ 04/15/24 07:28:52.463
â€¢ [6.321 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
test/e2e/auth/service_accounts.go:78
  STEP: Creating a kubernetes client @ 04/15/24 07:28:52.478
  Apr 15 07:28:52.478: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename svcaccounts @ 04/15/24 07:28:52.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:52.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:52.518
  E0415 07:28:53.073127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:54.071041      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 04/15/24 07:28:54.594
  Apr 15 07:28:54.595: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7011 pod-service-account-a84d568e-21de-4825-92d4-f1b501fb8348 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  E0415 07:28:55.071980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 04/15/24 07:28:55.084
  Apr 15 07:28:55.084: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7011 pod-service-account-a84d568e-21de-4825-92d4-f1b501fb8348 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 04/15/24 07:28:55.461
  Apr 15 07:28:55.462: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7011 pod-service-account-a84d568e-21de-4825-92d4-f1b501fb8348 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Apr 15 07:28:55.764: INFO: Got root ca configmap in namespace "svcaccounts-7011"
  Apr 15 07:28:55.769: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7011" for this suite. @ 04/15/24 07:28:55.778
â€¢ [3.315 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]
test/e2e/kubectl/kubectl.go:1027
  STEP: Creating a kubernetes client @ 04/15/24 07:28:55.801
  Apr 15 07:28:55.801: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 07:28:55.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:55.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:55.862
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/15/24 07:28:55.868
  Apr 15 07:28:55.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-5223 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  E0415 07:28:56.072490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:56.076: INFO: stderr: ""
  Apr 15 07:28:56.076: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 04/15/24 07:28:56.076
  Apr 15 07:28:56.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-5223 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
  Apr 15 07:28:56.289: INFO: stderr: ""
  Apr 15 07:28:56.289: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/15/24 07:28:56.289
  Apr 15 07:28:56.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-5223 delete pods e2e-test-httpd-pod'
  E0415 07:28:57.073089      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:28:58.073713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:28:58.957: INFO: stderr: ""
  Apr 15 07:28:58.957: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 15 07:28:58.957: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5223" for this suite. @ 04/15/24 07:28:58.967
â€¢ [3.180 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 04/15/24 07:28:58.986
  Apr 15 07:28:58.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 07:28:58.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:28:59.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:28:59.029
  STEP: Creating pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701 @ 04/15/24 07:28:59.036
  E0415 07:28:59.074724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:00.074788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:01.075445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/15/24 07:29:01.121
  Apr 15 07:29:01.131: INFO: Initial restart count of pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf is 0
  Apr 15 07:29:01.140: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:02.075780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:03.075863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:03.149: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:04.076854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:05.076602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:05.160: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:06.076557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:07.077391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:07.171: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:08.077740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:09.077633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:09.179: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:10.077737      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:11.078569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:11.188: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:12.079375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:13.081395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:13.210: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:14.082176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:15.083207      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:15.220: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:16.083731      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:17.084502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:17.231: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:18.085233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:19.088366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:19.245: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:20.086303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:21.086416      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:21.255: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:22.087151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:23.087600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:23.263: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:24.088674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:25.089598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:25.273: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:26.089950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:27.090589      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:27.283: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:28.090580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:29.090673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:29.292: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:30.090782      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:31.091034      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:31.309: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:32.091300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:33.091514      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:33.319: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:34.091892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:35.092909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:35.330: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:36.093133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:37.093408      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:37.345: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:38.093807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:39.096443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:39.352: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:40.096052      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:41.096647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:41.362: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:42.097165      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:43.097434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:43.378: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:44.098153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:45.098821      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:45.389: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:46.099509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:47.100316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:47.400: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:48.100340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:49.100595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:49.413: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:50.101028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:51.101139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:51.422: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:52.101310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:53.102139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:53.430: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:54.102335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:55.102531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:55.442: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:56.102784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:57.103151      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:57.455: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:29:58.103768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:29:59.104306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:29:59.471: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:00.104574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:01.104874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:01.479: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:02.105290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:03.106245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:03.488: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:04.106288      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:05.106960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:05.497: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:06.107164      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:07.108215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:07.508: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:08.108522      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:09.108555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:09.518: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:10.108701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:11.108930      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:11.543: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:12.110603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:13.109480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:13.557: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:14.111839      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:15.110499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:15.573: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:16.111204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:17.113668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:17.582: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:18.112427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:19.112751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:19.594: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:20.113424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:21.113372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:21.604: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:22.113721      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:23.114179      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:23.615: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:24.114363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:25.114486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:25.625: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:26.115441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:27.116344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:27.636: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:28.116602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:29.116992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:29.644: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:30.117982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:31.119045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:31.655: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:32.119837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:33.119938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:33.663: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:34.120380      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:35.121710      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:35.673: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:36.121822      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:37.122974      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:37.687: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:38.123487      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:39.124403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:39.698: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:40.125254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:41.125358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:41.709: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:42.125547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:43.125872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:43.718: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:44.130078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:45.129704      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:45.728: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:46.130624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:47.131588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:47.742: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:48.132045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:49.132729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:49.752: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:50.133037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:51.133148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:51.764: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:52.133503      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:53.133662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:53.776: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:54.133810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:55.134631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:55.786: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:56.134702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:57.135744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:57.799: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:30:58.136402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:30:59.136924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:30:59.808: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:00.137890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:01.138135      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:01.822: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:02.138215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:03.138811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:03.830: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:04.139689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:05.140492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:05.842: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:06.140643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:07.140871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:07.854: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:08.141950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:09.142579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:09.865: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:10.143285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:11.146594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:11.873: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:12.144547      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:13.144658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:13.884: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:14.145691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:15.145890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:15.893: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:16.147270      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:17.147802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:17.904: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:18.148063      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:19.148975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:19.929: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:20.149964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:21.149838      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:21.939: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:22.150021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:23.150606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:23.947: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:24.152575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:25.152959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:25.954: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:26.154100      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:27.155422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:27.964: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:28.155304      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:29.155566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:29.978: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:30.156021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:31.156231      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:31.994: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:32.157973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:33.157374      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:34.005: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:34.158330      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:35.158234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:36.015: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:36.159423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:37.161411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:38.030: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:38.161147      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:39.161534      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:40.042: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:40.161730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:41.163059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:42.053: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:42.163436      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:43.164196      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:44.064: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:44.164880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:45.165889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:46.077: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:46.166753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:47.167432      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:48.089: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:48.168191      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:49.169026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:50.101: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:50.169957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:51.170697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:52.112: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:52.171050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:53.171343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:54.122: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:54.172122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:55.172938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:56.159: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:56.173660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:57.174236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:31:58.171: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:31:58.174903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:31:59.175914      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:00.176423      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:00.183: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:01.176802      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:02.177784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:02.193: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:03.177481      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:04.177816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:04.201: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:05.178841      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:06.179438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:06.212: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:07.179493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:08.179809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:08.228: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:09.180639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:10.181751      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:10.245: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:11.181943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:12.182045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:12.257: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:13.182566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:14.182853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:14.268: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:15.183962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:16.184502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:16.277: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:17.184733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:18.185373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:18.290: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:19.185615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:20.186661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:20.300: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:21.186787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:22.187706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:22.309: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:23.188056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:24.188451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:24.319: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:25.189219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:26.190214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:26.331: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:27.190162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:28.190439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:28.346: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:29.191127      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:30.191703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:30.356: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:31.192327      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:32.192643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:32.368: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:33.192975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:34.193611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:34.377: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:35.194145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:36.194654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:36.389: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:37.195225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:38.196391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:38.403: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:39.196062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:40.196247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:40.417: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:41.197153      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:42.197890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:42.428: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:43.197911      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:44.198513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:44.446: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:45.198956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:46.198969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:46.477: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:47.199199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:48.199504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:48.491: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:49.200457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:50.201329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:50.503: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:51.201489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:52.201674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:52.514: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:53.202526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:54.202417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:54.524: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:55.202928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:56.203088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:56.535: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:57.203260      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:32:58.204126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:32:58.555: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:32:59.204964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:00.205377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:33:00.567: INFO: Get pod liveness-ea3cabe4-c024-4844-b50a-144e0fbd68cf in namespace container-probe-6701
  E0415 07:33:01.205664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:02.205835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:33:02.568: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:33:02.581
  STEP: Destroying namespace "container-probe-6701" for this suite. @ 04/15/24 07:33:02.611
â€¢ [243.647 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
test/e2e/apps/rc.go:85
  STEP: Creating a kubernetes client @ 04/15/24 07:33:02.657
  Apr 15 07:33:02.657: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replication-controller @ 04/15/24 07:33:02.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:33:02.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:33:02.746
  Apr 15 07:33:02.754: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0415 07:33:03.206533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 04/15/24 07:33:03.784
  STEP: Checking rc "condition-test" has the desired failure condition set @ 04/15/24 07:33:03.797
  E0415 07:33:04.207356      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 04/15/24 07:33:04.812
  Apr 15 07:33:04.833: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 04/15/24 07:33:04.834
  E0415 07:33:05.208075      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:33:05.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-525" for this suite. @ 04/15/24 07:33:05.866
â€¢ [3.225 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 04/15/24 07:33:05.9
  Apr 15 07:33:05.900: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 07:33:05.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:33:05.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:33:05.935
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 07:33:05.941
  E0415 07:33:06.209214      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:07.209490      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:08.210500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:09.210787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:33:09.992
  Apr 15 07:33:10.001: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-1af67f9e-d7e1-40b7-95c5-d229eb5c17a1 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 07:33:10.051
  Apr 15 07:33:10.092: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6869" for this suite. @ 04/15/24 07:33:10.107
â€¢ [4.222 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster  [Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 04/15/24 07:33:10.131
  Apr 15 07:33:10.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename dns @ 04/15/24 07:33:10.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:33:10.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:33:10.182
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/15/24 07:33:10.189
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/15/24 07:33:10.189
  STEP: creating a pod to probe DNS @ 04/15/24 07:33:10.19
  STEP: submitting the pod to kubernetes @ 04/15/24 07:33:10.19
  E0415 07:33:10.211646      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:11.211831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:12.212913      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:13.212575      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:14.213940      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/15/24 07:33:14.259
  STEP: looking for the results for each expected name from probers @ 04/15/24 07:33:14.266
  Apr 15 07:33:14.316: INFO: DNS probes using dns-7344/dns-test-aa0332dd-7a25-446c-a110-cbc3fb1afe1f succeeded

  Apr 15 07:33:14.317: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:33:14.336
  STEP: Destroying namespace "dns-7344" for this suite. @ 04/15/24 07:33:14.373
â€¢ [4.267 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]
test/e2e/network/endpointslice.go:68
  STEP: Creating a kubernetes client @ 04/15/24 07:33:14.426
  Apr 15 07:33:14.426: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename endpointslice @ 04/15/24 07:33:14.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:33:14.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:33:14.499
  Apr 15 07:33:14.527: INFO: Endpoints addresses: [192.168.121.141 192.168.121.17] , ports: [6443]
  Apr 15 07:33:14.528: INFO: EndpointSlices addresses: [192.168.121.141 192.168.121.17] , ports: [6443]
  Apr 15 07:33:14.529: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-295" for this suite. @ 04/15/24 07:33:14.542
â€¢ [0.131 seconds]
------------------------------
SSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:104
  STEP: Creating a kubernetes client @ 04/15/24 07:33:14.559
  Apr 15 07:33:14.559: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename runtimeclass @ 04/15/24 07:33:14.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:33:14.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:33:14.612
  E0415 07:33:15.214612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:16.214428      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:33:16.670: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6440" for this suite. @ 04/15/24 07:33:16.712
â€¢ [2.187 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 04/15/24 07:33:16.754
  Apr 15 07:33:16.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-preemption @ 04/15/24 07:33:16.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:33:16.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:33:16.804
  Apr 15 07:33:16.874: INFO: Waiting up to 1m0s for all nodes to be ready
  E0415 07:33:17.215138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:18.215425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:19.216259      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:20.216296      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:21.216650      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:22.226624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:23.223258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:24.225455      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:25.224842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:26.225748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:27.225892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:28.226068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:29.226658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:30.226860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:31.227491      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:32.228103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:33.229019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:34.229199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:35.229803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:36.229968      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:37.230188      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:38.230223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:39.230916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:40.232090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:41.233029      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:42.233140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:43.233433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:44.234654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:45.234610      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:46.234983      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:47.235245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:48.236219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:49.236675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:50.236944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:51.237042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:52.237419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:53.237464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:54.238244      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:55.238400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:56.239081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:57.240627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:58.240230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:33:59.241194      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:00.241200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:01.242031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:02.242552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:03.243174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:04.244115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:05.245819      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:06.245774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:07.246026      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:08.246258      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:09.247006      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:10.247109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:11.248298      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:12.248442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:13.249745      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:14.249800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:15.249937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:16.250141      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:34:16.955: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/15/24 07:34:16.962
  Apr 15 07:34:17.031: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 15 07:34:17.073: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 15 07:34:17.126: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 15 07:34:17.191: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  E0415 07:34:17.250602      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:34:17.303: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Apr 15 07:34:17.341: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/15/24 07:34:17.341
  E0415 07:34:18.250880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:19.251831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:20.255543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:21.252824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 04/15/24 07:34:21.446
  E0415 07:34:22.253290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:23.253629      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:24.253506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:25.253990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:34:25.618: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1461" for this suite. @ 04/15/24 07:34:25.826
â€¢ [69.101 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 04/15/24 07:34:25.86
  Apr 15 07:34:25.861: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-preemption @ 04/15/24 07:34:25.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:34:25.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:34:25.909
  Apr 15 07:34:25.973: INFO: Waiting up to 1m0s for all nodes to be ready
  E0415 07:34:26.255087      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:27.255322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:28.256562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:29.256766      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:30.256965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:31.257211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:32.258032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:33.258477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:34.259023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:35.259148      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:36.259371      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:37.259684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:38.260072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:39.260285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:40.260803      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:41.261424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:42.261378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:43.261655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:44.264321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:45.263539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:46.264441      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:47.264881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:48.265917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:49.266641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:50.267598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:51.269979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:52.269065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:53.269251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:54.270170      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:55.270908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:56.272056      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:57.272649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:58.272855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:34:59.272973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:00.273763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:01.273991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:02.274459      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:03.274668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:04.274758      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:05.275036      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:06.276388      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:07.276425      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:08.276993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:09.277845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:10.278027      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:11.278221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:12.278626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:13.278729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:14.279695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:15.279825      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:16.280846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:17.281292      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:18.282157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:19.284401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:20.285014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:21.285324      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:22.285872      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:23.286924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:24.287885      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:25.288438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:35:26.049: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/15/24 07:35:26.061
  Apr 15 07:35:26.061: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/15/24 07:35:26.067
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:35:26.111
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:35:26.118
  STEP: Finding an available node @ 04/15/24 07:35:26.126
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/15/24 07:35:26.126
  E0415 07:35:26.289495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:27.289809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/15/24 07:35:28.205
  Apr 15 07:35:28.233: INFO: found a healthy node: phiefi7ighaa-3
  E0415 07:35:28.290642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:29.291494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:30.292323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:31.292494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:32.292641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:33.293023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:34.293002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:35:34.415: INFO: pods created so far: [1 1 1]
  Apr 15 07:35:34.415: INFO: length of pods created so far: 3
  E0415 07:35:35.293332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:36.293915      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:35:36.439: INFO: pods created so far: [2 2 1]
  E0415 07:35:37.294189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:38.294852      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:39.295246      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:40.296367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:41.296641      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:42.296863      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:43.296990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:35:43.440: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 07:35:43.529: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-5715" for this suite. @ 04/15/24 07:35:43.692
  STEP: Destroying namespace "sched-preemption-3915" for this suite. @ 04/15/24 07:35:43.707
â€¢ [77.865 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
test/e2e/apimachinery/resource_quota.go:693
  STEP: Creating a kubernetes client @ 04/15/24 07:35:43.73
  Apr 15 07:35:43.730: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 07:35:43.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:35:43.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:35:43.777
  STEP: Creating a ResourceQuota with terminating scope @ 04/15/24 07:35:43.782
  STEP: Ensuring ResourceQuota status is calculated @ 04/15/24 07:35:43.794
  E0415 07:35:44.297480      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:45.298146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 04/15/24 07:35:45.803
  STEP: Ensuring ResourceQuota status is calculated @ 04/15/24 07:35:45.816
  E0415 07:35:46.299297      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:47.300360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 04/15/24 07:35:47.827
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 04/15/24 07:35:47.859
  E0415 07:35:48.300991      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:49.301724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 04/15/24 07:35:49.871
  E0415 07:35:50.301998      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:51.302215      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/15/24 07:35:51.882
  STEP: Ensuring resource quota status released the pod usage @ 04/15/24 07:35:51.907
  E0415 07:35:52.302775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:53.303009      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 04/15/24 07:35:53.921
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 04/15/24 07:35:53.948
  E0415 07:35:54.303669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:55.303224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 04/15/24 07:35:55.961
  E0415 07:35:56.304847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:57.305679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 04/15/24 07:35:57.972
  STEP: Ensuring resource quota status released the pod usage @ 04/15/24 07:35:58.004
  E0415 07:35:58.306234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:35:59.307218      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:00.016: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5718" for this suite. @ 04/15/24 07:36:00.031
â€¢ [16.323 seconds]
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:176
  STEP: Creating a kubernetes client @ 04/15/24 07:36:00.054
  Apr 15 07:36:00.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-webhook @ 04/15/24 07:36:00.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:36:00.095
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:36:00.099
  STEP: Setting up server cert @ 04/15/24 07:36:00.105
  E0415 07:36:00.307376      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:01.307661      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/15/24 07:36:01.451
  STEP: Deploying the custom resource conversion webhook pod @ 04/15/24 07:36:01.474
  STEP: Wait for the deployment to be ready @ 04/15/24 07:36:01.511
  Apr 15 07:36:01.531: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0415 07:36:02.308451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:03.309019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 07:36:03.558
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 07:36:03.585
  E0415 07:36:04.309671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:04.586: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 15 07:36:04.604: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:36:05.309880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:06.310125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:07.310521      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/15/24 07:36:07.388
  STEP: Create a v2 custom resource @ 04/15/24 07:36:07.446
  STEP: List CRs in v1 @ 04/15/24 07:36:07.903
  STEP: List CRs in v2 @ 04/15/24 07:36:07.913
  Apr 15 07:36:07.929: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 07:36:08.310680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-webhook-5304" for this suite. @ 04/15/24 07:36:08.614
â€¢ [8.584 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 04/15/24 07:36:08.644
  Apr 15 07:36:08.644: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename downward-api @ 04/15/24 07:36:08.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:36:08.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:36:08.707
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 07:36:08.718
  E0415 07:36:09.310877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:10.316733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:11.313398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:12.314213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:36:12.767
  Apr 15 07:36:12.775: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-e4aaab26-ab17-4e47-9932-7764d81b803d container client-container: <nil>
  STEP: delete the pod @ 04/15/24 07:36:12.808
  Apr 15 07:36:12.852: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1897" for this suite. @ 04/15/24 07:36:12.877
â€¢ [4.248 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 04/15/24 07:36:12.898
  Apr 15 07:36:12.898: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 07:36:12.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:36:12.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:36:12.955
  STEP: Creating pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625 @ 04/15/24 07:36:12.964
  E0415 07:36:13.314417      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:14.317574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/15/24 07:36:15.023
  Apr 15 07:36:15.029: INFO: Initial restart count of pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 is 0
  Apr 15 07:36:15.038: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:15.315446      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:16.316535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:17.057: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:17.317331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:18.317368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:19.066: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:19.318606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:20.319676      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:21.076: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:21.320715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:22.321688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:23.085: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:23.322634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:24.323422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:25.132: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:25.323966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:26.324790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:27.140: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:27.325718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:28.326678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:29.149: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:29.326827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:30.327997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:31.160: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:31.328623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:32.328805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:33.169: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:33.329383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:34.329612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:35.180: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:35.330133      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:36.330776      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:37.190: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:37.331929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:38.343361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:39.200: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:39.333334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:40.333810      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:41.209: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:41.333875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:42.334199      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:43.218: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:43.335046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:44.335770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:45.231: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:45.336722      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:46.337462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:47.242: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:47.338510      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:48.338620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:49.252: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:49.337868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:50.338172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:51.261: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:51.339350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:52.339631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:53.275: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:53.340568      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:54.340931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:55.283: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:55.341359      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:56.341784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:57.292: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:57.342241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:36:58.342890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:36:59.315: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:36:59.343453      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:00.343387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:37:01.327: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:37:01.344896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:02.345367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:03.345608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:37:03.364: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  E0415 07:37:04.345740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:05.346042      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:37:05.374: INFO: Get pod busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 in namespace container-probe-625
  Apr 15 07:37:05.374: INFO: Restart count of pod container-probe-625/busybox-efd6f0e7-61e8-4c6e-aa2c-3a2b36233c85 is now 1 (50.344161634s elapsed)
  Apr 15 07:37:05.374: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:37:05.388
  STEP: Destroying namespace "container-probe-625" for this suite. @ 04/15/24 07:37:05.43
â€¢ [52.561 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]
test/e2e/apimachinery/resource_quota.go:946
  STEP: Creating a kubernetes client @ 04/15/24 07:37:05.479
  Apr 15 07:37:05.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 07:37:05.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:37:05.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:37:05.524
  STEP: Creating a ResourceQuota @ 04/15/24 07:37:05.531
  STEP: Getting a ResourceQuota @ 04/15/24 07:37:05.544
  STEP: Listing all ResourceQuotas with LabelSelector @ 04/15/24 07:37:05.554
  STEP: Patching the ResourceQuota @ 04/15/24 07:37:05.564
  STEP: Deleting a Collection of ResourceQuotas @ 04/15/24 07:37:05.58
  STEP: Verifying the deleted ResourceQuota @ 04/15/24 07:37:05.598
  Apr 15 07:37:05.606: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4925" for this suite. @ 04/15/24 07:37:05.621
â€¢ [0.170 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 04/15/24 07:37:05.654
  Apr 15 07:37:05.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename disruption @ 04/15/24 07:37:05.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:37:05.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:37:05.719
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:37:05.74
  E0415 07:37:06.346643      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:07.346984      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 04/15/24 07:37:07.827
  Apr 15 07:37:07.845: INFO: running pods: 0 < 3
  E0415 07:37:08.346809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:09.347267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:37:09.862: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-7617" for this suite. @ 04/15/24 07:37:09.872
â€¢ [4.243 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 04/15/24 07:37:09.903
  Apr 15 07:37:09.903: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/15/24 07:37:09.906
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:37:09.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:37:09.945
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 04/15/24 07:37:09.954
  Apr 15 07:37:09.956: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:37:10.348097      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:11.348929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:37:12.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:37:12.350012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:13.351284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:14.351494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:15.352486      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:16.353435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:17.353631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:18.353741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:19.355903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:37:20.008: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8967" for this suite. @ 04/15/24 07:37:20.036
â€¢ [10.152 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:95
  STEP: Creating a kubernetes client @ 04/15/24 07:37:20.058
  Apr 15 07:37:20.058: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 07:37:20.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:37:20.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:37:20.099
  STEP: creating secret secrets-5503/secret-test-a8d5f494-f186-4fbd-9964-1de66a6e654e @ 04/15/24 07:37:20.104
  STEP: Creating a pod to test consume secrets @ 04/15/24 07:37:20.115
  E0415 07:37:20.355470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:21.356871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:22.356826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:23.357347      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:37:24.214
  Apr 15 07:37:24.225: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-5ba67603-cb01-4137-91f8-1ae57d908734 container env-test: <nil>
  STEP: delete the pod @ 04/15/24 07:37:24.254
  Apr 15 07:37:24.299: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5503" for this suite. @ 04/15/24 07:37:24.309
â€¢ [4.270 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529
  STEP: Creating a kubernetes client @ 04/15/24 07:37:24.331
  Apr 15 07:37:24.332: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename svcaccounts @ 04/15/24 07:37:24.335
  E0415 07:37:24.356879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:37:24.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:37:24.377
  Apr 15 07:37:24.416: INFO: created pod
  E0415 07:37:25.357784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:26.357933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:27.358203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:28.358823      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:37:28.442
  E0415 07:37:29.358907      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:30.359086      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:31.359332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:32.359468      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:33.359688      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:34.359815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:35.360888      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:36.361675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:37.362755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:38.367088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:39.364462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:40.364790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:41.365028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:42.365255      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:43.365405      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:44.365552      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:45.366291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:46.368928      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:47.367840      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:48.369450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:49.370094      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:50.370053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:51.370483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:52.370443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:53.370778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:54.370858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:55.371345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:56.371565      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:57.371777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:37:58.372341      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:37:58.444: INFO: polling logs
  Apr 15 07:37:58.461: INFO: Pod logs: 
  I0415 07:37:25.327944       1 log.go:245] OK: Got token
  I0415 07:37:25.329452       1 log.go:245] validating with in-cluster discovery
  I0415 07:37:25.332826       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0415 07:37:25.333007       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-1390:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc00046f040), NotBefore:(*jwt.NumericDate)(0xc00046f128), IssuedAt:(*jwt.NumericDate)(0xc00046f050), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1390", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c8d01bb6-26a3-487f-9200-763f2e7da8cc"}}}
  I0415 07:37:25.378103       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0415 07:37:25.397370       1 log.go:245] OK: Validated signature on JWT
  I0415 07:37:25.397504       1 log.go:245] OK: Got valid claims from token!
  I0415 07:37:25.397544       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-1390:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc00046f968), NotBefore:(*jwt.NumericDate)(0xc00046f990), IssuedAt:(*jwt.NumericDate)(0xc00046f970), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1390", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c8d01bb6-26a3-487f-9200-763f2e7da8cc"}}}

  Apr 15 07:37:58.461: INFO: completed pod
  Apr 15 07:37:58.484: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1390" for this suite. @ 04/15/24 07:37:58.499
â€¢ [34.185 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:156
  STEP: Creating a kubernetes client @ 04/15/24 07:37:58.521
  Apr 15 07:37:58.521: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename runtimeclass @ 04/15/24 07:37:58.529
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:37:58.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:37:58.572
  STEP: Deleting RuntimeClass runtimeclass-9845-delete-me @ 04/15/24 07:37:58.599
  STEP: Waiting for the RuntimeClass to disappear @ 04/15/24 07:37:58.615
  Apr 15 07:37:58.638: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9845" for this suite. @ 04/15/24 07:37:58.655
â€¢ [0.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 04/15/24 07:37:58.678
  Apr 15 07:37:58.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 07:37:58.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:37:58.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:37:58.725
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-016e40eb-6db9-42ea-94dd-691c3acc546a @ 04/15/24 07:37:58.741
  STEP: Creating the pod @ 04/15/24 07:37:58.753
  E0415 07:37:59.372618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:00.373788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-016e40eb-6db9-42ea-94dd-691c3acc546a @ 04/15/24 07:38:00.826
  STEP: waiting to observe update in volume @ 04/15/24 07:38:00.839
  E0415 07:38:01.374625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:02.374331      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:02.880: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6570" for this suite. @ 04/15/24 07:38:02.896
â€¢ [4.239 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 04/15/24 07:38:02.922
  Apr 15 07:38:02.922: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 07:38:02.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:38:02.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:38:02.989
  STEP: Creating pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680 @ 04/15/24 07:38:02.997
  E0415 07:38:03.375120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:04.375757      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/15/24 07:38:05.047
  Apr 15 07:38:05.064: INFO: Initial restart count of pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f is 0
  Apr 15 07:38:05.071: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:05.376693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:06.377140      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:07.084: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:07.378113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:08.378295      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:09.092: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:09.379440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:10.379786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:11.102: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:11.380128      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:12.380657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:13.117: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:13.381242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:14.380917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:15.126: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:15.384649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:16.385299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:17.135: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:17.385419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:18.386142      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:19.145: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:19.387059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:20.387137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:21.157: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:21.387717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:22.388284      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:23.168: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:23.388917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:24.389411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:25.178: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:25.390060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:26.390172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:27.186: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:27.390471      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:28.391301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:29.197: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:29.392543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:30.392016      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:31.217: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:31.393613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:32.393489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:33.229: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:33.394157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:34.395226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:35.238: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:35.396364      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:36.397045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:37.249: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:37.398301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:38.398593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:39.255: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:39.399211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:40.399493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:41.268: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:41.399835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:42.400473      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:43.285: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:43.400578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:44.401366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:45.294: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:45.401656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:46.401941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:47.340: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:47.402683      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:48.403108      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:49.352: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:49.403685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:50.404329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:51.366: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:51.404906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:52.411305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:53.376: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:53.406787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:54.406979      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:55.387: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:55.408010      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:56.408559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:57.399: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:38:57.409000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:58.410560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:38:59.410941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:38:59.414: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:00.411084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:01.412278      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:01.428: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:02.412637      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:03.412598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:03.442: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:04.412674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:05.413349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:05.453: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:06.414095      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:07.414611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:07.466: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:08.414561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:09.414857      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:09.478: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:10.415358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:11.416138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:11.488: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:12.416621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:13.416673      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:13.500: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:14.417213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:15.417791      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:15.512: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:16.417741      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:17.417777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:17.521: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:18.417941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:19.418794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:19.533: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:20.418448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:21.418811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:21.550: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:22.419674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:23.419427      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:23.561: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:24.420019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:25.420366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:25.569: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:26.420485      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:27.420703      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:27.581: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:28.421517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:29.422299      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:29.590: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:30.423536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:31.424301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:31.606: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:32.425092      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:33.424866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:33.629: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:34.425391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:35.426333      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:35.640: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:36.426651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:37.427541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:37.651: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:38.427927      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:39.428682      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:39.669: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:40.429603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:41.431597      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:41.691: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:42.431237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:43.431948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:43.706: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:44.433679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:45.433513      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:45.717: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:46.433674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:47.433760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:47.727: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:48.434019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:49.435023      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:49.737: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:50.435343      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:51.435847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:51.747: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:52.436046      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:53.436247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:53.755: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:54.436454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:55.437032      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:55.766: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:56.437254      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:57.437519      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:57.777: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:39:58.437658      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:39:59.438456      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:39:59.784: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:00.439467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:01.439574      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:01.798: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:02.440585      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:03.441655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:03.820: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:04.441956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:05.442282      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:05.832: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:06.442774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:07.443448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:07.842: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:08.443842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:09.443895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:09.850: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:10.444319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:11.444621      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:11.860: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:12.444772      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:13.445657      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:13.872: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:14.445855      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:15.446599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:15.881: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:16.446458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:17.446631      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:17.891: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:18.447541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:19.448693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:19.903: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:20.450263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:21.450345      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:21.917: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:22.451475      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:23.450639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:23.927: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:24.450701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:25.450934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:25.938: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:26.451789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:27.452266      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:27.946: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:28.453329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:29.455775      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:29.961: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:30.455000      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:31.455448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:31.973: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:32.455875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:33.456835      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:33.984: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:34.457489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:35.457833      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:36.002: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:36.458826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:37.459638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:38.013: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:38.460120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:39.460223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:40.023: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:40.460448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:41.460929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:42.036: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:42.462219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:43.462640      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:44.052: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:44.463424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:45.463452      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:46.062: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:46.463956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:47.464694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:48.072: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:48.465693      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:49.466162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:50.083: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:50.467037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:51.467312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:52.096: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:52.468230      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:53.468072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:54.109: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:54.468361      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:55.469470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:56.126: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:56.469966      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:57.470723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:40:58.138: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:40:58.470499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:40:59.471385      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:00.150: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:00.471918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:01.472505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:02.162: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:02.472926      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:03.473360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:04.172: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:04.474497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:05.474685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:06.183: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:06.474895      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:07.475531      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:08.194: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:08.476344      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:09.476897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:10.204: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:10.477728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:11.478492      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:12.217: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:12.478262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:13.479387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:14.225: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:14.479814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:15.480084      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:16.235: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:16.481187      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:17.481681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:18.244: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:18.482497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:19.486512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:20.253: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:20.483583      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:21.483570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:22.265: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:22.483788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:23.484119      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:24.277: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:24.485559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:25.485505      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:26.289: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:26.485874      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:27.486701      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:28.299: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:28.487467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:29.487956      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:30.308: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:30.488370      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:31.493440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:32.320: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:32.489975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:33.490816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:34.330: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:34.490809      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:35.491779      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:36.342: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:36.492849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:37.493062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:38.350: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:38.493897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:39.494002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:40.359: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:40.495003      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:41.495279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:42.372: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:42.496025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:43.496652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:44.382: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:44.497618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:45.497625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:46.391: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:46.498190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:47.499019      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:48.403: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:48.499718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:49.500760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:50.413: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:50.501303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:51.502044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:52.425: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:52.502466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:53.502638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:54.434: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:54.502982      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:55.504669      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:56.456: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:56.504784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:57.504755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:41:58.467: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:41:58.504848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:41:59.505655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:42:00.481: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:42:00.505844      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:01.506933      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:42:02.499: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:42:02.508400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:03.507664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:04.508765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:42:04.509: INFO: Get pod busybox-07a22aad-d705-4a8c-bd79-b13ef54a0d5f in namespace container-probe-5680
  E0415 07:42:05.509044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:06.509601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:42:06.511: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:42:06.531
  STEP: Destroying namespace "container-probe-5680" for this suite. @ 04/15/24 07:42:06.573
â€¢ [243.670 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:125
  STEP: Creating a kubernetes client @ 04/15/24 07:42:06.603
  Apr 15 07:42:06.603: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename discovery @ 04/15/24 07:42:06.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:42:06.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:42:06.655
  STEP: Setting up server cert @ 04/15/24 07:42:06.666
  E0415 07:42:07.509992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:42:08.303: INFO: Checking APIGroup: apiregistration.k8s.io
  Apr 15 07:42:08.305: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Apr 15 07:42:08.305: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Apr 15 07:42:08.305: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Apr 15 07:42:08.305: INFO: Checking APIGroup: apps
  Apr 15 07:42:08.309: INFO: PreferredVersion.GroupVersion: apps/v1
  Apr 15 07:42:08.309: INFO: Versions found [{apps/v1 v1}]
  Apr 15 07:42:08.309: INFO: apps/v1 matches apps/v1
  Apr 15 07:42:08.309: INFO: Checking APIGroup: events.k8s.io
  Apr 15 07:42:08.311: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Apr 15 07:42:08.311: INFO: Versions found [{events.k8s.io/v1 v1}]
  Apr 15 07:42:08.311: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Apr 15 07:42:08.311: INFO: Checking APIGroup: authentication.k8s.io
  Apr 15 07:42:08.314: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Apr 15 07:42:08.314: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Apr 15 07:42:08.314: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Apr 15 07:42:08.314: INFO: Checking APIGroup: authorization.k8s.io
  Apr 15 07:42:08.317: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Apr 15 07:42:08.317: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Apr 15 07:42:08.317: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Apr 15 07:42:08.317: INFO: Checking APIGroup: autoscaling
  Apr 15 07:42:08.320: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Apr 15 07:42:08.320: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Apr 15 07:42:08.320: INFO: autoscaling/v2 matches autoscaling/v2
  Apr 15 07:42:08.320: INFO: Checking APIGroup: batch
  Apr 15 07:42:08.325: INFO: PreferredVersion.GroupVersion: batch/v1
  Apr 15 07:42:08.325: INFO: Versions found [{batch/v1 v1}]
  Apr 15 07:42:08.325: INFO: batch/v1 matches batch/v1
  Apr 15 07:42:08.325: INFO: Checking APIGroup: certificates.k8s.io
  Apr 15 07:42:08.327: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Apr 15 07:42:08.328: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Apr 15 07:42:08.329: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Apr 15 07:42:08.329: INFO: Checking APIGroup: networking.k8s.io
  Apr 15 07:42:08.333: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Apr 15 07:42:08.333: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Apr 15 07:42:08.333: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Apr 15 07:42:08.333: INFO: Checking APIGroup: policy
  Apr 15 07:42:08.335: INFO: PreferredVersion.GroupVersion: policy/v1
  Apr 15 07:42:08.335: INFO: Versions found [{policy/v1 v1}]
  Apr 15 07:42:08.336: INFO: policy/v1 matches policy/v1
  Apr 15 07:42:08.336: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Apr 15 07:42:08.339: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Apr 15 07:42:08.340: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Apr 15 07:42:08.340: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Apr 15 07:42:08.341: INFO: Checking APIGroup: storage.k8s.io
  Apr 15 07:42:08.343: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Apr 15 07:42:08.344: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Apr 15 07:42:08.345: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Apr 15 07:42:08.345: INFO: Checking APIGroup: admissionregistration.k8s.io
  Apr 15 07:42:08.347: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Apr 15 07:42:08.348: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Apr 15 07:42:08.348: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Apr 15 07:42:08.348: INFO: Checking APIGroup: apiextensions.k8s.io
  Apr 15 07:42:08.350: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Apr 15 07:42:08.350: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Apr 15 07:42:08.351: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Apr 15 07:42:08.352: INFO: Checking APIGroup: scheduling.k8s.io
  Apr 15 07:42:08.354: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Apr 15 07:42:08.354: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Apr 15 07:42:08.354: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Apr 15 07:42:08.354: INFO: Checking APIGroup: coordination.k8s.io
  Apr 15 07:42:08.356: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Apr 15 07:42:08.357: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Apr 15 07:42:08.357: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Apr 15 07:42:08.358: INFO: Checking APIGroup: node.k8s.io
  Apr 15 07:42:08.361: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Apr 15 07:42:08.361: INFO: Versions found [{node.k8s.io/v1 v1}]
  Apr 15 07:42:08.361: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Apr 15 07:42:08.361: INFO: Checking APIGroup: discovery.k8s.io
  Apr 15 07:42:08.363: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Apr 15 07:42:08.364: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Apr 15 07:42:08.365: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Apr 15 07:42:08.366: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Apr 15 07:42:08.370: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
  Apr 15 07:42:08.371: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
  Apr 15 07:42:08.371: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
  Apr 15 07:42:08.371: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-8360" for this suite. @ 04/15/24 07:42:08.386
â€¢ [1.799 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 04/15/24 07:42:08.403
  Apr 15 07:42:08.403: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename var-expansion @ 04/15/24 07:42:08.406
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:42:08.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:42:08.448
  STEP: Creating a pod to test substitution in container's args @ 04/15/24 07:42:08.455
  E0415 07:42:08.511400      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:09.511398      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:10.511549      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:11.511910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:12.513889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:42:12.515
  Apr 15 07:42:12.524: INFO: Trying to get logs from node phiefi7ighaa-3 pod var-expansion-a21a8dee-91ac-4b85-bd8e-d0de650333c4 container dapi-container: <nil>
  STEP: delete the pod @ 04/15/24 07:42:12.568
  Apr 15 07:42:12.605: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5870" for this suite. @ 04/15/24 07:42:12.619
â€¢ [4.232 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 04/15/24 07:42:12.637
  Apr 15 07:42:12.637: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 07:42:12.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:42:12.679
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:42:12.687
  STEP: Creating configMap with name projected-configmap-test-volume-map-1006235e-a898-4f76-8d1b-dcfc42ebe37f @ 04/15/24 07:42:12.694
  STEP: Creating a pod to test consume configMaps @ 04/15/24 07:42:12.702
  E0415 07:42:13.514116      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:14.514406      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:15.515634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:16.515435      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:42:16.757
  Apr 15 07:42:16.762: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-configmaps-9b99fb84-c5ed-45e3-bd97-12ab33aa4e47 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 07:42:16.778
  Apr 15 07:42:16.811: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6274" for this suite. @ 04/15/24 07:42:16.822
â€¢ [4.201 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]
test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 04/15/24 07:42:16.841
  Apr 15 07:42:16.841: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename subpath @ 04/15/24 07:42:16.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:42:16.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:42:16.875
  STEP: Setting up data @ 04/15/24 07:42:16.881
  STEP: Creating pod pod-subpath-test-projected-s5z9 @ 04/15/24 07:42:16.9
  STEP: Creating a pod to test atomic-volume-subpath @ 04/15/24 07:42:16.901
  E0415 07:42:17.516500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:18.517283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:19.518093      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:20.518617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:21.518465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:22.519504      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:23.519351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:24.520252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:25.521137      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:26.521908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:27.522711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:28.523366      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:29.524226      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:30.524203      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:31.524523      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:32.524793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:33.525420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:34.526065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:35.526743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:36.526886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:37.527754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:38.529419      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:39.528698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:40.528916      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:42:41.108
  Apr 15 07:42:41.117: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-subpath-test-projected-s5z9 container test-container-subpath-projected-s5z9: <nil>
  STEP: delete the pod @ 04/15/24 07:42:41.16
  STEP: Deleting pod pod-subpath-test-projected-s5z9 @ 04/15/24 07:42:41.191
  Apr 15 07:42:41.191: INFO: Deleting pod "pod-subpath-test-projected-s5z9" in namespace "subpath-8196"
  Apr 15 07:42:41.198: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8196" for this suite. @ 04/15/24 07:42:41.213
â€¢ [24.388 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 04/15/24 07:42:41.235
  Apr 15 07:42:41.235: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename configmap @ 04/15/24 07:42:41.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:42:41.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:42:41.278
  STEP: Creating configMap with name configmap-test-volume-map-89912f80-5e24-4934-8a39-e5dfd49022d6 @ 04/15/24 07:42:41.285
  STEP: Creating a pod to test consume configMaps @ 04/15/24 07:42:41.296
  E0415 07:42:41.529970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:42.530939      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:43.531798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:44.531899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:42:45.349
  Apr 15 07:42:45.356: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-configmaps-a10acbf9-ca06-44c1-b5e9-1a111c39284f container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 07:42:45.371
  Apr 15 07:42:45.396: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5681" for this suite. @ 04/15/24 07:42:45.409
â€¢ [4.191 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 04/15/24 07:42:45.427
  Apr 15 07:42:45.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename pods @ 04/15/24 07:42:45.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:42:45.46
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:42:45.465
  Apr 15 07:42:45.471: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: creating the pod @ 04/15/24 07:42:45.474
  STEP: submitting the pod to kubernetes @ 04/15/24 07:42:45.475
  E0415 07:42:45.532004      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:46.532458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:47.533232      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:42:47.580: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6408" for this suite. @ 04/15/24 07:42:47.593
â€¢ [2.181 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/replica_set.go:111
  STEP: Creating a kubernetes client @ 04/15/24 07:42:47.612
  Apr 15 07:42:47.612: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replicaset @ 04/15/24 07:42:47.615
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:42:47.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:42:47.649
  Apr 15 07:42:47.654: INFO: Creating ReplicaSet my-hostname-basic-0ab372f0-b93b-4bcc-9692-82961ec2f43c
  Apr 15 07:42:47.689: INFO: Pod name my-hostname-basic-0ab372f0-b93b-4bcc-9692-82961ec2f43c: Found 0 pods out of 1
  E0415 07:42:48.533424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:49.533739      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:50.534028      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:51.534786      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:52.534636      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:42:52.709: INFO: Pod name my-hostname-basic-0ab372f0-b93b-4bcc-9692-82961ec2f43c: Found 1 pods out of 1
  Apr 15 07:42:52.710: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0ab372f0-b93b-4bcc-9692-82961ec2f43c" is running
  Apr 15 07:42:52.717: INFO: Pod "my-hostname-basic-0ab372f0-b93b-4bcc-9692-82961ec2f43c-jr8r9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-15 07:42:47 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-15 07:42:48 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-15 07:42:48 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-15 07:42:47 +0000 UTC Reason: Message:}])
  Apr 15 07:42:52.717: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/15/24 07:42:52.717
  Apr 15 07:42:52.741: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9733" for this suite. @ 04/15/24 07:42:52.751
â€¢ [5.155 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:321
  STEP: Creating a kubernetes client @ 04/15/24 07:42:52.777
  Apr 15 07:42:52.777: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename gc @ 04/15/24 07:42:52.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:42:52.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:42:52.836
  STEP: create the rc @ 04/15/24 07:42:52.843
  W0415 07:42:52.857183      13 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0415 07:42:53.535461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:54.535639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:55.535934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:56.536122      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:57.536268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/15/24 07:42:57.888
  STEP: wait for all pods to be garbage collected @ 04/15/24 07:42:57.911
  E0415 07:42:58.536880      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:42:59.537190      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:00.538699      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:01.538311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:02.538451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/15/24 07:43:02.932
  Apr 15 07:43:03.252: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 15 07:43:03.254: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7224" for this suite. @ 04/15/24 07:43:03.274
â€¢ [10.523 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:398
  STEP: Creating a kubernetes client @ 04/15/24 07:43:03.301
  Apr 15 07:43:03.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename namespaces @ 04/15/24 07:43:03.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:03.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:03.406
  STEP: Creating namespace "e2e-ns-2529t" @ 04/15/24 07:43:03.417
  Apr 15 07:43:03.464: INFO: Namespace "e2e-ns-2529t-9380" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-2529t-9380" @ 04/15/24 07:43:03.465
  Apr 15 07:43:03.487: INFO: Namespace "e2e-ns-2529t-9380" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-2529t-9380" @ 04/15/24 07:43:03.488
  Apr 15 07:43:03.514: INFO: Namespace "e2e-ns-2529t-9380" has []v1.FinalizerName{"kubernetes"}
  Apr 15 07:43:03.515: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1567" for this suite. @ 04/15/24 07:43:03.527
  E0415 07:43:03.538910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "e2e-ns-2529t-9380" for this suite. @ 04/15/24 07:43:03.549
â€¢ [0.264 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
test/e2e/kubectl/kubectl.go:1641
  STEP: Creating a kubernetes client @ 04/15/24 07:43:03.571
  Apr 15 07:43:03.571: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 07:43:03.574
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:03.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:03.624
  STEP: creating Agnhost RC @ 04/15/24 07:43:03.631
  Apr 15 07:43:03.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-5936 create -f -'
  E0415 07:43:04.539734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:05.282: INFO: stderr: ""
  Apr 15 07:43:05.283: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/15/24 07:43:05.284
  E0415 07:43:05.541813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:06.299: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 15 07:43:06.299: INFO: Found 0 / 1
  E0415 07:43:06.541783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:07.296: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 15 07:43:07.296: INFO: Found 1 / 1
  Apr 15 07:43:07.296: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 04/15/24 07:43:07.296
  Apr 15 07:43:07.311: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 15 07:43:07.311: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 15 07:43:07.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-5936 patch pod agnhost-primary-jwjtj -p {"metadata":{"annotations":{"x":"y"}}}'
  E0415 07:43:07.542424      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:07.581: INFO: stderr: ""
  Apr 15 07:43:07.581: INFO: stdout: "pod/agnhost-primary-jwjtj patched\n"
  STEP: checking annotations @ 04/15/24 07:43:07.581
  Apr 15 07:43:07.590: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 15 07:43:07.590: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 15 07:43:07.590: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5936" for this suite. @ 04/15/24 07:43:07.611
â€¢ [4.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance]
test/e2e/common/node/lease.go:72
  STEP: Creating a kubernetes client @ 04/15/24 07:43:07.647
  Apr 15 07:43:07.647: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename lease-test @ 04/15/24 07:43:07.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:07.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:07.699
  Apr 15 07:43:07.875: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-5384" for this suite. @ 04/15/24 07:43:07.888
â€¢ [0.266 seconds]
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 04/15/24 07:43:07.913
  Apr 15 07:43:07.913: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename tables @ 04/15/24 07:43:07.916
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:07.948
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:07.956
  Apr 15 07:43:07.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-4633" for this suite. @ 04/15/24 07:43:08.011
â€¢ [0.126 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 04/15/24 07:43:08.051
  Apr 15 07:43:08.051: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 07:43:08.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:08.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:08.143
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-274 @ 04/15/24 07:43:08.151
  STEP: changing the ExternalName service to type=ClusterIP @ 04/15/24 07:43:08.191
  STEP: creating replication controller externalname-service in namespace services-274 @ 04/15/24 07:43:08.263
  I0415 07:43:08.290272      13 runners.go:197] Created replication controller with name: externalname-service, namespace: services-274, replica count: 2
  E0415 07:43:08.544543      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:09.543663      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:10.543714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 07:43:11.350721      13 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 15 07:43:11.350: INFO: Creating new exec pod
  E0415 07:43:11.545139      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:12.545272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:13.545144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:14.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-274 exec execpod66tvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0415 07:43:14.545497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:15.545762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:16.545981      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:16.811: INFO: rc: 1
  Apr 15 07:43:16.811: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-274 exec execpod66tvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 externalname-service 80
  nc: connect to externalname-service port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  E0415 07:43:17.547066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:17.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-274 exec execpod66tvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 15 07:43:18.138: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 15 07:43:18.138: INFO: stdout: ""
  E0415 07:43:18.548040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:18.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-274 exec execpod66tvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0415 07:43:19.548846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:20.549144      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:21.184: INFO: rc: 1
  Apr 15 07:43:21.184: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-274 exec execpod66tvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 externalname-service 80
  nc: connect to externalname-service port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  E0415 07:43:21.549713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:21.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-274 exec execpod66tvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  E0415 07:43:22.549785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:23.172: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 15 07:43:23.172: INFO: stdout: ""
  E0415 07:43:23.550720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:23.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-274 exec execpod66tvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 15 07:43:24.110: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 15 07:43:24.110: INFO: stdout: ""
  E0415 07:43:24.551541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:24.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-274 exec execpod66tvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 15 07:43:25.142: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 15 07:43:25.142: INFO: stdout: "externalname-service-czmmp"
  Apr 15 07:43:25.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-274 exec execpod66tvd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.54.3 80'
  Apr 15 07:43:25.432: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.54.3 80\nConnection to 10.233.54.3 80 port [tcp/http] succeeded!\n"
  Apr 15 07:43:25.432: INFO: stdout: "externalname-service-czmmp"
  Apr 15 07:43:25.432: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 07:43:25.444: INFO: Cleaning up the ExternalName to ClusterIP test service
  STEP: Destroying namespace "services-274" for this suite. @ 04/15/24 07:43:25.504
â€¢ [17.467 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
test/e2e/apps/rc.go:94
  STEP: Creating a kubernetes client @ 04/15/24 07:43:25.522
  Apr 15 07:43:25.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename replication-controller @ 04/15/24 07:43:25.524
  E0415 07:43:25.551783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:25.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:25.56
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 04/15/24 07:43:25.565
  E0415 07:43:26.552332      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:27.552469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 04/15/24 07:43:27.617
  STEP: Then the orphan pod is adopted @ 04/15/24 07:43:27.636
  E0415 07:43:28.553569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:28.664: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9390" for this suite. @ 04/15/24 07:43:28.679
â€¢ [3.171 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 04/15/24 07:43:28.7
  Apr 15 07:43:28.700: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubelet-test @ 04/15/24 07:43:28.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:28.742
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:28.748
  Apr 15 07:43:28.800: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6266" for this suite. @ 04/15/24 07:43:28.817
â€¢ [0.131 seconds]
------------------------------
SS
------------------------------
[sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]
test/e2e/storage/csistoragecapacity.go:49
  STEP: Creating a kubernetes client @ 04/15/24 07:43:28.833
  Apr 15 07:43:28.833: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename csistoragecapacity @ 04/15/24 07:43:28.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:28.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:28.876
  STEP: getting /apis @ 04/15/24 07:43:28.882
  STEP: getting /apis/storage.k8s.io @ 04/15/24 07:43:28.891
  STEP: getting /apis/storage.k8s.io/v1 @ 04/15/24 07:43:28.893
  STEP: creating @ 04/15/24 07:43:28.896
  STEP: watching @ 04/15/24 07:43:28.927
  Apr 15 07:43:28.927: INFO: starting watch
  STEP: getting @ 04/15/24 07:43:28.944
  STEP: listing in namespace @ 04/15/24 07:43:28.951
  STEP: listing across namespaces @ 04/15/24 07:43:28.958
  STEP: patching @ 04/15/24 07:43:28.963
  STEP: updating @ 04/15/24 07:43:28.975
  Apr 15 07:43:28.984: INFO: waiting for watch events with expected annotations in namespace
  Apr 15 07:43:28.985: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 04/15/24 07:43:28.986
  STEP: deleting a collection @ 04/15/24 07:43:29.009
  Apr 15 07:43:29.039: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-4054" for this suite. @ 04/15/24 07:43:29.058
â€¢ [0.240 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 04/15/24 07:43:29.076
  Apr 15 07:43:29.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename dns @ 04/15/24 07:43:29.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:29.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:29.142
  STEP: Creating a test headless service @ 04/15/24 07:43:29.148
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2526.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2526.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 04/15/24 07:43:29.159
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2526.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2526.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 04/15/24 07:43:29.159
  STEP: creating a pod to probe DNS @ 04/15/24 07:43:29.159
  STEP: submitting the pod to kubernetes @ 04/15/24 07:43:29.159
  E0415 07:43:29.553898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:30.554875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/15/24 07:43:31.227
  STEP: looking for the results for each expected name from probers @ 04/15/24 07:43:31.239
  Apr 15 07:43:31.354: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-2526/dns-test-fbe3ab92-02fa-4da5-ac2a-487c98f5cf4f: the server could not find the requested resource (get pods dns-test-fbe3ab92-02fa-4da5-ac2a-487c98f5cf4f)
  Apr 15 07:43:31.355: INFO: Lookups using dns-2526/dns-test-fbe3ab92-02fa-4da5-ac2a-487c98f5cf4f failed for: [jessie_hosts@dns-querier-2]

  Apr 15 07:43:31.378: INFO: Pod client logs for webserver: 
  Apr 15 07:43:31.393: INFO: Pod client logs for querier: 
  Apr 15 07:43:31.413: INFO: Pod client logs for jessie-querier: 
  E0415 07:43:31.555351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:32.555162      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:33.556001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:34.556314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:35.556691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:36.446: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-2526/dns-test-fbe3ab92-02fa-4da5-ac2a-487c98f5cf4f: the server could not find the requested resource (get pods dns-test-fbe3ab92-02fa-4da5-ac2a-487c98f5cf4f)
  Apr 15 07:43:36.446: INFO: Lookups using dns-2526/dns-test-fbe3ab92-02fa-4da5-ac2a-487c98f5cf4f failed for: [jessie_hosts@dns-querier-2]

  Apr 15 07:43:36.462: INFO: Pod client logs for webserver: 
  Apr 15 07:43:36.478: INFO: Pod client logs for querier: 
  Apr 15 07:43:36.513: INFO: Pod client logs for jessie-querier: 
  E0415 07:43:36.556777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:37.557146      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:38.558115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:39.558973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:40.558943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:41.461: INFO: DNS probes using dns-2526/dns-test-fbe3ab92-02fa-4da5-ac2a-487c98f5cf4f succeeded

  Apr 15 07:43:41.462: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:43:41.478
  STEP: deleting the test headless service @ 04/15/24 07:43:41.545
  E0415 07:43:41.559205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "dns-2526" for this suite. @ 04/15/24 07:43:41.639
â€¢ [12.622 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 04/15/24 07:43:41.699
  Apr 15 07:43:41.699: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 07:43:41.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:41.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:41.74
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-2616 @ 04/15/24 07:43:41.748
  STEP: changing the ExternalName service to type=NodePort @ 04/15/24 07:43:41.765
  STEP: creating replication controller externalname-service in namespace services-2616 @ 04/15/24 07:43:41.854
  I0415 07:43:41.877231      13 runners.go:197] Created replication controller with name: externalname-service, namespace: services-2616, replica count: 2
  E0415 07:43:42.561690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:43.561652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:44.561793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  I0415 07:43:44.939024      13 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 15 07:43:44.939: INFO: Creating new exec pod
  E0415 07:43:45.562083      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:46.562227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:47.562908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:47.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-2616 exec execpodfvg6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 15 07:43:48.412: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 15 07:43:48.412: INFO: stdout: "externalname-service-zhtn7"
  Apr 15 07:43:48.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-2616 exec execpodfvg6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.36.154 80'
  E0415 07:43:48.563680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:48.685: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.36.154 80\nConnection to 10.233.36.154 80 port [tcp/http] succeeded!\n"
  Apr 15 07:43:48.685: INFO: stdout: "externalname-service-zhtn7"
  Apr 15 07:43:48.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-2616 exec execpodfvg6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.206 31268'
  Apr 15 07:43:48.971: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.206 31268\nConnection to 192.168.121.206 31268 port [tcp/*] succeeded!\n"
  Apr 15 07:43:48.971: INFO: stdout: "externalname-service-zhtn7"
  Apr 15 07:43:48.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-2616 exec execpodfvg6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.141 31268'
  Apr 15 07:43:49.289: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.141 31268\nConnection to 192.168.121.141 31268 port [tcp/*] succeeded!\n"
  Apr 15 07:43:49.289: INFO: stdout: ""
  E0415 07:43:49.564808      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:50.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-2616 exec execpodfvg6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.141 31268'
  E0415 07:43:50.565351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:50.595: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.141 31268\nConnection to 192.168.121.141 31268 port [tcp/*] succeeded!\n"
  Apr 15 07:43:50.595: INFO: stdout: ""
  Apr 15 07:43:51.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-2616 exec execpodfvg6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.141 31268'
  E0415 07:43:51.565754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:51.570: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.141 31268\nConnection to 192.168.121.141 31268 port [tcp/*] succeeded!\n"
  Apr 15 07:43:51.570: INFO: stdout: "externalname-service-zhtn7"
  Apr 15 07:43:51.570: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Apr 15 07:43:51.608: INFO: Cleaning up the ExternalName to NodePort test service
  STEP: Destroying namespace "services-2616" for this suite. @ 04/15/24 07:43:51.667
â€¢ [10.004 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 04/15/24 07:43:51.704
  Apr 15 07:43:51.704: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/15/24 07:43:51.707
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:51.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:51.785
  Apr 15 07:43:51.794: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:43:52.566483      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:53.566563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/15/24 07:43:54.125
  Apr 15 07:43:54.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-9081 --namespace=crd-publish-openapi-9081 create -f -'
  E0415 07:43:54.567615      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:55.567898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:55.575: INFO: stderr: ""
  Apr 15 07:43:55.575: INFO: stdout: "e2e-test-crd-publish-openapi-1539-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 15 07:43:55.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-9081 --namespace=crd-publish-openapi-9081 delete e2e-test-crd-publish-openapi-1539-crds test-cr'
  Apr 15 07:43:55.746: INFO: stderr: ""
  Apr 15 07:43:55.747: INFO: stdout: "e2e-test-crd-publish-openapi-1539-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Apr 15 07:43:55.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-9081 --namespace=crd-publish-openapi-9081 apply -f -'
  Apr 15 07:43:56.211: INFO: stderr: ""
  Apr 15 07:43:56.211: INFO: stdout: "e2e-test-crd-publish-openapi-1539-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 15 07:43:56.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-9081 --namespace=crd-publish-openapi-9081 delete e2e-test-crd-publish-openapi-1539-crds test-cr'
  Apr 15 07:43:56.383: INFO: stderr: ""
  Apr 15 07:43:56.383: INFO: stdout: "e2e-test-crd-publish-openapi-1539-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/15/24 07:43:56.383
  Apr 15 07:43:56.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=crd-publish-openapi-9081 explain e2e-test-crd-publish-openapi-1539-crds'
  E0415 07:43:56.568482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:57.483: INFO: stderr: ""
  Apr 15 07:43:57.483: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-1539-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0415 07:43:57.568734      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:58.569813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:43:59.570945      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:43:59.724: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9081" for this suite. @ 04/15/24 07:43:59.747
â€¢ [8.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 04/15/24 07:43:59.768
  Apr 15 07:43:59.768: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename disruption @ 04/15/24 07:43:59.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:43:59.799
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:43:59.805
  STEP: Creating a pdb that targets all three pods in a test replica set @ 04/15/24 07:43:59.818
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:43:59.838
  E0415 07:44:00.571790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:01.571999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 04/15/24 07:44:01.892
  STEP: Waiting for all pods to be running @ 04/15/24 07:44:01.892
  Apr 15 07:44:01.910: INFO: pods: 0 < 3
  E0415 07:44:02.572580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:03.574252      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:44:03.928: INFO: running pods: 1 < 3
  E0415 07:44:04.573875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:05.574059      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/15/24 07:44:05.92
  STEP: Updating the pdb to allow a pod to be evicted @ 04/15/24 07:44:05.947
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:44:05.978
  E0415 07:44:06.574353      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:07.574764      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/15/24 07:44:07.995
  STEP: Waiting for all pods to be running @ 04/15/24 07:44:07.995
  STEP: Waiting for the pdb to observed all healthy pods @ 04/15/24 07:44:08.003
  STEP: Patching the pdb to disallow a pod to be evicted @ 04/15/24 07:44:08.063
  STEP: Waiting for the pdb to be processed @ 04/15/24 07:44:08.121
  E0415 07:44:08.575066      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:09.575291      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 04/15/24 07:44:10.156
  STEP: locating a running pod @ 04/15/24 07:44:10.169
  STEP: Deleting the pdb to allow a pod to be evicted @ 04/15/24 07:44:10.194
  STEP: Waiting for the pdb to be deleted @ 04/15/24 07:44:10.213
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/15/24 07:44:10.219
  STEP: Waiting for all pods to be running @ 04/15/24 07:44:10.22
  Apr 15 07:44:10.276: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3839" for this suite. @ 04/15/24 07:44:10.35
â€¢ [10.613 seconds]
------------------------------
SS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 04/15/24 07:44:10.382
  Apr 15 07:44:10.382: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename taint-single-pod @ 04/15/24 07:44:10.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:44:10.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:44:10.456
  Apr 15 07:44:10.465: INFO: Waiting up to 1m0s for all nodes to be ready
  E0415 07:44:10.575500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:11.576238      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:12.577281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:13.578222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:14.580557      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:15.578706      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:16.579526      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:17.579993      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:18.590611      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:19.590584      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:20.590743      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:21.591664      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:22.592576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:23.592921      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:24.593363      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:25.594208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:26.594618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:27.594879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:28.595963      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:29.596713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:30.597397      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:31.597996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:32.598593      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:33.599020      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:34.599263      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:35.600085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:36.600781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:37.601012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:38.601623      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:39.602689      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:40.602788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:41.602954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:42.603817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:43.604358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:44.605268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:45.605399      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:46.606355      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:47.607403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:48.607442      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:49.607620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:50.608769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:51.608962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:52.609892      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:53.610106      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:54.610314      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:55.610458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:56.611015      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:57.611730      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:58.612759      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:44:59.612967      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:00.614039      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:01.614281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:02.615301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:03.615465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:04.615996      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:05.617096      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:06.617525      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:07.617978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:08.618879      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:09.619111      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:45:10.521: INFO: Waiting for terminating namespaces to be deleted...
  Apr 15 07:45:10.531: INFO: Starting informer...
  STEP: Starting pod... @ 04/15/24 07:45:10.532
  E0415 07:45:10.620319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:45:10.784: INFO: Pod is running on phiefi7ighaa-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/15/24 07:45:10.784
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/15/24 07:45:10.82
  STEP: Waiting short time to make sure Pod is queued for deletion @ 04/15/24 07:45:10.86
  Apr 15 07:45:10.861: INFO: Pod wasn't evicted. Proceeding
  Apr 15 07:45:10.863: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/15/24 07:45:10.924
  STEP: Waiting some time to make sure that toleration time passed. @ 04/15/24 07:45:11.01
  E0415 07:45:11.620569      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:12.621672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:13.622310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:14.622462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:15.623691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:16.624372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:17.625367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:18.625599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:19.625790      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:20.625965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:21.626495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:22.626540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:23.626665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:24.627472      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:25.627744      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:26.627866      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:27.628454      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:28.628633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:29.629158      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:30.629157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:31.629545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:32.629680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:33.630374      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:34.631157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:35.632030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:36.632762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:37.632817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:38.633001      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:39.633208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:40.633338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:41.634157      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:42.634800      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:43.635067      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:44.636402      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:45.636477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:46.636582      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:47.636932      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:48.637943      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:49.638224      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:50.638831      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:51.639439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:52.639666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:53.639924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:54.640377      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:55.641033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:56.641648      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:57.642957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:58.642618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:45:59.643245      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:00.645051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:01.646209      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:02.646917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:03.647308      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:04.647890      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:05.648562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:06.649555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:07.649948      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:08.650279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:09.651208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:10.651763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:11.652204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:12.652690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:13.653807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:14.653842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:15.654539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:16.655054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:17.655465      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:18.661814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:19.662679      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:20.662240      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:21.662348      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:22.662477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:23.662665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:24.663674      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:25.663826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:46:26.011: INFO: Pod wasn't evicted. Test successful
  Apr 15 07:46:26.011: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-2772" for this suite. @ 04/15/24 07:46:26.033
â€¢ [135.673 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 04/15/24 07:46:26.061
  Apr 15 07:46:26.061: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 07:46:26.066
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:46:26.113
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:46:26.119
  STEP: Setting up server cert @ 04/15/24 07:46:26.175
  E0415 07:46:26.664040      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 07:46:27.091
  STEP: Deploying the webhook pod @ 04/15/24 07:46:27.112
  STEP: Wait for the deployment to be ready @ 04/15/24 07:46:27.155
  Apr 15 07:46:27.193: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 07:46:27.664733      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:28.664862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 07:46:29.221
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 07:46:29.255
  E0415 07:46:29.665691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:46:30.256: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 15 07:46:30.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:46:30.666613      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8184-crds.webhook.example.com via the AdmissionRegistration API @ 04/15/24 07:46:30.805
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/15/24 07:46:30.846
  E0415 07:46:31.666592      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:32.667369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:46:33.139: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 07:46:33.668500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-283" for this suite. @ 04/15/24 07:46:33.926
  STEP: Destroying namespace "webhook-markers-962" for this suite. @ 04/15/24 07:46:33.939
â€¢ [7.890 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 04/15/24 07:46:33.955
  Apr 15 07:46:33.955: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename containers @ 04/15/24 07:46:33.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:46:33.992
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:46:33.997
  STEP: Creating a pod to test override all @ 04/15/24 07:46:34.005
  E0415 07:46:34.668865      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:35.668718      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:36.669680      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:37.669941      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:46:38.066
  Apr 15 07:46:38.072: INFO: Trying to get logs from node phiefi7ighaa-3 pod client-containers-96eae466-a215-4cc2-8fd9-e7bae3997593 container agnhost-container: <nil>
  STEP: delete the pod @ 04/15/24 07:46:38.098
  Apr 15 07:46:38.128: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3514" for this suite. @ 04/15/24 07:46:38.138
â€¢ [4.194 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:167
  STEP: Creating a kubernetes client @ 04/15/24 07:46:38.15
  Apr 15 07:46:38.150: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 07:46:38.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:46:38.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:46:38.193
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/15/24 07:46:38.2
  E0415 07:46:38.671008      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:39.672638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:40.672407      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:41.673287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:46:42.25
  Apr 15 07:46:42.255: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-00637fed-a768-4664-b83b-529289ae277f container test-container: <nil>
  STEP: delete the pod @ 04/15/24 07:46:42.265
  Apr 15 07:46:42.284: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6598" for this suite. @ 04/15/24 07:46:42.294
â€¢ [4.157 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
test/e2e/common/storage/empty_dir.go:227
  STEP: Creating a kubernetes client @ 04/15/24 07:46:42.31
  Apr 15 07:46:42.311: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 07:46:42.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:46:42.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:46:42.346
  STEP: Creating Pod @ 04/15/24 07:46:42.35
  E0415 07:46:42.673898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:43.674576      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 04/15/24 07:46:44.384
  Apr 15 07:46:44.384: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3817 PodName:pod-sharedvolume-588e0640-f7a7-45c5-aeac-b3aa4e7fbde2 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 15 07:46:44.384: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  Apr 15 07:46:44.386: INFO: ExecWithOptions: Clientset creation
  Apr 15 07:46:44.386: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-3817/pods/pod-sharedvolume-588e0640-f7a7-45c5-aeac-b3aa4e7fbde2/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Apr 15 07:46:44.490: INFO: Exec stderr: ""
  Apr 15 07:46:44.490: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3817" for this suite. @ 04/15/24 07:46:44.498
â€¢ [2.199 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:808
  STEP: Creating a kubernetes client @ 04/15/24 07:46:44.512
  Apr 15 07:46:44.512: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename svcaccounts @ 04/15/24 07:46:44.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:46:44.542
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:46:44.547
  STEP: Creating ServiceAccount "e2e-sa-h928j"  @ 04/15/24 07:46:44.551
  Apr 15 07:46:44.557: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-h928j"  @ 04/15/24 07:46:44.558
  Apr 15 07:46:44.576: INFO: AutomountServiceAccountToken: true
  Apr 15 07:46:44.577: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9995" for this suite. @ 04/15/24 07:46:44.588
â€¢ [0.089 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:117
  STEP: Creating a kubernetes client @ 04/15/24 07:46:44.602
  Apr 15 07:46:44.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename emptydir @ 04/15/24 07:46:44.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:46:44.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:46:44.645
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/15/24 07:46:44.652
  E0415 07:46:44.675048      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:45.675445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:46.675573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:47.675773      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:48.676362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:46:48.698
  Apr 15 07:46:48.704: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-4067ce91-5b6b-4d75-919e-e55634646216 container test-container: <nil>
  STEP: delete the pod @ 04/15/24 07:46:48.718
  Apr 15 07:46:48.748: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9006" for this suite. @ 04/15/24 07:46:48.761
â€¢ [4.173 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 04/15/24 07:46:48.779
  Apr 15 07:46:48.780: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename init-container @ 04/15/24 07:46:48.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:46:48.817
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:46:48.823
  STEP: creating the pod @ 04/15/24 07:46:48.829
  Apr 15 07:46:48.829: INFO: PodSpec: initContainers in spec.initContainers
  E0415 07:46:49.676434      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:50.677461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:51.677535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:52.685937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:53.680448      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:54.681556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:55.681632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:56.682349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:57.682723      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:58.683250      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:46:59.683600      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:00.684860      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:01.685702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:02.686319      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:03.686656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:04.687281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:05.687639      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:06.687989      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:07.688138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:08.689315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:09.689660      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:10.690606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:11.691021      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:12.691620      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:13.692528      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:14.693595      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:15.693794      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:16.694080      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:17.694228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:18.694493      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:19.694952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:20.695024      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:21.695538      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:22.695771      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:23.695711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:24.696578      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:25.697433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:26.698213      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:27.698788      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:28.699524      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:29.699826      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:30.700090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:31.700813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:32.701506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:47:33.280: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-71abd4e3-4f89-4c8e-b9d1-3d018cdee9ce", GenerateName:"", Namespace:"init-container-316", SelfLink:"", UID:"31900edf-7a25-4431-96fc-259fb1e3d5d4", ResourceVersion:"175039", Generation:0, CreationTimestamp:time.Date(2024, time.April, 15, 7, 46, 48, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"829570002"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 15, 7, 46, 48, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001462c18), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 15, 7, 47, 33, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001462c48), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-4nl2n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004cd2300), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-4nl2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-4nl2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-4nl2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004921e68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"phiefi7ighaa-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0000f6850), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004921ef0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004921f10)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004921f18), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004921f1c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc002d74ee0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 15, 7, 46, 48, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 15, 7, 46, 48, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 15, 7, 46, 48, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 15, 7, 46, 48, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.206", HostIPs:[]v1.HostIP(nil), PodIP:"10.233.66.111", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.66.111"}}, StartTime:time.Date(2024, time.April, 15, 7, 46, 48, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0000f6a10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0000f6af0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"cri-o://da5c446623030cb6c6bde438d55d55995f802a206386654eeed0675e61b8e5d8", Started:(*bool)(0xc004921fbf), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004cd23a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(0xc004921fc5), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004cd2380), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc004921f94), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Apr 15 07:47:33.285: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-316" for this suite. @ 04/15/24 07:47:33.303
â€¢ [44.547 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
test/e2e/apimachinery/resource_quota.go:161
  STEP: Creating a kubernetes client @ 04/15/24 07:47:33.343
  Apr 15 07:47:33.343: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename resourcequota @ 04/15/24 07:47:33.35
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:47:33.393
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:47:33.399
  STEP: Discovering how many secrets are in namespace by default @ 04/15/24 07:47:33.407
  E0415 07:47:33.701897      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:34.702652      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:35.703317      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:36.703799      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:37.704577      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 04/15/24 07:47:38.417
  E0415 07:47:38.705368      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:39.706535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:40.706690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:41.707391      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:42.708696      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 04/15/24 07:47:43.426
  STEP: Ensuring resource quota status is calculated @ 04/15/24 07:47:43.447
  E0415 07:47:43.709264      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:44.709560      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 04/15/24 07:47:45.456
  STEP: Ensuring resource quota status captures secret creation @ 04/15/24 07:47:45.491
  E0415 07:47:45.710654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:46.711561      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 04/15/24 07:47:47.501
  STEP: Ensuring resource quota status released usage @ 04/15/24 07:47:47.514
  E0415 07:47:47.712212      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:48.712556      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:47:49.525: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9256" for this suite. @ 04/15/24 07:47:49.537
â€¢ [16.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 04/15/24 07:47:49.556
  Apr 15 07:47:49.556: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename secrets @ 04/15/24 07:47:49.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:47:49.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:47:49.596
  STEP: Creating secret with name secret-test-2d8f3872-5034-49b2-8cf1-cfecb29b9fbf @ 04/15/24 07:47:49.604
  STEP: Creating a pod to test consume secrets @ 04/15/24 07:47:49.617
  E0415 07:47:49.712469      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:50.713085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:51.713401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:52.714847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:47:53.674
  Apr 15 07:47:53.681: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-secrets-1cd8ec8e-70fe-4c79-8219-171242cfdb86 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 07:47:53.703
  E0415 07:47:53.715163      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:47:53.735: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8499" for this suite. @ 04/15/24 07:47:53.745
â€¢ [4.204 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 04/15/24 07:47:53.764
  Apr 15 07:47:53.764: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-probe @ 04/15/24 07:47:53.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:47:53.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:47:53.801
  E0415 07:47:54.715433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:55.715369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:56.715762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:57.715954      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:58.716761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:47:59.717058      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:00.717290      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:01.717421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:02.717515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:03.717817      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:04.718506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:05.718853      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:06.719049      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:07.719925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:08.720335      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:09.721211      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:10.721551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:11.721684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:12.721795      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:13.722008      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:14.722617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:15.722889      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:48:15.961: INFO: Container started at 2024-04-15 07:47:54 +0000 UTC, pod became ready at 2024-04-15 07:48:14 +0000 UTC
  Apr 15 07:48:15.961: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3837" for this suite. @ 04/15/24 07:48:15.974
â€¢ [22.233 seconds]
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
test/e2e/apps/job.go:370
  STEP: Creating a kubernetes client @ 04/15/24 07:48:15.999
  Apr 15 07:48:16.000: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename job @ 04/15/24 07:48:16.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:48:16.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:48:16.044
  STEP: Creating Indexed job @ 04/15/24 07:48:16.049
  STEP: Ensuring job reaches completions @ 04/15/24 07:48:16.06
  E0415 07:48:16.727820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:17.730054      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:18.729202      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:19.778716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:20.767957      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:21.767807      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:22.769305      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:23.769572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 04/15/24 07:48:24.069
  Apr 15 07:48:24.081: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-6981" for this suite. @ 04/15/24 07:48:24.095
â€¢ [8.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance]
test/e2e/network/service.go:3142
  STEP: Creating a kubernetes client @ 04/15/24 07:48:24.125
  Apr 15 07:48:24.125: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 07:48:24.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:48:24.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:48:24.179
  STEP: creating an Endpoint @ 04/15/24 07:48:24.193
  STEP: waiting for available Endpoint @ 04/15/24 07:48:24.227
  STEP: listing all Endpoints @ 04/15/24 07:48:24.231
  STEP: updating the Endpoint @ 04/15/24 07:48:24.24
  STEP: fetching the Endpoint @ 04/15/24 07:48:24.251
  STEP: patching the Endpoint @ 04/15/24 07:48:24.257
  STEP: fetching the Endpoint @ 04/15/24 07:48:24.273
  STEP: deleting the Endpoint by Collection @ 04/15/24 07:48:24.278
  STEP: waiting for Endpoint deletion @ 04/15/24 07:48:24.294
  STEP: fetching the Endpoint @ 04/15/24 07:48:24.297
  Apr 15 07:48:24.303: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-502" for this suite. @ 04/15/24 07:48:24.312
â€¢ [0.201 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 04/15/24 07:48:24.331
  Apr 15 07:48:24.331: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/15/24 07:48:24.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:48:24.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:48:24.38
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 04/15/24 07:48:24.385
  Apr 15 07:48:24.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:48:24.769964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:25.770714      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:26.771467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:27.772540      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:28.772816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:29.773708      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:30.774078      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:31.774988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 04/15/24 07:48:32.218
  Apr 15 07:48:32.220: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:48:32.775126      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:33.776060      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:48:34.019: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:48:34.777279      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:35.778114      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:36.789511      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:37.789178      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:38.789482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:39.789429      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:40.789440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:48:41.579: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4349" for this suite. @ 04/15/24 07:48:41.6
â€¢ [17.288 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance]
test/e2e/network/service.go:3117
  STEP: Creating a kubernetes client @ 04/15/24 07:48:41.627
  Apr 15 07:48:41.628: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 07:48:41.63
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:48:41.665
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:48:41.669
  STEP: fetching services @ 04/15/24 07:48:41.676
  Apr 15 07:48:41.683: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-448" for this suite. @ 04/15/24 07:48:41.69
â€¢ [0.075 seconds]
------------------------------
SS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance]
test/e2e/common/node/podtemplates.go:122
  STEP: Creating a kubernetes client @ 04/15/24 07:48:41.702
  Apr 15 07:48:41.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename podtemplate @ 04/15/24 07:48:41.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:48:41.741
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:48:41.747
  STEP: Create set of pod templates @ 04/15/24 07:48:41.752
  Apr 15 07:48:41.762: INFO: created test-podtemplate-1
  Apr 15 07:48:41.771: INFO: created test-podtemplate-2
  Apr 15 07:48:41.780: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 04/15/24 07:48:41.78
  STEP: delete collection of pod templates @ 04/15/24 07:48:41.785
  Apr 15 07:48:41.785: INFO: requesting DeleteCollection of pod templates
  E0415 07:48:41.789445      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check that the list of pod templates matches the requested quantity @ 04/15/24 07:48:41.827
  Apr 15 07:48:41.827: INFO: requesting list of pod templates to confirm quantity
  Apr 15 07:48:41.849: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-2479" for this suite. @ 04/15/24 07:48:41.859
â€¢ [0.173 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]
test/e2e/kubectl/kubectl.go:1806
  STEP: Creating a kubernetes client @ 04/15/24 07:48:41.883
  Apr 15 07:48:41.883: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename kubectl @ 04/15/24 07:48:41.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:48:41.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:48:41.929
  STEP: Starting the proxy @ 04/15/24 07:48:41.937
  Apr 15 07:48:41.939: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=kubectl-2982 proxy --unix-socket=/tmp/kubectl-proxy-unix2269026108/test'
  STEP: retrieving proxy /api/ output @ 04/15/24 07:48:42.117
  Apr 15 07:48:42.121: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2982" for this suite. @ 04/15/24 07:48:42.131
â€¢ [0.259 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance]
test/e2e/instrumentation/core_events.go:175
  STEP: Creating a kubernetes client @ 04/15/24 07:48:42.143
  Apr 15 07:48:42.143: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename events @ 04/15/24 07:48:42.146
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:48:42.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:48:42.181
  STEP: Create set of events @ 04/15/24 07:48:42.185
  Apr 15 07:48:42.197: INFO: created test-event-1
  Apr 15 07:48:42.207: INFO: created test-event-2
  Apr 15 07:48:42.216: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 04/15/24 07:48:42.216
  STEP: delete collection of events @ 04/15/24 07:48:42.222
  Apr 15 07:48:42.222: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/15/24 07:48:42.262
  Apr 15 07:48:42.263: INFO: requesting list of events to confirm quantity
  Apr 15 07:48:42.268: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-5130" for this suite. @ 04/15/24 07:48:42.275
â€¢ [0.148 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]
test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 04/15/24 07:48:42.291
  Apr 15 07:48:42.291: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename subpath @ 04/15/24 07:48:42.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:48:42.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:48:42.328
  STEP: Setting up data @ 04/15/24 07:48:42.332
  STEP: Creating pod pod-subpath-test-configmap-mpns @ 04/15/24 07:48:42.35
  STEP: Creating a pod to test atomic-volume-subpath @ 04/15/24 07:48:42.35
  E0415 07:48:42.790515      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:43.791340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:44.792325      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:45.793241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:46.793918      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:47.794303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:48.793978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:49.794746      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:50.795121      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:51.796204      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:52.796848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:53.797401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:54.797962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:55.798705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:56.799227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:57.799403      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:58.799555      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:48:59.800662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:00.801349      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:01.801599      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:02.802316      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:03.802925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:04.803898      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:05.804724      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:49:06.48
  Apr 15 07:49:06.486: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-subpath-test-configmap-mpns container test-container-subpath-configmap-mpns: <nil>
  STEP: delete the pod @ 04/15/24 07:49:06.517
  STEP: Deleting pod pod-subpath-test-configmap-mpns @ 04/15/24 07:49:06.553
  Apr 15 07:49:06.553: INFO: Deleting pod "pod-subpath-test-configmap-mpns" in namespace "subpath-7362"
  Apr 15 07:49:06.561: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7362" for this suite. @ 04/15/24 07:49:06.572
â€¢ [24.302 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 04/15/24 07:49:06.601
  Apr 15 07:49:06.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 07:49:06.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:49:06.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:49:06.661
  STEP: Setting up server cert @ 04/15/24 07:49:06.712
  E0415 07:49:06.805740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:07.806847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 07:49:07.938
  STEP: Deploying the webhook pod @ 04/15/24 07:49:07.961
  STEP: Wait for the deployment to be ready @ 04/15/24 07:49:07.986
  Apr 15 07:49:08.000: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0415 07:49:08.806899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:09.807960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:49:10.026: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 15, 7, 49, 8, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 7, 49, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 15, 7, 49, 8, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 15, 7, 49, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7c55c7d74c\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0415 07:49:10.808814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:11.808624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 07:49:12.037
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 07:49:12.073
  E0415 07:49:12.809217      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:49:13.075: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/15/24 07:49:13.262
  STEP: Creating a configMap that should be mutated @ 04/15/24 07:49:13.293
  STEP: Deleting the collection of validation webhooks @ 04/15/24 07:49:13.353
  STEP: Creating a configMap that should not be mutated @ 04/15/24 07:49:13.464
  Apr 15 07:49:13.620: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1597" for this suite. @ 04/15/24 07:49:13.742
  STEP: Destroying namespace "webhook-markers-5579" for this suite. @ 04/15/24 07:49:13.766
â€¢ [7.189 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]
test/e2e/scheduling/limit_range.go:239
  STEP: Creating a kubernetes client @ 04/15/24 07:49:13.798
  Apr 15 07:49:13.798: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename limitrange @ 04/15/24 07:49:13.806
  E0415 07:49:13.808951      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:49:13.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:49:13.85
  STEP: Creating LimitRange "e2e-limitrange-5mbpv" in namespace "limitrange-7407" @ 04/15/24 07:49:13.86
  STEP: Creating another limitRange in another namespace @ 04/15/24 07:49:13.871
  Apr 15 07:49:13.900: INFO: Namespace "e2e-limitrange-5mbpv-776" created
  Apr 15 07:49:13.900: INFO: Creating LimitRange "e2e-limitrange-5mbpv" in namespace "e2e-limitrange-5mbpv-776"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-5mbpv" @ 04/15/24 07:49:13.92
  Apr 15 07:49:13.933: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-5mbpv" in "limitrange-7407" namespace @ 04/15/24 07:49:13.933
  Apr 15 07:49:13.951: INFO: LimitRange "e2e-limitrange-5mbpv" has been patched
  STEP: Delete LimitRange "e2e-limitrange-5mbpv" by Collection with labelSelector: "e2e-limitrange-5mbpv=patched" @ 04/15/24 07:49:13.951
  STEP: Confirm that the limitRange "e2e-limitrange-5mbpv" has been deleted @ 04/15/24 07:49:13.966
  Apr 15 07:49:13.966: INFO: Requesting list of LimitRange to confirm quantity
  Apr 15 07:49:13.972: INFO: Found 0 LimitRange with label "e2e-limitrange-5mbpv=patched"
  Apr 15 07:49:13.972: INFO: LimitRange "e2e-limitrange-5mbpv" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-5mbpv" @ 04/15/24 07:49:13.972
  Apr 15 07:49:13.977: INFO: Found 1 limitRange
  Apr 15 07:49:13.978: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-7407" for this suite. @ 04/15/24 07:49:13.989
  STEP: Destroying namespace "e2e-limitrange-5mbpv-776" for this suite. @ 04/15/24 07:49:14.004
â€¢ [0.220 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 04/15/24 07:49:14.043
  Apr 15 07:49:14.043: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename taint-multiple-pods @ 04/15/24 07:49:14.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:49:14.085
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:49:14.09
  Apr 15 07:49:14.096: INFO: Waiting up to 1m0s for all nodes to be ready
  E0415 07:49:14.812395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:15.813551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:16.813690      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:17.813904      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:18.814223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:19.814277      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:20.814461      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:21.814950      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:22.815438      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:23.815628      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:24.816340      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:25.816482      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:26.816944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:27.817559      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:28.818729      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:29.818713      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:30.818975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:31.819573      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:32.820079      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:33.820467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:34.821709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:35.821649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:36.821813      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:37.822440      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:38.823125      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:39.823272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:40.824410      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:41.824942      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:42.825612      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:43.826174      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:44.826579      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:45.826720      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:46.826992      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:47.827684      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:48.828694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:49.829311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:50.829618      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:51.829891      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:52.830323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:53.830598      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:54.830785      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:55.831545      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:56.832622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:57.832789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:58.832962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:49:59.832836      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:00.833221      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:01.833765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:02.834237      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:03.835160      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:04.835605      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:05.835999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:06.836938      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:07.837159      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:08.837770      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:09.838666      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:10.839103      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:11.839323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:12.839709      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:13.839626      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:50:14.142: INFO: Waiting for terminating namespaces to be deleted...
  Apr 15 07:50:14.150: INFO: Starting informer...
  STEP: Starting pods... @ 04/15/24 07:50:14.15
  Apr 15 07:50:14.390: INFO: Pod1 is running on phiefi7ighaa-3. Tainting Node
  E0415 07:50:14.840401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:15.840702      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:50:16.661: INFO: Pod2 is running on phiefi7ighaa-3. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/15/24 07:50:16.661
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/15/24 07:50:16.684
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 04/15/24 07:50:16.693
  E0415 07:50:16.840784      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:17.841494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:18.841460      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:19.842047      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:20.842065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:21.842908      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:50:22.169: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E0415 07:50:22.843061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:23.843236      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:24.843387      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:25.844088      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:26.844322      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:27.845806      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:28.850748      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:29.847536      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:30.848372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:31.848014      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:32.848248      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:33.848917      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:34.849924      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:35.850065      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:36.850176      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:37.850379      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:38.851268      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:39.851622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:40.852283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:41.853081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:50:42.220: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  Apr 15 07:50:42.222: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/15/24 07:50:42.288
  STEP: Destroying namespace "taint-multiple-pods-3490" for this suite. @ 04/15/24 07:50:42.305
â€¢ [88.281 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 04/15/24 07:50:42.327
  Apr 15 07:50:42.327: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 07:50:42.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:50:42.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:50:42.427
  STEP: Setting up server cert @ 04/15/24 07:50:42.499
  E0415 07:50:42.853444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:43.854451      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 07:50:44.279
  STEP: Deploying the webhook pod @ 04/15/24 07:50:44.304
  STEP: Wait for the deployment to be ready @ 04/15/24 07:50:44.344
  Apr 15 07:50:44.372: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 07:50:44.854851      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:45.855053      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 07:50:46.4
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 07:50:46.455
  E0415 07:50:46.855768      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:50:47.455: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/15/24 07:50:47.488
  STEP: create a pod @ 04/15/24 07:50:47.544
  E0415 07:50:47.855912      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:48.856925      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 04/15/24 07:50:49.593
  Apr 15 07:50:49.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=webhook-3264 attach --namespace=webhook-3264 to-be-attached-pod -i -c=container1'
  E0415 07:50:49.856500      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:50:49.869: INFO: rc: 1
  Apr 15 07:50:49.870: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3264" for this suite. @ 04/15/24 07:50:50.011
  STEP: Destroying namespace "webhook-markers-4697" for this suite. @ 04/15/24 07:50:50.029
â€¢ [7.718 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 04/15/24 07:50:50.051
  Apr 15 07:50:50.051: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename cronjob @ 04/15/24 07:50:50.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:50:50.138
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:50:50.147
  STEP: Creating a ForbidConcurrent cronjob @ 04/15/24 07:50:50.156
  STEP: Ensuring a job is scheduled @ 04/15/24 07:50:50.171
  E0415 07:50:50.856964      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:51.857437      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:52.858798      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:53.859762      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:54.859607      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:55.860102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:56.860502      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:57.860909      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:58.860985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:50:59.861805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/15/24 07:51:00.177
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/15/24 07:51:00.195
  STEP: Ensuring no more jobs are scheduled @ 04/15/24 07:51:00.203
  E0415 07:51:00.861783      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:01.862247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:02.862587      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:03.862887      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:04.863433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:05.864115      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:06.864051      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:07.864467      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:08.864430      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:09.864847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:10.865311      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:11.865421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:12.865624      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:13.866007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:14.866208      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:15.866533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:16.867320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:17.867675      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:18.867827      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:19.868533      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:20.869262      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:21.869591      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:22.870310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:23.870728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:24.871426      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:25.871558      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:26.871965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:27.871850      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:28.871980      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:29.872760      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:30.873642      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:31.873846      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:32.874458      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:33.874671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:34.875338      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:35.875875      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:36.876369      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:37.877242      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:38.877002      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:39.877200      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:40.877627      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:41.877763      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:42.878303      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:43.878566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:44.879532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:45.879876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:46.880205      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:47.880320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:48.880997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:49.881978      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:50.882464      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:51.883318      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:52.883668      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:53.885307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:54.884617      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:55.884965      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:56.885293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:57.886222      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:58.887074      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:51:59.887594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:00.888382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:01.892765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:02.890085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:03.890815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:04.891275      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:05.891654      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:06.892662      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:07.893532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:08.893816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:09.894031      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:10.893845      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:11.894247      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:12.894539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:13.894934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:14.895728      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:15.896431      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:16.896962      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:17.897090      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:18.897294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:19.898109      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:20.898285      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:21.899061      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:22.899697      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:23.899858      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:24.900604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:25.900778      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:26.900969      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:27.901985      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:28.903450      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:29.903081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:30.903563      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:31.904228      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:32.904755      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:33.905601      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:34.906145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:35.906307      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:36.906527      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:37.906649      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:38.907457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:39.907961      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:40.908457      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:41.908886      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:42.909881      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:43.909323      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:44.909566      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:45.910118      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:46.910367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:47.910988      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:48.911532      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:49.912045      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:50.912462      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:51.912719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:52.913769      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:53.914062      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:54.914499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:55.914719      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:56.915635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:57.916302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:58.916625      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:52:59.917037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:00.917447      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:01.917685      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:02.917753      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:03.917975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:04.918687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:05.919705      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:06.919975      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:07.920233      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:08.920700      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:09.921830      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:10.922861      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:11.923695      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:12.924420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:13.924842      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:14.925871      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:15.926754      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:16.927832      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:17.928616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:18.928619      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:19.929535      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:20.929780      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:21.929960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:22.930315      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:23.931025      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:24.931401      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:25.931509      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:26.931672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:27.932681      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:28.932896      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:29.933761      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:30.933854      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:31.934068      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:32.934301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:33.934494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:34.935050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:35.935113      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:36.935829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:37.935815      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:38.936382      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:39.936765      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:40.937572      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:41.937609      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:42.938383      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:43.938375      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:44.940350      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:45.940433      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:46.940694      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:47.941294      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:48.941622      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:49.942929      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:50.942997      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:51.943287      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:52.943378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:53.943952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:54.943952      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:55.944351      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:56.945372      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:57.946172      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:58.946272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:53:59.947012      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:00.947189      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:01.948970      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:02.948312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:03.950691      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:04.949608      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:05.950037      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:06.950181      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:07.951145      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:08.951358      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:09.952072      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:10.952678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:11.953414      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:12.953439      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:13.953715      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:14.954711      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:15.955112      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:16.954934      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:17.955420      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:18.955596      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:19.956124      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:20.956781      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:21.957281      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:22.957739      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:23.958081      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:24.958793      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:25.959030      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:26.959241      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:27.960082      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:28.960227      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:29.960570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:30.960903      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:31.961671      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:32.961973      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:33.962301      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:34.962849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:35.963946      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:36.964293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:37.965219      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:38.965497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:39.965551      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:40.965829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:41.965900      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:42.966995      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:43.967234      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:44.967902      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:45.968479      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:46.968570      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:47.968868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:48.968959      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:49.969334      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:50.969517      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:51.970102      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:52.970329      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:53.971038      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:54.971716      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:55.972870      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:56.973787      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:57.974413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:58.974632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:54:59.974910      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:00.975801      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:01.976506      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:02.976594      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:03.976876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:04.977494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:05.977692      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:06.977816      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:07.978044      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:08.978476      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:09.978869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:10.979726      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:11.980367      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:12.981326      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:13.981747      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:14.982606      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:15.983413      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:16.983603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:17.984449      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:18.985310      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:19.985328      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:20.985588      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:21.986251      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:22.986489      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:23.986638      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:24.987678      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:25.988321      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:26.988541      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:27.988805      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:28.989877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:29.990633      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:30.990937      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:31.991717      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:32.991906      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:33.992411      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:34.992444      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:35.992656      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:36.992774      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:37.994120      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:38.993672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:39.993740      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:40.994293      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:41.995849      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:42.995470      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:43.996443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:44.997306      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:45.998312      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:46.998494      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:47.999651      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:49.002395      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:50.000497      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:51.001197      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:52.001267      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:53.001239      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:54.001672      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:55.002616      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:56.002899      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:57.002944      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:58.003302      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:55:59.004562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:00.004931      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 04/15/24 07:56:00.221
  Apr 15 07:56:00.236: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-7477" for this suite. @ 04/15/24 07:56:00.253
â€¢ [310.221 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 04/15/24 07:56:00.293
  Apr 15 07:56:00.293: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename container-runtime @ 04/15/24 07:56:00.302
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:56:00.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:56:00.412
  STEP: create the container @ 04/15/24 07:56:00.421
  W0415 07:56:00.443491      13 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/15/24 07:56:00.444
  E0415 07:56:01.005873      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:02.006712      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:03.006868      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/15/24 07:56:03.486
  STEP: the container should be terminated @ 04/15/24 07:56:03.492
  STEP: the termination message should be set @ 04/15/24 07:56:03.492
  Apr 15 07:56:03.493: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 04/15/24 07:56:03.493
  Apr 15 07:56:03.518: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-2535" for this suite. @ 04/15/24 07:56:03.537
â€¢ [3.257 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 04/15/24 07:56:03.554
  Apr 15 07:56:03.555: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 07:56:03.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:56:03.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:56:03.609
  STEP: Creating projection with secret that has name projected-secret-test-14ecfc18-a031-4a59-be49-5b3200eceb28 @ 04/15/24 07:56:03.621
  STEP: Creating a pod to test consume secrets @ 04/15/24 07:56:03.634
  E0415 07:56:04.007138      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:05.007829      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:06.009033      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:07.009877      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:56:07.681
  Apr 15 07:56:07.688: INFO: Trying to get logs from node phiefi7ighaa-3 pod pod-projected-secrets-9f2b0ed3-5a13-48cc-84ce-7e1d4a393703 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/15/24 07:56:07.737
  Apr 15 07:56:07.779: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7304" for this suite. @ 04/15/24 07:56:07.791
â€¢ [4.251 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 04/15/24 07:56:07.808
  Apr 15 07:56:07.808: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename projected @ 04/15/24 07:56:07.813
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:56:07.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:56:07.858
  STEP: Creating a pod to test downward API volume plugin @ 04/15/24 07:56:07.867
  E0415 07:56:08.010811      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:09.011837      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:10.012665      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:11.012824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/15/24 07:56:11.942
  Apr 15 07:56:11.958: INFO: Trying to get logs from node phiefi7ighaa-3 pod downwardapi-volume-423332c7-5eb7-49d4-bf5c-f85302bde703 container client-container: <nil>
  STEP: delete the pod @ 04/15/24 07:56:11.981
  E0415 07:56:12.013847      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:12.017: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4459" for this suite. @ 04/15/24 07:56:12.032
â€¢ [4.241 seconds]
------------------------------
[sig-network] DNS should provide DNS for services  [Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 04/15/24 07:56:12.049
  Apr 15 07:56:12.050: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename dns @ 04/15/24 07:56:12.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:56:12.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:56:12.111
  STEP: Creating a test headless service @ 04/15/24 07:56:12.123
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5381.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5381.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5381.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5381.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5381.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5381.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5381.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5381.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5381.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 151.47.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.47.151_udp@PTR;check="$$(dig +tcp +noall +answer +search 151.47.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.47.151_tcp@PTR;sleep 1; done
   @ 04/15/24 07:56:12.205
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5381.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5381.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5381.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5381.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5381.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5381.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5381.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5381.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5381.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5381.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 151.47.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.47.151_udp@PTR;check="$$(dig +tcp +noall +answer +search 151.47.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.47.151_tcp@PTR;sleep 1; done
   @ 04/15/24 07:56:12.205
  STEP: creating a pod to probe DNS @ 04/15/24 07:56:12.205
  STEP: submitting the pod to kubernetes @ 04/15/24 07:56:12.206
  E0415 07:56:13.014225      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:14.014443      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/15/24 07:56:14.261
  STEP: looking for the results for each expected name from probers @ 04/15/24 07:56:14.269
  Apr 15 07:56:14.285: INFO: Unable to read wheezy_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:14.294: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:14.303: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:14.313: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:14.365: INFO: Unable to read jessie_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:14.372: INFO: Unable to read jessie_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:14.380: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:14.389: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:14.421: INFO: Lookups using dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3 failed for: [wheezy_udp@dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_udp@dns-test-service.dns-5381.svc.cluster.local jessie_tcp@dns-test-service.dns-5381.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local]

  Apr 15 07:56:14.436: INFO: Pod client logs for webserver: 
  Apr 15 07:56:14.451: INFO: Pod client logs for querier: 
  Apr 15 07:56:14.468: INFO: Pod client logs for jessie-querier: 
  E0415 07:56:15.014990      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:16.015007      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:17.015499      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:18.016223      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:19.016647      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:19.480: INFO: Unable to read wheezy_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:19.488: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:19.495: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:19.502: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:19.540: INFO: Unable to read jessie_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:19.547: INFO: Unable to read jessie_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:19.555: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:19.563: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:19.610: INFO: Lookups using dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3 failed for: [wheezy_udp@dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_udp@dns-test-service.dns-5381.svc.cluster.local jessie_tcp@dns-test-service.dns-5381.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local]

  Apr 15 07:56:19.625: INFO: Pod client logs for webserver: 
  Apr 15 07:56:19.638: INFO: Pod client logs for querier: 
  Apr 15 07:56:19.652: INFO: Pod client logs for jessie-querier: 
  E0415 07:56:20.017539      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:21.018553      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:22.019789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:23.019360      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:24.019580      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:24.480: INFO: Unable to read wheezy_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:24.488: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:24.496: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:24.504: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:24.543: INFO: Unable to read jessie_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:24.550: INFO: Unable to read jessie_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:24.556: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:24.563: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:24.605: INFO: Lookups using dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3 failed for: [wheezy_udp@dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_udp@dns-test-service.dns-5381.svc.cluster.local jessie_tcp@dns-test-service.dns-5381.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local]

  Apr 15 07:56:24.620: INFO: Pod client logs for webserver: 
  Apr 15 07:56:24.634: INFO: Pod client logs for querier: 
  Apr 15 07:56:24.649: INFO: Pod client logs for jessie-querier: 
  E0415 07:56:25.020634      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:26.021362      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:27.023922      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:28.023632      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:29.024272      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:29.479: INFO: Unable to read wheezy_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:29.489: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:29.498: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:29.507: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:29.561: INFO: Unable to read jessie_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:29.570: INFO: Unable to read jessie_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:29.579: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:29.594: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:29.649: INFO: Lookups using dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3 failed for: [wheezy_udp@dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_udp@dns-test-service.dns-5381.svc.cluster.local jessie_tcp@dns-test-service.dns-5381.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local]

  Apr 15 07:56:29.667: INFO: Pod client logs for webserver: 
  Apr 15 07:56:29.681: INFO: Pod client logs for querier: 
  Apr 15 07:56:29.693: INFO: Pod client logs for jessie-querier: 
  E0415 07:56:30.024789      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:31.025824      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:32.026604      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:33.026960      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:34.026777      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:34.479: INFO: Unable to read wheezy_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:34.488: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:34.496: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:34.506: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:34.553: INFO: Unable to read jessie_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:34.560: INFO: Unable to read jessie_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:34.570: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:34.586: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:34.623: INFO: Lookups using dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3 failed for: [wheezy_udp@dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_udp@dns-test-service.dns-5381.svc.cluster.local jessie_tcp@dns-test-service.dns-5381.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local]

  Apr 15 07:56:34.640: INFO: Pod client logs for webserver: 
  Apr 15 07:56:34.654: INFO: Pod client logs for querier: 
  Apr 15 07:56:34.674: INFO: Pod client logs for jessie-querier: 
  E0415 07:56:35.027603      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:36.027862      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:37.028422      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:38.028300      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:39.028530      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:39.480: INFO: Unable to read wheezy_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:39.489: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:39.498: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:39.507: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:39.557: INFO: Unable to read jessie_udp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:39.567: INFO: Unable to read jessie_tcp@dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:39.577: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:39.585: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local from pod dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3: the server could not find the requested resource (get pods dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3)
  Apr 15 07:56:39.631: INFO: Lookups using dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3 failed for: [wheezy_udp@dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@dns-test-service.dns-5381.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_udp@dns-test-service.dns-5381.svc.cluster.local jessie_tcp@dns-test-service.dns-5381.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5381.svc.cluster.local]

  Apr 15 07:56:39.649: INFO: Pod client logs for webserver: 
  Apr 15 07:56:39.671: INFO: Pod client logs for querier: 
  Apr 15 07:56:39.688: INFO: Pod client logs for jessie-querier: 
  E0415 07:56:40.028848      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:41.029876      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:42.029421      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:43.030085      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:44.030635      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:44.662: INFO: DNS probes using dns-5381/dns-test-5a0c86f3-874d-4031-88ad-08433ee044d3 succeeded

  Apr 15 07:56:44.662: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/15/24 07:56:44.683
  STEP: deleting the test service @ 04/15/24 07:56:44.729
  STEP: deleting the test headless service @ 04/15/24 07:56:44.804
  STEP: Destroying namespace "dns-5381" for this suite. @ 04/15/24 07:56:44.841
â€¢ [32.810 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 04/15/24 07:56:44.863
  Apr 15 07:56:44.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename webhook @ 04/15/24 07:56:44.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:56:44.916
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:56:44.921
  STEP: Setting up server cert @ 04/15/24 07:56:45.008
  E0415 07:56:45.031022      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:46.032313      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/15/24 07:56:46.451
  STEP: Deploying the webhook pod @ 04/15/24 07:56:46.478
  STEP: Wait for the deployment to be ready @ 04/15/24 07:56:46.516
  Apr 15 07:56:46.549: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0415 07:56:47.032373      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:48.032814      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/15/24 07:56:48.584
  STEP: Verifying the service has paired with the endpoint @ 04/15/24 07:56:48.617
  E0415 07:56:49.033869      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:49.617: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 15 07:56:49.642: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  E0415 07:56:50.033687      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3093-crds.webhook.example.com via the AdmissionRegistration API @ 04/15/24 07:56:50.181
  STEP: Creating a custom resource while v1 is storage version @ 04/15/24 07:56:50.245
  E0415 07:56:51.034050      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:52.034562      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 04/15/24 07:56:52.579
  STEP: Patching the custom resource while v2 is storage version @ 04/15/24 07:56:52.638
  Apr 15 07:56:52.668: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E0415 07:56:53.034655      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-6728" for this suite. @ 04/15/24 07:56:53.435
  STEP: Destroying namespace "webhook-markers-7240" for this suite. @ 04/15/24 07:56:53.46
â€¢ [8.615 seconds]
------------------------------
[sig-network] Services should serve a basic endpoint from pods  [Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 04/15/24 07:56:53.48
  Apr 15 07:56:53.480: INFO: >>> kubeConfig: /tmp/kubeconfig-1742378093
  STEP: Building a namespace api object, basename services @ 04/15/24 07:56:53.484
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/15/24 07:56:53.531
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/15/24 07:56:53.536
  STEP: creating service endpoint-test2 in namespace services-174 @ 04/15/24 07:56:53.543
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-174 to expose endpoints map[] @ 04/15/24 07:56:53.588
  Apr 15 07:56:53.625: INFO: successfully validated that service endpoint-test2 in namespace services-174 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-174 @ 04/15/24 07:56:53.625
  E0415 07:56:54.034999      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:55.036283      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-174 to expose endpoints map[pod1:[80]] @ 04/15/24 07:56:55.684
  Apr 15 07:56:55.710: INFO: successfully validated that service endpoint-test2 in namespace services-174 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 04/15/24 07:56:55.71
  Apr 15 07:56:55.710: INFO: Creating new exec pod
  E0415 07:56:56.038512      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:57.038320      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:56:58.038820      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:58.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-174 exec execpod8z62w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0415 07:56:59.038698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:56:59.289: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 15 07:56:59.289: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 07:56:59.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-174 exec execpod8z62w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.164 80'
  Apr 15 07:56:59.651: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.164 80\nConnection to 10.233.42.164 80 port [tcp/http] succeeded!\n"
  Apr 15 07:56:59.651: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-174 @ 04/15/24 07:56:59.651
  E0415 07:57:00.040273      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  E0415 07:57:01.040567      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-174 to expose endpoints map[pod1:[80] pod2:[80]] @ 04/15/24 07:57:01.691
  Apr 15 07:57:01.727: INFO: successfully validated that service endpoint-test2 in namespace services-174 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 04/15/24 07:57:01.728
  E0415 07:57:02.041495      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:57:02.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-174 exec execpod8z62w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0415 07:57:03.042477      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:57:03.077: INFO: stderr: "+ + echo hostName\nnc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 15 07:57:03.077: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 07:57:03.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-174 exec execpod8z62w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.164 80'
  Apr 15 07:57:03.446: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.164 80\nConnection to 10.233.42.164 80 port [tcp/http] succeeded!\n"
  Apr 15 07:57:03.446: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-174 @ 04/15/24 07:57:03.446
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-174 to expose endpoints map[pod2:[80]] @ 04/15/24 07:57:03.481
  E0415 07:57:04.043378      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:57:04.532: INFO: successfully validated that service endpoint-test2 in namespace services-174 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 04/15/24 07:57:04.532
  E0415 07:57:05.043466      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:57:05.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-174 exec execpod8z62w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 15 07:57:05.861: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 15 07:57:05.861: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 15 07:57:05.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1742378093 --namespace=services-174 exec execpod8z62w -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.164 80'
  E0415 07:57:06.044392      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:57:06.258: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.164 80\nConnection to 10.233.42.164 80 port [tcp/http] succeeded!\n"
  Apr 15 07:57:06.258: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-174 @ 04/15/24 07:57:06.258
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-174 to expose endpoints map[] @ 04/15/24 07:57:06.288
  E0415 07:57:07.044698      13 retrywatcher.go:129] "Watch failed" err="context canceled"
  Apr 15 07:57:07.377: INFO: successfully validated that service endpoint-test2 in namespace services-174 exposes endpoints map[]
  Apr 15 07:57:07.380: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-174" for this suite. @ 04/15/24 07:57:07.452
â€¢ [13.995 seconds]
------------------------------
SSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Apr 15 07:57:07.514: INFO: Running AfterSuite actions on node 1
  Apr 15 07:57:07.514: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:157
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:585
[ReportAfterSuite] PASSED [0.171 seconds]
------------------------------

Ran 380 of 7389 Specs in 6042.237 seconds
SUCCESS! -- 380 Passed | 0 Failed | 0 Pending | 7009 Skipped
PASS

Ginkgo ran 1 suite in 1h40m43.783207714s
Test Suite Passed

I1221 12:11:15.277478      20 test_context.go:410] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-796893939
I1221 12:11:15.277598      20 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I1221 12:11:15.277727      20 e2e.go:124] Starting e2e run "24ee7c31-e26a-4c7a-9c45-b22d427de6ef" on Ginkgo node 1
{"msg":"Test Suite starting","total":273,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1608552673 - Will randomize all specs
Will run 273 of 4992 specs

Dec 21 12:11:15.351: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:11:15.354: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 21 12:11:15.377: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 21 12:11:15.423: INFO: 24 / 24 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 21 12:11:15.423: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Dec 21 12:11:15.423: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 21 12:11:15.435: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Dec 21 12:11:15.435: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 21 12:11:15.435: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Dec 21 12:11:15.435: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Dec 21 12:11:15.435: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'syseleven-node-problem-detector' (0 seconds elapsed)
Dec 21 12:11:15.435: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'user-ssh-keys-agent' (0 seconds elapsed)
Dec 21 12:11:15.435: INFO: e2e test version: v1.18.8
Dec 21 12:11:15.437: INFO: kube-apiserver version: v1.18.8
Dec 21 12:11:15.437: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:11:15.443: INFO: Cluster IP family: ipv4
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:11:15.443: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-probe
Dec 21 12:11:15.483: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec 21 12:11:15.495: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4670
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-c96b54be-752b-4a12-a097-d02d5b74e397 in namespace container-probe-4670
Dec 21 12:11:19.636: INFO: Started pod busybox-c96b54be-752b-4a12-a097-d02d5b74e397 in namespace container-probe-4670
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 12:11:19.641: INFO: Initial restart count of pod busybox-c96b54be-752b-4a12-a097-d02d5b74e397 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:15:20.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4670" for this suite.

• [SLOW TEST:244.971 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":273,"completed":1,"skipped":5,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:15:20.414: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-f146aff3-c94d-4f6e-bc2d-ea435ffe861b
STEP: Creating a pod to test consume secrets
Dec 21 12:15:20.578: INFO: Waiting up to 5m0s for pod "pod-secrets-34b49ea0-0b67-47e2-8b28-5f5abd71e41d" in namespace "secrets-1878" to be "Succeeded or Failed"
Dec 21 12:15:20.582: INFO: Pod "pod-secrets-34b49ea0-0b67-47e2-8b28-5f5abd71e41d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.310975ms
Dec 21 12:15:22.586: INFO: Pod "pod-secrets-34b49ea0-0b67-47e2-8b28-5f5abd71e41d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007716602s
Dec 21 12:15:24.609: INFO: Pod "pod-secrets-34b49ea0-0b67-47e2-8b28-5f5abd71e41d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030337748s
STEP: Saw pod success
Dec 21 12:15:24.609: INFO: Pod "pod-secrets-34b49ea0-0b67-47e2-8b28-5f5abd71e41d" satisfied condition "Succeeded or Failed"
Dec 21 12:15:24.633: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-secrets-34b49ea0-0b67-47e2-8b28-5f5abd71e41d container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 12:15:24.714: INFO: Waiting for pod pod-secrets-34b49ea0-0b67-47e2-8b28-5f5abd71e41d to disappear
Dec 21 12:15:24.733: INFO: Pod pod-secrets-34b49ea0-0b67-47e2-8b28-5f5abd71e41d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:15:24.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1878" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":273,"completed":2,"skipped":18,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:15:24.770: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7729
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-7729/secret-test-b48ed921-5f63-4df0-8234-83ed3d80d6e8
STEP: Creating a pod to test consume secrets
Dec 21 12:15:25.017: INFO: Waiting up to 5m0s for pod "pod-configmaps-c016f7ac-ce3d-45b3-822e-7689369bffa1" in namespace "secrets-7729" to be "Succeeded or Failed"
Dec 21 12:15:25.020: INFO: Pod "pod-configmaps-c016f7ac-ce3d-45b3-822e-7689369bffa1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.37397ms
Dec 21 12:15:27.026: INFO: Pod "pod-configmaps-c016f7ac-ce3d-45b3-822e-7689369bffa1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008794701s
STEP: Saw pod success
Dec 21 12:15:27.026: INFO: Pod "pod-configmaps-c016f7ac-ce3d-45b3-822e-7689369bffa1" satisfied condition "Succeeded or Failed"
Dec 21 12:15:27.029: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-configmaps-c016f7ac-ce3d-45b3-822e-7689369bffa1 container env-test: <nil>
STEP: delete the pod
Dec 21 12:15:27.055: INFO: Waiting for pod pod-configmaps-c016f7ac-ce3d-45b3-822e-7689369bffa1 to disappear
Dec 21 12:15:27.059: INFO: Pod pod-configmaps-c016f7ac-ce3d-45b3-822e-7689369bffa1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:15:27.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7729" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":273,"completed":3,"skipped":32,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:15:27.075: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-479
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Dec 21 12:15:29.795: INFO: Successfully updated pod "annotationupdatec7875a6a-8b8b-4305-a948-da1b54ad2155"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:15:33.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-479" for this suite.

• [SLOW TEST:6.787 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":273,"completed":4,"skipped":57,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:15:33.864: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1316
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:15:34.021: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:15:35.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1316" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":273,"completed":5,"skipped":68,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:15:35.267: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:15:35.446: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84d9efe9-27d2-4729-bd25-79b2577e8595" in namespace "projected-4401" to be "Succeeded or Failed"
Dec 21 12:15:35.451: INFO: Pod "downwardapi-volume-84d9efe9-27d2-4729-bd25-79b2577e8595": Phase="Pending", Reason="", readiness=false. Elapsed: 5.29645ms
Dec 21 12:15:37.461: INFO: Pod "downwardapi-volume-84d9efe9-27d2-4729-bd25-79b2577e8595": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01576856s
Dec 21 12:15:39.469: INFO: Pod "downwardapi-volume-84d9efe9-27d2-4729-bd25-79b2577e8595": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02344956s
STEP: Saw pod success
Dec 21 12:15:39.469: INFO: Pod "downwardapi-volume-84d9efe9-27d2-4729-bd25-79b2577e8595" satisfied condition "Succeeded or Failed"
Dec 21 12:15:39.473: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod downwardapi-volume-84d9efe9-27d2-4729-bd25-79b2577e8595 container client-container: <nil>
STEP: delete the pod
Dec 21 12:15:39.502: INFO: Waiting for pod downwardapi-volume-84d9efe9-27d2-4729-bd25-79b2577e8595 to disappear
Dec 21 12:15:39.508: INFO: Pod downwardapi-volume-84d9efe9-27d2-4729-bd25-79b2577e8595 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:15:39.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4401" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":273,"completed":6,"skipped":103,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:15:39.521: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4549
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 21 12:15:39.699: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:15:43.214: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:15:56.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4549" for this suite.

• [SLOW TEST:17.263 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":273,"completed":7,"skipped":130,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:15:56.784: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:15:56.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2341" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":273,"completed":8,"skipped":141,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:15:57.004: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7736
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:16:03.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7736" for this suite.

• [SLOW TEST:6.199 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":273,"completed":9,"skipped":148,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:16:03.204: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Dec 21 12:16:03.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-3903'
Dec 21 12:16:04.136: INFO: stderr: ""
Dec 21 12:16:04.136: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 12:16:04.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3903'
Dec 21 12:16:04.243: INFO: stderr: ""
Dec 21 12:16:04.243: INFO: stdout: "update-demo-nautilus-87pr8 update-demo-nautilus-lt2df "
Dec 21 12:16:04.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-87pr8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3903'
Dec 21 12:16:04.321: INFO: stderr: ""
Dec 21 12:16:04.322: INFO: stdout: ""
Dec 21 12:16:04.322: INFO: update-demo-nautilus-87pr8 is created but not running
Dec 21 12:16:09.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3903'
Dec 21 12:16:09.421: INFO: stderr: ""
Dec 21 12:16:09.421: INFO: stdout: "update-demo-nautilus-87pr8 update-demo-nautilus-lt2df "
Dec 21 12:16:09.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-87pr8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3903'
Dec 21 12:16:09.526: INFO: stderr: ""
Dec 21 12:16:09.526: INFO: stdout: "true"
Dec 21 12:16:09.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-87pr8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3903'
Dec 21 12:16:09.681: INFO: stderr: ""
Dec 21 12:16:09.681: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 12:16:09.681: INFO: validating pod update-demo-nautilus-87pr8
Dec 21 12:16:09.778: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 12:16:09.778: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 12:16:09.778: INFO: update-demo-nautilus-87pr8 is verified up and running
Dec 21 12:16:09.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-lt2df -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3903'
Dec 21 12:16:09.865: INFO: stderr: ""
Dec 21 12:16:09.865: INFO: stdout: "true"
Dec 21 12:16:09.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-lt2df -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3903'
Dec 21 12:16:09.998: INFO: stderr: ""
Dec 21 12:16:09.998: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 12:16:09.998: INFO: validating pod update-demo-nautilus-lt2df
Dec 21 12:16:10.015: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 12:16:10.015: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 12:16:10.015: INFO: update-demo-nautilus-lt2df is verified up and running
STEP: using delete to clean up resources
Dec 21 12:16:10.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete --grace-period=0 --force -f - --namespace=kubectl-3903'
Dec 21 12:16:10.191: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 12:16:10.191: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 21 12:16:10.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3903'
Dec 21 12:16:10.282: INFO: stderr: "No resources found in kubectl-3903 namespace.\n"
Dec 21 12:16:10.282: INFO: stdout: ""
Dec 21 12:16:10.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -l name=update-demo --namespace=kubectl-3903 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 21 12:16:10.358: INFO: stderr: ""
Dec 21 12:16:10.358: INFO: stdout: "update-demo-nautilus-87pr8\nupdate-demo-nautilus-lt2df\n"
Dec 21 12:16:10.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3903'
Dec 21 12:16:10.958: INFO: stderr: "No resources found in kubectl-3903 namespace.\n"
Dec 21 12:16:10.958: INFO: stdout: ""
Dec 21 12:16:10.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -l name=update-demo --namespace=kubectl-3903 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 21 12:16:11.034: INFO: stderr: ""
Dec 21 12:16:11.034: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:16:11.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3903" for this suite.

• [SLOW TEST:7.842 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":273,"completed":10,"skipped":162,"failed":0}
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:16:11.047: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-4006
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 21 12:16:23.315: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:23.315: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:24.336: INFO: Exec stderr: ""
Dec 21 12:16:24.337: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:24.337: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:24.583: INFO: Exec stderr: ""
Dec 21 12:16:24.583: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:24.583: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:24.907: INFO: Exec stderr: ""
Dec 21 12:16:24.907: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:24.907: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:25.285: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 21 12:16:25.285: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:25.286: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:25.606: INFO: Exec stderr: ""
Dec 21 12:16:25.607: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:25.607: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:25.872: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 21 12:16:25.872: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:25.872: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:26.245: INFO: Exec stderr: ""
Dec 21 12:16:26.245: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:26.245: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:26.559: INFO: Exec stderr: ""
Dec 21 12:16:26.559: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:26.560: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:26.969: INFO: Exec stderr: ""
Dec 21 12:16:26.969: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4006 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:26.969: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:27.336: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:16:27.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4006" for this suite.

• [SLOW TEST:16.305 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":11,"skipped":163,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:16:27.354: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-7095
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 21 12:16:27.519: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 21 12:16:27.564: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:16:29.576: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:16:31.586: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:16:33.569: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:16:35.568: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:16:37.569: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:16:39.569: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:16:41.573: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:16:43.580: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:16:45.568: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:16:47.569: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 21 12:16:47.577: INFO: The status of Pod netserver-1 is Running (Ready = true)
Dec 21 12:16:47.585: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Dec 21 12:16:51.636: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.3.11:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7095 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:51.636: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:51.925: INFO: Found all expected endpoints: [netserver-0]
Dec 21 12:16:51.929: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.4.13:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7095 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:51.929: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:52.277: INFO: Found all expected endpoints: [netserver-1]
Dec 21 12:16:52.283: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.5.8:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7095 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:16:52.283: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:16:52.569: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:16:52.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7095" for this suite.

• [SLOW TEST:25.229 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":12,"skipped":176,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:16:52.584: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1156
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Dec 21 12:16:52.754: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:16:58.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1156" for this suite.

• [SLOW TEST:6.263 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":273,"completed":13,"skipped":185,"failed":0}
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:16:58.848: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:17:59.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9923" for this suite.

• [SLOW TEST:60.201 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":273,"completed":14,"skipped":190,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:17:59.051: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2778
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2778
STEP: creating replication controller externalsvc in namespace services-2778
I1221 12:17:59.230640      20 runners.go:190] Created replication controller with name: externalsvc, namespace: services-2778, replica count: 2
I1221 12:18:02.281678      20 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 21 12:18:02.301: INFO: Creating new exec pod
Dec 21 12:18:04.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=services-2778 execpodlkz8x -- /bin/sh -x -c nslookup clusterip-service'
Dec 21 12:18:04.780: INFO: stderr: "+ nslookup clusterip-service\n"
Dec 21 12:18:04.780: INFO: stdout: "Server:\t\t169.254.20.10\nAddress:\t169.254.20.10#53\n\nclusterip-service.services-2778.svc.cluster.local\tcanonical name = externalsvc.services-2778.svc.cluster.local.\nName:\texternalsvc.services-2778.svc.cluster.local\nAddress: 10.240.19.218\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2778, will wait for the garbage collector to delete the pods
Dec 21 12:18:04.847: INFO: Deleting ReplicationController externalsvc took: 11.960712ms
Dec 21 12:18:05.449: INFO: Terminating ReplicationController externalsvc pods took: 601.890154ms
Dec 21 12:18:09.378: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:18:09.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2778" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:10.377 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":273,"completed":15,"skipped":257,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:18:09.437: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8437
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-3ca5be54-0c5a-4e8c-9393-6a51706ef925
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:18:09.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8437" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":273,"completed":16,"skipped":272,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:18:09.607: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8153
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1221 12:18:49.802942      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 21 12:18:49.802: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:18:49.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8153" for this suite.

• [SLOW TEST:40.211 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":273,"completed":17,"skipped":290,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:18:49.820: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:19:07.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7985" for this suite.

• [SLOW TEST:17.297 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":273,"completed":18,"skipped":296,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:19:07.118: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-39
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:19:07.309: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-6d095794-a48c-47bc-ba53-d9b21486cd6d" in namespace "security-context-test-39" to be "Succeeded or Failed"
Dec 21 12:19:07.312: INFO: Pod "alpine-nnp-false-6d095794-a48c-47bc-ba53-d9b21486cd6d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.782776ms
Dec 21 12:19:09.317: INFO: Pod "alpine-nnp-false-6d095794-a48c-47bc-ba53-d9b21486cd6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008425575s
Dec 21 12:19:11.323: INFO: Pod "alpine-nnp-false-6d095794-a48c-47bc-ba53-d9b21486cd6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014458749s
Dec 21 12:19:11.323: INFO: Pod "alpine-nnp-false-6d095794-a48c-47bc-ba53-d9b21486cd6d" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:19:11.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-39" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":19,"skipped":308,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:19:11.361: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:19:15.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8259" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":273,"completed":20,"skipped":326,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:19:15.634: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9146
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:19:15.896: INFO: (0) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 96.301009ms)
Dec 21 12:19:15.909: INFO: (1) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 13.097283ms)
Dec 21 12:19:15.953: INFO: (2) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 43.657499ms)
Dec 21 12:19:15.968: INFO: (3) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 14.748211ms)
Dec 21 12:19:16.013: INFO: (4) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 44.987497ms)
Dec 21 12:19:16.021: INFO: (5) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.483559ms)
Dec 21 12:19:16.027: INFO: (6) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.975013ms)
Dec 21 12:19:16.034: INFO: (7) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.177413ms)
Dec 21 12:19:16.046: INFO: (8) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 12.28903ms)
Dec 21 12:19:16.055: INFO: (9) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.897816ms)
Dec 21 12:19:16.062: INFO: (10) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.502365ms)
Dec 21 12:19:16.070: INFO: (11) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.905984ms)
Dec 21 12:19:16.077: INFO: (12) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.591228ms)
Dec 21 12:19:16.084: INFO: (13) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.610513ms)
Dec 21 12:19:16.093: INFO: (14) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.960674ms)
Dec 21 12:19:16.100: INFO: (15) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.582058ms)
Dec 21 12:19:16.106: INFO: (16) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.048562ms)
Dec 21 12:19:16.112: INFO: (17) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.046747ms)
Dec 21 12:19:16.118: INFO: (18) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.352284ms)
Dec 21 12:19:16.124: INFO: (19) /api/v1/nodes/ip-172-31-183-240.eu-central-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.632594ms)
[AfterEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:19:16.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9146" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":273,"completed":21,"skipped":340,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:19:16.138: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3554
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7955
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1242
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:19:44.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3554" for this suite.
STEP: Destroying namespace "nsdeletetest-7955" for this suite.
Dec 21 12:19:44.677: INFO: Namespace nsdeletetest-7955 was already deleted
STEP: Destroying namespace "nsdeletetest-1242" for this suite.

• [SLOW TEST:28.545 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":273,"completed":22,"skipped":344,"failed":0}
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:19:44.686: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4036
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-519b2c31-eca2-4492-b58a-1496fe3b07be
STEP: Creating configMap with name cm-test-opt-upd-9b843851-34c5-4698-8e37-3d4cda7f41ad
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-519b2c31-eca2-4492-b58a-1496fe3b07be
STEP: Updating configmap cm-test-opt-upd-9b843851-34c5-4698-8e37-3d4cda7f41ad
STEP: Creating configMap with name cm-test-opt-create-78261e91-6f46-4c79-8f47-5df8192aaf55
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:19:49.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4036" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":23,"skipped":347,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:19:49.180: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5412
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 21 12:19:49.324: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 12:19:49.339: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 12:19:49.343: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-183-240.eu-central-1.compute.internal before test
Dec 21 12:19:49.364: INFO: canal-z66nn from kube-system started at 2020-12-21 11:46:17 +0000 UTC (2 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 12:19:49.364: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 12:19:49.364: INFO: node-local-dns-htgfk from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 12:19:49.364: INFO: coredns-854998958f-nm6p2 from kube-system started at 2020-12-21 11:46:38 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container coredns ready: true, restart count 0
Dec 21 12:19:49.364: INFO: dns-autoscaler-596856b68b-qzt9r from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container autoscaler ready: true, restart count 0
Dec 21 12:19:49.364: INFO: openvpn-client-56dc45fdbd-pvwz9 from kube-system started at 2020-12-21 11:49:06 +0000 UTC (2 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 21 12:19:49.364: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 21 12:19:49.364: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-g9pqh from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:19:49.364: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 12:19:49.364: INFO: user-ssh-keys-agent-282ml from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 12:19:49.364: INFO: syseleven-node-problem-detector-xwkkt from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 12:19:49.364: INFO: kube-proxy-2s25g from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 12:19:49.364: INFO: tiller-deploy-5648ccb4b6-c8nqp from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container tiller ready: true, restart count 0
Dec 21 12:19:49.364: INFO: node-exporter-hjpfq from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.364: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 12:19:49.365: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-232-239.eu-central-1.compute.internal before test
Dec 21 12:19:49.401: INFO: syseleven-node-problem-detector-6vfvr from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.401: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 12:19:49.401: INFO: user-ssh-keys-agent-4gr8h from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.401: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 12:19:49.401: INFO: cluster-autoscaler-5c8c86777b-9jllr from kube-system started at 2020-12-21 11:52:18 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.401: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 21 12:19:49.401: INFO: pod-configmaps-9f2a7434-b41b-4c21-a538-4dc384b0fd5c from configmap-4036 started at 2020-12-21 12:19:44 +0000 UTC (3 container statuses recorded)
Dec 21 12:19:49.401: INFO: 	Container createcm-volume-test ready: true, restart count 0
Dec 21 12:19:49.402: INFO: 	Container delcm-volume-test ready: true, restart count 0
Dec 21 12:19:49.402: INFO: 	Container updcm-volume-test ready: true, restart count 0
Dec 21 12:19:49.402: INFO: kube-proxy-wmhd2 from kube-system started at 2020-12-21 11:48:44 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.402: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 12:19:49.402: INFO: node-exporter-8m5jv from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.402: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 12:19:49.402: INFO: node-local-dns-qpm75 from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.402: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 12:19:49.402: INFO: canal-w4p2b from kube-system started at 2020-12-21 11:48:45 +0000 UTC (2 container statuses recorded)
Dec 21 12:19:49.402: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 12:19:49.403: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 12:19:49.403: INFO: coredns-854998958f-sf9zb from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.403: INFO: 	Container coredns ready: true, restart count 0
Dec 21 12:19:49.403: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-xp6km from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:19:49.403: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:19:49.403: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 12:19:49.403: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-244-13.eu-central-1.compute.internal before test
Dec 21 12:19:49.432: INFO: user-ssh-keys-agent-jx8sl from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.432: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 12:19:49.432: INFO: kube-proxy-rvhxj from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.432: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 12:19:49.432: INFO: canal-ljp6n from kube-system started at 2020-12-21 11:51:56 +0000 UTC (2 container statuses recorded)
Dec 21 12:19:49.432: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 12:19:49.432: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 12:19:49.432: INFO: node-exporter-hzvfb from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.432: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 12:19:49.432: INFO: node-local-dns-wqj25 from kube-system started at 2020-12-21 11:51:57 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.432: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 12:19:49.432: INFO: sonobuoy from sonobuoy started at 2020-12-21 12:10:49 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.432: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 21 12:19:49.432: INFO: syseleven-node-problem-detector-f6dnk from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:19:49.432: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 12:19:49.432: INFO: sonobuoy-e2e-job-12016c8e6e68444f from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:19:49.432: INFO: 	Container e2e ready: true, restart count 0
Dec 21 12:19:49.432: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:19:49.432: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-8p5kx from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:19:49.432: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:19:49.432: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6ac157cd-2d31-4b4d-872e-36fa657d832b 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-6ac157cd-2d31-4b4d-872e-36fa657d832b off the node ip-172-31-183-240.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6ac157cd-2d31-4b4d-872e-36fa657d832b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:24:57.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5412" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:308.370 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":273,"completed":24,"skipped":412,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:24:57.552: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1537
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Dec 21 12:24:57.712: INFO: Waiting up to 5m0s for pod "client-containers-10be04a2-43e6-4aca-b683-df76f6ce7eba" in namespace "containers-1537" to be "Succeeded or Failed"
Dec 21 12:24:57.718: INFO: Pod "client-containers-10be04a2-43e6-4aca-b683-df76f6ce7eba": Phase="Pending", Reason="", readiness=false. Elapsed: 6.450374ms
Dec 21 12:24:59.727: INFO: Pod "client-containers-10be04a2-43e6-4aca-b683-df76f6ce7eba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015460624s
STEP: Saw pod success
Dec 21 12:24:59.727: INFO: Pod "client-containers-10be04a2-43e6-4aca-b683-df76f6ce7eba" satisfied condition "Succeeded or Failed"
Dec 21 12:24:59.732: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod client-containers-10be04a2-43e6-4aca-b683-df76f6ce7eba container test-container: <nil>
STEP: delete the pod
Dec 21 12:24:59.763: INFO: Waiting for pod client-containers-10be04a2-43e6-4aca-b683-df76f6ce7eba to disappear
Dec 21 12:24:59.769: INFO: Pod client-containers-10be04a2-43e6-4aca-b683-df76f6ce7eba no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:24:59.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1537" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":273,"completed":25,"skipped":423,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:24:59.785: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2311
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-2311/configmap-test-28dfef2a-73a1-4df5-a61d-e15cf158a0a6
STEP: Creating a pod to test consume configMaps
Dec 21 12:24:59.960: INFO: Waiting up to 5m0s for pod "pod-configmaps-9ee5092a-6936-4f6c-be32-3991ebd60ca8" in namespace "configmap-2311" to be "Succeeded or Failed"
Dec 21 12:24:59.964: INFO: Pod "pod-configmaps-9ee5092a-6936-4f6c-be32-3991ebd60ca8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.671119ms
Dec 21 12:25:01.969: INFO: Pod "pod-configmaps-9ee5092a-6936-4f6c-be32-3991ebd60ca8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008655014s
Dec 21 12:25:03.974: INFO: Pod "pod-configmaps-9ee5092a-6936-4f6c-be32-3991ebd60ca8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01354994s
STEP: Saw pod success
Dec 21 12:25:03.974: INFO: Pod "pod-configmaps-9ee5092a-6936-4f6c-be32-3991ebd60ca8" satisfied condition "Succeeded or Failed"
Dec 21 12:25:03.978: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-configmaps-9ee5092a-6936-4f6c-be32-3991ebd60ca8 container env-test: <nil>
STEP: delete the pod
Dec 21 12:25:04.008: INFO: Waiting for pod pod-configmaps-9ee5092a-6936-4f6c-be32-3991ebd60ca8 to disappear
Dec 21 12:25:04.012: INFO: Pod pod-configmaps-9ee5092a-6936-4f6c-be32-3991ebd60ca8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:25:04.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2311" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":273,"completed":26,"skipped":445,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:25:04.028: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:25:04.189: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90e2446f-d310-4a4d-95a5-cb6647efcbf1" in namespace "projected-5478" to be "Succeeded or Failed"
Dec 21 12:25:04.198: INFO: Pod "downwardapi-volume-90e2446f-d310-4a4d-95a5-cb6647efcbf1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.6547ms
Dec 21 12:25:06.203: INFO: Pod "downwardapi-volume-90e2446f-d310-4a4d-95a5-cb6647efcbf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01346446s
Dec 21 12:25:08.207: INFO: Pod "downwardapi-volume-90e2446f-d310-4a4d-95a5-cb6647efcbf1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017592195s
STEP: Saw pod success
Dec 21 12:25:08.207: INFO: Pod "downwardapi-volume-90e2446f-d310-4a4d-95a5-cb6647efcbf1" satisfied condition "Succeeded or Failed"
Dec 21 12:25:08.211: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-90e2446f-d310-4a4d-95a5-cb6647efcbf1 container client-container: <nil>
STEP: delete the pod
Dec 21 12:25:08.244: INFO: Waiting for pod downwardapi-volume-90e2446f-d310-4a4d-95a5-cb6647efcbf1 to disappear
Dec 21 12:25:08.249: INFO: Pod downwardapi-volume-90e2446f-d310-4a4d-95a5-cb6647efcbf1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:25:08.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5478" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":27,"skipped":472,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:25:08.265: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2817
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:25:24.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2817" for this suite.

• [SLOW TEST:16.296 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":273,"completed":28,"skipped":475,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:25:24.562: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-1768
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1768 to expose endpoints map[]
Dec 21 12:25:24.749: INFO: successfully validated that service multi-endpoint-test in namespace services-1768 exposes endpoints map[] (5.146693ms elapsed)
STEP: Creating pod pod1 in namespace services-1768
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1768 to expose endpoints map[pod1:[100]]
Dec 21 12:25:27.826: INFO: successfully validated that service multi-endpoint-test in namespace services-1768 exposes endpoints map[pod1:[100]] (3.068877178s elapsed)
STEP: Creating pod pod2 in namespace services-1768
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1768 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 21 12:25:30.908: INFO: successfully validated that service multi-endpoint-test in namespace services-1768 exposes endpoints map[pod1:[100] pod2:[101]] (3.07420477s elapsed)
STEP: Deleting pod pod1 in namespace services-1768
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1768 to expose endpoints map[pod2:[101]]
Dec 21 12:25:30.928: INFO: successfully validated that service multi-endpoint-test in namespace services-1768 exposes endpoints map[pod2:[101]] (11.317609ms elapsed)
STEP: Deleting pod pod2 in namespace services-1768
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1768 to expose endpoints map[]
Dec 21 12:25:31.952: INFO: successfully validated that service multi-endpoint-test in namespace services-1768 exposes endpoints map[] (1.010073203s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:25:31.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1768" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:7.432 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":273,"completed":29,"skipped":493,"failed":0}
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:25:31.994: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9323
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 21 12:25:42.186: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:25:42.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1221 12:25:42.185992      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9323" for this suite.

• [SLOW TEST:10.203 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":273,"completed":30,"skipped":496,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:25:42.199: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1053
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:25:55.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1053" for this suite.

• [SLOW TEST:13.248 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":273,"completed":31,"skipped":497,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:25:55.447: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2639
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1221 12:25:57.175499      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 21 12:25:57.175: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:25:57.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2639" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":273,"completed":32,"skipped":498,"failed":0}
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:25:57.195: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7461
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 21 12:25:59.375: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:25:59.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7461" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":273,"completed":33,"skipped":504,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:25:59.410: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-987
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-b569
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 12:25:59.584: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-b569" in namespace "subpath-987" to be "Succeeded or Failed"
Dec 21 12:25:59.590: INFO: Pod "pod-subpath-test-projected-b569": Phase="Pending", Reason="", readiness=false. Elapsed: 6.096723ms
Dec 21 12:26:01.595: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 2.010824374s
Dec 21 12:26:03.600: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 4.015478015s
Dec 21 12:26:05.605: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 6.021067806s
Dec 21 12:26:07.610: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 8.025591544s
Dec 21 12:26:09.615: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 10.030922656s
Dec 21 12:26:11.620: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 12.035562589s
Dec 21 12:26:13.627: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 14.042304707s
Dec 21 12:26:15.631: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 16.046313556s
Dec 21 12:26:17.635: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 18.050643766s
Dec 21 12:26:19.640: INFO: Pod "pod-subpath-test-projected-b569": Phase="Running", Reason="", readiness=true. Elapsed: 20.055213414s
Dec 21 12:26:21.647: INFO: Pod "pod-subpath-test-projected-b569": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.062424986s
STEP: Saw pod success
Dec 21 12:26:21.647: INFO: Pod "pod-subpath-test-projected-b569" satisfied condition "Succeeded or Failed"
Dec 21 12:26:21.651: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-subpath-test-projected-b569 container test-container-subpath-projected-b569: <nil>
STEP: delete the pod
Dec 21 12:26:21.681: INFO: Waiting for pod pod-subpath-test-projected-b569 to disappear
Dec 21 12:26:21.687: INFO: Pod pod-subpath-test-projected-b569 no longer exists
STEP: Deleting pod pod-subpath-test-projected-b569
Dec 21 12:26:21.687: INFO: Deleting pod "pod-subpath-test-projected-b569" in namespace "subpath-987"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:26:21.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-987" for this suite.

• [SLOW TEST:22.294 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":273,"completed":34,"skipped":507,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:26:21.704: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2822
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 21 12:26:25.892: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-2822 PodName:pod-sharedvolume-2b20f429-0ab7-4c5d-ad70-9fcb9ebd8a1c ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:26:25.892: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:26:26.268: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:26:26.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2822" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":273,"completed":35,"skipped":535,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:26:26.284: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7548
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 21 12:26:26.439: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 12:26:26.456: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 12:26:26.460: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-183-240.eu-central-1.compute.internal before test
Dec 21 12:26:26.486: INFO: canal-z66nn from kube-system started at 2020-12-21 11:46:17 +0000 UTC (2 container statuses recorded)
Dec 21 12:26:26.486: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 12:26:26.486: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 12:26:26.486: INFO: node-local-dns-htgfk from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.486: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 12:26:26.486: INFO: coredns-854998958f-nm6p2 from kube-system started at 2020-12-21 11:46:38 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.486: INFO: 	Container coredns ready: true, restart count 0
Dec 21 12:26:26.486: INFO: dns-autoscaler-596856b68b-qzt9r from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.486: INFO: 	Container autoscaler ready: true, restart count 0
Dec 21 12:26:26.486: INFO: openvpn-client-56dc45fdbd-pvwz9 from kube-system started at 2020-12-21 11:49:06 +0000 UTC (2 container statuses recorded)
Dec 21 12:26:26.486: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 21 12:26:26.486: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 21 12:26:26.486: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-g9pqh from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:26:26.486: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:26:26.486: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 12:26:26.486: INFO: user-ssh-keys-agent-282ml from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.486: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 12:26:26.486: INFO: syseleven-node-problem-detector-xwkkt from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.486: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 12:26:26.487: INFO: kube-proxy-2s25g from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.487: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 12:26:26.487: INFO: tiller-deploy-5648ccb4b6-c8nqp from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.487: INFO: 	Container tiller ready: true, restart count 0
Dec 21 12:26:26.487: INFO: node-exporter-hjpfq from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.487: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 12:26:26.487: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-232-239.eu-central-1.compute.internal before test
Dec 21 12:26:26.570: INFO: pod-sharedvolume-2b20f429-0ab7-4c5d-ad70-9fcb9ebd8a1c from emptydir-2822 started at 2020-12-21 12:26:21 +0000 UTC (2 container statuses recorded)
Dec 21 12:26:26.570: INFO: 	Container busybox-main-container ready: true, restart count 0
Dec 21 12:26:26.570: INFO: 	Container busybox-sub-container ready: false, restart count 0
Dec 21 12:26:26.570: INFO: syseleven-node-problem-detector-6vfvr from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.570: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 12:26:26.570: INFO: user-ssh-keys-agent-4gr8h from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.570: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 12:26:26.570: INFO: cluster-autoscaler-5c8c86777b-9jllr from kube-system started at 2020-12-21 11:52:18 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.570: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 21 12:26:26.571: INFO: canal-w4p2b from kube-system started at 2020-12-21 11:48:45 +0000 UTC (2 container statuses recorded)
Dec 21 12:26:26.571: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 12:26:26.571: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 12:26:26.571: INFO: coredns-854998958f-sf9zb from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.571: INFO: 	Container coredns ready: true, restart count 0
Dec 21 12:26:26.571: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-xp6km from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:26:26.571: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:26:26.571: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 12:26:26.571: INFO: kube-proxy-wmhd2 from kube-system started at 2020-12-21 11:48:44 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.571: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 12:26:26.571: INFO: node-exporter-8m5jv from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.571: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 12:26:26.571: INFO: node-local-dns-qpm75 from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.571: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 12:26:26.571: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-244-13.eu-central-1.compute.internal before test
Dec 21 12:26:26.630: INFO: user-ssh-keys-agent-jx8sl from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.630: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 12:26:26.630: INFO: kube-proxy-rvhxj from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.630: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 12:26:26.630: INFO: canal-ljp6n from kube-system started at 2020-12-21 11:51:56 +0000 UTC (2 container statuses recorded)
Dec 21 12:26:26.630: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 12:26:26.630: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 12:26:26.630: INFO: node-exporter-hzvfb from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.630: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 12:26:26.630: INFO: node-local-dns-wqj25 from kube-system started at 2020-12-21 11:51:57 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.630: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 12:26:26.630: INFO: sonobuoy from sonobuoy started at 2020-12-21 12:10:49 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.630: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 21 12:26:26.630: INFO: syseleven-node-problem-detector-f6dnk from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:26:26.630: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 12:26:26.630: INFO: sonobuoy-e2e-job-12016c8e6e68444f from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:26:26.630: INFO: 	Container e2e ready: true, restart count 0
Dec 21 12:26:26.630: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:26:26.630: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-8p5kx from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:26:26.630: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:26:26.630: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6f65a040-69e0-4ca0-a1cc-35c9206b108d 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-6f65a040-69e0-4ca0-a1cc-35c9206b108d off the node ip-172-31-183-240.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6f65a040-69e0-4ca0-a1cc-35c9206b108d
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:26:32.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7548" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:6.459 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":273,"completed":36,"skipped":542,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:26:32.744: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3227
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:26:33.750: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 12:26:35.769: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150393, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150393, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150393, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150393, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:26:38.791: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:26:38.798: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:26:40.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3227" for this suite.
STEP: Destroying namespace "webhook-3227-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.786 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":273,"completed":37,"skipped":569,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:26:40.536: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6472
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 21 12:26:40.690: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:26:56.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6472" for this suite.

• [SLOW TEST:16.260 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":273,"completed":38,"skipped":578,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:26:56.797: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9371
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:26:56.959: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:26:59.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9371" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":273,"completed":39,"skipped":592,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:26:59.041: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8897
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:26:59.223: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7bce0885-f242-48c4-8fe3-0a0a6b03019d" in namespace "projected-8897" to be "Succeeded or Failed"
Dec 21 12:26:59.227: INFO: Pod "downwardapi-volume-7bce0885-f242-48c4-8fe3-0a0a6b03019d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.555316ms
Dec 21 12:27:01.234: INFO: Pod "downwardapi-volume-7bce0885-f242-48c4-8fe3-0a0a6b03019d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009801082s
STEP: Saw pod success
Dec 21 12:27:01.234: INFO: Pod "downwardapi-volume-7bce0885-f242-48c4-8fe3-0a0a6b03019d" satisfied condition "Succeeded or Failed"
Dec 21 12:27:01.238: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod downwardapi-volume-7bce0885-f242-48c4-8fe3-0a0a6b03019d container client-container: <nil>
STEP: delete the pod
Dec 21 12:27:01.289: INFO: Waiting for pod downwardapi-volume-7bce0885-f242-48c4-8fe3-0a0a6b03019d to disappear
Dec 21 12:27:01.296: INFO: Pod downwardapi-volume-7bce0885-f242-48c4-8fe3-0a0a6b03019d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:27:01.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8897" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":273,"completed":40,"skipped":602,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:27:01.337: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-745a2d50-a44f-4d0f-af73-a043ba7159ca
STEP: Creating a pod to test consume secrets
Dec 21 12:27:01.524: INFO: Waiting up to 5m0s for pod "pod-secrets-58d878ff-5479-40ca-b9d7-8922db585327" in namespace "secrets-9925" to be "Succeeded or Failed"
Dec 21 12:27:01.543: INFO: Pod "pod-secrets-58d878ff-5479-40ca-b9d7-8922db585327": Phase="Pending", Reason="", readiness=false. Elapsed: 19.19719ms
Dec 21 12:27:03.547: INFO: Pod "pod-secrets-58d878ff-5479-40ca-b9d7-8922db585327": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023382429s
Dec 21 12:27:05.552: INFO: Pod "pod-secrets-58d878ff-5479-40ca-b9d7-8922db585327": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028218456s
STEP: Saw pod success
Dec 21 12:27:05.552: INFO: Pod "pod-secrets-58d878ff-5479-40ca-b9d7-8922db585327" satisfied condition "Succeeded or Failed"
Dec 21 12:27:05.556: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-secrets-58d878ff-5479-40ca-b9d7-8922db585327 container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 12:27:05.581: INFO: Waiting for pod pod-secrets-58d878ff-5479-40ca-b9d7-8922db585327 to disappear
Dec 21 12:27:05.586: INFO: Pod pod-secrets-58d878ff-5479-40ca-b9d7-8922db585327 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:27:05.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9925" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":41,"skipped":609,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:27:05.613: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9941
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:27:12.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9941" for this suite.

• [SLOW TEST:7.208 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":273,"completed":42,"skipped":632,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:27:12.835: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 21 12:27:24.051: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:27:25.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1023" for this suite.

• [SLOW TEST:12.263 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":273,"completed":43,"skipped":680,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:27:25.099: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5657
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Dec 21 12:27:25.290: INFO: Waiting up to 5m0s for pod "var-expansion-58addd0a-2046-4deb-af8c-41d05f0c0b7a" in namespace "var-expansion-5657" to be "Succeeded or Failed"
Dec 21 12:27:25.299: INFO: Pod "var-expansion-58addd0a-2046-4deb-af8c-41d05f0c0b7a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.965489ms
Dec 21 12:27:27.309: INFO: Pod "var-expansion-58addd0a-2046-4deb-af8c-41d05f0c0b7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019599145s
Dec 21 12:27:29.314: INFO: Pod "var-expansion-58addd0a-2046-4deb-af8c-41d05f0c0b7a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024081182s
Dec 21 12:27:31.330: INFO: Pod "var-expansion-58addd0a-2046-4deb-af8c-41d05f0c0b7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040075559s
STEP: Saw pod success
Dec 21 12:27:31.330: INFO: Pod "var-expansion-58addd0a-2046-4deb-af8c-41d05f0c0b7a" satisfied condition "Succeeded or Failed"
Dec 21 12:27:31.353: INFO: Trying to get logs from node ip-172-31-244-13.eu-central-1.compute.internal pod var-expansion-58addd0a-2046-4deb-af8c-41d05f0c0b7a container dapi-container: <nil>
STEP: delete the pod
Dec 21 12:27:31.399: INFO: Waiting for pod var-expansion-58addd0a-2046-4deb-af8c-41d05f0c0b7a to disappear
Dec 21 12:27:31.405: INFO: Pod var-expansion-58addd0a-2046-4deb-af8c-41d05f0c0b7a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:27:31.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5657" for this suite.

• [SLOW TEST:6.324 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":273,"completed":44,"skipped":687,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:27:31.424: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9489
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-01d98862-d36d-48c5-9a82-6404241b19ed
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-01d98862-d36d-48c5-9a82-6404241b19ed
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:27:39.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9489" for this suite.

• [SLOW TEST:8.357 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":45,"skipped":689,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:27:39.782: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 21 12:27:39.944: INFO: Waiting up to 5m0s for pod "downward-api-92e9d918-dedb-43bf-948a-97cee0fd1d3a" in namespace "downward-api-9084" to be "Succeeded or Failed"
Dec 21 12:27:39.948: INFO: Pod "downward-api-92e9d918-dedb-43bf-948a-97cee0fd1d3a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.382479ms
Dec 21 12:27:41.955: INFO: Pod "downward-api-92e9d918-dedb-43bf-948a-97cee0fd1d3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011515365s
STEP: Saw pod success
Dec 21 12:27:41.955: INFO: Pod "downward-api-92e9d918-dedb-43bf-948a-97cee0fd1d3a" satisfied condition "Succeeded or Failed"
Dec 21 12:27:41.960: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod downward-api-92e9d918-dedb-43bf-948a-97cee0fd1d3a container dapi-container: <nil>
STEP: delete the pod
Dec 21 12:27:42.001: INFO: Waiting for pod downward-api-92e9d918-dedb-43bf-948a-97cee0fd1d3a to disappear
Dec 21 12:27:42.005: INFO: Pod downward-api-92e9d918-dedb-43bf-948a-97cee0fd1d3a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:27:42.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9084" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":273,"completed":46,"skipped":704,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:27:42.024: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9574
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-b9e7981a-684e-47c9-860c-90bc9e1bad81
STEP: Creating secret with name s-test-opt-upd-6098b4c5-7a5b-43c0-85bf-feee7a252d8a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b9e7981a-684e-47c9-860c-90bc9e1bad81
STEP: Updating secret s-test-opt-upd-6098b4c5-7a5b-43c0-85bf-feee7a252d8a
STEP: Creating secret with name s-test-opt-create-02eed989-a37a-4f03-9650-a17488e8f026
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:29:15.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9574" for this suite.

• [SLOW TEST:93.288 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":47,"skipped":705,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:29:15.320: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1741
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:29:15.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1741" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":273,"completed":48,"skipped":712,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:29:15.504: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-vg9bk in namespace proxy-1586
I1221 12:29:15.679853      20 runners.go:190] Created replication controller with name: proxy-service-vg9bk, namespace: proxy-1586, replica count: 1
I1221 12:29:16.733678      20 runners.go:190] proxy-service-vg9bk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1221 12:29:17.734053      20 runners.go:190] proxy-service-vg9bk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 12:29:18.735330      20 runners.go:190] proxy-service-vg9bk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 12:29:19.735475      20 runners.go:190] proxy-service-vg9bk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1221 12:29:20.736309      20 runners.go:190] proxy-service-vg9bk Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 21 12:29:20.745: INFO: setup took 5.090114479s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 21 12:29:20.810: INFO: (0) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 64.936499ms)
Dec 21 12:29:20.810: INFO: (0) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 64.572298ms)
Dec 21 12:29:20.810: INFO: (0) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 65.564119ms)
Dec 21 12:29:20.810: INFO: (0) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 65.687533ms)
Dec 21 12:29:20.817: INFO: (0) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 70.885495ms)
Dec 21 12:29:20.817: INFO: (0) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 70.915291ms)
Dec 21 12:29:20.817: INFO: (0) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 71.107175ms)
Dec 21 12:29:20.833: INFO: (0) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 87.384673ms)
Dec 21 12:29:20.833: INFO: (0) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 87.593582ms)
Dec 21 12:29:20.835: INFO: (0) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 89.383854ms)
Dec 21 12:29:20.835: INFO: (0) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 90.397165ms)
Dec 21 12:29:20.839: INFO: (0) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 93.313292ms)
Dec 21 12:29:20.839: INFO: (0) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 93.537706ms)
Dec 21 12:29:20.840: INFO: (0) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 93.719795ms)
Dec 21 12:29:20.881: INFO: (0) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 135.901407ms)
Dec 21 12:29:20.882: INFO: (0) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 135.898281ms)
Dec 21 12:29:20.889: INFO: (1) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 7.25803ms)
Dec 21 12:29:20.890: INFO: (1) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 7.966472ms)
Dec 21 12:29:20.890: INFO: (1) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 8.179206ms)
Dec 21 12:29:20.890: INFO: (1) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 8.590254ms)
Dec 21 12:29:20.890: INFO: (1) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 8.572224ms)
Dec 21 12:29:20.891: INFO: (1) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 9.242769ms)
Dec 21 12:29:20.892: INFO: (1) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 10.070019ms)
Dec 21 12:29:20.892: INFO: (1) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 10.128748ms)
Dec 21 12:29:20.892: INFO: (1) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 10.198199ms)
Dec 21 12:29:20.892: INFO: (1) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 10.308633ms)
Dec 21 12:29:20.895: INFO: (1) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 12.555815ms)
Dec 21 12:29:20.895: INFO: (1) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 12.55118ms)
Dec 21 12:29:20.895: INFO: (1) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 12.975805ms)
Dec 21 12:29:20.895: INFO: (1) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 13.222312ms)
Dec 21 12:29:20.942: INFO: (1) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 59.805096ms)
Dec 21 12:29:20.942: INFO: (1) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 60.279395ms)
Dec 21 12:29:20.990: INFO: (2) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 48.093468ms)
Dec 21 12:29:20.990: INFO: (2) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 48.102055ms)
Dec 21 12:29:20.991: INFO: (2) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 48.385455ms)
Dec 21 12:29:20.991: INFO: (2) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 48.616114ms)
Dec 21 12:29:20.991: INFO: (2) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 48.478782ms)
Dec 21 12:29:20.991: INFO: (2) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 48.843252ms)
Dec 21 12:29:20.991: INFO: (2) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 48.678513ms)
Dec 21 12:29:20.991: INFO: (2) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 48.549289ms)
Dec 21 12:29:20.991: INFO: (2) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 49.027109ms)
Dec 21 12:29:21.009: INFO: (2) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 66.893774ms)
Dec 21 12:29:21.009: INFO: (2) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 67.061891ms)
Dec 21 12:29:21.009: INFO: (2) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 67.127509ms)
Dec 21 12:29:21.053: INFO: (2) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 111.240197ms)
Dec 21 12:29:21.053: INFO: (2) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 111.382855ms)
Dec 21 12:29:21.053: INFO: (2) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 111.097874ms)
Dec 21 12:29:21.053: INFO: (2) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 111.179257ms)
Dec 21 12:29:21.105: INFO: (3) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 50.790185ms)
Dec 21 12:29:21.105: INFO: (3) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 50.719952ms)
Dec 21 12:29:21.105: INFO: (3) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 50.839109ms)
Dec 21 12:29:21.105: INFO: (3) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 50.403332ms)
Dec 21 12:29:21.105: INFO: (3) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 51.131121ms)
Dec 21 12:29:21.105: INFO: (3) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 50.816526ms)
Dec 21 12:29:21.106: INFO: (3) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 51.452166ms)
Dec 21 12:29:21.106: INFO: (3) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 51.430659ms)
Dec 21 12:29:21.106: INFO: (3) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 51.374156ms)
Dec 21 12:29:21.107: INFO: (3) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 53.894194ms)
Dec 21 12:29:21.108: INFO: (3) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 53.311668ms)
Dec 21 12:29:21.108: INFO: (3) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 53.775836ms)
Dec 21 12:29:21.158: INFO: (3) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 104.016502ms)
Dec 21 12:29:21.162: INFO: (3) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 107.389217ms)
Dec 21 12:29:21.162: INFO: (3) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 107.55185ms)
Dec 21 12:29:21.162: INFO: (3) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 107.346294ms)
Dec 21 12:29:21.170: INFO: (4) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 7.512358ms)
Dec 21 12:29:21.184: INFO: (4) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 22.060279ms)
Dec 21 12:29:21.184: INFO: (4) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 21.657576ms)
Dec 21 12:29:21.185: INFO: (4) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 22.201747ms)
Dec 21 12:29:21.185: INFO: (4) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 22.340327ms)
Dec 21 12:29:21.185: INFO: (4) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 22.346931ms)
Dec 21 12:29:21.185: INFO: (4) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 22.253062ms)
Dec 21 12:29:21.185: INFO: (4) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 22.664631ms)
Dec 21 12:29:21.185: INFO: (4) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 22.607919ms)
Dec 21 12:29:21.186: INFO: (4) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 22.783704ms)
Dec 21 12:29:21.230: INFO: (4) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 67.145024ms)
Dec 21 12:29:21.230: INFO: (4) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 67.529236ms)
Dec 21 12:29:21.230: INFO: (4) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 67.498436ms)
Dec 21 12:29:21.230: INFO: (4) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 67.223281ms)
Dec 21 12:29:21.231: INFO: (4) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 68.220948ms)
Dec 21 12:29:21.231: INFO: (4) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 68.923972ms)
Dec 21 12:29:21.238: INFO: (5) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 6.588363ms)
Dec 21 12:29:21.240: INFO: (5) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 8.209361ms)
Dec 21 12:29:21.240: INFO: (5) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 8.181319ms)
Dec 21 12:29:21.240: INFO: (5) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 8.536911ms)
Dec 21 12:29:21.240: INFO: (5) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 8.304072ms)
Dec 21 12:29:21.240: INFO: (5) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 8.560942ms)
Dec 21 12:29:21.241: INFO: (5) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 9.207229ms)
Dec 21 12:29:21.241: INFO: (5) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 8.904199ms)
Dec 21 12:29:21.241: INFO: (5) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 9.043395ms)
Dec 21 12:29:21.241: INFO: (5) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 9.108922ms)
Dec 21 12:29:21.243: INFO: (5) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 11.13994ms)
Dec 21 12:29:21.243: INFO: (5) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 10.997613ms)
Dec 21 12:29:21.243: INFO: (5) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 11.375978ms)
Dec 21 12:29:21.243: INFO: (5) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 11.138254ms)
Dec 21 12:29:21.245: INFO: (5) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 12.930704ms)
Dec 21 12:29:21.245: INFO: (5) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 12.871573ms)
Dec 21 12:29:21.290: INFO: (6) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 45.051696ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 45.489342ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 45.954206ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 45.516476ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 45.732797ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 45.798397ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 46.524423ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 45.876122ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 46.15526ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 46.594902ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 46.394746ms)
Dec 21 12:29:21.291: INFO: (6) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 45.300681ms)
Dec 21 12:29:21.378: INFO: (6) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 132.403089ms)
Dec 21 12:29:21.378: INFO: (6) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 132.580704ms)
Dec 21 12:29:21.378: INFO: (6) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 133.039401ms)
Dec 21 12:29:21.378: INFO: (6) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 133.329078ms)
Dec 21 12:29:21.423: INFO: (7) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 44.318743ms)
Dec 21 12:29:21.423: INFO: (7) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 44.945564ms)
Dec 21 12:29:21.424: INFO: (7) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 45.144451ms)
Dec 21 12:29:21.424: INFO: (7) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 44.730928ms)
Dec 21 12:29:21.424: INFO: (7) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 44.595731ms)
Dec 21 12:29:21.424: INFO: (7) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 44.64838ms)
Dec 21 12:29:21.424: INFO: (7) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 44.580142ms)
Dec 21 12:29:21.424: INFO: (7) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 44.608992ms)
Dec 21 12:29:21.424: INFO: (7) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 45.067316ms)
Dec 21 12:29:21.424: INFO: (7) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 44.805492ms)
Dec 21 12:29:21.425: INFO: (7) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 45.594224ms)
Dec 21 12:29:21.426: INFO: (7) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 46.482568ms)
Dec 21 12:29:21.466: INFO: (7) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 87.272527ms)
Dec 21 12:29:21.467: INFO: (7) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 87.931253ms)
Dec 21 12:29:21.467: INFO: (7) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 88.128682ms)
Dec 21 12:29:21.467: INFO: (7) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 88.894984ms)
Dec 21 12:29:21.515: INFO: (8) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 47.206607ms)
Dec 21 12:29:21.515: INFO: (8) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 47.3386ms)
Dec 21 12:29:21.515: INFO: (8) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 47.45247ms)
Dec 21 12:29:21.516: INFO: (8) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 47.538601ms)
Dec 21 12:29:21.519: INFO: (8) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 51.411511ms)
Dec 21 12:29:21.519: INFO: (8) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 50.970891ms)
Dec 21 12:29:21.519: INFO: (8) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 51.36407ms)
Dec 21 12:29:21.519: INFO: (8) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 50.931018ms)
Dec 21 12:29:21.519: INFO: (8) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 51.325204ms)
Dec 21 12:29:21.519: INFO: (8) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 51.118058ms)
Dec 21 12:29:21.519: INFO: (8) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 51.131773ms)
Dec 21 12:29:21.519: INFO: (8) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 51.32468ms)
Dec 21 12:29:21.567: INFO: (8) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 99.161384ms)
Dec 21 12:29:21.567: INFO: (8) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 99.272925ms)
Dec 21 12:29:21.567: INFO: (8) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 98.848278ms)
Dec 21 12:29:21.567: INFO: (8) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 98.991043ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 50.090298ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 50.14711ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 50.189815ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 50.431ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 50.356988ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 50.166639ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 50.403801ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 50.595829ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 50.295472ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 50.739833ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 50.984007ms)
Dec 21 12:29:21.618: INFO: (9) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 50.880512ms)
Dec 21 12:29:21.662: INFO: (9) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 94.259949ms)
Dec 21 12:29:21.662: INFO: (9) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 94.125438ms)
Dec 21 12:29:21.662: INFO: (9) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 94.241642ms)
Dec 21 12:29:21.662: INFO: (9) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 94.611304ms)
Dec 21 12:29:21.670: INFO: (10) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 7.402633ms)
Dec 21 12:29:21.671: INFO: (10) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 8.51491ms)
Dec 21 12:29:21.672: INFO: (10) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 9.82549ms)
Dec 21 12:29:21.672: INFO: (10) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 9.796329ms)
Dec 21 12:29:21.673: INFO: (10) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 10.059712ms)
Dec 21 12:29:21.673: INFO: (10) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 10.364121ms)
Dec 21 12:29:21.673: INFO: (10) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 10.802094ms)
Dec 21 12:29:21.673: INFO: (10) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 10.720627ms)
Dec 21 12:29:21.673: INFO: (10) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 10.92986ms)
Dec 21 12:29:21.673: INFO: (10) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 11.115284ms)
Dec 21 12:29:21.673: INFO: (10) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 11.106793ms)
Dec 21 12:29:21.674: INFO: (10) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 11.792245ms)
Dec 21 12:29:21.675: INFO: (10) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 12.00177ms)
Dec 21 12:29:21.675: INFO: (10) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 12.001171ms)
Dec 21 12:29:21.675: INFO: (10) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 12.946114ms)
Dec 21 12:29:21.685: INFO: (10) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 22.15384ms)
Dec 21 12:29:21.699: INFO: (11) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 13.483563ms)
Dec 21 12:29:21.699: INFO: (11) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 13.513294ms)
Dec 21 12:29:21.699: INFO: (11) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 14.175199ms)
Dec 21 12:29:21.699: INFO: (11) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 14.323354ms)
Dec 21 12:29:21.700: INFO: (11) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 14.521616ms)
Dec 21 12:29:21.699: INFO: (11) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 13.478167ms)
Dec 21 12:29:21.700: INFO: (11) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 14.308401ms)
Dec 21 12:29:21.700: INFO: (11) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 14.435044ms)
Dec 21 12:29:21.700: INFO: (11) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 15.003237ms)
Dec 21 12:29:21.700: INFO: (11) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 14.489218ms)
Dec 21 12:29:21.700: INFO: (11) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 14.678441ms)
Dec 21 12:29:21.704: INFO: (11) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 18.693678ms)
Dec 21 12:29:21.750: INFO: (11) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 64.669326ms)
Dec 21 12:29:21.750: INFO: (11) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 64.490171ms)
Dec 21 12:29:21.750: INFO: (11) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 64.879011ms)
Dec 21 12:29:21.750: INFO: (11) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 64.929737ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 46.682847ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 46.496643ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 46.988656ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 46.117963ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 46.406334ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 46.678607ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 46.215389ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 46.531251ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 46.460229ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 46.676793ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 47.411509ms)
Dec 21 12:29:21.798: INFO: (12) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 47.122147ms)
Dec 21 12:29:21.844: INFO: (12) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 92.738429ms)
Dec 21 12:29:21.844: INFO: (12) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 92.871725ms)
Dec 21 12:29:21.844: INFO: (12) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 93.462952ms)
Dec 21 12:29:21.844: INFO: (12) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 93.722046ms)
Dec 21 12:29:21.852: INFO: (13) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 7.14074ms)
Dec 21 12:29:21.853: INFO: (13) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 8.188239ms)
Dec 21 12:29:21.853: INFO: (13) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 8.405152ms)
Dec 21 12:29:21.853: INFO: (13) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 8.791421ms)
Dec 21 12:29:21.853: INFO: (13) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 8.563912ms)
Dec 21 12:29:21.854: INFO: (13) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 8.532887ms)
Dec 21 12:29:21.857: INFO: (13) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 12.403644ms)
Dec 21 12:29:21.857: INFO: (13) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 12.118546ms)
Dec 21 12:29:21.857: INFO: (13) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 12.195109ms)
Dec 21 12:29:21.859: INFO: (13) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 14.120162ms)
Dec 21 12:29:21.867: INFO: (13) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 22.297667ms)
Dec 21 12:29:21.868: INFO: (13) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 23.037785ms)
Dec 21 12:29:21.868: INFO: (13) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 22.603749ms)
Dec 21 12:29:21.868: INFO: (13) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 23.014641ms)
Dec 21 12:29:21.868: INFO: (13) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 23.101876ms)
Dec 21 12:29:21.869: INFO: (13) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 23.766528ms)
Dec 21 12:29:21.898: INFO: (14) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 28.754893ms)
Dec 21 12:29:21.898: INFO: (14) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 28.73008ms)
Dec 21 12:29:21.898: INFO: (14) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 28.867032ms)
Dec 21 12:29:21.898: INFO: (14) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 28.817514ms)
Dec 21 12:29:21.898: INFO: (14) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 28.840246ms)
Dec 21 12:29:21.898: INFO: (14) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 29.256777ms)
Dec 21 12:29:21.898: INFO: (14) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 29.161318ms)
Dec 21 12:29:21.899: INFO: (14) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 30.130841ms)
Dec 21 12:29:21.899: INFO: (14) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 30.281855ms)
Dec 21 12:29:21.899: INFO: (14) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 30.604922ms)
Dec 21 12:29:21.899: INFO: (14) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 30.503357ms)
Dec 21 12:29:21.899: INFO: (14) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 30.321618ms)
Dec 21 12:29:21.900: INFO: (14) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 31.108224ms)
Dec 21 12:29:21.901: INFO: (14) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 32.00548ms)
Dec 21 12:29:21.901: INFO: (14) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 32.213387ms)
Dec 21 12:29:21.901: INFO: (14) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 32.807904ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 47.379932ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 47.345338ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 47.314314ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 47.278434ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 47.957877ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 48.464614ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 48.035205ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 48.191613ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 48.256299ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 48.028289ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 48.45957ms)
Dec 21 12:29:21.950: INFO: (15) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 48.225085ms)
Dec 21 12:29:21.998: INFO: (15) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 95.822052ms)
Dec 21 12:29:21.998: INFO: (15) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 96.108323ms)
Dec 21 12:29:21.998: INFO: (15) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 96.72161ms)
Dec 21 12:29:21.998: INFO: (15) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 96.564435ms)
Dec 21 12:29:22.041: INFO: (16) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 41.706203ms)
Dec 21 12:29:22.041: INFO: (16) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 42.446607ms)
Dec 21 12:29:22.047: INFO: (16) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 48.000861ms)
Dec 21 12:29:22.048: INFO: (16) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 47.88099ms)
Dec 21 12:29:22.048: INFO: (16) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 49.388291ms)
Dec 21 12:29:22.048: INFO: (16) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 48.962718ms)
Dec 21 12:29:22.048: INFO: (16) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 48.839735ms)
Dec 21 12:29:22.048: INFO: (16) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 48.702923ms)
Dec 21 12:29:22.048: INFO: (16) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 48.202788ms)
Dec 21 12:29:22.048: INFO: (16) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 48.682728ms)
Dec 21 12:29:22.049: INFO: (16) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 49.517046ms)
Dec 21 12:29:22.049: INFO: (16) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 50.398383ms)
Dec 21 12:29:22.050: INFO: (16) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 50.986977ms)
Dec 21 12:29:22.050: INFO: (16) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 50.136478ms)
Dec 21 12:29:22.050: INFO: (16) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 51.325506ms)
Dec 21 12:29:22.051: INFO: (16) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 51.210077ms)
Dec 21 12:29:22.060: INFO: (17) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 8.647297ms)
Dec 21 12:29:22.061: INFO: (17) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 10.191237ms)
Dec 21 12:29:22.072: INFO: (17) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 20.500409ms)
Dec 21 12:29:22.072: INFO: (17) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 20.511942ms)
Dec 21 12:29:22.072: INFO: (17) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 20.886088ms)
Dec 21 12:29:22.072: INFO: (17) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 20.483411ms)
Dec 21 12:29:22.072: INFO: (17) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 20.477662ms)
Dec 21 12:29:22.072: INFO: (17) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 20.744796ms)
Dec 21 12:29:22.073: INFO: (17) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 21.748483ms)
Dec 21 12:29:22.121: INFO: (17) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 69.708151ms)
Dec 21 12:29:22.121: INFO: (17) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 69.40556ms)
Dec 21 12:29:22.121: INFO: (17) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 69.708089ms)
Dec 21 12:29:22.121: INFO: (17) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 69.832797ms)
Dec 21 12:29:22.121: INFO: (17) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 69.653903ms)
Dec 21 12:29:22.121: INFO: (17) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 69.701363ms)
Dec 21 12:29:22.121: INFO: (17) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 69.890237ms)
Dec 21 12:29:22.133: INFO: (18) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 11.647811ms)
Dec 21 12:29:22.140: INFO: (18) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 18.138978ms)
Dec 21 12:29:22.140: INFO: (18) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 18.35273ms)
Dec 21 12:29:22.140: INFO: (18) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 18.518954ms)
Dec 21 12:29:22.141: INFO: (18) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 19.007137ms)
Dec 21 12:29:22.141: INFO: (18) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 19.318586ms)
Dec 21 12:29:22.141: INFO: (18) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 19.716587ms)
Dec 21 12:29:22.141: INFO: (18) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 19.527369ms)
Dec 21 12:29:22.141: INFO: (18) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 19.452304ms)
Dec 21 12:29:22.142: INFO: (18) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 19.794162ms)
Dec 21 12:29:22.142: INFO: (18) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 19.993196ms)
Dec 21 12:29:22.142: INFO: (18) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 20.694773ms)
Dec 21 12:29:22.143: INFO: (18) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 21.144429ms)
Dec 21 12:29:22.144: INFO: (18) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 21.367687ms)
Dec 21 12:29:22.144: INFO: (18) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 22.02682ms)
Dec 21 12:29:22.144: INFO: (18) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 22.693363ms)
Dec 21 12:29:22.193: INFO: (19) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87/proxy/rewriteme">test</a> (200; 48.702772ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 49.28297ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname1/proxy/: foo (200; 48.470284ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname1/proxy/: tls baz (200; 48.958154ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/services/https:proxy-service-vg9bk:tlsportname2/proxy/: tls qux (200; 48.627938ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:460/proxy/: tls baz (200; 48.958341ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 48.839685ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">... (200; 49.801544ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:443/proxy/tlsrewritem... (200; 48.771481ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/: <a href="/api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:1080/proxy/rewriteme">test<... (200; 49.005226ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/pods/https:proxy-service-vg9bk-qsq87:462/proxy/: tls qux (200; 49.075932ms)
Dec 21 12:29:22.194: INFO: (19) /api/v1/namespaces/proxy-1586/pods/http:proxy-service-vg9bk-qsq87:162/proxy/: bar (200; 48.999732ms)
Dec 21 12:29:22.242: INFO: (19) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname1/proxy/: foo (200; 96.978318ms)
Dec 21 12:29:22.242: INFO: (19) /api/v1/namespaces/proxy-1586/pods/proxy-service-vg9bk-qsq87:160/proxy/: foo (200; 96.647037ms)
Dec 21 12:29:22.242: INFO: (19) /api/v1/namespaces/proxy-1586/services/proxy-service-vg9bk:portname2/proxy/: bar (200; 96.780138ms)
Dec 21 12:29:22.242: INFO: (19) /api/v1/namespaces/proxy-1586/services/http:proxy-service-vg9bk:portname2/proxy/: bar (200; 96.835816ms)
STEP: deleting ReplicationController proxy-service-vg9bk in namespace proxy-1586, will wait for the garbage collector to delete the pods
Dec 21 12:29:22.308: INFO: Deleting ReplicationController proxy-service-vg9bk took: 11.419492ms
Dec 21 12:29:22.909: INFO: Terminating ReplicationController proxy-service-vg9bk pods took: 600.538912ms
[AfterEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:29:34.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1586" for this suite.

• [SLOW TEST:19.320 seconds]
[sig-network] Proxy
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":273,"completed":49,"skipped":727,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:29:34.825: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3656
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3656 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3656;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3656 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3656;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3656.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3656.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3656.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3656.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3656.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3656.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3656.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3656.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3656.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3656.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3656.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 175.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.175_udp@PTR;check="$$(dig +tcp +noall +answer +search 175.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.175_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3656 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3656;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3656 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3656;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3656.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3656.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3656.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3656.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3656.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3656.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3656.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3656.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3656.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3656.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3656.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3656.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 175.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.175_udp@PTR;check="$$(dig +tcp +noall +answer +search 175.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.175_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 12:29:45.136: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.177: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.225: INFO: Unable to read wheezy_udp@dns-test-service.dns-3656 from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.274: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3656 from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.282: INFO: Unable to read wheezy_udp@dns-test-service.dns-3656.svc from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.291: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3656.svc from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.297: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.312: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.581: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.589: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.595: INFO: Unable to read jessie_udp@dns-test-service.dns-3656 from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.601: INFO: Unable to read jessie_tcp@dns-test-service.dns-3656 from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.607: INFO: Unable to read jessie_udp@dns-test-service.dns-3656.svc from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.620: INFO: Unable to read jessie_tcp@dns-test-service.dns-3656.svc from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.629: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3656.svc from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.634: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc from pod dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8: the server could not find the requested resource (get pods dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8)
Dec 21 12:29:45.848: INFO: Lookups using dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3656 wheezy_tcp@dns-test-service.dns-3656 wheezy_udp@dns-test-service.dns-3656.svc wheezy_tcp@dns-test-service.dns-3656.svc wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3656 jessie_tcp@dns-test-service.dns-3656 jessie_udp@dns-test-service.dns-3656.svc jessie_tcp@dns-test-service.dns-3656.svc jessie_udp@_http._tcp.dns-test-service.dns-3656.svc jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc]

Dec 21 12:29:51.810: INFO: DNS probes using dns-3656/dns-test-349da8f2-e90f-4aba-9c5d-549f2e1da6b8 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:29:51.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3656" for this suite.

• [SLOW TEST:17.091 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":273,"completed":50,"skipped":744,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:29:51.916: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-96
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-8bb597fd-b129-4bad-bb83-9d972c1c6845
STEP: Creating a pod to test consume configMaps
Dec 21 12:29:52.088: INFO: Waiting up to 5m0s for pod "pod-configmaps-5fbd68aa-84a0-41b0-8c13-4dcb0d381f64" in namespace "configmap-96" to be "Succeeded or Failed"
Dec 21 12:29:52.091: INFO: Pod "pod-configmaps-5fbd68aa-84a0-41b0-8c13-4dcb0d381f64": Phase="Pending", Reason="", readiness=false. Elapsed: 3.230596ms
Dec 21 12:29:54.096: INFO: Pod "pod-configmaps-5fbd68aa-84a0-41b0-8c13-4dcb0d381f64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007691889s
STEP: Saw pod success
Dec 21 12:29:54.096: INFO: Pod "pod-configmaps-5fbd68aa-84a0-41b0-8c13-4dcb0d381f64" satisfied condition "Succeeded or Failed"
Dec 21 12:29:54.099: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-configmaps-5fbd68aa-84a0-41b0-8c13-4dcb0d381f64 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 12:29:54.130: INFO: Waiting for pod pod-configmaps-5fbd68aa-84a0-41b0-8c13-4dcb0d381f64 to disappear
Dec 21 12:29:54.133: INFO: Pod pod-configmaps-5fbd68aa-84a0-41b0-8c13-4dcb0d381f64 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:29:54.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-96" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":273,"completed":51,"skipped":773,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:29:54.147: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:30:10.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9782" for this suite.

• [SLOW TEST:16.238 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":273,"completed":52,"skipped":790,"failed":0}
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:30:10.386: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-6742
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 21 12:30:10.663: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 21 12:30:10.798: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:30:12.802: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:30:14.811: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:30:16.802: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:30:18.803: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:30:20.803: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:30:22.805: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:30:24.805: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:30:26.805: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:30:28.806: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 21 12:30:28.817: INFO: The status of Pod netserver-1 is Running (Ready = true)
Dec 21 12:30:28.826: INFO: The status of Pod netserver-2 is Running (Ready = false)
Dec 21 12:30:30.830: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Dec 21 12:30:32.912: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.3.30 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6742 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:30:32.912: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:30:34.183: INFO: Found all expected endpoints: [netserver-0]
Dec 21 12:30:34.189: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.4.41 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6742 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:30:34.189: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:30:35.522: INFO: Found all expected endpoints: [netserver-1]
Dec 21 12:30:35.526: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.5.17 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6742 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:30:35.527: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:30:36.940: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:30:36.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6742" for this suite.

• [SLOW TEST:26.586 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":53,"skipped":794,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:30:36.973: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 21 12:30:37.165: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7864 /api/v1/namespaces/watch-7864/configmaps/e2e-watch-test-watch-closed b716236f-c967-49c8-bcb6-cc065a2c54e4 36029432 0 2020-12-21 12:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-12-21 12:30:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 12:30:37.166: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7864 /api/v1/namespaces/watch-7864/configmaps/e2e-watch-test-watch-closed b716236f-c967-49c8-bcb6-cc065a2c54e4 36029433 0 2020-12-21 12:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-12-21 12:30:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 21 12:30:37.188: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7864 /api/v1/namespaces/watch-7864/configmaps/e2e-watch-test-watch-closed b716236f-c967-49c8-bcb6-cc065a2c54e4 36029434 0 2020-12-21 12:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-12-21 12:30:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 12:30:37.188: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7864 /api/v1/namespaces/watch-7864/configmaps/e2e-watch-test-watch-closed b716236f-c967-49c8-bcb6-cc065a2c54e4 36029435 0 2020-12-21 12:30:37 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-12-21 12:30:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:30:37.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7864" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":273,"completed":54,"skipped":809,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:30:37.205: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-6455
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Dec 21 12:30:37.365: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Dec 21 12:30:37.757: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 21 12:30:39.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 12:30:41.817: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 12:30:43.817: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 12:30:45.817: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 12:30:47.817: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150637, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 12:30:50.604: INFO: Waited 776.18326ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:30:51.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6455" for this suite.

• [SLOW TEST:14.211 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":273,"completed":55,"skipped":845,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:30:51.420: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Dec 21 12:30:51.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-2303 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 21 12:30:51.968: INFO: stderr: ""
Dec 21 12:30:51.968: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Dec 21 12:30:51.968: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 21 12:30:51.968: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2303" to be "running and ready, or succeeded"
Dec 21 12:30:51.971: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.460938ms
Dec 21 12:30:53.977: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008964054s
Dec 21 12:30:53.977: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 21 12:30:53.977: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 21 12:30:53.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 logs logs-generator logs-generator --namespace=kubectl-2303'
Dec 21 12:30:54.090: INFO: stderr: ""
Dec 21 12:30:54.090: INFO: stdout: "I1221 12:30:52.921787       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/t7c 589\nI1221 12:30:53.121932       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/8mt9 431\nI1221 12:30:53.321853       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/g8z2 487\nI1221 12:30:53.521904       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/z28 249\nI1221 12:30:53.721939       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/xmf 511\nI1221 12:30:53.921859       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/xv8 499\n"
STEP: limiting log lines
Dec 21 12:30:54.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 logs logs-generator logs-generator --namespace=kubectl-2303 --tail=1'
Dec 21 12:30:54.234: INFO: stderr: ""
Dec 21 12:30:54.234: INFO: stdout: "I1221 12:30:54.121910       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/b7j 590\n"
Dec 21 12:30:54.234: INFO: got output "I1221 12:30:54.121910       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/b7j 590\n"
STEP: limiting log bytes
Dec 21 12:30:54.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 logs logs-generator logs-generator --namespace=kubectl-2303 --limit-bytes=1'
Dec 21 12:30:54.340: INFO: stderr: ""
Dec 21 12:30:54.340: INFO: stdout: "I"
Dec 21 12:30:54.340: INFO: got output "I"
STEP: exposing timestamps
Dec 21 12:30:54.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 logs logs-generator logs-generator --namespace=kubectl-2303 --tail=1 --timestamps'
Dec 21 12:30:54.464: INFO: stderr: ""
Dec 21 12:30:54.464: INFO: stdout: "2020-12-21T12:30:54.322046545Z I1221 12:30:54.321894       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/75p 377\n"
Dec 21 12:30:54.464: INFO: got output "2020-12-21T12:30:54.322046545Z I1221 12:30:54.321894       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/75p 377\n"
STEP: restricting to a time range
Dec 21 12:30:56.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 logs logs-generator logs-generator --namespace=kubectl-2303 --since=1s'
Dec 21 12:30:57.140: INFO: stderr: ""
Dec 21 12:30:57.140: INFO: stdout: "I1221 12:30:56.321910       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/rbqq 498\nI1221 12:30:56.521917       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/45mt 381\nI1221 12:30:56.722093       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/x59 549\nI1221 12:30:56.921861       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/wnbt 350\nI1221 12:30:57.121872       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/mlp 299\n"
Dec 21 12:30:57.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 logs logs-generator logs-generator --namespace=kubectl-2303 --since=24h'
Dec 21 12:30:57.255: INFO: stderr: ""
Dec 21 12:30:57.255: INFO: stdout: "I1221 12:30:52.921787       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/t7c 589\nI1221 12:30:53.121932       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/8mt9 431\nI1221 12:30:53.321853       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/g8z2 487\nI1221 12:30:53.521904       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/z28 249\nI1221 12:30:53.721939       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/xmf 511\nI1221 12:30:53.921859       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/xv8 499\nI1221 12:30:54.121910       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/b7j 590\nI1221 12:30:54.321894       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/75p 377\nI1221 12:30:54.522322       1 logs_generator.go:76] 8 POST /api/v1/namespaces/kube-system/pods/lx28 473\nI1221 12:30:54.721874       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/hp6q 452\nI1221 12:30:54.921940       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/sqs4 588\nI1221 12:30:55.123403       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/5wvm 385\nI1221 12:30:55.322064       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/2nsf 427\nI1221 12:30:55.521901       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/8bg 282\nI1221 12:30:55.724111       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/gxz8 506\nI1221 12:30:55.921885       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/d58c 456\nI1221 12:30:56.121961       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/rvf 246\nI1221 12:30:56.321910       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/rbqq 498\nI1221 12:30:56.521917       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/45mt 381\nI1221 12:30:56.722093       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/x59 549\nI1221 12:30:56.921861       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/wnbt 350\nI1221 12:30:57.121872       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/mlp 299\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Dec 21 12:30:57.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete pod logs-generator --namespace=kubectl-2303'
Dec 21 12:30:59.404: INFO: stderr: ""
Dec 21 12:30:59.404: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:30:59.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2303" for this suite.

• [SLOW TEST:7.995 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1284
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":273,"completed":56,"skipped":848,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:30:59.415: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-652
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:30:59.577: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1da0ad47-8206-467f-b000-ae519a26551d" in namespace "downward-api-652" to be "Succeeded or Failed"
Dec 21 12:30:59.581: INFO: Pod "downwardapi-volume-1da0ad47-8206-467f-b000-ae519a26551d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.330683ms
Dec 21 12:31:01.586: INFO: Pod "downwardapi-volume-1da0ad47-8206-467f-b000-ae519a26551d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009367827s
Dec 21 12:31:03.591: INFO: Pod "downwardapi-volume-1da0ad47-8206-467f-b000-ae519a26551d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014182063s
STEP: Saw pod success
Dec 21 12:31:03.591: INFO: Pod "downwardapi-volume-1da0ad47-8206-467f-b000-ae519a26551d" satisfied condition "Succeeded or Failed"
Dec 21 12:31:03.601: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-1da0ad47-8206-467f-b000-ae519a26551d container client-container: <nil>
STEP: delete the pod
Dec 21 12:31:03.660: INFO: Waiting for pod downwardapi-volume-1da0ad47-8206-467f-b000-ae519a26551d to disappear
Dec 21 12:31:03.666: INFO: Pod downwardapi-volume-1da0ad47-8206-467f-b000-ae519a26551d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:31:03.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-652" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":273,"completed":57,"skipped":856,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:31:03.702: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-375
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 21 12:31:03.914: INFO: Waiting up to 5m0s for pod "downward-api-c32c12f6-9e01-4bd7-bbbb-8f27937043e5" in namespace "downward-api-375" to be "Succeeded or Failed"
Dec 21 12:31:03.924: INFO: Pod "downward-api-c32c12f6-9e01-4bd7-bbbb-8f27937043e5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.101342ms
Dec 21 12:31:05.939: INFO: Pod "downward-api-c32c12f6-9e01-4bd7-bbbb-8f27937043e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024897401s
STEP: Saw pod success
Dec 21 12:31:05.941: INFO: Pod "downward-api-c32c12f6-9e01-4bd7-bbbb-8f27937043e5" satisfied condition "Succeeded or Failed"
Dec 21 12:31:05.960: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downward-api-c32c12f6-9e01-4bd7-bbbb-8f27937043e5 container dapi-container: <nil>
STEP: delete the pod
Dec 21 12:31:06.038: INFO: Waiting for pod downward-api-c32c12f6-9e01-4bd7-bbbb-8f27937043e5 to disappear
Dec 21 12:31:06.050: INFO: Pod downward-api-c32c12f6-9e01-4bd7-bbbb-8f27937043e5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:31:06.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-375" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":273,"completed":58,"skipped":893,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:31:06.092: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-80
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Dec 21 12:31:10.841: INFO: Successfully updated pod "annotationupdate4f8c4375-efee-41ef-bb9d-cde2008c2a93"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:31:12.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-80" for this suite.

• [SLOW TEST:6.833 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":273,"completed":59,"skipped":941,"failed":0}
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:31:12.926: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2729
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:31:13.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2729" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":273,"completed":60,"skipped":941,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:31:13.103: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2724
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 21 12:31:13.567: INFO: Pod name wrapped-volume-race-d6e3f8f4-c6b4-492d-93ac-5ed663c1b06e: Found 0 pods out of 5
Dec 21 12:31:18.580: INFO: Pod name wrapped-volume-race-d6e3f8f4-c6b4-492d-93ac-5ed663c1b06e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d6e3f8f4-c6b4-492d-93ac-5ed663c1b06e in namespace emptydir-wrapper-2724, will wait for the garbage collector to delete the pods
Dec 21 12:31:30.683: INFO: Deleting ReplicationController wrapped-volume-race-d6e3f8f4-c6b4-492d-93ac-5ed663c1b06e took: 9.802467ms
Dec 21 12:31:31.283: INFO: Terminating ReplicationController wrapped-volume-race-d6e3f8f4-c6b4-492d-93ac-5ed663c1b06e pods took: 600.228252ms
STEP: Creating RC which spawns configmap-volume pods
Dec 21 12:31:44.905: INFO: Pod name wrapped-volume-race-b79a6d9e-7f60-4f81-94a2-d6906c72eb4a: Found 0 pods out of 5
Dec 21 12:31:49.920: INFO: Pod name wrapped-volume-race-b79a6d9e-7f60-4f81-94a2-d6906c72eb4a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b79a6d9e-7f60-4f81-94a2-d6906c72eb4a in namespace emptydir-wrapper-2724, will wait for the garbage collector to delete the pods
Dec 21 12:32:02.043: INFO: Deleting ReplicationController wrapped-volume-race-b79a6d9e-7f60-4f81-94a2-d6906c72eb4a took: 23.336078ms
Dec 21 12:32:02.745: INFO: Terminating ReplicationController wrapped-volume-race-b79a6d9e-7f60-4f81-94a2-d6906c72eb4a pods took: 701.256706ms
STEP: Creating RC which spawns configmap-volume pods
Dec 21 12:32:14.867: INFO: Pod name wrapped-volume-race-2e48d56f-ebcb-46c9-be35-ca53e598b478: Found 0 pods out of 5
Dec 21 12:32:19.877: INFO: Pod name wrapped-volume-race-2e48d56f-ebcb-46c9-be35-ca53e598b478: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2e48d56f-ebcb-46c9-be35-ca53e598b478 in namespace emptydir-wrapper-2724, will wait for the garbage collector to delete the pods
Dec 21 12:32:33.983: INFO: Deleting ReplicationController wrapped-volume-race-2e48d56f-ebcb-46c9-be35-ca53e598b478 took: 12.43461ms
Dec 21 12:32:34.686: INFO: Terminating ReplicationController wrapped-volume-race-2e48d56f-ebcb-46c9-be35-ca53e598b478 pods took: 702.876747ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:32:47.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2724" for this suite.

• [SLOW TEST:94.308 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":273,"completed":61,"skipped":967,"failed":0}
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:32:47.411: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6436
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:32:47.612: INFO: Creating ReplicaSet my-hostname-basic-ce8682dc-dd7c-48f7-84bd-0668f9a73951
Dec 21 12:32:47.623: INFO: Pod name my-hostname-basic-ce8682dc-dd7c-48f7-84bd-0668f9a73951: Found 0 pods out of 1
Dec 21 12:32:52.628: INFO: Pod name my-hostname-basic-ce8682dc-dd7c-48f7-84bd-0668f9a73951: Found 1 pods out of 1
Dec 21 12:32:52.628: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-ce8682dc-dd7c-48f7-84bd-0668f9a73951" is running
Dec 21 12:32:52.632: INFO: Pod "my-hostname-basic-ce8682dc-dd7c-48f7-84bd-0668f9a73951-hx64n" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-21 12:32:47 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-21 12:32:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-21 12:32:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-21 12:32:47 +0000 UTC Reason: Message:}])
Dec 21 12:32:52.633: INFO: Trying to dial the pod
Dec 21 12:32:57.699: INFO: Controller my-hostname-basic-ce8682dc-dd7c-48f7-84bd-0668f9a73951: Got expected result from replica 1 [my-hostname-basic-ce8682dc-dd7c-48f7-84bd-0668f9a73951-hx64n]: "my-hostname-basic-ce8682dc-dd7c-48f7-84bd-0668f9a73951-hx64n", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:32:57.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6436" for this suite.

• [SLOW TEST:10.307 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":273,"completed":62,"skipped":967,"failed":0}
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:32:57.719: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 21 12:33:00.463: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-265 pod-service-account-92975431-27b3-4313-bed6-0868c4c93d04 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 21 12:33:00.899: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-265 pod-service-account-92975431-27b3-4313-bed6-0868c4c93d04 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 21 12:33:01.538: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-265 pod-service-account-92975431-27b3-4313-bed6-0868c4c93d04 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:02.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-265" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":273,"completed":63,"skipped":970,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:02.279: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9719
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-99869bc6-62b8-4e92-a9b8-453b8234002f
STEP: Creating a pod to test consume secrets
Dec 21 12:33:02.461: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2a9bbdc3-1f59-4623-9197-285c568e9810" in namespace "projected-9719" to be "Succeeded or Failed"
Dec 21 12:33:02.467: INFO: Pod "pod-projected-secrets-2a9bbdc3-1f59-4623-9197-285c568e9810": Phase="Pending", Reason="", readiness=false. Elapsed: 6.335496ms
Dec 21 12:33:04.472: INFO: Pod "pod-projected-secrets-2a9bbdc3-1f59-4623-9197-285c568e9810": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011529034s
Dec 21 12:33:06.478: INFO: Pod "pod-projected-secrets-2a9bbdc3-1f59-4623-9197-285c568e9810": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017042633s
STEP: Saw pod success
Dec 21 12:33:06.478: INFO: Pod "pod-projected-secrets-2a9bbdc3-1f59-4623-9197-285c568e9810" satisfied condition "Succeeded or Failed"
Dec 21 12:33:06.487: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-projected-secrets-2a9bbdc3-1f59-4623-9197-285c568e9810 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 12:33:06.539: INFO: Waiting for pod pod-projected-secrets-2a9bbdc3-1f59-4623-9197-285c568e9810 to disappear
Dec 21 12:33:06.542: INFO: Pod pod-projected-secrets-2a9bbdc3-1f59-4623-9197-285c568e9810 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:06.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9719" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":64,"skipped":1012,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:06.560: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1594
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Dec 21 12:33:06.715: INFO: Waiting up to 5m0s for pod "var-expansion-83baa6b3-d5a4-446c-bd62-cf95d63efe9a" in namespace "var-expansion-1594" to be "Succeeded or Failed"
Dec 21 12:33:06.719: INFO: Pod "var-expansion-83baa6b3-d5a4-446c-bd62-cf95d63efe9a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.40171ms
Dec 21 12:33:08.723: INFO: Pod "var-expansion-83baa6b3-d5a4-446c-bd62-cf95d63efe9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008653847s
STEP: Saw pod success
Dec 21 12:33:08.723: INFO: Pod "var-expansion-83baa6b3-d5a4-446c-bd62-cf95d63efe9a" satisfied condition "Succeeded or Failed"
Dec 21 12:33:08.727: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod var-expansion-83baa6b3-d5a4-446c-bd62-cf95d63efe9a container dapi-container: <nil>
STEP: delete the pod
Dec 21 12:33:08.754: INFO: Waiting for pod var-expansion-83baa6b3-d5a4-446c-bd62-cf95d63efe9a to disappear
Dec 21 12:33:08.766: INFO: Pod var-expansion-83baa6b3-d5a4-446c-bd62-cf95d63efe9a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:08.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1594" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":273,"completed":65,"skipped":1019,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:08.785: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2675
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:08.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2675" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":273,"completed":66,"skipped":1027,"failed":0}

------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:09.007: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-375
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Dec 21 12:33:09.155: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-796893939 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:09.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-375" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":273,"completed":67,"skipped":1027,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:09.263: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-433
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-f0f303ee-bbe6-4d28-8089-fb5f2f474564
STEP: Creating a pod to test consume configMaps
Dec 21 12:33:09.448: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d57287a3-9071-47f5-ae53-2584e5e48f0b" in namespace "projected-433" to be "Succeeded or Failed"
Dec 21 12:33:09.452: INFO: Pod "pod-projected-configmaps-d57287a3-9071-47f5-ae53-2584e5e48f0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.821773ms
Dec 21 12:33:11.458: INFO: Pod "pod-projected-configmaps-d57287a3-9071-47f5-ae53-2584e5e48f0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009918523s
Dec 21 12:33:13.467: INFO: Pod "pod-projected-configmaps-d57287a3-9071-47f5-ae53-2584e5e48f0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019077996s
STEP: Saw pod success
Dec 21 12:33:13.467: INFO: Pod "pod-projected-configmaps-d57287a3-9071-47f5-ae53-2584e5e48f0b" satisfied condition "Succeeded or Failed"
Dec 21 12:33:13.475: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-projected-configmaps-d57287a3-9071-47f5-ae53-2584e5e48f0b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 12:33:13.567: INFO: Waiting for pod pod-projected-configmaps-d57287a3-9071-47f5-ae53-2584e5e48f0b to disappear
Dec 21 12:33:13.571: INFO: Pod pod-projected-configmaps-d57287a3-9071-47f5-ae53-2584e5e48f0b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:13.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-433" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":273,"completed":68,"skipped":1033,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:13.596: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3037
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-2befb21e-4c26-48dd-95dc-67a2dc50dc0e
STEP: Creating a pod to test consume secrets
Dec 21 12:33:13.779: INFO: Waiting up to 5m0s for pod "pod-secrets-2e2b6528-2758-49dc-81e9-ff10b16e1e03" in namespace "secrets-3037" to be "Succeeded or Failed"
Dec 21 12:33:13.785: INFO: Pod "pod-secrets-2e2b6528-2758-49dc-81e9-ff10b16e1e03": Phase="Pending", Reason="", readiness=false. Elapsed: 6.747916ms
Dec 21 12:33:15.790: INFO: Pod "pod-secrets-2e2b6528-2758-49dc-81e9-ff10b16e1e03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011120571s
STEP: Saw pod success
Dec 21 12:33:15.790: INFO: Pod "pod-secrets-2e2b6528-2758-49dc-81e9-ff10b16e1e03" satisfied condition "Succeeded or Failed"
Dec 21 12:33:15.795: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-secrets-2e2b6528-2758-49dc-81e9-ff10b16e1e03 container secret-env-test: <nil>
STEP: delete the pod
Dec 21 12:33:15.817: INFO: Waiting for pod pod-secrets-2e2b6528-2758-49dc-81e9-ff10b16e1e03 to disappear
Dec 21 12:33:15.821: INFO: Pod pod-secrets-2e2b6528-2758-49dc-81e9-ff10b16e1e03 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:15.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3037" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":273,"completed":69,"skipped":1064,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:15.838: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2201
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-ef942130-54b6-466b-971f-006298022392
STEP: Creating secret with name secret-projected-all-test-volume-f5fbe465-0ed6-49fe-8a60-963393366b66
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 21 12:33:16.083: INFO: Waiting up to 5m0s for pod "projected-volume-3401cd61-a2a8-4940-b2b0-a4c84cfb029a" in namespace "projected-2201" to be "Succeeded or Failed"
Dec 21 12:33:16.090: INFO: Pod "projected-volume-3401cd61-a2a8-4940-b2b0-a4c84cfb029a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.758807ms
Dec 21 12:33:18.095: INFO: Pod "projected-volume-3401cd61-a2a8-4940-b2b0-a4c84cfb029a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011878016s
STEP: Saw pod success
Dec 21 12:33:18.095: INFO: Pod "projected-volume-3401cd61-a2a8-4940-b2b0-a4c84cfb029a" satisfied condition "Succeeded or Failed"
Dec 21 12:33:18.099: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod projected-volume-3401cd61-a2a8-4940-b2b0-a4c84cfb029a container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 21 12:33:18.126: INFO: Waiting for pod projected-volume-3401cd61-a2a8-4940-b2b0-a4c84cfb029a to disappear
Dec 21 12:33:18.130: INFO: Pod projected-volume-3401cd61-a2a8-4940-b2b0-a4c84cfb029a no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:18.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2201" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":273,"completed":70,"skipped":1084,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:18.143: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6624
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:33:18.297: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 21 12:33:20.349: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:21.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6624" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":273,"completed":71,"skipped":1095,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:21.390: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1926
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:33:21.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 version'
Dec 21 12:33:21.632: INFO: stderr: ""
Dec 21 12:33:21.632: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.8\", GitCommit:\"9f2892aab98fe339f3bd70e3c470144299398ace\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T16:12:48Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.8\", GitCommit:\"9f2892aab98fe339f3bd70e3c470144299398ace\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T16:04:18Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:21.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1926" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":273,"completed":72,"skipped":1096,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:21.647: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9065
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Dec 21 12:33:21.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-9065'
Dec 21 12:33:22.223: INFO: stderr: ""
Dec 21 12:33:22.223: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 12:33:22.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9065'
Dec 21 12:33:22.346: INFO: stderr: ""
Dec 21 12:33:22.346: INFO: stdout: "update-demo-nautilus-2k62g update-demo-nautilus-cl9bm "
Dec 21 12:33:22.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-2k62g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:22.445: INFO: stderr: ""
Dec 21 12:33:22.445: INFO: stdout: ""
Dec 21 12:33:22.445: INFO: update-demo-nautilus-2k62g is created but not running
Dec 21 12:33:27.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9065'
Dec 21 12:33:27.557: INFO: stderr: ""
Dec 21 12:33:27.557: INFO: stdout: "update-demo-nautilus-2k62g update-demo-nautilus-cl9bm "
Dec 21 12:33:27.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-2k62g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:27.655: INFO: stderr: ""
Dec 21 12:33:27.655: INFO: stdout: "true"
Dec 21 12:33:27.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-2k62g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:27.753: INFO: stderr: ""
Dec 21 12:33:27.753: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 12:33:27.753: INFO: validating pod update-demo-nautilus-2k62g
Dec 21 12:33:27.845: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 12:33:27.845: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 12:33:27.845: INFO: update-demo-nautilus-2k62g is verified up and running
Dec 21 12:33:27.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-cl9bm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:27.921: INFO: stderr: ""
Dec 21 12:33:27.921: INFO: stdout: "true"
Dec 21 12:33:27.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-cl9bm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:28.006: INFO: stderr: ""
Dec 21 12:33:28.006: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 12:33:28.006: INFO: validating pod update-demo-nautilus-cl9bm
Dec 21 12:33:28.118: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 12:33:28.118: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 12:33:28.118: INFO: update-demo-nautilus-cl9bm is verified up and running
STEP: scaling down the replication controller
Dec 21 12:33:28.119: INFO: scanned /root for discovery docs: <nil>
Dec 21 12:33:28.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9065'
Dec 21 12:33:29.233: INFO: stderr: ""
Dec 21 12:33:29.233: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 12:33:29.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9065'
Dec 21 12:33:29.312: INFO: stderr: ""
Dec 21 12:33:29.312: INFO: stdout: "update-demo-nautilus-2k62g update-demo-nautilus-cl9bm "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 21 12:33:34.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9065'
Dec 21 12:33:34.401: INFO: stderr: ""
Dec 21 12:33:34.401: INFO: stdout: "update-demo-nautilus-2k62g update-demo-nautilus-cl9bm "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 21 12:33:39.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9065'
Dec 21 12:33:39.538: INFO: stderr: ""
Dec 21 12:33:39.538: INFO: stdout: "update-demo-nautilus-2k62g "
Dec 21 12:33:39.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-2k62g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:39.631: INFO: stderr: ""
Dec 21 12:33:39.631: INFO: stdout: "true"
Dec 21 12:33:39.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-2k62g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:39.748: INFO: stderr: ""
Dec 21 12:33:39.748: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 12:33:39.748: INFO: validating pod update-demo-nautilus-2k62g
Dec 21 12:33:39.797: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 12:33:39.797: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 12:33:39.797: INFO: update-demo-nautilus-2k62g is verified up and running
STEP: scaling up the replication controller
Dec 21 12:33:39.799: INFO: scanned /root for discovery docs: <nil>
Dec 21 12:33:39.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9065'
Dec 21 12:33:40.936: INFO: stderr: ""
Dec 21 12:33:40.936: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 21 12:33:40.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9065'
Dec 21 12:33:41.057: INFO: stderr: ""
Dec 21 12:33:41.057: INFO: stdout: "update-demo-nautilus-2k62g update-demo-nautilus-mj5tb "
Dec 21 12:33:41.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-2k62g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:41.139: INFO: stderr: ""
Dec 21 12:33:41.139: INFO: stdout: "true"
Dec 21 12:33:41.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-2k62g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:41.231: INFO: stderr: ""
Dec 21 12:33:41.231: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 12:33:41.231: INFO: validating pod update-demo-nautilus-2k62g
Dec 21 12:33:41.289: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 12:33:41.289: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 12:33:41.289: INFO: update-demo-nautilus-2k62g is verified up and running
Dec 21 12:33:41.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-mj5tb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:41.379: INFO: stderr: ""
Dec 21 12:33:41.379: INFO: stdout: ""
Dec 21 12:33:41.379: INFO: update-demo-nautilus-mj5tb is created but not running
Dec 21 12:33:46.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9065'
Dec 21 12:33:46.491: INFO: stderr: ""
Dec 21 12:33:46.491: INFO: stdout: "update-demo-nautilus-2k62g update-demo-nautilus-mj5tb "
Dec 21 12:33:46.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-2k62g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:46.586: INFO: stderr: ""
Dec 21 12:33:46.586: INFO: stdout: "true"
Dec 21 12:33:46.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-2k62g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:46.676: INFO: stderr: ""
Dec 21 12:33:46.676: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 12:33:46.676: INFO: validating pod update-demo-nautilus-2k62g
Dec 21 12:33:46.684: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 12:33:46.684: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 12:33:46.684: INFO: update-demo-nautilus-2k62g is verified up and running
Dec 21 12:33:46.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-mj5tb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:46.823: INFO: stderr: ""
Dec 21 12:33:46.823: INFO: stdout: "true"
Dec 21 12:33:46.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods update-demo-nautilus-mj5tb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9065'
Dec 21 12:33:46.904: INFO: stderr: ""
Dec 21 12:33:46.905: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 21 12:33:46.905: INFO: validating pod update-demo-nautilus-mj5tb
Dec 21 12:33:46.955: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 21 12:33:46.955: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 21 12:33:46.955: INFO: update-demo-nautilus-mj5tb is verified up and running
STEP: using delete to clean up resources
Dec 21 12:33:46.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete --grace-period=0 --force -f - --namespace=kubectl-9065'
Dec 21 12:33:47.043: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 12:33:47.043: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 21 12:33:47.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9065'
Dec 21 12:33:47.138: INFO: stderr: "No resources found in kubectl-9065 namespace.\n"
Dec 21 12:33:47.138: INFO: stdout: ""
Dec 21 12:33:47.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -l name=update-demo --namespace=kubectl-9065 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 21 12:33:47.212: INFO: stderr: ""
Dec 21 12:33:47.212: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:47.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9065" for this suite.

• [SLOW TEST:25.587 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":273,"completed":73,"skipped":1108,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:47.236: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:33:47.396: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 21 12:33:52.401: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 21 12:33:52.401: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 21 12:33:52.442: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6927 /apis/apps/v1/namespaces/deployment-6927/deployments/test-cleanup-deployment e1cdf666-5644-4272-96b0-9c0d6d72f7f0 36031910 1 2020-12-21 12:33:52 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2020-12-21 12:33:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bfcaa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec 21 12:33:52.449: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-6927 /apis/apps/v1/namespaces/deployment-6927/replicasets/test-cleanup-deployment-b4867b47f be5ffd31-20d3-4422-9be3-cccff4d7b0ea 36031917 1 2020-12-21 12:33:52 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment e1cdf666-5644-4272-96b0-9c0d6d72f7f0 0xc003bfcf90 0xc003bfcf91}] []  [{kube-controller-manager Update apps/v1 2020-12-21 12:33:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 49 99 100 102 54 54 54 45 53 54 52 52 45 52 50 55 50 45 57 54 98 48 45 57 99 48 100 54 100 55 50 102 55 102 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bfd008 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 12:33:52.450: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 21 12:33:52.450: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-6927 /apis/apps/v1/namespaces/deployment-6927/replicasets/test-cleanup-controller 66be1f8e-a894-4099-b601-2814bc6cd4b6 36031911 1 2020-12-21 12:33:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment e1cdf666-5644-4272-96b0-9c0d6d72f7f0 0xc003bfce7f 0xc003bfce90}] []  [{e2e.test Update apps/v1 2020-12-21 12:33:47 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-21 12:33:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 49 99 100 102 54 54 54 45 53 54 52 52 45 52 50 55 50 45 57 54 98 48 45 57 99 48 100 54 100 55 50 102 55 102 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003bfcf28 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 21 12:33:52.464: INFO: Pod "test-cleanup-controller-ps7dl" is available:
&Pod{ObjectMeta:{test-cleanup-controller-ps7dl test-cleanup-controller- deployment-6927 /api/v1/namespaces/deployment-6927/pods/test-cleanup-controller-ps7dl 572ce5cc-85ca-4293-83e9-b544ac5bb5e2 36031866 0 2020-12-21 12:33:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:172.25.4.64/32 cni.projectcalico.org/podIPs:172.25.4.64/32] [{apps/v1 ReplicaSet test-cleanup-controller 66be1f8e-a894-4099-b601-2814bc6cd4b6 0xc003bfd507 0xc003bfd508}] []  [{kube-controller-manager Update v1 2020-12-21 12:33:47 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 54 98 101 49 102 56 101 45 97 56 57 52 45 52 48 57 57 45 98 54 48 49 45 50 56 49 52 98 99 54 99 100 52 98 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:33:48 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:33:48 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 52 46 54 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xz59g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xz59g,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xz59g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:33:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:33:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:33:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:33:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.232.239,PodIP:172.25.4.64,StartTime:2020-12-21 12:33:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:33:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://906daf1f16a242a4bd8a2e0decbb66d377544b9f5f4aef5d02d2eeeb62ea3025,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.4.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:33:52.464: INFO: Pod "test-cleanup-deployment-b4867b47f-vltm4" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-vltm4 test-cleanup-deployment-b4867b47f- deployment-6927 /api/v1/namespaces/deployment-6927/pods/test-cleanup-deployment-b4867b47f-vltm4 7428de33-9a38-4ac9-a5be-203272106b07 36031916 0 2020-12-21 12:33:52 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f be5ffd31-20d3-4422-9be3-cccff4d7b0ea 0xc003bfd6c0 0xc003bfd6c1}] []  [{kube-controller-manager Update v1 2020-12-21 12:33:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 101 53 102 102 100 51 49 45 50 48 100 51 45 52 52 50 50 45 57 98 101 51 45 99 99 99 102 102 52 100 55 98 48 101 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xz59g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xz59g,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xz59g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:33:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:33:52.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6927" for this suite.

• [SLOW TEST:5.241 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":273,"completed":74,"skipped":1139,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:33:52.479: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4893
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 21 12:33:52.683: INFO: Number of nodes with available pods: 0
Dec 21 12:33:52.683: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:33:53.694: INFO: Number of nodes with available pods: 0
Dec 21 12:33:53.694: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:33:54.696: INFO: Number of nodes with available pods: 1
Dec 21 12:33:54.696: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:33:55.698: INFO: Number of nodes with available pods: 2
Dec 21 12:33:55.698: INFO: Node ip-172-31-244-13.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:33:56.694: INFO: Number of nodes with available pods: 2
Dec 21 12:33:56.694: INFO: Node ip-172-31-244-13.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:33:57.694: INFO: Number of nodes with available pods: 2
Dec 21 12:33:57.694: INFO: Node ip-172-31-244-13.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:33:58.693: INFO: Number of nodes with available pods: 2
Dec 21 12:33:58.693: INFO: Node ip-172-31-244-13.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:33:59.695: INFO: Number of nodes with available pods: 2
Dec 21 12:33:59.695: INFO: Node ip-172-31-244-13.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:34:00.694: INFO: Number of nodes with available pods: 3
Dec 21 12:34:00.694: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 21 12:34:00.739: INFO: Number of nodes with available pods: 2
Dec 21 12:34:00.739: INFO: Node ip-172-31-232-239.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:34:01.760: INFO: Number of nodes with available pods: 2
Dec 21 12:34:01.760: INFO: Node ip-172-31-232-239.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:34:02.755: INFO: Number of nodes with available pods: 2
Dec 21 12:34:02.755: INFO: Node ip-172-31-232-239.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:34:03.769: INFO: Number of nodes with available pods: 2
Dec 21 12:34:03.769: INFO: Node ip-172-31-232-239.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:34:04.777: INFO: Number of nodes with available pods: 2
Dec 21 12:34:04.777: INFO: Node ip-172-31-232-239.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:34:05.750: INFO: Number of nodes with available pods: 3
Dec 21 12:34:05.750: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4893, will wait for the garbage collector to delete the pods
Dec 21 12:34:05.824: INFO: Deleting DaemonSet.extensions daemon-set took: 10.137214ms
Dec 21 12:34:05.925: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.016885ms
Dec 21 12:34:17.428: INFO: Number of nodes with available pods: 0
Dec 21 12:34:17.429: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 12:34:17.444: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4893/daemonsets","resourceVersion":"36032145"},"items":null}

Dec 21 12:34:17.448: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4893/pods","resourceVersion":"36032145"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:34:17.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4893" for this suite.

• [SLOW TEST:24.999 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":273,"completed":75,"skipped":1180,"failed":0}
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:34:17.479: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1943
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 21 12:34:20.211: INFO: Successfully updated pod "pod-update-activedeadlineseconds-7d6ba011-e3a7-43fa-bf92-a8957402bed7"
Dec 21 12:34:20.211: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-7d6ba011-e3a7-43fa-bf92-a8957402bed7" in namespace "pods-1943" to be "terminated due to deadline exceeded"
Dec 21 12:34:20.217: INFO: Pod "pod-update-activedeadlineseconds-7d6ba011-e3a7-43fa-bf92-a8957402bed7": Phase="Running", Reason="", readiness=true. Elapsed: 5.838467ms
Dec 21 12:34:22.223: INFO: Pod "pod-update-activedeadlineseconds-7d6ba011-e3a7-43fa-bf92-a8957402bed7": Phase="Running", Reason="", readiness=true. Elapsed: 2.011695392s
Dec 21 12:34:24.227: INFO: Pod "pod-update-activedeadlineseconds-7d6ba011-e3a7-43fa-bf92-a8957402bed7": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015896921s
Dec 21 12:34:24.227: INFO: Pod "pod-update-activedeadlineseconds-7d6ba011-e3a7-43fa-bf92-a8957402bed7" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:34:24.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1943" for this suite.

• [SLOW TEST:6.761 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":273,"completed":76,"skipped":1180,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:34:24.240: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1008
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-b9c060bb-cfc2-4920-9b40-3a50bba729e5
STEP: Creating a pod to test consume configMaps
Dec 21 12:34:24.407: INFO: Waiting up to 5m0s for pod "pod-configmaps-86cb96eb-bd33-4a8c-bf04-04f766d88988" in namespace "configmap-1008" to be "Succeeded or Failed"
Dec 21 12:34:24.418: INFO: Pod "pod-configmaps-86cb96eb-bd33-4a8c-bf04-04f766d88988": Phase="Pending", Reason="", readiness=false. Elapsed: 11.785666ms
Dec 21 12:34:26.432: INFO: Pod "pod-configmaps-86cb96eb-bd33-4a8c-bf04-04f766d88988": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02519123s
Dec 21 12:34:28.436: INFO: Pod "pod-configmaps-86cb96eb-bd33-4a8c-bf04-04f766d88988": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029736765s
STEP: Saw pod success
Dec 21 12:34:28.437: INFO: Pod "pod-configmaps-86cb96eb-bd33-4a8c-bf04-04f766d88988" satisfied condition "Succeeded or Failed"
Dec 21 12:34:28.446: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-configmaps-86cb96eb-bd33-4a8c-bf04-04f766d88988 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 12:34:28.519: INFO: Waiting for pod pod-configmaps-86cb96eb-bd33-4a8c-bf04-04f766d88988 to disappear
Dec 21 12:34:28.525: INFO: Pod pod-configmaps-86cb96eb-bd33-4a8c-bf04-04f766d88988 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:34:28.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1008" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":273,"completed":77,"skipped":1186,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:34:28.553: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6403
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:34:28.785: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aef47d28-4300-4c11-beeb-fd395d47542b" in namespace "downward-api-6403" to be "Succeeded or Failed"
Dec 21 12:34:28.797: INFO: Pod "downwardapi-volume-aef47d28-4300-4c11-beeb-fd395d47542b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.801078ms
Dec 21 12:34:30.801: INFO: Pod "downwardapi-volume-aef47d28-4300-4c11-beeb-fd395d47542b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016169461s
STEP: Saw pod success
Dec 21 12:34:30.801: INFO: Pod "downwardapi-volume-aef47d28-4300-4c11-beeb-fd395d47542b" satisfied condition "Succeeded or Failed"
Dec 21 12:34:30.805: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-aef47d28-4300-4c11-beeb-fd395d47542b container client-container: <nil>
STEP: delete the pod
Dec 21 12:34:30.903: INFO: Waiting for pod downwardapi-volume-aef47d28-4300-4c11-beeb-fd395d47542b to disappear
Dec 21 12:34:30.907: INFO: Pod downwardapi-volume-aef47d28-4300-4c11-beeb-fd395d47542b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:34:30.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6403" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":273,"completed":78,"skipped":1195,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:34:30.923: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4369
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 21 12:34:31.106: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 21 12:34:44.011: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:34:47.596: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:35:01.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4369" for this suite.

• [SLOW TEST:30.151 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":273,"completed":79,"skipped":1220,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:35:01.078: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8860
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:35:01.464: INFO: (0) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 221.62197ms)
Dec 21 12:35:01.514: INFO: (1) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 49.328732ms)
Dec 21 12:35:01.525: INFO: (2) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 10.825139ms)
Dec 21 12:35:01.571: INFO: (3) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 46.614082ms)
Dec 21 12:35:01.579: INFO: (4) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.371358ms)
Dec 21 12:35:01.587: INFO: (5) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.682065ms)
Dec 21 12:35:01.593: INFO: (6) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.511712ms)
Dec 21 12:35:01.600: INFO: (7) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.379798ms)
Dec 21 12:35:01.608: INFO: (8) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.157809ms)
Dec 21 12:35:01.621: INFO: (9) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 13.087432ms)
Dec 21 12:35:01.631: INFO: (10) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 9.086524ms)
Dec 21 12:35:01.647: INFO: (11) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 15.844068ms)
Dec 21 12:35:01.655: INFO: (12) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.491878ms)
Dec 21 12:35:01.661: INFO: (13) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.150834ms)
Dec 21 12:35:01.669: INFO: (14) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.178849ms)
Dec 21 12:35:01.686: INFO: (15) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 14.305616ms)
Dec 21 12:35:01.719: INFO: (16) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 32.684367ms)
Dec 21 12:35:01.727: INFO: (17) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.446338ms)
Dec 21 12:35:01.733: INFO: (18) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.136374ms)
Dec 21 12:35:01.741: INFO: (19) /api/v1/nodes/ip-172-31-232-239.eu-central-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 7.87588ms)
[AfterEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:35:01.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8860" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":273,"completed":80,"skipped":1291,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:35:01.768: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-6383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Dec 21 12:35:01.943: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-6383" to be "Succeeded or Failed"
Dec 21 12:35:01.954: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.57779ms
Dec 21 12:35:03.963: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.020510314s
Dec 21 12:35:05.968: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025074486s
STEP: Saw pod success
Dec 21 12:35:05.968: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Dec 21 12:35:05.972: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 21 12:35:06.006: INFO: Waiting for pod pod-host-path-test to disappear
Dec 21 12:35:06.012: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:35:06.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-6383" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":81,"skipped":1340,"failed":0}
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:35:06.031: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 21 12:35:06.309: INFO: Number of nodes with available pods: 0
Dec 21 12:35:06.309: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:35:07.331: INFO: Number of nodes with available pods: 0
Dec 21 12:35:07.331: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:35:08.318: INFO: Number of nodes with available pods: 2
Dec 21 12:35:08.318: INFO: Node ip-172-31-232-239.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:35:09.359: INFO: Number of nodes with available pods: 3
Dec 21 12:35:09.359: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 21 12:35:09.421: INFO: Number of nodes with available pods: 2
Dec 21 12:35:09.421: INFO: Node ip-172-31-244-13.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:35:10.433: INFO: Number of nodes with available pods: 2
Dec 21 12:35:10.433: INFO: Node ip-172-31-244-13.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:35:11.434: INFO: Number of nodes with available pods: 3
Dec 21 12:35:11.435: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8882, will wait for the garbage collector to delete the pods
Dec 21 12:35:11.565: INFO: Deleting DaemonSet.extensions daemon-set took: 57.62359ms
Dec 21 12:35:12.168: INFO: Terminating DaemonSet.extensions daemon-set pods took: 603.38362ms
Dec 21 12:35:24.774: INFO: Number of nodes with available pods: 0
Dec 21 12:35:24.774: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 12:35:24.778: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8882/daemonsets","resourceVersion":"36032751"},"items":null}

Dec 21 12:35:24.782: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8882/pods","resourceVersion":"36032751"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:35:24.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8882" for this suite.

• [SLOW TEST:18.779 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":273,"completed":82,"skipped":1341,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:35:24.813: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5795
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 21 12:35:31.016: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 12:35:31.024: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 12:35:33.024: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 12:35:33.029: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 12:35:35.024: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 12:35:35.029: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 12:35:37.024: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 12:35:37.029: INFO: Pod pod-with-prestop-http-hook still exists
Dec 21 12:35:39.024: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 21 12:35:39.028: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:35:39.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5795" for this suite.

• [SLOW TEST:14.242 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":273,"completed":83,"skipped":1407,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:35:39.060: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8316
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-8316
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 21 12:35:39.214: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 21 12:35:39.258: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:35:41.262: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:35:43.263: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:35:45.263: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:35:47.263: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:35:49.263: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:35:51.263: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:35:53.263: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 21 12:35:53.269: INFO: The status of Pod netserver-1 is Running (Ready = false)
Dec 21 12:35:55.277: INFO: The status of Pod netserver-1 is Running (Ready = false)
Dec 21 12:35:57.274: INFO: The status of Pod netserver-1 is Running (Ready = false)
Dec 21 12:35:59.280: INFO: The status of Pod netserver-1 is Running (Ready = true)
Dec 21 12:35:59.288: INFO: The status of Pod netserver-2 is Running (Ready = false)
Dec 21 12:36:01.299: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Dec 21 12:36:05.348: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.4.74:8080/dial?request=hostname&protocol=http&host=172.25.3.41&port=8080&tries=1'] Namespace:pod-network-test-8316 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:36:05.348: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:36:05.696: INFO: Waiting for responses: map[]
Dec 21 12:36:05.705: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.4.74:8080/dial?request=hostname&protocol=http&host=172.25.4.73&port=8080&tries=1'] Namespace:pod-network-test-8316 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:36:05.705: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:36:06.186: INFO: Waiting for responses: map[]
Dec 21 12:36:06.194: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.4.74:8080/dial?request=hostname&protocol=http&host=172.25.5.27&port=8080&tries=1'] Namespace:pod-network-test-8316 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:36:06.194: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:36:06.502: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:36:06.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8316" for this suite.

• [SLOW TEST:27.458 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":273,"completed":84,"skipped":1432,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:36:06.519: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1966
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:36:07.172: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:36:10.208: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:36:10.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1966" for this suite.
STEP: Destroying namespace "webhook-1966-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":273,"completed":85,"skipped":1438,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:36:10.403: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6494
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:36:10.608: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 21 12:36:14.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-6494 create -f -'
Dec 21 12:36:14.598: INFO: stderr: ""
Dec 21 12:36:14.598: INFO: stdout: "e2e-test-crd-publish-openapi-1140-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 21 12:36:14.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-6494 delete e2e-test-crd-publish-openapi-1140-crds test-cr'
Dec 21 12:36:14.682: INFO: stderr: ""
Dec 21 12:36:14.682: INFO: stdout: "e2e-test-crd-publish-openapi-1140-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 21 12:36:14.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-6494 apply -f -'
Dec 21 12:36:14.870: INFO: stderr: ""
Dec 21 12:36:14.870: INFO: stdout: "e2e-test-crd-publish-openapi-1140-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 21 12:36:14.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-6494 delete e2e-test-crd-publish-openapi-1140-crds test-cr'
Dec 21 12:36:14.953: INFO: stderr: ""
Dec 21 12:36:14.953: INFO: stdout: "e2e-test-crd-publish-openapi-1140-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 21 12:36:14.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 explain e2e-test-crd-publish-openapi-1140-crds'
Dec 21 12:36:15.116: INFO: stderr: ""
Dec 21 12:36:15.116: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1140-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:36:18.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6494" for this suite.

• [SLOW TEST:8.303 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":273,"completed":86,"skipped":1453,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:36:18.709: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:36:19.702: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 21 12:36:21.714: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150979, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150979, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150979, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744150979, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:36:24.734: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:36:24.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8146" for this suite.
STEP: Destroying namespace "webhook-8146-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.270 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":273,"completed":87,"skipped":1537,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:36:24.981: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7109
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Dec 21 12:36:25.205: INFO: namespace kubectl-7109
Dec 21 12:36:25.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-7109'
Dec 21 12:36:25.500: INFO: stderr: ""
Dec 21 12:36:25.500: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Dec 21 12:36:26.505: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 12:36:26.505: INFO: Found 0 / 1
Dec 21 12:36:27.504: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 12:36:27.504: INFO: Found 1 / 1
Dec 21 12:36:27.504: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 21 12:36:27.508: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 12:36:27.508: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 21 12:36:27.508: INFO: wait on agnhost-master startup in kubectl-7109 
Dec 21 12:36:27.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 logs agnhost-master-md42l agnhost-master --namespace=kubectl-7109'
Dec 21 12:36:27.609: INFO: stderr: ""
Dec 21 12:36:27.609: INFO: stdout: "Paused\n"
STEP: exposing RC
Dec 21 12:36:27.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7109'
Dec 21 12:36:27.724: INFO: stderr: ""
Dec 21 12:36:27.724: INFO: stdout: "service/rm2 exposed\n"
Dec 21 12:36:27.727: INFO: Service rm2 in namespace kubectl-7109 found.
STEP: exposing service
Dec 21 12:36:29.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7109'
Dec 21 12:36:29.855: INFO: stderr: ""
Dec 21 12:36:29.855: INFO: stdout: "service/rm3 exposed\n"
Dec 21 12:36:29.860: INFO: Service rm3 in namespace kubectl-7109 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:36:31.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7109" for this suite.

• [SLOW TEST:6.917 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1119
    should create services for rc  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":273,"completed":88,"skipped":1568,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:36:31.899: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2475.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2475.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2475.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2475.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2475.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2475.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 12:36:34.432: INFO: DNS probes using dns-2475/dns-test-103b0323-a44d-479e-9b5a-540a70486931 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:36:34.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2475" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":273,"completed":89,"skipped":1585,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:36:34.488: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8290
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 21 12:36:34.657: INFO: Waiting up to 5m0s for pod "pod-363d3159-9c2c-4f6c-9674-e50f3615ebb1" in namespace "emptydir-8290" to be "Succeeded or Failed"
Dec 21 12:36:34.662: INFO: Pod "pod-363d3159-9c2c-4f6c-9674-e50f3615ebb1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.393018ms
Dec 21 12:36:36.667: INFO: Pod "pod-363d3159-9c2c-4f6c-9674-e50f3615ebb1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009870074s
Dec 21 12:36:38.671: INFO: Pod "pod-363d3159-9c2c-4f6c-9674-e50f3615ebb1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014095188s
STEP: Saw pod success
Dec 21 12:36:38.671: INFO: Pod "pod-363d3159-9c2c-4f6c-9674-e50f3615ebb1" satisfied condition "Succeeded or Failed"
Dec 21 12:36:38.675: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-363d3159-9c2c-4f6c-9674-e50f3615ebb1 container test-container: <nil>
STEP: delete the pod
Dec 21 12:36:38.744: INFO: Waiting for pod pod-363d3159-9c2c-4f6c-9674-e50f3615ebb1 to disappear
Dec 21 12:36:38.749: INFO: Pod pod-363d3159-9c2c-4f6c-9674-e50f3615ebb1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:36:38.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8290" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":90,"skipped":1606,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:36:38.767: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:36:50.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1519" for this suite.

• [SLOW TEST:11.284 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":273,"completed":91,"skipped":1622,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:36:50.052: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:36:50.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7782" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":273,"completed":92,"skipped":1628,"failed":0}

------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:36:50.287: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-840
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-840
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-840
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-840
Dec 21 12:36:50.485: INFO: Found 0 stateful pods, waiting for 1
Dec 21 12:37:00.489: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 21 12:37:00.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-840 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 12:37:01.159: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 12:37:01.159: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 12:37:01.159: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 12:37:01.164: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 21 12:37:11.182: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 12:37:11.182: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 12:37:11.213: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999719s
Dec 21 12:37:12.218: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994424455s
Dec 21 12:37:13.223: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989095134s
Dec 21 12:37:14.237: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.984539197s
Dec 21 12:37:15.243: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.969225652s
Dec 21 12:37:16.255: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.964356601s
Dec 21 12:37:17.260: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.952130159s
Dec 21 12:37:18.265: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.947335304s
Dec 21 12:37:19.271: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.942708459s
Dec 21 12:37:20.275: INFO: Verifying statefulset ss doesn't scale past 1 for another 936.292191ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-840
Dec 21 12:37:21.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-840 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 12:37:21.731: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 12:37:21.731: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 12:37:21.731: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 12:37:21.735: INFO: Found 1 stateful pods, waiting for 3
Dec 21 12:37:31.758: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 12:37:31.758: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 12:37:31.758: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 21 12:37:31.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-840 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 12:37:32.179: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 12:37:32.179: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 12:37:32.179: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 12:37:32.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-840 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 12:37:32.857: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 12:37:32.857: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 12:37:32.857: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 12:37:32.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-840 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 12:37:33.440: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 12:37:33.440: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 12:37:33.440: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 12:37:33.440: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 12:37:33.452: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec 21 12:37:43.460: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 12:37:43.460: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 12:37:43.460: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 12:37:43.477: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999623s
Dec 21 12:37:44.482: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995879042s
Dec 21 12:37:45.488: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990876023s
Dec 21 12:37:46.493: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985015768s
Dec 21 12:37:47.501: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979791254s
Dec 21 12:37:48.507: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972000741s
Dec 21 12:37:49.514: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965798739s
Dec 21 12:37:50.520: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958969992s
Dec 21 12:37:51.528: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.952923626s
Dec 21 12:37:52.534: INFO: Verifying statefulset ss doesn't scale past 3 for another 945.161336ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-840
Dec 21 12:37:53.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-840 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 12:37:53.880: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 12:37:53.880: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 12:37:53.880: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 12:37:53.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-840 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 12:37:54.270: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 12:37:54.270: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 12:37:54.270: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 12:37:54.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-840 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 12:37:54.730: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 12:37:54.730: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 12:37:54.731: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 12:37:54.731: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 21 12:38:24.749: INFO: Deleting all statefulset in ns statefulset-840
Dec 21 12:38:24.753: INFO: Scaling statefulset ss to 0
Dec 21 12:38:24.765: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 12:38:24.769: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:24.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-840" for this suite.

• [SLOW TEST:94.521 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":273,"completed":93,"skipped":1628,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:24.808: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-63
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 21 12:38:24.962: INFO: Waiting up to 5m0s for pod "pod-f2475b81-41dc-4d1a-80df-21919b68150d" in namespace "emptydir-63" to be "Succeeded or Failed"
Dec 21 12:38:24.966: INFO: Pod "pod-f2475b81-41dc-4d1a-80df-21919b68150d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.812192ms
Dec 21 12:38:26.971: INFO: Pod "pod-f2475b81-41dc-4d1a-80df-21919b68150d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0090143s
Dec 21 12:38:28.977: INFO: Pod "pod-f2475b81-41dc-4d1a-80df-21919b68150d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014761017s
STEP: Saw pod success
Dec 21 12:38:28.977: INFO: Pod "pod-f2475b81-41dc-4d1a-80df-21919b68150d" satisfied condition "Succeeded or Failed"
Dec 21 12:38:28.982: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-f2475b81-41dc-4d1a-80df-21919b68150d container test-container: <nil>
STEP: delete the pod
Dec 21 12:38:29.047: INFO: Waiting for pod pod-f2475b81-41dc-4d1a-80df-21919b68150d to disappear
Dec 21 12:38:29.050: INFO: Pod pod-f2475b81-41dc-4d1a-80df-21919b68150d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:29.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-63" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":94,"skipped":1635,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:29.062: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1088
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:38:29.268: INFO: Waiting up to 5m0s for pod "downwardapi-volume-379b3497-29ad-42a8-b586-6e1a4d0dcf84" in namespace "downward-api-1088" to be "Succeeded or Failed"
Dec 21 12:38:29.274: INFO: Pod "downwardapi-volume-379b3497-29ad-42a8-b586-6e1a4d0dcf84": Phase="Pending", Reason="", readiness=false. Elapsed: 6.655737ms
Dec 21 12:38:31.279: INFO: Pod "downwardapi-volume-379b3497-29ad-42a8-b586-6e1a4d0dcf84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01104995s
STEP: Saw pod success
Dec 21 12:38:31.279: INFO: Pod "downwardapi-volume-379b3497-29ad-42a8-b586-6e1a4d0dcf84" satisfied condition "Succeeded or Failed"
Dec 21 12:38:31.283: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-379b3497-29ad-42a8-b586-6e1a4d0dcf84 container client-container: <nil>
STEP: delete the pod
Dec 21 12:38:31.346: INFO: Waiting for pod downwardapi-volume-379b3497-29ad-42a8-b586-6e1a4d0dcf84 to disappear
Dec 21 12:38:31.350: INFO: Pod downwardapi-volume-379b3497-29ad-42a8-b586-6e1a4d0dcf84 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:31.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1088" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":273,"completed":95,"skipped":1646,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:31.361: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-951
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 21 12:38:33.538: INFO: &Pod{ObjectMeta:{send-events-d3920050-366c-4942-a0b6-d016084f77c2  events-951 /api/v1/namespaces/events-951/pods/send-events-d3920050-366c-4942-a0b6-d016084f77c2 d22de835-607a-409e-9255-67105b0cf86e 36034426 0 2020-12-21 12:38:31 +0000 UTC <nil> <nil> map[name:foo time:514166236] map[cni.projectcalico.org/podIP:172.25.4.81/32 cni.projectcalico.org/podIPs:172.25.4.81/32] [] []  [{e2e.test Update v1 2020-12-21 12:38:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:38:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:38:33 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 52 46 56 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2cb9w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2cb9w,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2cb9w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:38:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:38:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:38:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:38:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.232.239,PodIP:172.25.4.81,StartTime:2020-12-21 12:38:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:38:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://c35793a7465862940c30b0af4ddf99f167b628490203d618df12c65accd998be,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.4.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec 21 12:38:35.545: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 21 12:38:37.550: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:37.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-951" for this suite.

• [SLOW TEST:6.211 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":273,"completed":96,"skipped":1663,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:37.573: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1482
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:38:37.727: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7382e6cd-9619-4a2b-942f-55af3dfa9787" in namespace "downward-api-1482" to be "Succeeded or Failed"
Dec 21 12:38:37.732: INFO: Pod "downwardapi-volume-7382e6cd-9619-4a2b-942f-55af3dfa9787": Phase="Pending", Reason="", readiness=false. Elapsed: 4.384938ms
Dec 21 12:38:39.738: INFO: Pod "downwardapi-volume-7382e6cd-9619-4a2b-942f-55af3dfa9787": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010283961s
STEP: Saw pod success
Dec 21 12:38:39.738: INFO: Pod "downwardapi-volume-7382e6cd-9619-4a2b-942f-55af3dfa9787" satisfied condition "Succeeded or Failed"
Dec 21 12:38:39.743: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod downwardapi-volume-7382e6cd-9619-4a2b-942f-55af3dfa9787 container client-container: <nil>
STEP: delete the pod
Dec 21 12:38:39.813: INFO: Waiting for pod downwardapi-volume-7382e6cd-9619-4a2b-942f-55af3dfa9787 to disappear
Dec 21 12:38:39.816: INFO: Pod downwardapi-volume-7382e6cd-9619-4a2b-942f-55af3dfa9787 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:39.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1482" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":273,"completed":97,"skipped":1711,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:39.831: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 21 12:38:40.056: INFO: Waiting up to 5m0s for pod "pod-ffec021c-4593-44de-8508-c4ff760f76bb" in namespace "emptydir-6576" to be "Succeeded or Failed"
Dec 21 12:38:40.070: INFO: Pod "pod-ffec021c-4593-44de-8508-c4ff760f76bb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.745155ms
Dec 21 12:38:42.075: INFO: Pod "pod-ffec021c-4593-44de-8508-c4ff760f76bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019274038s
STEP: Saw pod success
Dec 21 12:38:42.075: INFO: Pod "pod-ffec021c-4593-44de-8508-c4ff760f76bb" satisfied condition "Succeeded or Failed"
Dec 21 12:38:42.087: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-ffec021c-4593-44de-8508-c4ff760f76bb container test-container: <nil>
STEP: delete the pod
Dec 21 12:38:42.156: INFO: Waiting for pod pod-ffec021c-4593-44de-8508-c4ff760f76bb to disappear
Dec 21 12:38:42.160: INFO: Pod pod-ffec021c-4593-44de-8508-c4ff760f76bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:42.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6576" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":98,"skipped":1713,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:42.172: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6395
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-ab54128e-1779-400b-8a63-de62e68584a4
STEP: Creating a pod to test consume secrets
Dec 21 12:38:42.332: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7bd29997-7ab1-4f62-a877-351e533744b2" in namespace "projected-6395" to be "Succeeded or Failed"
Dec 21 12:38:42.338: INFO: Pod "pod-projected-secrets-7bd29997-7ab1-4f62-a877-351e533744b2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.602266ms
Dec 21 12:38:44.344: INFO: Pod "pod-projected-secrets-7bd29997-7ab1-4f62-a877-351e533744b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011383117s
STEP: Saw pod success
Dec 21 12:38:44.344: INFO: Pod "pod-projected-secrets-7bd29997-7ab1-4f62-a877-351e533744b2" satisfied condition "Succeeded or Failed"
Dec 21 12:38:44.349: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-projected-secrets-7bd29997-7ab1-4f62-a877-351e533744b2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 12:38:44.374: INFO: Waiting for pod pod-projected-secrets-7bd29997-7ab1-4f62-a877-351e533744b2 to disappear
Dec 21 12:38:44.378: INFO: Pod pod-projected-secrets-7bd29997-7ab1-4f62-a877-351e533744b2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:44.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6395" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":273,"completed":99,"skipped":1744,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:44.399: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4723
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 21 12:38:44.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-4723'
Dec 21 12:38:44.643: INFO: stderr: ""
Dec 21 12:38:44.643: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 21 12:38:49.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pod e2e-test-httpd-pod --namespace=kubectl-4723 -o json'
Dec 21 12:38:49.790: INFO: stderr: ""
Dec 21 12:38:49.790: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"172.25.3.49/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.25.3.49/32\"\n        },\n        \"creationTimestamp\": \"2020-12-21T12:38:44Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-12-21T12:38:44Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \".\": {},\n                            \"f:cni.projectcalico.org/podIP\": {},\n                            \"f:cni.projectcalico.org/podIPs\": {}\n                        }\n                    }\n                },\n                \"manager\": \"calico\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-12-21T12:38:45Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"172.25.3.49\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-12-21T12:38:46Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4723\",\n        \"resourceVersion\": \"36034607\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-4723/pods/e2e-test-httpd-pod\",\n        \"uid\": \"428e6fab-c240-41be-b9ba-8c1339cd4a00\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-shl7z\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-183-240.eu-central-1.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-shl7z\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-shl7z\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-12-21T12:38:44Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-12-21T12:38:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-12-21T12:38:46Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-12-21T12:38:44Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://79ebadc4f99b3633a48ac9a0cfcb856fa53e324e3b0ebd61e711f054143a042f\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-12-21T12:38:45Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.183.240\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.25.3.49\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.25.3.49\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-12-21T12:38:44Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 21 12:38:49.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 replace -f - --namespace=kubectl-4723'
Dec 21 12:38:50.057: INFO: stderr: ""
Dec 21 12:38:50.057: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec 21 12:38:50.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete pods e2e-test-httpd-pod --namespace=kubectl-4723'
Dec 21 12:38:53.476: INFO: stderr: ""
Dec 21 12:38:53.476: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:53.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4723" for this suite.

• [SLOW TEST:9.097 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1450
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":273,"completed":100,"skipped":1786,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:53.496: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-158
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-3ade7cb9-5324-4a67-b566-58fb07d269b9
STEP: Creating configMap with name cm-test-opt-upd-b2a868b7-60f9-46ac-9cb7-e8fda89bb952
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3ade7cb9-5324-4a67-b566-58fb07d269b9
STEP: Updating configmap cm-test-opt-upd-b2a868b7-60f9-46ac-9cb7-e8fda89bb952
STEP: Creating configMap with name cm-test-opt-create-dd949c3b-186f-4ce5-a813-527b0badb075
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:57.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-158" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":101,"skipped":1805,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:57.959: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-6535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:38:58.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-6535" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":273,"completed":102,"skipped":1812,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:38:58.121: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8003
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:38:58.297: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 21 12:39:01.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-8003 create -f -'
Dec 21 12:39:02.363: INFO: stderr: ""
Dec 21 12:39:02.363: INFO: stdout: "e2e-test-crd-publish-openapi-4085-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 21 12:39:02.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-8003 delete e2e-test-crd-publish-openapi-4085-crds test-cr'
Dec 21 12:39:02.454: INFO: stderr: ""
Dec 21 12:39:02.454: INFO: stdout: "e2e-test-crd-publish-openapi-4085-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 21 12:39:02.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-8003 apply -f -'
Dec 21 12:39:02.647: INFO: stderr: ""
Dec 21 12:39:02.647: INFO: stdout: "e2e-test-crd-publish-openapi-4085-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 21 12:39:02.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-8003 delete e2e-test-crd-publish-openapi-4085-crds test-cr'
Dec 21 12:39:02.742: INFO: stderr: ""
Dec 21 12:39:02.742: INFO: stdout: "e2e-test-crd-publish-openapi-4085-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 21 12:39:02.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 explain e2e-test-crd-publish-openapi-4085-crds'
Dec 21 12:39:03.088: INFO: stderr: ""
Dec 21 12:39:03.088: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4085-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:39:06.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8003" for this suite.

• [SLOW TEST:7.958 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":273,"completed":103,"skipped":1828,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:39:06.079: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4908
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Dec 21 12:39:06.251: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:39:23.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4908" for this suite.

• [SLOW TEST:17.656 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":273,"completed":104,"skipped":1832,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:39:23.735: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8279
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:39:23.946: INFO: Create a RollingUpdate DaemonSet
Dec 21 12:39:23.953: INFO: Check that daemon pods launch on every node of the cluster
Dec 21 12:39:23.960: INFO: Number of nodes with available pods: 0
Dec 21 12:39:23.960: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:39:24.973: INFO: Number of nodes with available pods: 0
Dec 21 12:39:24.973: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:39:25.977: INFO: Number of nodes with available pods: 1
Dec 21 12:39:25.977: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:39:26.973: INFO: Number of nodes with available pods: 2
Dec 21 12:39:26.973: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 12:39:27.972: INFO: Number of nodes with available pods: 3
Dec 21 12:39:27.972: INFO: Number of running nodes: 3, number of available pods: 3
Dec 21 12:39:27.972: INFO: Update the DaemonSet to trigger a rollout
Dec 21 12:39:27.983: INFO: Updating DaemonSet daemon-set
Dec 21 12:39:35.009: INFO: Roll back the DaemonSet before rollout is complete
Dec 21 12:39:35.023: INFO: Updating DaemonSet daemon-set
Dec 21 12:39:35.023: INFO: Make sure DaemonSet rollback is complete
Dec 21 12:39:35.027: INFO: Wrong image for pod: daemon-set-c5b6r. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 21 12:39:35.027: INFO: Pod daemon-set-c5b6r is not available
Dec 21 12:39:36.045: INFO: Wrong image for pod: daemon-set-c5b6r. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 21 12:39:36.045: INFO: Pod daemon-set-c5b6r is not available
Dec 21 12:39:37.044: INFO: Wrong image for pod: daemon-set-c5b6r. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 21 12:39:37.044: INFO: Pod daemon-set-c5b6r is not available
Dec 21 12:39:38.042: INFO: Pod daemon-set-5rzbm is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8279, will wait for the garbage collector to delete the pods
Dec 21 12:39:38.122: INFO: Deleting DaemonSet.extensions daemon-set took: 10.308879ms
Dec 21 12:39:38.725: INFO: Terminating DaemonSet.extensions daemon-set pods took: 602.59525ms
Dec 21 12:41:04.729: INFO: Number of nodes with available pods: 0
Dec 21 12:41:04.729: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 12:41:04.733: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8279/daemonsets","resourceVersion":"36035464"},"items":null}

Dec 21 12:41:04.737: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8279/pods","resourceVersion":"36035464"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:41:04.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8279" for this suite.

• [SLOW TEST:101.035 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":273,"completed":105,"skipped":1842,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:41:04.773: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3056
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:41:06.970: INFO: Waiting up to 5m0s for pod "client-envvars-b5be326f-17ff-439d-b468-56a120477511" in namespace "pods-3056" to be "Succeeded or Failed"
Dec 21 12:41:06.975: INFO: Pod "client-envvars-b5be326f-17ff-439d-b468-56a120477511": Phase="Pending", Reason="", readiness=false. Elapsed: 4.385401ms
Dec 21 12:41:08.990: INFO: Pod "client-envvars-b5be326f-17ff-439d-b468-56a120477511": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019383651s
STEP: Saw pod success
Dec 21 12:41:08.990: INFO: Pod "client-envvars-b5be326f-17ff-439d-b468-56a120477511" satisfied condition "Succeeded or Failed"
Dec 21 12:41:08.998: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod client-envvars-b5be326f-17ff-439d-b468-56a120477511 container env3cont: <nil>
STEP: delete the pod
Dec 21 12:41:09.077: INFO: Waiting for pod client-envvars-b5be326f-17ff-439d-b468-56a120477511 to disappear
Dec 21 12:41:09.103: INFO: Pod client-envvars-b5be326f-17ff-439d-b468-56a120477511 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:41:09.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3056" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":273,"completed":106,"skipped":1864,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:41:09.140: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-935
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Dec 21 12:41:09.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 cluster-info'
Dec 21 12:41:09.470: INFO: stderr: ""
Dec 21 12:41:09.470: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.240.16.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.240.16.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:41:09.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-935" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":273,"completed":107,"skipped":1949,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:41:09.484: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1352
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 21 12:41:09.650: INFO: Waiting up to 5m0s for pod "downward-api-dbbb88a3-12d3-4623-a7aa-daeaefa16040" in namespace "downward-api-1352" to be "Succeeded or Failed"
Dec 21 12:41:09.654: INFO: Pod "downward-api-dbbb88a3-12d3-4623-a7aa-daeaefa16040": Phase="Pending", Reason="", readiness=false. Elapsed: 3.820636ms
Dec 21 12:41:11.659: INFO: Pod "downward-api-dbbb88a3-12d3-4623-a7aa-daeaefa16040": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009177917s
STEP: Saw pod success
Dec 21 12:41:11.659: INFO: Pod "downward-api-dbbb88a3-12d3-4623-a7aa-daeaefa16040" satisfied condition "Succeeded or Failed"
Dec 21 12:41:11.663: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod downward-api-dbbb88a3-12d3-4623-a7aa-daeaefa16040 container dapi-container: <nil>
STEP: delete the pod
Dec 21 12:41:11.689: INFO: Waiting for pod downward-api-dbbb88a3-12d3-4623-a7aa-daeaefa16040 to disappear
Dec 21 12:41:11.692: INFO: Pod downward-api-dbbb88a3-12d3-4623-a7aa-daeaefa16040 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:41:11.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1352" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":273,"completed":108,"skipped":1967,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:41:11.706: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:41:11.918: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e91178ed-25a1-49a9-9d2f-97e7d1773e8e" in namespace "downward-api-3607" to be "Succeeded or Failed"
Dec 21 12:41:11.925: INFO: Pod "downwardapi-volume-e91178ed-25a1-49a9-9d2f-97e7d1773e8e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042522ms
Dec 21 12:41:13.929: INFO: Pod "downwardapi-volume-e91178ed-25a1-49a9-9d2f-97e7d1773e8e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010533585s
Dec 21 12:41:15.934: INFO: Pod "downwardapi-volume-e91178ed-25a1-49a9-9d2f-97e7d1773e8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014800183s
STEP: Saw pod success
Dec 21 12:41:15.934: INFO: Pod "downwardapi-volume-e91178ed-25a1-49a9-9d2f-97e7d1773e8e" satisfied condition "Succeeded or Failed"
Dec 21 12:41:15.937: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod downwardapi-volume-e91178ed-25a1-49a9-9d2f-97e7d1773e8e container client-container: <nil>
STEP: delete the pod
Dec 21 12:41:15.961: INFO: Waiting for pod downwardapi-volume-e91178ed-25a1-49a9-9d2f-97e7d1773e8e to disappear
Dec 21 12:41:15.964: INFO: Pod downwardapi-volume-e91178ed-25a1-49a9-9d2f-97e7d1773e8e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:41:15.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3607" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":273,"completed":109,"skipped":1977,"failed":0}
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:41:15.976: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-4834
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 21 12:41:16.131: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 21 12:41:16.184: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:41:18.189: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:41:20.188: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:41:22.196: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:41:24.190: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:41:26.192: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:41:28.197: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:41:30.189: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:41:32.191: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:41:34.189: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:41:36.189: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 21 12:41:38.189: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 21 12:41:38.198: INFO: The status of Pod netserver-1 is Running (Ready = true)
Dec 21 12:41:38.207: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Dec 21 12:41:40.236: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.4.87:8080/dial?request=hostname&protocol=udp&host=172.25.3.55&port=8081&tries=1'] Namespace:pod-network-test-4834 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:41:40.236: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:41:40.610: INFO: Waiting for responses: map[]
Dec 21 12:41:40.618: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.4.87:8080/dial?request=hostname&protocol=udp&host=172.25.4.86&port=8081&tries=1'] Namespace:pod-network-test-4834 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:41:40.619: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:41:41.011: INFO: Waiting for responses: map[]
Dec 21 12:41:41.019: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.4.87:8080/dial?request=hostname&protocol=udp&host=172.25.5.30&port=8081&tries=1'] Namespace:pod-network-test-4834 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:41:41.019: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:41:41.461: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:41:41.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4834" for this suite.

• [SLOW TEST:25.499 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":273,"completed":110,"skipped":1983,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:41:41.475: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-31258a68-45b0-4d20-8625-1c9c57d44be9
STEP: Creating a pod to test consume configMaps
Dec 21 12:41:41.639: INFO: Waiting up to 5m0s for pod "pod-configmaps-1ae8176d-1b2b-48db-884b-ea0718f263f3" in namespace "configmap-8679" to be "Succeeded or Failed"
Dec 21 12:41:41.643: INFO: Pod "pod-configmaps-1ae8176d-1b2b-48db-884b-ea0718f263f3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.889864ms
Dec 21 12:41:43.650: INFO: Pod "pod-configmaps-1ae8176d-1b2b-48db-884b-ea0718f263f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011529755s
Dec 21 12:41:45.655: INFO: Pod "pod-configmaps-1ae8176d-1b2b-48db-884b-ea0718f263f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015763586s
STEP: Saw pod success
Dec 21 12:41:45.655: INFO: Pod "pod-configmaps-1ae8176d-1b2b-48db-884b-ea0718f263f3" satisfied condition "Succeeded or Failed"
Dec 21 12:41:45.659: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-configmaps-1ae8176d-1b2b-48db-884b-ea0718f263f3 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 12:41:45.731: INFO: Waiting for pod pod-configmaps-1ae8176d-1b2b-48db-884b-ea0718f263f3 to disappear
Dec 21 12:41:45.735: INFO: Pod pod-configmaps-1ae8176d-1b2b-48db-884b-ea0718f263f3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:41:45.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8679" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":111,"skipped":1990,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:41:45.749: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8670
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 21 12:41:45.909: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-a 52b137fa-30d7-4b49-aa9e-8e06cac6e157 36035895 0 2020-12-21 12:41:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-21 12:41:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 12:41:45.909: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-a 52b137fa-30d7-4b49-aa9e-8e06cac6e157 36035895 0 2020-12-21 12:41:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-21 12:41:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 21 12:41:55.924: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-a 52b137fa-30d7-4b49-aa9e-8e06cac6e157 36035992 0 2020-12-21 12:41:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-21 12:41:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 12:41:55.924: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-a 52b137fa-30d7-4b49-aa9e-8e06cac6e157 36035992 0 2020-12-21 12:41:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-21 12:41:55 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 21 12:42:05.934: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-a 52b137fa-30d7-4b49-aa9e-8e06cac6e157 36036037 0 2020-12-21 12:41:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-21 12:42:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 12:42:05.934: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-a 52b137fa-30d7-4b49-aa9e-8e06cac6e157 36036037 0 2020-12-21 12:41:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-21 12:42:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 21 12:42:15.946: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-a 52b137fa-30d7-4b49-aa9e-8e06cac6e157 36036077 0 2020-12-21 12:41:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-21 12:42:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 12:42:15.946: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-a 52b137fa-30d7-4b49-aa9e-8e06cac6e157 36036077 0 2020-12-21 12:41:45 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-21 12:42:05 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 21 12:42:25.957: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-b 1a8f6e56-1695-4ec0-952c-4441d075cf03 36036119 0 2020-12-21 12:42:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-12-21 12:42:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 12:42:25.957: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-b 1a8f6e56-1695-4ec0-952c-4441d075cf03 36036119 0 2020-12-21 12:42:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-12-21 12:42:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 21 12:42:35.966: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-b 1a8f6e56-1695-4ec0-952c-4441d075cf03 36036162 0 2020-12-21 12:42:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-12-21 12:42:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 12:42:35.966: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8670 /api/v1/namespaces/watch-8670/configmaps/e2e-watch-test-configmap-b 1a8f6e56-1695-4ec0-952c-4441d075cf03 36036162 0 2020-12-21 12:42:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-12-21 12:42:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:42:45.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8670" for this suite.

• [SLOW TEST:60.230 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":273,"completed":112,"skipped":2006,"failed":0}
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:42:45.979: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8759
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-8759
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Dec 21 12:42:46.173: INFO: Found 0 stateful pods, waiting for 3
Dec 21 12:42:56.178: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 12:42:56.179: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 12:42:56.179: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 21 12:42:56.213: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 21 12:43:06.265: INFO: Updating stateful set ss2
Dec 21 12:43:06.314: INFO: Waiting for Pod statefulset-8759/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 12:43:16.323: INFO: Waiting for Pod statefulset-8759/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec 21 12:43:26.397: INFO: Found 2 stateful pods, waiting for 3
Dec 21 12:43:36.403: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 12:43:36.403: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 12:43:36.403: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 21 12:43:36.438: INFO: Updating stateful set ss2
Dec 21 12:43:36.448: INFO: Waiting for Pod statefulset-8759/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 12:43:46.459: INFO: Waiting for Pod statefulset-8759/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 12:43:56.485: INFO: Updating stateful set ss2
Dec 21 12:43:56.508: INFO: Waiting for StatefulSet statefulset-8759/ss2 to complete update
Dec 21 12:43:56.508: INFO: Waiting for Pod statefulset-8759/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 12:44:06.518: INFO: Waiting for StatefulSet statefulset-8759/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 21 12:44:16.516: INFO: Deleting all statefulset in ns statefulset-8759
Dec 21 12:44:16.520: INFO: Scaling statefulset ss2 to 0
Dec 21 12:44:36.544: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 12:44:36.549: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:44:36.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8759" for this suite.

• [SLOW TEST:110.628 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":273,"completed":113,"skipped":2010,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:44:36.609: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7721
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-7721
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-7721
Dec 21 12:44:36.848: INFO: Found 0 stateful pods, waiting for 1
Dec 21 12:44:46.852: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 21 12:44:46.882: INFO: Deleting all statefulset in ns statefulset-7721
Dec 21 12:44:46.889: INFO: Scaling statefulset ss to 0
Dec 21 12:45:06.919: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 12:45:06.924: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:45:06.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7721" for this suite.

• [SLOW TEST:30.358 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":273,"completed":114,"skipped":2022,"failed":0}
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:45:06.968: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-60a01dec-b4ca-4897-bded-a145564ff35a
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:45:07.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5262" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":273,"completed":115,"skipped":2030,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:45:07.293: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3192
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-2f57cdcd-3e24-461d-a617-8dfe3257876f
STEP: Creating a pod to test consume configMaps
Dec 21 12:45:07.521: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-135af22a-3612-44d1-9987-80b08810e954" in namespace "projected-3192" to be "Succeeded or Failed"
Dec 21 12:45:07.525: INFO: Pod "pod-projected-configmaps-135af22a-3612-44d1-9987-80b08810e954": Phase="Pending", Reason="", readiness=false. Elapsed: 4.44448ms
Dec 21 12:45:09.530: INFO: Pod "pod-projected-configmaps-135af22a-3612-44d1-9987-80b08810e954": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009194892s
STEP: Saw pod success
Dec 21 12:45:09.530: INFO: Pod "pod-projected-configmaps-135af22a-3612-44d1-9987-80b08810e954" satisfied condition "Succeeded or Failed"
Dec 21 12:45:09.534: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-projected-configmaps-135af22a-3612-44d1-9987-80b08810e954 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 12:45:09.568: INFO: Waiting for pod pod-projected-configmaps-135af22a-3612-44d1-9987-80b08810e954 to disappear
Dec 21 12:45:09.573: INFO: Pod pod-projected-configmaps-135af22a-3612-44d1-9987-80b08810e954 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:45:09.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3192" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":273,"completed":116,"skipped":2068,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:45:09.588: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9820
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:45:10.797: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 12:45:12.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151510, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151510, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151510, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151510, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:45:15.830: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:45:26.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9820" for this suite.
STEP: Destroying namespace "webhook-9820-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:17.240 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":273,"completed":117,"skipped":2100,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:45:26.848: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3335
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-a2f7b848-ed2e-4cfc-b56f-03c8a153e8f2
STEP: Creating a pod to test consume secrets
Dec 21 12:45:27.084: INFO: Waiting up to 5m0s for pod "pod-secrets-c22c19be-7849-4cb0-a65a-84f443ce8a55" in namespace "secrets-3335" to be "Succeeded or Failed"
Dec 21 12:45:27.091: INFO: Pod "pod-secrets-c22c19be-7849-4cb0-a65a-84f443ce8a55": Phase="Pending", Reason="", readiness=false. Elapsed: 6.79666ms
Dec 21 12:45:29.097: INFO: Pod "pod-secrets-c22c19be-7849-4cb0-a65a-84f443ce8a55": Phase="Running", Reason="", readiness=true. Elapsed: 2.013390317s
Dec 21 12:45:31.107: INFO: Pod "pod-secrets-c22c19be-7849-4cb0-a65a-84f443ce8a55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022771148s
STEP: Saw pod success
Dec 21 12:45:31.107: INFO: Pod "pod-secrets-c22c19be-7849-4cb0-a65a-84f443ce8a55" satisfied condition "Succeeded or Failed"
Dec 21 12:45:31.112: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-secrets-c22c19be-7849-4cb0-a65a-84f443ce8a55 container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 12:45:31.174: INFO: Waiting for pod pod-secrets-c22c19be-7849-4cb0-a65a-84f443ce8a55 to disappear
Dec 21 12:45:31.181: INFO: Pod pod-secrets-c22c19be-7849-4cb0-a65a-84f443ce8a55 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:45:31.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3335" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":273,"completed":118,"skipped":2126,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:45:31.205: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4945
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-a8ce11a1-0358-45ee-913e-ecf39432a5b6
STEP: Creating a pod to test consume configMaps
Dec 21 12:45:31.366: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2228e32f-25ec-45b3-b35d-2e3abaa13690" in namespace "projected-4945" to be "Succeeded or Failed"
Dec 21 12:45:31.373: INFO: Pod "pod-projected-configmaps-2228e32f-25ec-45b3-b35d-2e3abaa13690": Phase="Pending", Reason="", readiness=false. Elapsed: 6.526489ms
Dec 21 12:45:33.380: INFO: Pod "pod-projected-configmaps-2228e32f-25ec-45b3-b35d-2e3abaa13690": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013285904s
STEP: Saw pod success
Dec 21 12:45:33.380: INFO: Pod "pod-projected-configmaps-2228e32f-25ec-45b3-b35d-2e3abaa13690" satisfied condition "Succeeded or Failed"
Dec 21 12:45:33.384: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-projected-configmaps-2228e32f-25ec-45b3-b35d-2e3abaa13690 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 12:45:33.458: INFO: Waiting for pod pod-projected-configmaps-2228e32f-25ec-45b3-b35d-2e3abaa13690 to disappear
Dec 21 12:45:33.470: INFO: Pod pod-projected-configmaps-2228e32f-25ec-45b3-b35d-2e3abaa13690 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:45:33.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4945" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":119,"skipped":2142,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:45:33.486: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9435
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:45:33.674: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d8af1919-32be-4bfd-a763-41aba7790745" in namespace "projected-9435" to be "Succeeded or Failed"
Dec 21 12:45:33.678: INFO: Pod "downwardapi-volume-d8af1919-32be-4bfd-a763-41aba7790745": Phase="Pending", Reason="", readiness=false. Elapsed: 3.654074ms
Dec 21 12:45:35.688: INFO: Pod "downwardapi-volume-d8af1919-32be-4bfd-a763-41aba7790745": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013702197s
Dec 21 12:45:37.693: INFO: Pod "downwardapi-volume-d8af1919-32be-4bfd-a763-41aba7790745": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018622037s
STEP: Saw pod success
Dec 21 12:45:37.693: INFO: Pod "downwardapi-volume-d8af1919-32be-4bfd-a763-41aba7790745" satisfied condition "Succeeded or Failed"
Dec 21 12:45:37.700: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-d8af1919-32be-4bfd-a763-41aba7790745 container client-container: <nil>
STEP: delete the pod
Dec 21 12:45:37.767: INFO: Waiting for pod downwardapi-volume-d8af1919-32be-4bfd-a763-41aba7790745 to disappear
Dec 21 12:45:37.772: INFO: Pod downwardapi-volume-d8af1919-32be-4bfd-a763-41aba7790745 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:45:37.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9435" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":120,"skipped":2187,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:45:37.786: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5850
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8253
STEP: Creating secret with name secret-test-e23ee098-a276-43e5-a10a-242d138b0da4
STEP: Creating a pod to test consume secrets
Dec 21 12:45:38.111: INFO: Waiting up to 5m0s for pod "pod-secrets-6d590849-7fb1-4304-ac54-3337459c2edf" in namespace "secrets-5850" to be "Succeeded or Failed"
Dec 21 12:45:38.117: INFO: Pod "pod-secrets-6d590849-7fb1-4304-ac54-3337459c2edf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.414896ms
Dec 21 12:45:40.124: INFO: Pod "pod-secrets-6d590849-7fb1-4304-ac54-3337459c2edf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012669857s
STEP: Saw pod success
Dec 21 12:45:40.124: INFO: Pod "pod-secrets-6d590849-7fb1-4304-ac54-3337459c2edf" satisfied condition "Succeeded or Failed"
Dec 21 12:45:40.132: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-secrets-6d590849-7fb1-4304-ac54-3337459c2edf container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 12:45:40.172: INFO: Waiting for pod pod-secrets-6d590849-7fb1-4304-ac54-3337459c2edf to disappear
Dec 21 12:45:40.177: INFO: Pod pod-secrets-6d590849-7fb1-4304-ac54-3337459c2edf no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:45:40.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5850" for this suite.
STEP: Destroying namespace "secret-namespace-8253" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":273,"completed":121,"skipped":2189,"failed":0}
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:45:40.200: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6442
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:46:07.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6442" for this suite.

• [SLOW TEST:27.558 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    when starting a container that exits
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":273,"completed":122,"skipped":2190,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:46:07.761: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-231
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-231
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-231
I1221 12:46:07.956349      20 runners.go:190] Created replication controller with name: externalname-service, namespace: services-231, replica count: 2
I1221 12:46:11.007729      20 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 21 12:46:11.007: INFO: Creating new exec pod
Dec 21 12:46:14.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=services-231 execpodphmp5 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 21 12:46:14.475: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 21 12:46:14.475: INFO: stdout: ""
Dec 21 12:46:14.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=services-231 execpodphmp5 -- /bin/sh -x -c nc -zv -t -w 2 10.240.28.128 80'
Dec 21 12:46:15.050: INFO: stderr: "+ nc -zv -t -w 2 10.240.28.128 80\nConnection to 10.240.28.128 80 port [tcp/http] succeeded!\n"
Dec 21 12:46:15.050: INFO: stdout: ""
Dec 21 12:46:15.050: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:46:15.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-231" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:7.337 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":273,"completed":123,"skipped":2208,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:46:15.097: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-5097
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:46:15.654: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:46:18.681: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:46:18.695: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:46:20.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5097" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:5.272 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":273,"completed":124,"skipped":2217,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:46:20.369: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5753
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:46:20.568: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92c5398b-2794-450a-b9ab-19d0c45e5ac5" in namespace "projected-5753" to be "Succeeded or Failed"
Dec 21 12:46:20.574: INFO: Pod "downwardapi-volume-92c5398b-2794-450a-b9ab-19d0c45e5ac5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.442263ms
Dec 21 12:46:22.579: INFO: Pod "downwardapi-volume-92c5398b-2794-450a-b9ab-19d0c45e5ac5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010617939s
STEP: Saw pod success
Dec 21 12:46:22.579: INFO: Pod "downwardapi-volume-92c5398b-2794-450a-b9ab-19d0c45e5ac5" satisfied condition "Succeeded or Failed"
Dec 21 12:46:22.586: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-92c5398b-2794-450a-b9ab-19d0c45e5ac5 container client-container: <nil>
STEP: delete the pod
Dec 21 12:46:22.659: INFO: Waiting for pod downwardapi-volume-92c5398b-2794-450a-b9ab-19d0c45e5ac5 to disappear
Dec 21 12:46:22.663: INFO: Pod downwardapi-volume-92c5398b-2794-450a-b9ab-19d0c45e5ac5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:46:22.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5753" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":273,"completed":125,"skipped":2220,"failed":0}
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:46:22.677: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2492
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Dec 21 12:46:22.829: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:46:25.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2492" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":273,"completed":126,"skipped":2223,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:46:25.590: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4801
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:46:26.199: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 12:46:28.214: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151586, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151586, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151586, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151586, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:46:31.229: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:46:31.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4801" for this suite.
STEP: Destroying namespace "webhook-4801-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.001 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":273,"completed":127,"skipped":2263,"failed":0}
SSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:46:31.592: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8180
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 21 12:46:36.304: INFO: Successfully updated pod "adopt-release-rxwpf"
STEP: Checking that the Job readopts the Pod
Dec 21 12:46:36.304: INFO: Waiting up to 15m0s for pod "adopt-release-rxwpf" in namespace "job-8180" to be "adopted"
Dec 21 12:46:36.309: INFO: Pod "adopt-release-rxwpf": Phase="Running", Reason="", readiness=true. Elapsed: 4.982579ms
Dec 21 12:46:38.314: INFO: Pod "adopt-release-rxwpf": Phase="Running", Reason="", readiness=true. Elapsed: 2.009969165s
Dec 21 12:46:38.314: INFO: Pod "adopt-release-rxwpf" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 21 12:46:38.827: INFO: Successfully updated pod "adopt-release-rxwpf"
STEP: Checking that the Job releases the Pod
Dec 21 12:46:38.827: INFO: Waiting up to 15m0s for pod "adopt-release-rxwpf" in namespace "job-8180" to be "released"
Dec 21 12:46:38.831: INFO: Pod "adopt-release-rxwpf": Phase="Running", Reason="", readiness=true. Elapsed: 3.230062ms
Dec 21 12:46:40.836: INFO: Pod "adopt-release-rxwpf": Phase="Running", Reason="", readiness=true. Elapsed: 2.008710058s
Dec 21 12:46:40.836: INFO: Pod "adopt-release-rxwpf" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:46:40.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8180" for this suite.

• [SLOW TEST:9.263 seconds]
[sig-apps] Job
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":273,"completed":128,"skipped":2268,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:46:40.856: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 21 12:46:41.023: INFO: Waiting up to 5m0s for pod "pod-860c4ba6-8566-4f50-89a7-090639cf206b" in namespace "emptydir-9104" to be "Succeeded or Failed"
Dec 21 12:46:41.033: INFO: Pod "pod-860c4ba6-8566-4f50-89a7-090639cf206b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.944552ms
Dec 21 12:46:43.038: INFO: Pod "pod-860c4ba6-8566-4f50-89a7-090639cf206b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014598273s
Dec 21 12:46:45.051: INFO: Pod "pod-860c4ba6-8566-4f50-89a7-090639cf206b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027673611s
STEP: Saw pod success
Dec 21 12:46:45.051: INFO: Pod "pod-860c4ba6-8566-4f50-89a7-090639cf206b" satisfied condition "Succeeded or Failed"
Dec 21 12:46:45.056: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-860c4ba6-8566-4f50-89a7-090639cf206b container test-container: <nil>
STEP: delete the pod
Dec 21 12:46:45.118: INFO: Waiting for pod pod-860c4ba6-8566-4f50-89a7-090639cf206b to disappear
Dec 21 12:46:45.122: INFO: Pod pod-860c4ba6-8566-4f50-89a7-090639cf206b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:46:45.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9104" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":129,"skipped":2289,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:46:45.137: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:46:45.299: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af3d0464-8567-4d3f-b3ad-7384f4c16e8d" in namespace "projected-4651" to be "Succeeded or Failed"
Dec 21 12:46:45.306: INFO: Pod "downwardapi-volume-af3d0464-8567-4d3f-b3ad-7384f4c16e8d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.417941ms
Dec 21 12:46:47.313: INFO: Pod "downwardapi-volume-af3d0464-8567-4d3f-b3ad-7384f4c16e8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0129677s
STEP: Saw pod success
Dec 21 12:46:47.313: INFO: Pod "downwardapi-volume-af3d0464-8567-4d3f-b3ad-7384f4c16e8d" satisfied condition "Succeeded or Failed"
Dec 21 12:46:47.320: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-af3d0464-8567-4d3f-b3ad-7384f4c16e8d container client-container: <nil>
STEP: delete the pod
Dec 21 12:46:47.393: INFO: Waiting for pod downwardapi-volume-af3d0464-8567-4d3f-b3ad-7384f4c16e8d to disappear
Dec 21 12:46:47.398: INFO: Pod downwardapi-volume-af3d0464-8567-4d3f-b3ad-7384f4c16e8d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:46:47.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4651" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":273,"completed":130,"skipped":2337,"failed":0}
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:46:47.417: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5376
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5376
STEP: Creating statefulset with conflicting port in namespace statefulset-5376
STEP: Waiting until pod test-pod will start running in namespace statefulset-5376
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5376
Dec 21 12:46:51.614: INFO: Observed stateful pod in namespace: statefulset-5376, name: ss-0, uid: 5b9e3b96-e1b0-4df0-b42f-41f81f93e210, status phase: Pending. Waiting for statefulset controller to delete.
Dec 21 12:46:51.800: INFO: Observed stateful pod in namespace: statefulset-5376, name: ss-0, uid: 5b9e3b96-e1b0-4df0-b42f-41f81f93e210, status phase: Failed. Waiting for statefulset controller to delete.
Dec 21 12:46:51.808: INFO: Observed stateful pod in namespace: statefulset-5376, name: ss-0, uid: 5b9e3b96-e1b0-4df0-b42f-41f81f93e210, status phase: Failed. Waiting for statefulset controller to delete.
Dec 21 12:46:51.811: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5376
STEP: Removing pod with conflicting port in namespace statefulset-5376
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5376 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 21 12:46:53.842: INFO: Deleting all statefulset in ns statefulset-5376
Dec 21 12:46:53.846: INFO: Scaling statefulset ss to 0
Dec 21 12:47:03.876: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 12:47:03.883: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:03.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5376" for this suite.

• [SLOW TEST:16.509 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":273,"completed":131,"skipped":2338,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:03.926: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 21 12:47:04.110: INFO: Waiting up to 5m0s for pod "downward-api-9addc439-b06a-4130-ad43-afd0d13830ad" in namespace "downward-api-4298" to be "Succeeded or Failed"
Dec 21 12:47:04.117: INFO: Pod "downward-api-9addc439-b06a-4130-ad43-afd0d13830ad": Phase="Pending", Reason="", readiness=false. Elapsed: 6.476138ms
Dec 21 12:47:06.122: INFO: Pod "downward-api-9addc439-b06a-4130-ad43-afd0d13830ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011292821s
STEP: Saw pod success
Dec 21 12:47:06.122: INFO: Pod "downward-api-9addc439-b06a-4130-ad43-afd0d13830ad" satisfied condition "Succeeded or Failed"
Dec 21 12:47:06.126: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downward-api-9addc439-b06a-4130-ad43-afd0d13830ad container dapi-container: <nil>
STEP: delete the pod
Dec 21 12:47:06.151: INFO: Waiting for pod downward-api-9addc439-b06a-4130-ad43-afd0d13830ad to disappear
Dec 21 12:47:06.155: INFO: Pod downward-api-9addc439-b06a-4130-ad43-afd0d13830ad no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:06.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4298" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":273,"completed":132,"skipped":2351,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:06.171: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6902
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 21 12:47:06.330: INFO: Waiting up to 5m0s for pod "pod-c795b039-fe93-4d44-baee-7f3ac075169e" in namespace "emptydir-6902" to be "Succeeded or Failed"
Dec 21 12:47:06.336: INFO: Pod "pod-c795b039-fe93-4d44-baee-7f3ac075169e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.217337ms
Dec 21 12:47:08.341: INFO: Pod "pod-c795b039-fe93-4d44-baee-7f3ac075169e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010671063s
STEP: Saw pod success
Dec 21 12:47:08.341: INFO: Pod "pod-c795b039-fe93-4d44-baee-7f3ac075169e" satisfied condition "Succeeded or Failed"
Dec 21 12:47:08.345: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-c795b039-fe93-4d44-baee-7f3ac075169e container test-container: <nil>
STEP: delete the pod
Dec 21 12:47:08.411: INFO: Waiting for pod pod-c795b039-fe93-4d44-baee-7f3ac075169e to disappear
Dec 21 12:47:08.415: INFO: Pod pod-c795b039-fe93-4d44-baee-7f3ac075169e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:08.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6902" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":133,"skipped":2373,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:08.447: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3299
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:47:08.600: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 21 12:47:08.611: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 21 12:47:13.616: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 21 12:47:13.616: INFO: Creating deployment "test-rolling-update-deployment"
Dec 21 12:47:13.624: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 21 12:47:13.634: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 21 12:47:15.647: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 21 12:47:15.653: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 21 12:47:15.674: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3299 /apis/apps/v1/namespaces/deployment-3299/deployments/test-rolling-update-deployment bc4d0a6b-8158-4c57-9a91-fdcd04a6ef5c 36038913 1 2020-12-21 12:47:13 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-12-21 12:47:13 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-21 12:47:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006b2b9a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-12-21 12:47:13 +0000 UTC,LastTransitionTime:2020-12-21 12:47:13 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-12-21 12:47:15 +0000 UTC,LastTransitionTime:2020-12-21 12:47:13 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 21 12:47:15.678: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-3299 /apis/apps/v1/namespaces/deployment-3299/replicasets/test-rolling-update-deployment-59d5cb45c7 2bd154bc-5718-4959-897c-57c8c87c0e2d 36038903 1 2020-12-21 12:47:13 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment bc4d0a6b-8158-4c57-9a91-fdcd04a6ef5c 0xc006b2bf37 0xc006b2bf38}] []  [{kube-controller-manager Update apps/v1 2020-12-21 12:47:15 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 99 52 100 48 97 54 98 45 56 49 53 56 45 52 99 53 55 45 57 97 57 49 45 102 100 99 100 48 52 97 54 101 102 53 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006b2bfc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 21 12:47:15.678: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 21 12:47:15.678: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3299 /apis/apps/v1/namespaces/deployment-3299/replicasets/test-rolling-update-controller e4c05f5c-2909-4c10-90ad-0ddf73725ac0 36038912 2 2020-12-21 12:47:08 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment bc4d0a6b-8158-4c57-9a91-fdcd04a6ef5c 0xc006b2be27 0xc006b2be28}] []  [{e2e.test Update apps/v1 2020-12-21 12:47:08 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-21 12:47:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 99 52 100 48 97 54 98 45 56 49 53 56 45 52 99 53 55 45 57 97 57 49 45 102 100 99 100 48 52 97 54 101 102 53 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc006b2bec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 12:47:15.683: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-5scdr" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-5scdr test-rolling-update-deployment-59d5cb45c7- deployment-3299 /api/v1/namespaces/deployment-3299/pods/test-rolling-update-deployment-59d5cb45c7-5scdr a8fe53a4-7e01-402b-94f1-a8e2aa312a4b 36038902 0 2020-12-21 12:47:13 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[cni.projectcalico.org/podIP:172.25.3.64/32 cni.projectcalico.org/podIPs:172.25.3.64/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 2bd154bc-5718-4959-897c-57c8c87c0e2d 0xc0069019f7 0xc0069019f8}] []  [{kube-controller-manager Update v1 2020-12-21 12:47:13 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 98 100 49 53 52 98 99 45 53 55 49 56 45 52 57 53 57 45 56 57 55 99 45 53 55 99 56 99 56 55 99 48 101 50 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:47:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:47:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 51 46 54 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mc624,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mc624,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mc624,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:47:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:47:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:47:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:47:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.183.240,PodIP:172.25.3.64,StartTime:2020-12-21 12:47:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:47:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://552cfb921811327941069927df4f9ff78b02db819cd6577e5c9c2d9e256bab8e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.3.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:15.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3299" for this suite.

• [SLOW TEST:7.248 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":273,"completed":134,"skipped":2439,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:15.696: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:17.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7866" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":135,"skipped":2451,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:17.905: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-16
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-16.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-16.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-16.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-16.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-16.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-16.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 12:47:20.359: INFO: DNS probes using dns-16/dns-test-59812280-513d-4333-bdcc-637ed2732873 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:20.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-16" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":273,"completed":136,"skipped":2474,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:20.391: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-902f9d56-5e2a-4cae-9cb6-93d8a1f61040
STEP: Creating a pod to test consume secrets
Dec 21 12:47:20.569: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-661490fa-67bb-4739-a214-513fcfb5f1bb" in namespace "projected-2417" to be "Succeeded or Failed"
Dec 21 12:47:20.575: INFO: Pod "pod-projected-secrets-661490fa-67bb-4739-a214-513fcfb5f1bb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.476389ms
Dec 21 12:47:22.580: INFO: Pod "pod-projected-secrets-661490fa-67bb-4739-a214-513fcfb5f1bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.010652891s
Dec 21 12:47:24.585: INFO: Pod "pod-projected-secrets-661490fa-67bb-4739-a214-513fcfb5f1bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016301883s
STEP: Saw pod success
Dec 21 12:47:24.586: INFO: Pod "pod-projected-secrets-661490fa-67bb-4739-a214-513fcfb5f1bb" satisfied condition "Succeeded or Failed"
Dec 21 12:47:24.589: INFO: Trying to get logs from node ip-172-31-244-13.eu-central-1.compute.internal pod pod-projected-secrets-661490fa-67bb-4739-a214-513fcfb5f1bb container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 12:47:24.663: INFO: Waiting for pod pod-projected-secrets-661490fa-67bb-4739-a214-513fcfb5f1bb to disappear
Dec 21 12:47:24.666: INFO: Pod pod-projected-secrets-661490fa-67bb-4739-a214-513fcfb5f1bb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:24.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2417" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":273,"completed":137,"skipped":2487,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:24.682: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 21 12:47:27.866: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:27.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8090" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":273,"completed":138,"skipped":2512,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:27.895: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6752
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:47:28.682: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:47:31.706: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:44.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6752" for this suite.
STEP: Destroying namespace "webhook-6752-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.606 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":273,"completed":139,"skipped":2517,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:44.501: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:47:44.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-85f4880d-67ea-4f0a-ac75-dbc9ff218087" in namespace "downward-api-9725" to be "Succeeded or Failed"
Dec 21 12:47:44.676: INFO: Pod "downwardapi-volume-85f4880d-67ea-4f0a-ac75-dbc9ff218087": Phase="Pending", Reason="", readiness=false. Elapsed: 14.152256ms
Dec 21 12:47:46.681: INFO: Pod "downwardapi-volume-85f4880d-67ea-4f0a-ac75-dbc9ff218087": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018756036s
STEP: Saw pod success
Dec 21 12:47:46.681: INFO: Pod "downwardapi-volume-85f4880d-67ea-4f0a-ac75-dbc9ff218087" satisfied condition "Succeeded or Failed"
Dec 21 12:47:46.684: INFO: Trying to get logs from node ip-172-31-244-13.eu-central-1.compute.internal pod downwardapi-volume-85f4880d-67ea-4f0a-ac75-dbc9ff218087 container client-container: <nil>
STEP: delete the pod
Dec 21 12:47:46.733: INFO: Waiting for pod downwardapi-volume-85f4880d-67ea-4f0a-ac75-dbc9ff218087 to disappear
Dec 21 12:47:46.737: INFO: Pod downwardapi-volume-85f4880d-67ea-4f0a-ac75-dbc9ff218087 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:46.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9725" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":140,"skipped":2520,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:46.759: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8217
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 21 12:47:46.917: INFO: Waiting up to 5m0s for pod "pod-e7a1c54b-a533-489f-b005-57d3d25b82e3" in namespace "emptydir-8217" to be "Succeeded or Failed"
Dec 21 12:47:46.923: INFO: Pod "pod-e7a1c54b-a533-489f-b005-57d3d25b82e3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.678794ms
Dec 21 12:47:48.928: INFO: Pod "pod-e7a1c54b-a533-489f-b005-57d3d25b82e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010514855s
STEP: Saw pod success
Dec 21 12:47:48.928: INFO: Pod "pod-e7a1c54b-a533-489f-b005-57d3d25b82e3" satisfied condition "Succeeded or Failed"
Dec 21 12:47:48.934: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-e7a1c54b-a533-489f-b005-57d3d25b82e3 container test-container: <nil>
STEP: delete the pod
Dec 21 12:47:48.966: INFO: Waiting for pod pod-e7a1c54b-a533-489f-b005-57d3d25b82e3 to disappear
Dec 21 12:47:48.970: INFO: Pod pod-e7a1c54b-a533-489f-b005-57d3d25b82e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:48.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8217" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":141,"skipped":2530,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:48.983: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4154
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-554cd69d-e466-425c-8cd3-f11cebe78f02
STEP: Creating a pod to test consume configMaps
Dec 21 12:47:49.147: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7131706f-82bf-45a5-86dd-32e92e1e2043" in namespace "projected-4154" to be "Succeeded or Failed"
Dec 21 12:47:49.163: INFO: Pod "pod-projected-configmaps-7131706f-82bf-45a5-86dd-32e92e1e2043": Phase="Pending", Reason="", readiness=false. Elapsed: 15.667744ms
Dec 21 12:47:51.171: INFO: Pod "pod-projected-configmaps-7131706f-82bf-45a5-86dd-32e92e1e2043": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023763584s
STEP: Saw pod success
Dec 21 12:47:51.171: INFO: Pod "pod-projected-configmaps-7131706f-82bf-45a5-86dd-32e92e1e2043" satisfied condition "Succeeded or Failed"
Dec 21 12:47:51.176: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-projected-configmaps-7131706f-82bf-45a5-86dd-32e92e1e2043 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 12:47:51.204: INFO: Waiting for pod pod-projected-configmaps-7131706f-82bf-45a5-86dd-32e92e1e2043 to disappear
Dec 21 12:47:51.210: INFO: Pod pod-projected-configmaps-7131706f-82bf-45a5-86dd-32e92e1e2043 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:51.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4154" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":273,"completed":142,"skipped":2563,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:51.227: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 21 12:47:51.392: INFO: Waiting up to 5m0s for pod "pod-83706d7b-66da-4777-9fd3-1c1596329e0d" in namespace "emptydir-380" to be "Succeeded or Failed"
Dec 21 12:47:51.402: INFO: Pod "pod-83706d7b-66da-4777-9fd3-1c1596329e0d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.381022ms
Dec 21 12:47:53.407: INFO: Pod "pod-83706d7b-66da-4777-9fd3-1c1596329e0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015041162s
Dec 21 12:47:55.411: INFO: Pod "pod-83706d7b-66da-4777-9fd3-1c1596329e0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019465947s
STEP: Saw pod success
Dec 21 12:47:55.412: INFO: Pod "pod-83706d7b-66da-4777-9fd3-1c1596329e0d" satisfied condition "Succeeded or Failed"
Dec 21 12:47:55.415: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-83706d7b-66da-4777-9fd3-1c1596329e0d container test-container: <nil>
STEP: delete the pod
Dec 21 12:47:55.441: INFO: Waiting for pod pod-83706d7b-66da-4777-9fd3-1c1596329e0d to disappear
Dec 21 12:47:55.444: INFO: Pod pod-83706d7b-66da-4777-9fd3-1c1596329e0d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:47:55.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-380" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":143,"skipped":2580,"failed":0}
SSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:47:55.457: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-5424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Dec 21 12:47:55.616: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Dec 21 12:47:55.623: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 21 12:47:55.623: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Dec 21 12:47:55.633: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 21 12:47:55.633: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Dec 21 12:47:55.644: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Dec 21 12:47:55.644: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Dec 21 12:48:02.684: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:02.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-5424" for this suite.

• [SLOW TEST:7.251 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":273,"completed":144,"skipped":2584,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:02.708: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-857
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:04.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-857" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":145,"skipped":2591,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:04.939: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8063
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-75d0f05e-70be-4a6c-ae83-8d3c22b93548
STEP: Creating a pod to test consume configMaps
Dec 21 12:48:05.118: INFO: Waiting up to 5m0s for pod "pod-configmaps-7f9afce1-349c-4a56-ac8a-b5362f1e8bfc" in namespace "configmap-8063" to be "Succeeded or Failed"
Dec 21 12:48:05.124: INFO: Pod "pod-configmaps-7f9afce1-349c-4a56-ac8a-b5362f1e8bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.604195ms
Dec 21 12:48:07.129: INFO: Pod "pod-configmaps-7f9afce1-349c-4a56-ac8a-b5362f1e8bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011528963s
STEP: Saw pod success
Dec 21 12:48:07.129: INFO: Pod "pod-configmaps-7f9afce1-349c-4a56-ac8a-b5362f1e8bfc" satisfied condition "Succeeded or Failed"
Dec 21 12:48:07.133: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-configmaps-7f9afce1-349c-4a56-ac8a-b5362f1e8bfc container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 12:48:07.159: INFO: Waiting for pod pod-configmaps-7f9afce1-349c-4a56-ac8a-b5362f1e8bfc to disappear
Dec 21 12:48:07.163: INFO: Pod pod-configmaps-7f9afce1-349c-4a56-ac8a-b5362f1e8bfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:07.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8063" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":146,"skipped":2624,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:07.176: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Dec 21 12:48:09.399: INFO: Pod pod-hostip-a642322a-256e-4769-8c7e-03aac669684c has hostIP: 172.31.232.239
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:09.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4988" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":273,"completed":147,"skipped":2639,"failed":0}

------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:09.416: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2604
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 21 12:48:09.596: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2604 /api/v1/namespaces/watch-2604/configmaps/e2e-watch-test-resource-version 988bbc54-659a-4579-a826-e522040e02b2 36039683 0 2020-12-21 12:48:09 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-12-21 12:48:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 12:48:09.596: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2604 /api/v1/namespaces/watch-2604/configmaps/e2e-watch-test-resource-version 988bbc54-659a-4579-a826-e522040e02b2 36039684 0 2020-12-21 12:48:09 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-12-21 12:48:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:09.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2604" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":273,"completed":148,"skipped":2639,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:09.612: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6200
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:48:09.771: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:48:11.777: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:13.776: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:15.776: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:17.777: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:19.779: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:21.776: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:23.777: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:25.776: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:27.775: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:29.778: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:31.780: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = false)
Dec 21 12:48:33.776: INFO: The status of Pod test-webserver-89c4c6a6-f804-40e9-95eb-7c5a1bb2a08a is Running (Ready = true)
Dec 21 12:48:33.781: INFO: Container started at 2020-12-21 12:48:11 +0000 UTC, pod became ready at 2020-12-21 12:48:32 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:33.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6200" for this suite.

• [SLOW TEST:24.182 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":273,"completed":149,"skipped":2700,"failed":0}
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:33.794: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3931
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Dec 21 12:48:33.951: INFO: Waiting up to 5m0s for pod "client-containers-3f977b94-070c-4ab9-b241-0f1c609e5090" in namespace "containers-3931" to be "Succeeded or Failed"
Dec 21 12:48:33.955: INFO: Pod "client-containers-3f977b94-070c-4ab9-b241-0f1c609e5090": Phase="Pending", Reason="", readiness=false. Elapsed: 4.6137ms
Dec 21 12:48:35.959: INFO: Pod "client-containers-3f977b94-070c-4ab9-b241-0f1c609e5090": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008806945s
STEP: Saw pod success
Dec 21 12:48:35.959: INFO: Pod "client-containers-3f977b94-070c-4ab9-b241-0f1c609e5090" satisfied condition "Succeeded or Failed"
Dec 21 12:48:35.966: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod client-containers-3f977b94-070c-4ab9-b241-0f1c609e5090 container test-container: <nil>
STEP: delete the pod
Dec 21 12:48:36.027: INFO: Waiting for pod client-containers-3f977b94-070c-4ab9-b241-0f1c609e5090 to disappear
Dec 21 12:48:36.033: INFO: Pod client-containers-3f977b94-070c-4ab9-b241-0f1c609e5090 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:36.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3931" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":273,"completed":150,"skipped":2703,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:36.047: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3260
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 21 12:48:36.209: INFO: Waiting up to 5m0s for pod "pod-216ec77d-65a5-445c-971d-0ae78a18bc1a" in namespace "emptydir-3260" to be "Succeeded or Failed"
Dec 21 12:48:36.216: INFO: Pod "pod-216ec77d-65a5-445c-971d-0ae78a18bc1a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.72271ms
Dec 21 12:48:38.220: INFO: Pod "pod-216ec77d-65a5-445c-971d-0ae78a18bc1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0106992s
STEP: Saw pod success
Dec 21 12:48:38.220: INFO: Pod "pod-216ec77d-65a5-445c-971d-0ae78a18bc1a" satisfied condition "Succeeded or Failed"
Dec 21 12:48:38.224: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-216ec77d-65a5-445c-971d-0ae78a18bc1a container test-container: <nil>
STEP: delete the pod
Dec 21 12:48:38.248: INFO: Waiting for pod pod-216ec77d-65a5-445c-971d-0ae78a18bc1a to disappear
Dec 21 12:48:38.252: INFO: Pod pod-216ec77d-65a5-445c-971d-0ae78a18bc1a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:38.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3260" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":151,"skipped":2710,"failed":0}
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:38.264: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1550
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Dec 21 12:48:38.410: INFO: Waiting up to 5m0s for pod "var-expansion-d1f9971b-f619-4cdb-9227-1802641111fc" in namespace "var-expansion-1550" to be "Succeeded or Failed"
Dec 21 12:48:38.414: INFO: Pod "var-expansion-d1f9971b-f619-4cdb-9227-1802641111fc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.739986ms
Dec 21 12:48:40.423: INFO: Pod "var-expansion-d1f9971b-f619-4cdb-9227-1802641111fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012431425s
STEP: Saw pod success
Dec 21 12:48:40.423: INFO: Pod "var-expansion-d1f9971b-f619-4cdb-9227-1802641111fc" satisfied condition "Succeeded or Failed"
Dec 21 12:48:40.433: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod var-expansion-d1f9971b-f619-4cdb-9227-1802641111fc container dapi-container: <nil>
STEP: delete the pod
Dec 21 12:48:40.537: INFO: Waiting for pod var-expansion-d1f9971b-f619-4cdb-9227-1802641111fc to disappear
Dec 21 12:48:40.544: INFO: Pod var-expansion-d1f9971b-f619-4cdb-9227-1802641111fc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:40.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1550" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":273,"completed":152,"skipped":2715,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:40.558: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Dec 21 12:48:40.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-7516'
Dec 21 12:48:41.033: INFO: stderr: ""
Dec 21 12:48:41.033: INFO: stdout: "pod/pause created\n"
Dec 21 12:48:41.033: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 21 12:48:41.033: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7516" to be "running and ready"
Dec 21 12:48:41.038: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.441593ms
Dec 21 12:48:43.046: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.012384128s
Dec 21 12:48:43.046: INFO: Pod "pause" satisfied condition "running and ready"
Dec 21 12:48:43.046: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 21 12:48:43.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 label pods pause testing-label=testing-label-value --namespace=kubectl-7516'
Dec 21 12:48:43.138: INFO: stderr: ""
Dec 21 12:48:43.138: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 21 12:48:43.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pod pause -L testing-label --namespace=kubectl-7516'
Dec 21 12:48:43.223: INFO: stderr: ""
Dec 21 12:48:43.223: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 21 12:48:43.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 label pods pause testing-label- --namespace=kubectl-7516'
Dec 21 12:48:43.333: INFO: stderr: ""
Dec 21 12:48:43.333: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 21 12:48:43.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pod pause -L testing-label --namespace=kubectl-7516'
Dec 21 12:48:43.428: INFO: stderr: ""
Dec 21 12:48:43.428: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Dec 21 12:48:43.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete --grace-period=0 --force -f - --namespace=kubectl-7516'
Dec 21 12:48:43.519: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 12:48:43.519: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 21 12:48:43.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get rc,svc -l name=pause --no-headers --namespace=kubectl-7516'
Dec 21 12:48:43.612: INFO: stderr: "No resources found in kubectl-7516 namespace.\n"
Dec 21 12:48:43.612: INFO: stdout: ""
Dec 21 12:48:43.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 get pods -l name=pause --namespace=kubectl-7516 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 21 12:48:43.695: INFO: stderr: ""
Dec 21 12:48:43.695: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:48:43.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7516" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":273,"completed":153,"skipped":2756,"failed":0}
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:48:43.709: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7749
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-9pfq
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 12:48:43.877: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9pfq" in namespace "subpath-7749" to be "Succeeded or Failed"
Dec 21 12:48:43.881: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Pending", Reason="", readiness=false. Elapsed: 3.330932ms
Dec 21 12:48:45.885: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 2.008166042s
Dec 21 12:48:47.891: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 4.013249588s
Dec 21 12:48:49.896: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 6.018282772s
Dec 21 12:48:51.900: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 8.023017472s
Dec 21 12:48:53.912: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 10.03495052s
Dec 21 12:48:55.917: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 12.039395676s
Dec 21 12:48:57.926: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 14.048337382s
Dec 21 12:48:59.931: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 16.053301121s
Dec 21 12:49:01.936: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 18.058529376s
Dec 21 12:49:03.950: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Running", Reason="", readiness=true. Elapsed: 20.073192625s
Dec 21 12:49:05.955: INFO: Pod "pod-subpath-test-secret-9pfq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.078070987s
STEP: Saw pod success
Dec 21 12:49:05.955: INFO: Pod "pod-subpath-test-secret-9pfq" satisfied condition "Succeeded or Failed"
Dec 21 12:49:05.959: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-subpath-test-secret-9pfq container test-container-subpath-secret-9pfq: <nil>
STEP: delete the pod
Dec 21 12:49:05.982: INFO: Waiting for pod pod-subpath-test-secret-9pfq to disappear
Dec 21 12:49:05.985: INFO: Pod pod-subpath-test-secret-9pfq no longer exists
STEP: Deleting pod pod-subpath-test-secret-9pfq
Dec 21 12:49:05.985: INFO: Deleting pod "pod-subpath-test-secret-9pfq" in namespace "subpath-7749"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:05.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7749" for this suite.

• [SLOW TEST:22.314 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":273,"completed":154,"skipped":2758,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:06.024: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Dec 21 12:49:06.185: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:10.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2066" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":273,"completed":155,"skipped":2773,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:10.079: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6935
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-ffbd8012-7480-4566-87e3-a7b4a5b6d4e6
STEP: Creating secret with name s-test-opt-upd-34269eb2-f9ba-468d-9ccb-3c84d40826e3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ffbd8012-7480-4566-87e3-a7b4a5b6d4e6
STEP: Updating secret s-test-opt-upd-34269eb2-f9ba-468d-9ccb-3c84d40826e3
STEP: Creating secret with name s-test-opt-create-442bfc41-35e8-4257-b5c9-b197a3d3a89f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:14.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6935" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":156,"skipped":2776,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:14.495: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2217
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:49:14.644: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:20.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2217" for this suite.

• [SLOW TEST:6.471 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":273,"completed":157,"skipped":2793,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:20.967: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1842
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:21.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1842" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":273,"completed":158,"skipped":2839,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:21.160: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4861
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:49:21.960: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:49:24.993: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 21 12:49:25.068: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:25.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4861" for this suite.
STEP: Destroying namespace "webhook-4861-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":273,"completed":159,"skipped":2891,"failed":0}

------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:25.203: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4476
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Dec 21 12:49:25.391: INFO: Created pod &Pod{ObjectMeta:{dns-4476  dns-4476 /api/v1/namespaces/dns-4476/pods/dns-4476 177c924a-8192-4ca6-b6a3-8e26ffc4bc72 36040507 0 2020-12-21 12:49:25 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2020-12-21 12:49:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j2vh9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j2vh9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j2vh9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:49:25.398: INFO: The status of Pod dns-4476 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:49:27.403: INFO: The status of Pod dns-4476 is Pending, waiting for it to be Running (with Ready = true)
Dec 21 12:49:29.403: INFO: The status of Pod dns-4476 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Dec 21 12:49:29.403: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4476 PodName:dns-4476 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:49:29.403: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Verifying customized DNS server is configured on pod...
Dec 21 12:49:29.666: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4476 PodName:dns-4476 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 21 12:49:29.666: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:49:30.495: INFO: Deleting pod dns-4476...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:30.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4476" for this suite.

• [SLOW TEST:5.354 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":273,"completed":160,"skipped":2891,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:30.557: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 21 12:49:34.811: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 12:49:34.815: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 12:49:36.815: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 12:49:36.820: INFO: Pod pod-with-poststart-http-hook still exists
Dec 21 12:49:38.815: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 21 12:49:38.820: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:38.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3909" for this suite.

• [SLOW TEST:8.285 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":273,"completed":161,"skipped":2904,"failed":0}
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:38.842: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7424
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 21 12:49:38.990: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 12:49:39.006: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 12:49:39.010: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-183-240.eu-central-1.compute.internal before test
Dec 21 12:49:39.041: INFO: openvpn-client-56dc45fdbd-pvwz9 from kube-system started at 2020-12-21 11:49:06 +0000 UTC (2 container statuses recorded)
Dec 21 12:49:39.041: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 21 12:49:39.041: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 21 12:49:39.041: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-g9pqh from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:49:39.041: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:49:39.041: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 12:49:39.041: INFO: kube-proxy-2s25g from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.041: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 12:49:39.041: INFO: tiller-deploy-5648ccb4b6-c8nqp from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.041: INFO: 	Container tiller ready: true, restart count 0
Dec 21 12:49:39.041: INFO: user-ssh-keys-agent-282ml from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.041: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 12:49:39.041: INFO: syseleven-node-problem-detector-xwkkt from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.043: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 12:49:39.043: INFO: node-exporter-hjpfq from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.043: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 12:49:39.043: INFO: coredns-854998958f-nm6p2 from kube-system started at 2020-12-21 11:46:38 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.043: INFO: 	Container coredns ready: true, restart count 0
Dec 21 12:49:39.043: INFO: dns-autoscaler-596856b68b-qzt9r from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.043: INFO: 	Container autoscaler ready: true, restart count 0
Dec 21 12:49:39.043: INFO: canal-z66nn from kube-system started at 2020-12-21 11:46:17 +0000 UTC (2 container statuses recorded)
Dec 21 12:49:39.043: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 12:49:39.043: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 12:49:39.043: INFO: node-local-dns-htgfk from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.043: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 12:49:39.043: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-232-239.eu-central-1.compute.internal before test
Dec 21 12:49:39.125: INFO: pod-handle-http-request from container-lifecycle-hook-3909 started at 2020-12-21 12:49:30 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.125: INFO: 	Container pod-handle-http-request ready: true, restart count 0
Dec 21 12:49:39.125: INFO: kube-proxy-wmhd2 from kube-system started at 2020-12-21 11:48:44 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.125: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 12:49:39.125: INFO: user-ssh-keys-agent-4gr8h from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.125: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 12:49:39.125: INFO: syseleven-node-problem-detector-6vfvr from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.125: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 12:49:39.125: INFO: node-local-dns-qpm75 from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.125: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 12:49:39.125: INFO: canal-w4p2b from kube-system started at 2020-12-21 11:48:45 +0000 UTC (2 container statuses recorded)
Dec 21 12:49:39.125: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 12:49:39.125: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 12:49:39.125: INFO: coredns-854998958f-sf9zb from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.125: INFO: 	Container coredns ready: true, restart count 0
Dec 21 12:49:39.125: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-xp6km from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:49:39.125: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:49:39.125: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 12:49:39.125: INFO: node-exporter-8m5jv from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.125: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 12:49:39.125: INFO: cluster-autoscaler-5c8c86777b-9jllr from kube-system started at 2020-12-21 11:52:18 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.126: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 21 12:49:39.126: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-244-13.eu-central-1.compute.internal before test
Dec 21 12:49:39.144: INFO: user-ssh-keys-agent-jx8sl from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.144: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 12:49:39.144: INFO: kube-proxy-rvhxj from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.144: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 12:49:39.145: INFO: sonobuoy from sonobuoy started at 2020-12-21 12:10:49 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.145: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 21 12:49:39.145: INFO: syseleven-node-problem-detector-f6dnk from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.145: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 12:49:39.145: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-8p5kx from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:49:39.145: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 12:49:39.145: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 12:49:39.145: INFO: canal-ljp6n from kube-system started at 2020-12-21 11:51:56 +0000 UTC (2 container statuses recorded)
Dec 21 12:49:39.145: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 12:49:39.145: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 12:49:39.145: INFO: node-exporter-hzvfb from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.145: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 12:49:39.145: INFO: node-local-dns-wqj25 from kube-system started at 2020-12-21 11:51:57 +0000 UTC (1 container statuses recorded)
Dec 21 12:49:39.145: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 12:49:39.145: INFO: sonobuoy-e2e-job-12016c8e6e68444f from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 12:49:39.145: INFO: 	Container e2e ready: true, restart count 0
Dec 21 12:49:39.145: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node ip-172-31-183-240.eu-central-1.compute.internal
STEP: verifying the node has the label node ip-172-31-232-239.eu-central-1.compute.internal
STEP: verifying the node has the label node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod pod-handle-http-request requesting resource cpu=0m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod canal-ljp6n requesting resource cpu=350m on Node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod canal-w4p2b requesting resource cpu=350m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod canal-z66nn requesting resource cpu=350m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod cluster-autoscaler-5c8c86777b-9jllr requesting resource cpu=10m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod coredns-854998958f-nm6p2 requesting resource cpu=100m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod coredns-854998958f-sf9zb requesting resource cpu=100m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod dns-autoscaler-596856b68b-qzt9r requesting resource cpu=20m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod kube-proxy-2s25g requesting resource cpu=75m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod kube-proxy-rvhxj requesting resource cpu=75m on Node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod kube-proxy-wmhd2 requesting resource cpu=75m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod node-exporter-8m5jv requesting resource cpu=3m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod node-exporter-hjpfq requesting resource cpu=3m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod node-exporter-hzvfb requesting resource cpu=3m on Node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod node-local-dns-htgfk requesting resource cpu=50m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod node-local-dns-qpm75 requesting resource cpu=50m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod node-local-dns-wqj25 requesting resource cpu=50m on Node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod openvpn-client-56dc45fdbd-pvwz9 requesting resource cpu=30m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod syseleven-node-problem-detector-6vfvr requesting resource cpu=10m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod syseleven-node-problem-detector-f6dnk requesting resource cpu=10m on Node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod syseleven-node-problem-detector-xwkkt requesting resource cpu=10m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod tiller-deploy-5648ccb4b6-c8nqp requesting resource cpu=0m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod user-ssh-keys-agent-282ml requesting resource cpu=0m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod user-ssh-keys-agent-4gr8h requesting resource cpu=0m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod user-ssh-keys-agent-jx8sl requesting resource cpu=0m on Node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod sonobuoy-e2e-job-12016c8e6e68444f requesting resource cpu=0m on Node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-8p5kx requesting resource cpu=0m on Node ip-172-31-244-13.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-g9pqh requesting resource cpu=0m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.243: INFO: Pod sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-xp6km requesting resource cpu=0m on Node ip-172-31-232-239.eu-central-1.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
Dec 21 12:49:39.243: INFO: Creating a pod which consumes cpu=813m on Node ip-172-31-183-240.eu-central-1.compute.internal
Dec 21 12:49:39.256: INFO: Creating a pod which consumes cpu=841m on Node ip-172-31-232-239.eu-central-1.compute.internal
Dec 21 12:49:39.263: INFO: Creating a pod which consumes cpu=918m on Node ip-172-31-244-13.eu-central-1.compute.internal
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-146cee28-9d9a-4625-b6b0-8caf19a09437.1652bc3b2dd01f8b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7424/filler-pod-146cee28-9d9a-4625-b6b0-8caf19a09437 to ip-172-31-244-13.eu-central-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-146cee28-9d9a-4625-b6b0-8caf19a09437.1652bc3b678659d7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-146cee28-9d9a-4625-b6b0-8caf19a09437.1652bc3b6a6789b5], Reason = [Created], Message = [Created container filler-pod-146cee28-9d9a-4625-b6b0-8caf19a09437]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-146cee28-9d9a-4625-b6b0-8caf19a09437.1652bc3b73794d77], Reason = [Started], Message = [Started container filler-pod-146cee28-9d9a-4625-b6b0-8caf19a09437]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-67a5451b-5ba4-48c5-818f-d5280f4d2c39.1652bc3b2deb3a65], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7424/filler-pod-67a5451b-5ba4-48c5-818f-d5280f4d2c39 to ip-172-31-183-240.eu-central-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-67a5451b-5ba4-48c5-818f-d5280f4d2c39.1652bc3b5da8c9d8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-67a5451b-5ba4-48c5-818f-d5280f4d2c39.1652bc3b60031aec], Reason = [Created], Message = [Created container filler-pod-67a5451b-5ba4-48c5-818f-d5280f4d2c39]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-67a5451b-5ba4-48c5-818f-d5280f4d2c39.1652bc3b67fc0adb], Reason = [Started], Message = [Started container filler-pod-67a5451b-5ba4-48c5-818f-d5280f4d2c39]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b68c2c26-5b5c-4ce7-aa0a-3bc6e08dd5ed.1652bc3b2d6f04c5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7424/filler-pod-b68c2c26-5b5c-4ce7-aa0a-3bc6e08dd5ed to ip-172-31-232-239.eu-central-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b68c2c26-5b5c-4ce7-aa0a-3bc6e08dd5ed.1652bc3b6128c40d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b68c2c26-5b5c-4ce7-aa0a-3bc6e08dd5ed.1652bc3b64a579d5], Reason = [Created], Message = [Created container filler-pod-b68c2c26-5b5c-4ce7-aa0a-3bc6e08dd5ed]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b68c2c26-5b5c-4ce7-aa0a-3bc6e08dd5ed.1652bc3b6f568fe4], Reason = [Started], Message = [Started container filler-pod-b68c2c26-5b5c-4ce7-aa0a-3bc6e08dd5ed]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1652bc3ba8229530], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1652bc3ba8b88112], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node ip-172-31-183-240.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-232-239.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-244-13.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:42.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7424" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":273,"completed":162,"skipped":2904,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:42.424: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-66
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-14d9fc34-54ee-4781-8126-8ed8ee75cb67
STEP: Creating a pod to test consume configMaps
Dec 21 12:49:42.588: INFO: Waiting up to 5m0s for pod "pod-configmaps-6a5ed763-87e4-486b-a9b8-bd064d218df2" in namespace "configmap-66" to be "Succeeded or Failed"
Dec 21 12:49:42.592: INFO: Pod "pod-configmaps-6a5ed763-87e4-486b-a9b8-bd064d218df2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.849106ms
Dec 21 12:49:44.596: INFO: Pod "pod-configmaps-6a5ed763-87e4-486b-a9b8-bd064d218df2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00842003s
STEP: Saw pod success
Dec 21 12:49:44.596: INFO: Pod "pod-configmaps-6a5ed763-87e4-486b-a9b8-bd064d218df2" satisfied condition "Succeeded or Failed"
Dec 21 12:49:44.600: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-configmaps-6a5ed763-87e4-486b-a9b8-bd064d218df2 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 12:49:44.630: INFO: Waiting for pod pod-configmaps-6a5ed763-87e4-486b-a9b8-bd064d218df2 to disappear
Dec 21 12:49:44.633: INFO: Pod pod-configmaps-6a5ed763-87e4-486b-a9b8-bd064d218df2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:49:44.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-66" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":273,"completed":163,"skipped":2911,"failed":0}
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:49:44.644: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2388
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-2388
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-2388
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2388
Dec 21 12:49:44.805: INFO: Found 0 stateful pods, waiting for 1
Dec 21 12:49:54.811: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 21 12:49:54.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-2388 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 12:49:55.695: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 12:49:55.695: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 12:49:55.695: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 12:49:55.699: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 21 12:50:05.704: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 12:50:05.704: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 12:50:05.747: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec 21 12:50:05.748: INFO: ss-0  ip-172-31-244-13.eu-central-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:44 +0000 UTC  }]
Dec 21 12:50:05.748: INFO: 
Dec 21 12:50:05.748: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 21 12:50:06.754: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988963929s
Dec 21 12:50:07.763: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982908783s
Dec 21 12:50:08.770: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.97353517s
Dec 21 12:50:09.776: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.966385726s
Dec 21 12:50:10.781: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.960912105s
Dec 21 12:50:11.788: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.956170101s
Dec 21 12:50:12.793: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.949125075s
Dec 21 12:50:13.799: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.943399801s
Dec 21 12:50:14.804: INFO: Verifying statefulset ss doesn't scale past 3 for another 938.060953ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2388
Dec 21 12:50:15.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-2388 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 12:50:16.345: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 12:50:16.345: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 12:50:16.345: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 12:50:16.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-2388 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 12:50:16.844: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 21 12:50:16.844: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 12:50:16.844: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 12:50:16.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-2388 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 12:50:17.271: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 21 12:50:17.271: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 12:50:17.271: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 12:50:17.276: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 12:50:17.276: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 12:50:17.276: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 21 12:50:17.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-2388 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 12:50:17.673: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 12:50:17.673: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 12:50:17.673: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 12:50:17.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-2388 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 12:50:18.179: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 12:50:18.179: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 12:50:18.179: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 12:50:18.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-2388 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 12:50:18.575: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 12:50:18.575: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 12:50:18.575: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 12:50:18.575: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 12:50:18.579: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 21 12:50:28.589: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 12:50:28.589: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 12:50:28.589: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 21 12:50:28.602: INFO: POD   NODE                                             PHASE    GRACE  CONDITIONS
Dec 21 12:50:28.602: INFO: ss-0  ip-172-31-244-13.eu-central-1.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:44 +0000 UTC  }]
Dec 21 12:50:28.602: INFO: ss-1  ip-172-31-232-239.eu-central-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:28.602: INFO: ss-2  ip-172-31-183-240.eu-central-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:28.602: INFO: 
Dec 21 12:50:28.602: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 21 12:50:29.607: INFO: POD   NODE                                             PHASE    GRACE  CONDITIONS
Dec 21 12:50:29.607: INFO: ss-0  ip-172-31-244-13.eu-central-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:44 +0000 UTC  }]
Dec 21 12:50:29.607: INFO: ss-1  ip-172-31-232-239.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:29.607: INFO: ss-2  ip-172-31-183-240.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:29.607: INFO: 
Dec 21 12:50:29.607: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 21 12:50:30.613: INFO: POD   NODE                                             PHASE    GRACE  CONDITIONS
Dec 21 12:50:30.613: INFO: ss-0  ip-172-31-244-13.eu-central-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:49:44 +0000 UTC  }]
Dec 21 12:50:30.613: INFO: ss-1  ip-172-31-232-239.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:30.613: INFO: ss-2  ip-172-31-183-240.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:30.613: INFO: 
Dec 21 12:50:30.613: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 21 12:50:31.618: INFO: POD   NODE                                             PHASE    GRACE  CONDITIONS
Dec 21 12:50:31.618: INFO: ss-1  ip-172-31-232-239.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:31.618: INFO: ss-2  ip-172-31-183-240.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:31.618: INFO: 
Dec 21 12:50:31.618: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 21 12:50:32.623: INFO: POD   NODE                                             PHASE    GRACE  CONDITIONS
Dec 21 12:50:32.623: INFO: ss-1  ip-172-31-232-239.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:32.623: INFO: ss-2  ip-172-31-183-240.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:32.623: INFO: 
Dec 21 12:50:32.623: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 21 12:50:33.629: INFO: POD   NODE                                             PHASE    GRACE  CONDITIONS
Dec 21 12:50:33.629: INFO: ss-1  ip-172-31-232-239.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:33.629: INFO: ss-2  ip-172-31-183-240.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:33.629: INFO: 
Dec 21 12:50:33.629: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 21 12:50:34.633: INFO: POD   NODE                                             PHASE    GRACE  CONDITIONS
Dec 21 12:50:34.633: INFO: ss-1  ip-172-31-232-239.eu-central-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:34.634: INFO: ss-2  ip-172-31-183-240.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:34.634: INFO: 
Dec 21 12:50:34.634: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 21 12:50:35.638: INFO: POD   NODE                                             PHASE    GRACE  CONDITIONS
Dec 21 12:50:35.638: INFO: ss-2  ip-172-31-183-240.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:35.638: INFO: 
Dec 21 12:50:35.638: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 21 12:50:36.643: INFO: POD   NODE                                             PHASE    GRACE  CONDITIONS
Dec 21 12:50:36.643: INFO: ss-2  ip-172-31-183-240.eu-central-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:19 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-21 12:50:05 +0000 UTC  }]
Dec 21 12:50:36.643: INFO: 
Dec 21 12:50:36.643: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 21 12:50:37.648: INFO: Verifying statefulset ss doesn't scale past 0 for another 954.658432ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2388
Dec 21 12:50:38.663: INFO: Scaling statefulset ss to 0
Dec 21 12:50:38.683: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 21 12:50:38.689: INFO: Deleting all statefulset in ns statefulset-2388
Dec 21 12:50:38.715: INFO: Scaling statefulset ss to 0
Dec 21 12:50:38.769: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 12:50:38.783: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:50:38.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2388" for this suite.

• [SLOW TEST:54.235 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":273,"completed":164,"skipped":2912,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:50:38.882: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4770
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 21 12:50:39.157: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
Dec 21 12:50:43.274: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:50:55.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4770" for this suite.

• [SLOW TEST:16.855 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":273,"completed":165,"skipped":2922,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:50:55.737: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4532
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 21 12:50:55.964: INFO: Waiting up to 5m0s for pod "pod-5fe9c527-21d9-48d0-b3b8-e408bee0853e" in namespace "emptydir-4532" to be "Succeeded or Failed"
Dec 21 12:50:55.968: INFO: Pod "pod-5fe9c527-21d9-48d0-b3b8-e408bee0853e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.547603ms
Dec 21 12:50:57.972: INFO: Pod "pod-5fe9c527-21d9-48d0-b3b8-e408bee0853e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007599197s
Dec 21 12:50:59.983: INFO: Pod "pod-5fe9c527-21d9-48d0-b3b8-e408bee0853e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018485612s
STEP: Saw pod success
Dec 21 12:50:59.983: INFO: Pod "pod-5fe9c527-21d9-48d0-b3b8-e408bee0853e" satisfied condition "Succeeded or Failed"
Dec 21 12:50:59.987: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-5fe9c527-21d9-48d0-b3b8-e408bee0853e container test-container: <nil>
STEP: delete the pod
Dec 21 12:51:00.059: INFO: Waiting for pod pod-5fe9c527-21d9-48d0-b3b8-e408bee0853e to disappear
Dec 21 12:51:00.066: INFO: Pod pod-5fe9c527-21d9-48d0-b3b8-e408bee0853e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:51:00.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4532" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":166,"skipped":2941,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:51:00.092: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6695
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:51:16.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6695" for this suite.

• [SLOW TEST:16.300 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":273,"completed":167,"skipped":2946,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:51:16.393: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8227
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 21 12:51:16.559: INFO: Waiting up to 5m0s for pod "pod-046a221c-acdd-426e-88ab-49d1cb8e7f40" in namespace "emptydir-8227" to be "Succeeded or Failed"
Dec 21 12:51:16.570: INFO: Pod "pod-046a221c-acdd-426e-88ab-49d1cb8e7f40": Phase="Pending", Reason="", readiness=false. Elapsed: 11.907258ms
Dec 21 12:51:18.575: INFO: Pod "pod-046a221c-acdd-426e-88ab-49d1cb8e7f40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016709819s
STEP: Saw pod success
Dec 21 12:51:18.575: INFO: Pod "pod-046a221c-acdd-426e-88ab-49d1cb8e7f40" satisfied condition "Succeeded or Failed"
Dec 21 12:51:18.580: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-046a221c-acdd-426e-88ab-49d1cb8e7f40 container test-container: <nil>
STEP: delete the pod
Dec 21 12:51:18.657: INFO: Waiting for pod pod-046a221c-acdd-426e-88ab-49d1cb8e7f40 to disappear
Dec 21 12:51:18.661: INFO: Pod pod-046a221c-acdd-426e-88ab-49d1cb8e7f40 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:51:18.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8227" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":168,"skipped":3025,"failed":0}

------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:51:18.677: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6362
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 21 12:51:18.850: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 21 12:51:23.855: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:51:23.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6362" for this suite.

• [SLOW TEST:5.216 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":273,"completed":169,"skipped":3025,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:51:23.894: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9827
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:51:24.072: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe0414d0-661e-46c4-9b0a-1074a9f3aae4" in namespace "projected-9827" to be "Succeeded or Failed"
Dec 21 12:51:24.077: INFO: Pod "downwardapi-volume-fe0414d0-661e-46c4-9b0a-1074a9f3aae4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.568021ms
Dec 21 12:51:26.092: INFO: Pod "downwardapi-volume-fe0414d0-661e-46c4-9b0a-1074a9f3aae4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020016562s
STEP: Saw pod success
Dec 21 12:51:26.092: INFO: Pod "downwardapi-volume-fe0414d0-661e-46c4-9b0a-1074a9f3aae4" satisfied condition "Succeeded or Failed"
Dec 21 12:51:26.102: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-fe0414d0-661e-46c4-9b0a-1074a9f3aae4 container client-container: <nil>
STEP: delete the pod
Dec 21 12:51:26.146: INFO: Waiting for pod downwardapi-volume-fe0414d0-661e-46c4-9b0a-1074a9f3aae4 to disappear
Dec 21 12:51:26.154: INFO: Pod downwardapi-volume-fe0414d0-661e-46c4-9b0a-1074a9f3aae4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:51:26.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9827" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":273,"completed":170,"skipped":3029,"failed":0}

------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:51:26.193: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8933
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8933.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8933.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8933.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8933.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8933.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8933.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8933.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8933.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8933.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8933.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 12:51:30.522: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local from pod dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5: the server could not find the requested resource (get pods dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5)
Dec 21 12:51:30.529: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local from pod dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5: the server could not find the requested resource (get pods dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5)
Dec 21 12:51:30.574: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8933.svc.cluster.local from pod dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5: the server could not find the requested resource (get pods dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5)
Dec 21 12:51:30.620: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8933.svc.cluster.local from pod dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5: the server could not find the requested resource (get pods dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5)
Dec 21 12:51:30.720: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local from pod dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5: the server could not find the requested resource (get pods dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5)
Dec 21 12:51:30.726: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local from pod dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5: the server could not find the requested resource (get pods dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5)
Dec 21 12:51:30.738: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8933.svc.cluster.local from pod dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5: the server could not find the requested resource (get pods dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5)
Dec 21 12:51:30.747: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8933.svc.cluster.local from pod dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5: the server could not find the requested resource (get pods dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5)
Dec 21 12:51:30.849: INFO: Lookups using dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8933.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8933.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8933.svc.cluster.local jessie_udp@dns-test-service-2.dns-8933.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8933.svc.cluster.local]

Dec 21 12:51:36.237: INFO: DNS probes using dns-8933/dns-test-8d9d06a5-1543-4097-ad82-eb710366ecc5 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:51:36.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8933" for this suite.

• [SLOW TEST:10.127 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":273,"completed":171,"skipped":3029,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:51:36.322: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-259
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:51:36.520: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:51:38.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-259" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":273,"completed":172,"skipped":3085,"failed":0}
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:51:38.870: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6418
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:51:39.074: INFO: Creating deployment "webserver-deployment"
Dec 21 12:51:39.087: INFO: Waiting for observed generation 1
Dec 21 12:51:41.097: INFO: Waiting for all required pods to come up
Dec 21 12:51:41.103: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 21 12:51:43.121: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 21 12:51:43.131: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 21 12:51:43.147: INFO: Updating deployment webserver-deployment
Dec 21 12:51:43.147: INFO: Waiting for observed generation 2
Dec 21 12:51:45.157: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 21 12:51:45.161: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 21 12:51:45.165: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 21 12:51:45.177: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 21 12:51:45.177: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 21 12:51:45.181: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 21 12:51:45.191: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 21 12:51:45.191: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 21 12:51:45.204: INFO: Updating deployment webserver-deployment
Dec 21 12:51:45.204: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 21 12:51:45.212: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 21 12:51:45.218: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 21 12:51:45.248: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6418 /apis/apps/v1/namespaces/deployment-6418/deployments/webserver-deployment 83c2fc9c-bc4d-4c0b-b853-d347e017e6f6 36042083 3 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a81288 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-12-21 12:51:43 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-12-21 12:51:45 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 21 12:51:45.268: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-6418 /apis/apps/v1/namespaces/deployment-6418/replicasets/webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 36042081 3 2020-12-21 12:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 83c2fc9c-bc4d-4c0b-b853-d347e017e6f6 0xc003a81a17 0xc003a81a18}] []  [{kube-controller-manager Update apps/v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 51 99 50 102 99 57 99 45 98 99 52 100 45 52 99 48 98 45 98 56 53 51 45 100 51 52 55 101 48 49 55 101 54 102 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a81ab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 12:51:45.268: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 21 12:51:45.291: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-6418 /apis/apps/v1/namespaces/deployment-6418/replicasets/webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 36042078 3 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 83c2fc9c-bc4d-4c0b-b853-d347e017e6f6 0xc003a81b27 0xc003a81b28}] []  [{kube-controller-manager Update apps/v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 51 99 50 102 99 57 99 45 98 99 52 100 45 52 99 48 98 45 98 56 53 51 45 100 51 52 55 101 48 49 55 101 54 102 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a81c48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 21 12:51:45.308: INFO: Pod "webserver-deployment-6676bcd6d4-27clk" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-27clk webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-27clk 87cb92b0-cdff-499c-9568-f6084073a04b 36042066 0 2020-12-21 12:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:172.25.5.45/32 cni.projectcalico.org/podIPs:172.25.5.45/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406e367 0xc00406e368}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.244.13,PodIP:,StartTime:2020-12-21 12:51:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.308: INFO: Pod "webserver-deployment-6676bcd6d4-2czqt" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-2czqt webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-2czqt 4a4a2b3a-bd70-42e6-84db-91f9981c163c 36042092 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406e5c7 0xc00406e5c8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.317: INFO: Pod "webserver-deployment-6676bcd6d4-4x8p9" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-4x8p9 webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-4x8p9 0515e2fd-a0bd-405d-b855-4ed99aa85ff6 36042139 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406e7d7 0xc00406e7d8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.318: INFO: Pod "webserver-deployment-6676bcd6d4-9vk2j" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-9vk2j webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-9vk2j ad9602a2-3ad6-4537-9be0-46532836bd4d 36042130 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406e927 0xc00406e928}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.319: INFO: Pod "webserver-deployment-6676bcd6d4-bqkr8" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-bqkr8 webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-bqkr8 436afc2d-227f-49a1-afc9-3ddfffac60a0 36042054 0 2020-12-21 12:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:172.25.4.137/32 cni.projectcalico.org/podIPs:172.25.4.137/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406ebd7 0xc00406ebd8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.232.239,PodIP:,StartTime:2020-12-21 12:51:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.319: INFO: Pod "webserver-deployment-6676bcd6d4-dv4xw" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-dv4xw webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-dv4xw a614d7be-d62c-4071-a890-a1a111dbe14d 36042068 0 2020-12-21 12:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:172.25.3.81/32 cni.projectcalico.org/podIPs:172.25.3.81/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406ee37 0xc00406ee38}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.183.240,PodIP:,StartTime:2020-12-21 12:51:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.319: INFO: Pod "webserver-deployment-6676bcd6d4-dxf58" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-dxf58 webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-dxf58 90bc866e-bbfc-41d3-8633-b1eb35265b36 36042070 0 2020-12-21 12:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:172.25.3.82/32 cni.projectcalico.org/podIPs:172.25.3.82/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406f027 0xc00406f028}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.183.240,PodIP:,StartTime:2020-12-21 12:51:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.321: INFO: Pod "webserver-deployment-6676bcd6d4-frtmp" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-frtmp webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-frtmp d41c8381-6226-4680-9051-5fcf7c47cf35 36042109 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406f2e7 0xc00406f2e8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.321: INFO: Pod "webserver-deployment-6676bcd6d4-g6sf5" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-g6sf5 webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-g6sf5 10ddc512-ab6d-4089-b457-172eea283a09 36042135 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406f477 0xc00406f478}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.322: INFO: Pod "webserver-deployment-6676bcd6d4-h2gjt" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-h2gjt webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-h2gjt fe6a1853-adb1-4dd3-9204-3e2d1db2cfc7 36042141 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406f5e7 0xc00406f5e8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.322: INFO: Pod "webserver-deployment-6676bcd6d4-tv6h2" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-tv6h2 webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-tv6h2 f6e07631-03ec-4f70-94e9-296a8367a8b4 36042104 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406f767 0xc00406f768}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.322: INFO: Pod "webserver-deployment-6676bcd6d4-vlmkn" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-vlmkn webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-vlmkn ed991d3c-29ff-4be7-ad5c-cc2808d97869 36042065 0 2020-12-21 12:51:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[cni.projectcalico.org/podIP:172.25.5.44/32 cni.projectcalico.org/podIPs:172.25.5.44/32] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406f8f7 0xc00406f8f8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:43 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.244.13,PodIP:,StartTime:2020-12-21 12:51:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.323: INFO: Pod "webserver-deployment-6676bcd6d4-vwzzt" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-vwzzt webserver-deployment-6676bcd6d4- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-6676bcd6d4-vwzzt ca1189c2-949b-4977-8717-1601d11b5bc3 36042124 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 32963281-bcf7-404a-a279-97f17d16b6a8 0xc00406faf7 0xc00406faf8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 50 57 54 51 50 56 49 45 98 99 102 55 45 52 48 52 97 45 97 50 55 57 45 57 55 102 49 55 100 49 54 98 54 97 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.323: INFO: Pod "webserver-deployment-84855cf797-2f8fw" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-2f8fw webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-2f8fw b2bb0684-d13d-40e2-b0f0-c72dfcb05941 36041971 0 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.3.77/32 cni.projectcalico.org/podIPs:172.25.3.77/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc00406fc67 0xc00406fc68}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:39 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 51 46 55 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.183.240,PodIP:172.25.3.77,StartTime:2020-12-21 12:51:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:51:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://644a7a9e9bc169a074744e2bb57328507aa8e44d4ec475cadfb566b235174835,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.3.77,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.323: INFO: Pod "webserver-deployment-84855cf797-5nv5v" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-5nv5v webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-5nv5v 1c1be503-ab8a-412d-bd65-8d9fccfb04f2 36042131 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc00406fe67 0xc00406fe68}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.324: INFO: Pod "webserver-deployment-84855cf797-6gc2f" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6gc2f webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-6gc2f 17de42c8-d50f-4297-85c4-91a3221cb417 36041951 0 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.5.42/32 cni.projectcalico.org/podIPs:172.25.5.42/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040ca037 0xc0040ca038}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:39 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 53 46 52 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.244.13,PodIP:172.25.5.42,StartTime:2020-12-21 12:51:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:51:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5ae32f075482a8f1c48c761a749872001b4c3bc7edd51d971c41ff527c399a2f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.5.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.324: INFO: Pod "webserver-deployment-84855cf797-6sp8c" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6sp8c webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-6sp8c c8d190d6-9f4b-449d-acdc-f73f87801ad0 36042132 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040ca367 0xc0040ca368}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.324: INFO: Pod "webserver-deployment-84855cf797-8gkhj" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-8gkhj webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-8gkhj 82b26d32-e404-4db2-adf2-cc8ec28cb5b7 36041939 0 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.4.134/32 cni.projectcalico.org/podIPs:172.25.4.134/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040ca4f7 0xc0040ca4f8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:39 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 52 46 49 51 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.232.239,PodIP:172.25.4.134,StartTime:2020-12-21 12:51:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:51:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://02a9d2143f3f807a23469a1d9c6524230c6a9570c12e281e1b89468f18e316c4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.4.134,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.325: INFO: Pod "webserver-deployment-84855cf797-9hl5l" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9hl5l webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-9hl5l ca706351-29f6-4b24-a30a-fce507b2c888 36041936 0 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.4.136/32 cni.projectcalico.org/podIPs:172.25.4.136/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040ca777 0xc0040ca778}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:39 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 52 46 49 51 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.232.239,PodIP:172.25.4.136,StartTime:2020-12-21 12:51:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:51:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://caaea5f142e50efcf6b7e9e55e93fc1d53e80f9be13386d9a486b6f6e582d4b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.4.136,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.330: INFO: Pod "webserver-deployment-84855cf797-9nmhq" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9nmhq webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-9nmhq ab616cbd-5ba5-4e8c-a7c7-65091b91c5c2 36042111 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040ca947 0xc0040ca948}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.183.240,PodIP:,StartTime:2020-12-21 12:51:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.330: INFO: Pod "webserver-deployment-84855cf797-b88kv" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-b88kv webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-b88kv fc78c484-597f-44b8-9300-f3030b4165cc 36042107 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040caac7 0xc0040caac8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.331: INFO: Pod "webserver-deployment-84855cf797-cbv7w" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-cbv7w webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-cbv7w 2ce7d26a-8d53-43a1-92dc-8d6e559f5de6 36042138 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040cad07 0xc0040cad08}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.331: INFO: Pod "webserver-deployment-84855cf797-h6trw" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-h6trw webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-h6trw e372e285-60f8-4871-9ec1-a8d876e80f45 36041942 0 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.4.135/32 cni.projectcalico.org/podIPs:172.25.4.135/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040caec7 0xc0040caec8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:39 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 52 46 49 51 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.232.239,PodIP:172.25.4.135,StartTime:2020-12-21 12:51:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:51:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://c03939fbce2faabcc66a201df9a18075f4f976af4eaaf34dee9eedef047851a6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.4.135,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.331: INFO: Pod "webserver-deployment-84855cf797-hfc9c" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-hfc9c webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-hfc9c 20969a19-c71d-46d5-9ab4-7df5ced148a3 36042091 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040cb147 0xc0040cb148}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.331: INFO: Pod "webserver-deployment-84855cf797-hpncm" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-hpncm webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-hpncm 587b8cb6-5c65-4183-86b3-0ccc434fac33 36042136 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040cb327 0xc0040cb328}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.244.13,PodIP:,StartTime:2020-12-21 12:51:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.332: INFO: Pod "webserver-deployment-84855cf797-kbz7f" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-kbz7f webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-kbz7f 51f6ce01-9b76-4872-b5cb-61e70635dc38 36041976 0 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.3.79/32 cni.projectcalico.org/podIPs:172.25.3.79/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040cb567 0xc0040cb568}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:39 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 51 46 55 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.183.240,PodIP:172.25.3.79,StartTime:2020-12-21 12:51:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:51:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://350394299cba56f529adceb8826e4f5e7563400ff90e1e5fc76cafd3a61545b4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.3.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.332: INFO: Pod "webserver-deployment-84855cf797-p6w9n" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-p6w9n webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-p6w9n c24dc63a-1311-4bff-9ebe-f463a264b6ae 36041957 0 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.5.41/32 cni.projectcalico.org/podIPs:172.25.5.41/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040cb807 0xc0040cb808}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:39 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 53 46 52 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.244.13,PodIP:172.25.5.41,StartTime:2020-12-21 12:51:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:51:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://655d7e2ef3aef0c452674b9eb22ee64203ab31fbb652e48e355f85604863fe6b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.5.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.332: INFO: Pod "webserver-deployment-84855cf797-srhjp" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-srhjp webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-srhjp c6b6366e-43ef-4dfd-93df-092ce24f30f0 36042103 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040cbb47 0xc0040cbb48}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.332: INFO: Pod "webserver-deployment-84855cf797-t7f9p" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-t7f9p webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-t7f9p 0673a7c5-8971-45dc-865a-d22d7c99d027 36042140 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040cbc97 0xc0040cbc98}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.232.239,PodIP:,StartTime:2020-12-21 12:51:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.333: INFO: Pod "webserver-deployment-84855cf797-w522d" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-w522d webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-w522d a35429b7-3eb5-462d-8642-fa868b563f4c 36041962 0 2020-12-21 12:51:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.5.43/32 cni.projectcalico.org/podIPs:172.25.5.43/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040cbea7 0xc0040cbea8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:39 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-21 12:51:40 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-21 12:51:41 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 53 46 52 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.244.13,PodIP:172.25.5.43,StartTime:2020-12-21 12:51:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 12:51:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://7721b49fef06b8f6e8f5900979b115f256cd6c5217f78de016eeaff74203f7f7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.5.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.333: INFO: Pod "webserver-deployment-84855cf797-z6w52" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-z6w52 webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-z6w52 8b783667-1c9b-4010-b839-da05727d2f99 36042126 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040ec137 0xc0040ec138}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.333: INFO: Pod "webserver-deployment-84855cf797-zcxdl" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-zcxdl webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-zcxdl 148f7217-bfe0-4539-8a8e-00f56ed0e08c 36042133 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040ec337 0xc0040ec338}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-183-240.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 21 12:51:45.333: INFO: Pod "webserver-deployment-84855cf797-zfj79" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-zfj79 webserver-deployment-84855cf797- deployment-6418 /api/v1/namespaces/deployment-6418/pods/webserver-deployment-84855cf797-zfj79 b3915ddb-b3a7-468e-be2e-fa132da660bd 36042105 0 2020-12-21 12:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 3128b549-04c6-4804-9378-57ee5805253c 0xc0040ec4a7 0xc0040ec4a8}] []  [{kube-controller-manager Update v1 2020-12-21 12:51:45 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 50 56 98 53 52 57 45 48 52 99 54 45 52 56 48 52 45 57 51 55 56 45 53 55 101 101 53 56 48 53 50 53 51 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm55,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm55,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm55,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:51:45.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6418" for this suite.

• [SLOW TEST:6.481 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":273,"completed":173,"skipped":3087,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:51:45.356: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5331
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5331.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5331.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5331.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5331.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 12:51:51.687: INFO: DNS probes using dns-test-6b20acfb-e492-444d-89a5-04fa06149864 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5331.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5331.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5331.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5331.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 12:51:57.863: INFO: DNS probes using dns-test-3c7231c7-aa3d-40a6-a464-8ff51c934bc5 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5331.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-5331.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5331.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-5331.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 12:52:02.033: INFO: DNS probes using dns-test-53e45ae8-7543-4d08-90b2-a796fa1cc6b7 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:52:02.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5331" for this suite.

• [SLOW TEST:16.752 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":273,"completed":174,"skipped":3124,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:52:02.109: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-248
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:52:03.167: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 12:52:05.180: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151923, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151923, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151923, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744151923, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:52:08.201: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:52:08.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-248" for this suite.
STEP: Destroying namespace "webhook-248-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.468 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":273,"completed":175,"skipped":3127,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:52:08.579: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:52:19.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8633" for this suite.

• [SLOW TEST:11.226 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":273,"completed":176,"skipped":3132,"failed":0}
S
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:52:19.805: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-6278
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:52:20.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-6278" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":273,"completed":177,"skipped":3133,"failed":0}
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:52:20.126: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:52:24.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5664" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":273,"completed":178,"skipped":3134,"failed":0}
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:52:24.326: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Dec 21 12:52:24.496: INFO: Waiting up to 5m0s for pod "client-containers-e636afce-bf78-4dff-9cc2-d007cc5b9e31" in namespace "containers-792" to be "Succeeded or Failed"
Dec 21 12:52:24.502: INFO: Pod "client-containers-e636afce-bf78-4dff-9cc2-d007cc5b9e31": Phase="Pending", Reason="", readiness=false. Elapsed: 5.489693ms
Dec 21 12:52:26.513: INFO: Pod "client-containers-e636afce-bf78-4dff-9cc2-d007cc5b9e31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016655056s
STEP: Saw pod success
Dec 21 12:52:26.514: INFO: Pod "client-containers-e636afce-bf78-4dff-9cc2-d007cc5b9e31" satisfied condition "Succeeded or Failed"
Dec 21 12:52:26.518: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod client-containers-e636afce-bf78-4dff-9cc2-d007cc5b9e31 container test-container: <nil>
STEP: delete the pod
Dec 21 12:52:26.549: INFO: Waiting for pod client-containers-e636afce-bf78-4dff-9cc2-d007cc5b9e31 to disappear
Dec 21 12:52:26.554: INFO: Pod client-containers-e636afce-bf78-4dff-9cc2-d007cc5b9e31 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:52:26.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-792" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":273,"completed":179,"skipped":3135,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:52:26.570: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6697
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Dec 21 12:52:26.723: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Dec 21 12:52:26.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-6697'
Dec 21 12:52:27.178: INFO: stderr: ""
Dec 21 12:52:27.178: INFO: stdout: "service/agnhost-slave created\n"
Dec 21 12:52:27.179: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Dec 21 12:52:27.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-6697'
Dec 21 12:52:27.539: INFO: stderr: ""
Dec 21 12:52:27.539: INFO: stdout: "service/agnhost-master created\n"
Dec 21 12:52:27.539: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 21 12:52:27.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-6697'
Dec 21 12:52:27.806: INFO: stderr: ""
Dec 21 12:52:27.806: INFO: stdout: "service/frontend created\n"
Dec 21 12:52:27.806: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Dec 21 12:52:27.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-6697'
Dec 21 12:52:28.023: INFO: stderr: ""
Dec 21 12:52:28.023: INFO: stdout: "deployment.apps/frontend created\n"
Dec 21 12:52:28.036: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 21 12:52:28.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-6697'
Dec 21 12:52:28.278: INFO: stderr: ""
Dec 21 12:52:28.278: INFO: stdout: "deployment.apps/agnhost-master created\n"
Dec 21 12:52:28.278: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 21 12:52:28.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-6697'
Dec 21 12:52:28.477: INFO: stderr: ""
Dec 21 12:52:28.477: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Dec 21 12:52:28.477: INFO: Waiting for all frontend pods to be Running.
Dec 21 12:52:33.527: INFO: Waiting for frontend to serve content.
Dec 21 12:52:33.637: INFO: Trying to add a new entry to the guestbook.
Dec 21 12:52:33.773: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 21 12:52:33.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete --grace-period=0 --force -f - --namespace=kubectl-6697'
Dec 21 12:52:34.008: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 12:52:34.008: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 12:52:34.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete --grace-period=0 --force -f - --namespace=kubectl-6697'
Dec 21 12:52:34.146: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 12:52:34.146: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 12:52:34.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete --grace-period=0 --force -f - --namespace=kubectl-6697'
Dec 21 12:52:34.308: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 12:52:34.308: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 12:52:34.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete --grace-period=0 --force -f - --namespace=kubectl-6697'
Dec 21 12:52:34.523: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 12:52:34.523: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 12:52:34.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete --grace-period=0 --force -f - --namespace=kubectl-6697'
Dec 21 12:52:34.674: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 12:52:34.674: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 21 12:52:34.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete --grace-period=0 --force -f - --namespace=kubectl-6697'
Dec 21 12:52:34.810: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 21 12:52:34.810: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:52:34.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6697" for this suite.

• [SLOW TEST:8.276 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:310
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":273,"completed":180,"skipped":3164,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:52:34.847: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9440
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 21 12:52:45.222: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1221 12:52:45.222258      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:52:45.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9440" for this suite.

• [SLOW TEST:10.398 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":273,"completed":181,"skipped":3175,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:52:45.247: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8973
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Dec 21 12:52:45.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 api-versions'
Dec 21 12:52:45.523: INFO: stderr: ""
Dec 21 12:52:45.523: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncluster.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd-publish-openapi-test-empty.example.com/v1\ncrd-publish-openapi-test-multi-to-single-ver.example.com/v5\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetakube.syseleven.de/v1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:52:45.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8973" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":273,"completed":182,"skipped":3187,"failed":0}
SSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:52:45.539: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9215
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-c6f71cbb-d66b-4328-961e-1b7007056eaa in namespace container-probe-9215
Dec 21 12:52:49.713: INFO: Started pod liveness-c6f71cbb-d66b-4328-961e-1b7007056eaa in namespace container-probe-9215
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 12:52:49.716: INFO: Initial restart count of pod liveness-c6f71cbb-d66b-4328-961e-1b7007056eaa is 0
Dec 21 12:53:07.789: INFO: Restart count of pod container-probe-9215/liveness-c6f71cbb-d66b-4328-961e-1b7007056eaa is now 1 (18.072544642s elapsed)
Dec 21 12:53:27.844: INFO: Restart count of pod container-probe-9215/liveness-c6f71cbb-d66b-4328-961e-1b7007056eaa is now 2 (38.128261735s elapsed)
Dec 21 12:53:49.910: INFO: Restart count of pod container-probe-9215/liveness-c6f71cbb-d66b-4328-961e-1b7007056eaa is now 3 (1m0.193865869s elapsed)
Dec 21 12:54:09.961: INFO: Restart count of pod container-probe-9215/liveness-c6f71cbb-d66b-4328-961e-1b7007056eaa is now 4 (1m20.245304389s elapsed)
Dec 21 12:55:14.191: INFO: Restart count of pod container-probe-9215/liveness-c6f71cbb-d66b-4328-961e-1b7007056eaa is now 5 (2m24.475319479s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:55:14.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9215" for this suite.

• [SLOW TEST:148.678 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":273,"completed":183,"skipped":3193,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:55:14.220: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9372
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 12:55:14.365: INFO: Creating deployment "test-recreate-deployment"
Dec 21 12:55:14.372: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 21 12:55:14.380: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 21 12:55:16.389: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 21 12:55:16.392: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152114, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152114, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152114, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152114, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 12:55:18.399: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 21 12:55:18.411: INFO: Updating deployment test-recreate-deployment
Dec 21 12:55:18.411: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 21 12:55:18.491: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9372 /apis/apps/v1/namespaces/deployment-9372/deployments/test-recreate-deployment 1b904c22-9c46-44c6-86a6-b667fb2db796 36044191 2 2020-12-21 12:55:14 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-12-21 12:55:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-21 12:55:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0040ec6c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-12-21 12:55:18 +0000 UTC,LastTransitionTime:2020-12-21 12:55:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-12-21 12:55:18 +0000 UTC,LastTransitionTime:2020-12-21 12:55:14 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 21 12:55:18.495: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-9372 /apis/apps/v1/namespaces/deployment-9372/replicasets/test-recreate-deployment-d5667d9c7 575ae690-a61c-4dff-8250-f6438d7493dc 36044190 1 2020-12-21 12:55:18 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 1b904c22-9c46-44c6-86a6-b667fb2db796 0xc0040cb1d0 0xc0040cb1d1}] []  [{kube-controller-manager Update apps/v1 2020-12-21 12:55:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 57 48 52 99 50 50 45 57 99 52 54 45 52 52 99 54 45 56 54 97 54 45 98 54 54 55 102 98 50 100 98 55 57 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0040cb248 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 12:55:18.495: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 21 12:55:18.496: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-9372 /apis/apps/v1/namespaces/deployment-9372/replicasets/test-recreate-deployment-74d98b5f7c 6b3f5ccd-96af-4693-800a-f34666c79322 36044180 2 2020-12-21 12:55:14 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 1b904c22-9c46-44c6-86a6-b667fb2db796 0xc0040cb0a7 0xc0040cb0a8}] []  [{kube-controller-manager Update apps/v1 2020-12-21 12:55:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 98 57 48 52 99 50 50 45 57 99 52 54 45 52 52 99 54 45 56 54 97 54 45 98 54 54 55 102 98 50 100 98 55 57 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0040cb158 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 12:55:18.499: INFO: Pod "test-recreate-deployment-d5667d9c7-t9d55" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-t9d55 test-recreate-deployment-d5667d9c7- deployment-9372 /api/v1/namespaces/deployment-9372/pods/test-recreate-deployment-d5667d9c7-t9d55 eb9f5b51-49b2-4074-bff3-ecd121b12414 36044192 0 2020-12-21 12:55:18 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 575ae690-a61c-4dff-8250-f6438d7493dc 0xc0040ecb00 0xc0040ecb01}] []  [{kube-controller-manager Update v1 2020-12-21 12:55:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 55 53 97 101 54 57 48 45 97 54 49 99 45 52 100 102 102 45 56 50 53 48 45 102 54 52 51 56 100 55 52 57 51 100 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 12:55:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hpfpp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hpfpp,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hpfpp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-232-239.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:55:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:55:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:55:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 12:55:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.232.239,PodIP:,StartTime:2020-12-21 12:55:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:55:18.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9372" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":273,"completed":184,"skipped":3204,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:55:18.524: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2813
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-f2a1bbe0-611f-4a03-8459-6f2168014b86
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:55:20.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2813" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":185,"skipped":3231,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:55:20.851: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1232
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-811a72f8-d125-4978-bdb7-51ddfc3e5fa3 in namespace container-probe-1232
Dec 21 12:55:23.021: INFO: Started pod liveness-811a72f8-d125-4978-bdb7-51ddfc3e5fa3 in namespace container-probe-1232
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 12:55:23.027: INFO: Initial restart count of pod liveness-811a72f8-d125-4978-bdb7-51ddfc3e5fa3 is 0
Dec 21 12:55:41.078: INFO: Restart count of pod container-probe-1232/liveness-811a72f8-d125-4978-bdb7-51ddfc3e5fa3 is now 1 (18.050434303s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:55:41.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1232" for this suite.

• [SLOW TEST:20.274 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":273,"completed":186,"skipped":3245,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:55:41.127: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 12:55:42.627: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 12:55:44.647: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152142, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152142, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152142, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152142, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 12:55:47.664: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 21 12:55:49.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 attach --namespace=webhook-3217 to-be-attached-pod -i -c=container1'
Dec 21 12:55:49.945: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:55:49.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3217" for this suite.
STEP: Destroying namespace "webhook-3217-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.919 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":273,"completed":187,"skipped":3247,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:55:50.061: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6189
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 12:55:50.235: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e9bd616-11f2-4039-89d5-f7f8e67730f5" in namespace "downward-api-6189" to be "Succeeded or Failed"
Dec 21 12:55:50.243: INFO: Pod "downwardapi-volume-4e9bd616-11f2-4039-89d5-f7f8e67730f5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.693443ms
Dec 21 12:55:52.249: INFO: Pod "downwardapi-volume-4e9bd616-11f2-4039-89d5-f7f8e67730f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013358613s
STEP: Saw pod success
Dec 21 12:55:52.249: INFO: Pod "downwardapi-volume-4e9bd616-11f2-4039-89d5-f7f8e67730f5" satisfied condition "Succeeded or Failed"
Dec 21 12:55:52.252: INFO: Trying to get logs from node ip-172-31-244-13.eu-central-1.compute.internal pod downwardapi-volume-4e9bd616-11f2-4039-89d5-f7f8e67730f5 container client-container: <nil>
STEP: delete the pod
Dec 21 12:55:52.279: INFO: Waiting for pod downwardapi-volume-4e9bd616-11f2-4039-89d5-f7f8e67730f5 to disappear
Dec 21 12:55:52.286: INFO: Pod downwardapi-volume-4e9bd616-11f2-4039-89d5-f7f8e67730f5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:55:52.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6189" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":188,"skipped":3253,"failed":0}
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:55:52.299: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-593
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-72g2
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 12:55:52.461: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-72g2" in namespace "subpath-593" to be "Succeeded or Failed"
Dec 21 12:55:52.470: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.932761ms
Dec 21 12:55:54.475: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013021095s
Dec 21 12:55:56.480: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 4.018344976s
Dec 21 12:55:58.484: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 6.022567955s
Dec 21 12:56:00.491: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 8.029172818s
Dec 21 12:56:02.496: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 10.034400098s
Dec 21 12:56:04.500: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 12.038776729s
Dec 21 12:56:06.505: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 14.043567058s
Dec 21 12:56:08.509: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 16.047861241s
Dec 21 12:56:10.517: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 18.055382549s
Dec 21 12:56:12.522: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 20.059947224s
Dec 21 12:56:14.527: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Running", Reason="", readiness=true. Elapsed: 22.065512153s
Dec 21 12:56:16.532: INFO: Pod "pod-subpath-test-configmap-72g2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.070109015s
STEP: Saw pod success
Dec 21 12:56:16.532: INFO: Pod "pod-subpath-test-configmap-72g2" satisfied condition "Succeeded or Failed"
Dec 21 12:56:16.535: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-subpath-test-configmap-72g2 container test-container-subpath-configmap-72g2: <nil>
STEP: delete the pod
Dec 21 12:56:16.563: INFO: Waiting for pod pod-subpath-test-configmap-72g2 to disappear
Dec 21 12:56:16.567: INFO: Pod pod-subpath-test-configmap-72g2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-72g2
Dec 21 12:56:16.567: INFO: Deleting pod "pod-subpath-test-configmap-72g2" in namespace "subpath-593"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 12:56:16.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-593" for this suite.

• [SLOW TEST:24.283 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":273,"completed":189,"skipped":3258,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 12:56:16.582: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-3defef1f-ed12-4f64-a4bd-70fe40bc395f in namespace container-probe-1113
Dec 21 12:56:18.762: INFO: Started pod test-webserver-3defef1f-ed12-4f64-a4bd-70fe40bc395f in namespace container-probe-1113
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 12:56:18.766: INFO: Initial restart count of pod test-webserver-3defef1f-ed12-4f64-a4bd-70fe40bc395f is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:00:19.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1113" for this suite.

• [SLOW TEST:243.013 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":273,"completed":190,"skipped":3284,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:00:19.598: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1221 13:00:21.398329      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 21 13:00:21.398: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:00:21.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9337" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":273,"completed":191,"skipped":3302,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:00:21.420: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-3af65583-29f3-47f3-98e6-1c178aca2e99
STEP: Creating a pod to test consume configMaps
Dec 21 13:00:21.628: INFO: Waiting up to 5m0s for pod "pod-configmaps-87e1e1f5-9009-4a98-b9ab-a6030cc4170f" in namespace "configmap-867" to be "Succeeded or Failed"
Dec 21 13:00:21.634: INFO: Pod "pod-configmaps-87e1e1f5-9009-4a98-b9ab-a6030cc4170f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.442045ms
Dec 21 13:00:23.643: INFO: Pod "pod-configmaps-87e1e1f5-9009-4a98-b9ab-a6030cc4170f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015086923s
Dec 21 13:00:25.648: INFO: Pod "pod-configmaps-87e1e1f5-9009-4a98-b9ab-a6030cc4170f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019758528s
STEP: Saw pod success
Dec 21 13:00:25.648: INFO: Pod "pod-configmaps-87e1e1f5-9009-4a98-b9ab-a6030cc4170f" satisfied condition "Succeeded or Failed"
Dec 21 13:00:25.658: INFO: Trying to get logs from node ip-172-31-244-13.eu-central-1.compute.internal pod pod-configmaps-87e1e1f5-9009-4a98-b9ab-a6030cc4170f container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 13:00:25.734: INFO: Waiting for pod pod-configmaps-87e1e1f5-9009-4a98-b9ab-a6030cc4170f to disappear
Dec 21 13:00:25.750: INFO: Pod pod-configmaps-87e1e1f5-9009-4a98-b9ab-a6030cc4170f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:00:25.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-867" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":273,"completed":192,"skipped":3311,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:00:25.767: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1894.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1894.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 13:00:30.278: INFO: DNS probes using dns-1894/dns-test-32f19618-7e3c-4f44-86a9-67965a74579f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:00:30.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1894" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":273,"completed":193,"skipped":3348,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:00:30.338: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-99
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-88ca639d-a627-4931-9f6d-e3fc1b177cb0 in namespace container-probe-99
Dec 21 13:00:32.551: INFO: Started pod busybox-88ca639d-a627-4931-9f6d-e3fc1b177cb0 in namespace container-probe-99
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 13:00:32.555: INFO: Initial restart count of pod busybox-88ca639d-a627-4931-9f6d-e3fc1b177cb0 is 0
Dec 21 13:01:18.712: INFO: Restart count of pod container-probe-99/busybox-88ca639d-a627-4931-9f6d-e3fc1b177cb0 is now 1 (46.156841948s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:01:18.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-99" for this suite.

• [SLOW TEST:48.416 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":273,"completed":194,"skipped":3357,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:01:18.766: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5178
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 21 13:01:18.937: INFO: Waiting up to 5m0s for pod "pod-10d49981-76e5-4992-a602-a798a81565b4" in namespace "emptydir-5178" to be "Succeeded or Failed"
Dec 21 13:01:18.948: INFO: Pod "pod-10d49981-76e5-4992-a602-a798a81565b4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.411048ms
Dec 21 13:01:20.952: INFO: Pod "pod-10d49981-76e5-4992-a602-a798a81565b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015229664s
Dec 21 13:01:22.957: INFO: Pod "pod-10d49981-76e5-4992-a602-a798a81565b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019791925s
STEP: Saw pod success
Dec 21 13:01:22.957: INFO: Pod "pod-10d49981-76e5-4992-a602-a798a81565b4" satisfied condition "Succeeded or Failed"
Dec 21 13:01:22.961: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-10d49981-76e5-4992-a602-a798a81565b4 container test-container: <nil>
STEP: delete the pod
Dec 21 13:01:23.000: INFO: Waiting for pod pod-10d49981-76e5-4992-a602-a798a81565b4 to disappear
Dec 21 13:01:23.004: INFO: Pod pod-10d49981-76e5-4992-a602-a798a81565b4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:01:23.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5178" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":195,"skipped":3391,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:01:23.022: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 13:01:23.203: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c19d10b9-0e0c-4ef1-ac13-9544687ea816" in namespace "projected-866" to be "Succeeded or Failed"
Dec 21 13:01:23.213: INFO: Pod "downwardapi-volume-c19d10b9-0e0c-4ef1-ac13-9544687ea816": Phase="Pending", Reason="", readiness=false. Elapsed: 9.640616ms
Dec 21 13:01:25.219: INFO: Pod "downwardapi-volume-c19d10b9-0e0c-4ef1-ac13-9544687ea816": Phase="Running", Reason="", readiness=true. Elapsed: 2.016019446s
Dec 21 13:01:27.236: INFO: Pod "downwardapi-volume-c19d10b9-0e0c-4ef1-ac13-9544687ea816": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033017492s
STEP: Saw pod success
Dec 21 13:01:27.236: INFO: Pod "downwardapi-volume-c19d10b9-0e0c-4ef1-ac13-9544687ea816" satisfied condition "Succeeded or Failed"
Dec 21 13:01:27.243: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-c19d10b9-0e0c-4ef1-ac13-9544687ea816 container client-container: <nil>
STEP: delete the pod
Dec 21 13:01:27.370: INFO: Waiting for pod downwardapi-volume-c19d10b9-0e0c-4ef1-ac13-9544687ea816 to disappear
Dec 21 13:01:27.378: INFO: Pod downwardapi-volume-c19d10b9-0e0c-4ef1-ac13-9544687ea816 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:01:27.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-866" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":273,"completed":196,"skipped":3410,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:01:27.416: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2610
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:01:29.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2610" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":273,"completed":197,"skipped":3426,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:01:29.711: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-867644b2-0072-4e1d-95ea-c160fb763df8
STEP: Creating a pod to test consume secrets
Dec 21 13:01:29.890: INFO: Waiting up to 5m0s for pod "pod-secrets-73abd39d-5708-4513-b54c-226c9a9c36ac" in namespace "secrets-6558" to be "Succeeded or Failed"
Dec 21 13:01:29.905: INFO: Pod "pod-secrets-73abd39d-5708-4513-b54c-226c9a9c36ac": Phase="Pending", Reason="", readiness=false. Elapsed: 14.633216ms
Dec 21 13:01:31.910: INFO: Pod "pod-secrets-73abd39d-5708-4513-b54c-226c9a9c36ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019837882s
Dec 21 13:01:33.915: INFO: Pod "pod-secrets-73abd39d-5708-4513-b54c-226c9a9c36ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025098335s
STEP: Saw pod success
Dec 21 13:01:33.916: INFO: Pod "pod-secrets-73abd39d-5708-4513-b54c-226c9a9c36ac" satisfied condition "Succeeded or Failed"
Dec 21 13:01:33.922: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-secrets-73abd39d-5708-4513-b54c-226c9a9c36ac container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 13:01:33.959: INFO: Waiting for pod pod-secrets-73abd39d-5708-4513-b54c-226c9a9c36ac to disappear
Dec 21 13:01:33.962: INFO: Pod pod-secrets-73abd39d-5708-4513-b54c-226c9a9c36ac no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:01:33.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6558" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":198,"skipped":3429,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:01:33.982: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6122
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-f987e5c7-5b16-4188-b8b9-8f086875f20d
STEP: Creating a pod to test consume secrets
Dec 21 13:01:34.182: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6fc14c3f-08ac-4049-a322-bb3599e99395" in namespace "projected-6122" to be "Succeeded or Failed"
Dec 21 13:01:34.188: INFO: Pod "pod-projected-secrets-6fc14c3f-08ac-4049-a322-bb3599e99395": Phase="Pending", Reason="", readiness=false. Elapsed: 6.23625ms
Dec 21 13:01:36.193: INFO: Pod "pod-projected-secrets-6fc14c3f-08ac-4049-a322-bb3599e99395": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010947729s
Dec 21 13:01:38.200: INFO: Pod "pod-projected-secrets-6fc14c3f-08ac-4049-a322-bb3599e99395": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018468348s
STEP: Saw pod success
Dec 21 13:01:38.200: INFO: Pod "pod-projected-secrets-6fc14c3f-08ac-4049-a322-bb3599e99395" satisfied condition "Succeeded or Failed"
Dec 21 13:01:38.205: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-projected-secrets-6fc14c3f-08ac-4049-a322-bb3599e99395 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 13:01:38.251: INFO: Waiting for pod pod-projected-secrets-6fc14c3f-08ac-4049-a322-bb3599e99395 to disappear
Dec 21 13:01:38.263: INFO: Pod pod-projected-secrets-6fc14c3f-08ac-4049-a322-bb3599e99395 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:01:38.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6122" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":199,"skipped":3474,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:01:38.287: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6150
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 13:01:39.268: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 13:01:41.300: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152499, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152499, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152499, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152499, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 13:01:44.317: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:01:44.322: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9573-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:01:45.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6150" for this suite.
STEP: Destroying namespace "webhook-6150-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.644 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":273,"completed":200,"skipped":3484,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:01:45.935: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6052
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Dec 21 13:01:46.097: INFO: PodSpec: initContainers in spec.initContainers
Dec 21 13:02:33.075: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-333e46ce-11c3-45d7-80bf-7a19b3147559", GenerateName:"", Namespace:"init-container-6052", SelfLink:"/api/v1/namespaces/init-container-6052/pods/pod-init-333e46ce-11c3-45d7-80bf-7a19b3147559", UID:"e66bde37-d16d-4188-a1b2-04e5d70bdc6a", ResourceVersion:"36046807", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63744152506, loc:(*time.Location)(0x7b565c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"97304583"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"172.25.4.166/32", "cni.projectcalico.org/podIPs":"172.25.4.166/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003538140), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003538160)}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003538180), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0035381a0)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0035381c0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0035381e0)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-dplsm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003ba6000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dplsm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dplsm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dplsm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00345e0d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-232-239.eu-central-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0031ea000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00345e150)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00345e170)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00345e178), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00345e17c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152506, loc:(*time.Location)(0x7b565c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152506, loc:(*time.Location)(0x7b565c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152506, loc:(*time.Location)(0x7b565c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744152506, loc:(*time.Location)(0x7b565c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.232.239", PodIP:"172.25.4.166", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.25.4.166"}}, StartTime:(*v1.Time)(0xc003538200), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0031ea0e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0031ea150)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://f2cfcf96ceaa56755134dd2e7c2b7047fc513843d4401e78bf127a619418294c", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003538240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003538220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc00345e1ff)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:02:33.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6052" for this suite.

• [SLOW TEST:47.192 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":273,"completed":201,"skipped":3496,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:02:33.129: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1418
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 21 13:02:33.392: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 13:02:33.409: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 13:02:33.421: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-183-240.eu-central-1.compute.internal before test
Dec 21 13:02:33.463: INFO: openvpn-client-56dc45fdbd-pvwz9 from kube-system started at 2020-12-21 11:49:06 +0000 UTC (2 container statuses recorded)
Dec 21 13:02:33.463: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 21 13:02:33.463: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 21 13:02:33.463: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-g9pqh from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 13:02:33.463: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 13:02:33.463: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 13:02:33.463: INFO: kube-proxy-2s25g from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.464: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 13:02:33.464: INFO: tiller-deploy-5648ccb4b6-c8nqp from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.464: INFO: 	Container tiller ready: true, restart count 0
Dec 21 13:02:33.472: INFO: user-ssh-keys-agent-282ml from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.472: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 13:02:33.472: INFO: syseleven-node-problem-detector-xwkkt from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.472: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 13:02:33.472: INFO: node-exporter-hjpfq from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.472: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 13:02:33.472: INFO: coredns-854998958f-nm6p2 from kube-system started at 2020-12-21 11:46:38 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.472: INFO: 	Container coredns ready: true, restart count 0
Dec 21 13:02:33.472: INFO: dns-autoscaler-596856b68b-qzt9r from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.472: INFO: 	Container autoscaler ready: true, restart count 0
Dec 21 13:02:33.472: INFO: canal-z66nn from kube-system started at 2020-12-21 11:46:17 +0000 UTC (2 container statuses recorded)
Dec 21 13:02:33.472: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 13:02:33.472: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 13:02:33.472: INFO: node-local-dns-htgfk from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.472: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 13:02:33.472: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-232-239.eu-central-1.compute.internal before test
Dec 21 13:02:33.545: INFO: cluster-autoscaler-5c8c86777b-9jllr from kube-system started at 2020-12-21 11:52:18 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.545: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 21 13:02:33.545: INFO: kube-proxy-wmhd2 from kube-system started at 2020-12-21 11:48:44 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.546: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 13:02:33.546: INFO: syseleven-node-problem-detector-6vfvr from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.546: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 13:02:33.546: INFO: user-ssh-keys-agent-4gr8h from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.546: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 13:02:33.546: INFO: pod-init-333e46ce-11c3-45d7-80bf-7a19b3147559 from init-container-6052 started at 2020-12-21 13:01:46 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.546: INFO: 	Container run1 ready: false, restart count 0
Dec 21 13:02:33.546: INFO: node-exporter-8m5jv from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.546: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 13:02:33.546: INFO: node-local-dns-qpm75 from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.546: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 13:02:33.546: INFO: canal-w4p2b from kube-system started at 2020-12-21 11:48:45 +0000 UTC (2 container statuses recorded)
Dec 21 13:02:33.546: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 13:02:33.546: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 13:02:33.546: INFO: coredns-854998958f-sf9zb from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.546: INFO: 	Container coredns ready: true, restart count 0
Dec 21 13:02:33.546: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-xp6km from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 13:02:33.546: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 13:02:33.546: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 13:02:33.546: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-244-13.eu-central-1.compute.internal before test
Dec 21 13:02:33.657: INFO: sonobuoy-e2e-job-12016c8e6e68444f from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 13:02:33.657: INFO: 	Container e2e ready: true, restart count 0
Dec 21 13:02:33.657: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 13:02:33.657: INFO: user-ssh-keys-agent-jx8sl from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.657: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 13:02:33.657: INFO: kube-proxy-rvhxj from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.657: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 13:02:33.657: INFO: sonobuoy from sonobuoy started at 2020-12-21 12:10:49 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.657: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 21 13:02:33.658: INFO: syseleven-node-problem-detector-f6dnk from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.658: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 13:02:33.658: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-8p5kx from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 13:02:33.658: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 13:02:33.658: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 13:02:33.658: INFO: canal-ljp6n from kube-system started at 2020-12-21 11:51:56 +0000 UTC (2 container statuses recorded)
Dec 21 13:02:33.658: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 13:02:33.658: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 13:02:33.658: INFO: node-exporter-hzvfb from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.658: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 13:02:33.658: INFO: node-local-dns-wqj25 from kube-system started at 2020-12-21 11:51:57 +0000 UTC (1 container statuses recorded)
Dec 21 13:02:33.658: INFO: 	Container node-cache ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3fc5f229-292c-4459-9339-6d0f8efe2560 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-3fc5f229-292c-4459-9339-6d0f8efe2560 off the node ip-172-31-183-240.eu-central-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3fc5f229-292c-4459-9339-6d0f8efe2560
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:02:41.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1418" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:8.719 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":273,"completed":202,"skipped":3528,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:02:41.849: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3173
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Dec 21 13:02:42.545: INFO: created pod pod-service-account-defaultsa
Dec 21 13:02:42.545: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 21 13:02:42.551: INFO: created pod pod-service-account-mountsa
Dec 21 13:02:42.551: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 21 13:02:42.558: INFO: created pod pod-service-account-nomountsa
Dec 21 13:02:42.558: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 21 13:02:42.565: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 21 13:02:42.565: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 21 13:02:42.572: INFO: created pod pod-service-account-mountsa-mountspec
Dec 21 13:02:42.572: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 21 13:02:42.582: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 21 13:02:42.582: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 21 13:02:42.587: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 21 13:02:42.587: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 21 13:02:42.598: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 21 13:02:42.602: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 21 13:02:42.622: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 21 13:02:42.626: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:02:42.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3173" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":273,"completed":203,"skipped":3559,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:02:42.661: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5971
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Dec 21 13:02:42.808: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:03:03.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5971" for this suite.

• [SLOW TEST:20.641 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":273,"completed":204,"skipped":3570,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:03:03.302: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:03:03.523: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-4a580006-9d3c-44d0-bb34-bae48c6150ca" in namespace "security-context-test-3694" to be "Succeeded or Failed"
Dec 21 13:03:03.527: INFO: Pod "busybox-privileged-false-4a580006-9d3c-44d0-bb34-bae48c6150ca": Phase="Pending", Reason="", readiness=false. Elapsed: 4.078049ms
Dec 21 13:03:05.534: INFO: Pod "busybox-privileged-false-4a580006-9d3c-44d0-bb34-bae48c6150ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011515842s
Dec 21 13:03:07.539: INFO: Pod "busybox-privileged-false-4a580006-9d3c-44d0-bb34-bae48c6150ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016299829s
Dec 21 13:03:07.539: INFO: Pod "busybox-privileged-false-4a580006-9d3c-44d0-bb34-bae48c6150ca" satisfied condition "Succeeded or Failed"
Dec 21 13:03:07.589: INFO: Got logs for pod "busybox-privileged-false-4a580006-9d3c-44d0-bb34-bae48c6150ca": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:03:07.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3694" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":205,"skipped":3580,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:03:07.608: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5986
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-7c2c2e47-8c10-4f21-8fe2-2878d7959914
STEP: Creating a pod to test consume configMaps
Dec 21 13:03:07.771: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7b8c54db-8ef4-44fd-a9bf-948fbb2182cf" in namespace "projected-5986" to be "Succeeded or Failed"
Dec 21 13:03:07.779: INFO: Pod "pod-projected-configmaps-7b8c54db-8ef4-44fd-a9bf-948fbb2182cf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.599403ms
Dec 21 13:03:09.786: INFO: Pod "pod-projected-configmaps-7b8c54db-8ef4-44fd-a9bf-948fbb2182cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014570394s
STEP: Saw pod success
Dec 21 13:03:09.786: INFO: Pod "pod-projected-configmaps-7b8c54db-8ef4-44fd-a9bf-948fbb2182cf" satisfied condition "Succeeded or Failed"
Dec 21 13:03:09.791: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-projected-configmaps-7b8c54db-8ef4-44fd-a9bf-948fbb2182cf container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 13:03:09.816: INFO: Waiting for pod pod-projected-configmaps-7b8c54db-8ef4-44fd-a9bf-948fbb2182cf to disappear
Dec 21 13:03:09.820: INFO: Pod pod-projected-configmaps-7b8c54db-8ef4-44fd-a9bf-948fbb2182cf no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:03:09.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5986" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":206,"skipped":3588,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:03:09.836: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3238
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 21 13:03:16.067: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:03:16.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1221 13:03:16.067166      20 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-3238" for this suite.

• [SLOW TEST:6.250 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":273,"completed":207,"skipped":3616,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:03:16.088: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1818
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:03:27.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1818" for this suite.

• [SLOW TEST:11.223 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":273,"completed":208,"skipped":3623,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:03:27.313: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-ec8c1195-b270-4b99-bcc5-daf1873208f7
STEP: Creating a pod to test consume configMaps
Dec 21 13:03:27.501: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9c712998-0d4a-417c-8059-6e5cd11853f9" in namespace "projected-7985" to be "Succeeded or Failed"
Dec 21 13:03:27.512: INFO: Pod "pod-projected-configmaps-9c712998-0d4a-417c-8059-6e5cd11853f9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.77558ms
Dec 21 13:03:29.517: INFO: Pod "pod-projected-configmaps-9c712998-0d4a-417c-8059-6e5cd11853f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015230237s
STEP: Saw pod success
Dec 21 13:03:29.517: INFO: Pod "pod-projected-configmaps-9c712998-0d4a-417c-8059-6e5cd11853f9" satisfied condition "Succeeded or Failed"
Dec 21 13:03:29.520: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-projected-configmaps-9c712998-0d4a-417c-8059-6e5cd11853f9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 13:03:29.588: INFO: Waiting for pod pod-projected-configmaps-9c712998-0d4a-417c-8059-6e5cd11853f9 to disappear
Dec 21 13:03:29.593: INFO: Pod pod-projected-configmaps-9c712998-0d4a-417c-8059-6e5cd11853f9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:03:29.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7985" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":273,"completed":209,"skipped":3626,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:03:29.615: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-6506
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-6506
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6506
STEP: Deleting pre-stop pod
Dec 21 13:03:42.926: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:03:42.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6506" for this suite.

• [SLOW TEST:13.336 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":273,"completed":210,"skipped":3641,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:03:42.951: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-942
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e9f362bc-ab22-42b6-9fbd-1d6a133b383a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e9f362bc-ab22-42b6-9fbd-1d6a133b383a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:03:47.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-942" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":211,"skipped":3642,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:03:47.292: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3977
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Dec 21 13:03:52.051: INFO: Successfully updated pod "labelsupdatee27c9a26-1971-4cfd-9f7b-bdcb4126e3ec"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:03:54.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3977" for this suite.

• [SLOW TEST:6.811 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":273,"completed":212,"skipped":3650,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:03:54.104: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-6742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8035
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5671
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:04:00.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6742" for this suite.
STEP: Destroying namespace "nsdeletetest-8035" for this suite.
Dec 21 13:04:00.667: INFO: Namespace nsdeletetest-8035 was already deleted
STEP: Destroying namespace "nsdeletetest-5671" for this suite.

• [SLOW TEST:6.571 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":273,"completed":213,"skipped":3664,"failed":0}
SSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:04:00.684: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-3083
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:04:08.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3083" for this suite.

• [SLOW TEST:8.188 seconds]
[sig-apps] Job
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":273,"completed":214,"skipped":3669,"failed":0}
S
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:04:08.872: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2796
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2796
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2796
STEP: creating replication controller externalsvc in namespace services-2796
I1221 13:04:09.081443      20 runners.go:190] Created replication controller with name: externalsvc, namespace: services-2796, replica count: 2
I1221 13:04:12.132195      20 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 21 13:04:12.157: INFO: Creating new exec pod
Dec 21 13:04:14.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=services-2796 execpodcmm7p -- /bin/sh -x -c nslookup nodeport-service'
Dec 21 13:04:15.231: INFO: stderr: "+ nslookup nodeport-service\n"
Dec 21 13:04:15.231: INFO: stdout: "Server:\t\t169.254.20.10\nAddress:\t169.254.20.10#53\n\nnodeport-service.services-2796.svc.cluster.local\tcanonical name = externalsvc.services-2796.svc.cluster.local.\nName:\texternalsvc.services-2796.svc.cluster.local\nAddress: 10.240.28.48\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2796, will wait for the garbage collector to delete the pods
Dec 21 13:04:15.297: INFO: Deleting ReplicationController externalsvc took: 11.608729ms
Dec 21 13:04:15.897: INFO: Terminating ReplicationController externalsvc pods took: 600.254376ms
Dec 21 13:04:26.866: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:04:26.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2796" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:18.026 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":273,"completed":215,"skipped":3670,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:04:26.905: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-9343
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9343 to expose endpoints map[]
Dec 21 13:04:27.105: INFO: Get endpoints failed (3.708569ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 21 13:04:28.109: INFO: successfully validated that service endpoint-test2 in namespace services-9343 exposes endpoints map[] (1.008037919s elapsed)
STEP: Creating pod pod1 in namespace services-9343
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9343 to expose endpoints map[pod1:[80]]
Dec 21 13:04:30.172: INFO: successfully validated that service endpoint-test2 in namespace services-9343 exposes endpoints map[pod1:[80]] (2.054286125s elapsed)
STEP: Creating pod pod2 in namespace services-9343
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9343 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 21 13:04:32.267: INFO: successfully validated that service endpoint-test2 in namespace services-9343 exposes endpoints map[pod1:[80] pod2:[80]] (2.086046587s elapsed)
STEP: Deleting pod pod1 in namespace services-9343
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9343 to expose endpoints map[pod2:[80]]
Dec 21 13:04:33.298: INFO: successfully validated that service endpoint-test2 in namespace services-9343 exposes endpoints map[pod2:[80]] (1.02049557s elapsed)
STEP: Deleting pod pod2 in namespace services-9343
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9343 to expose endpoints map[]
Dec 21 13:04:34.331: INFO: successfully validated that service endpoint-test2 in namespace services-9343 exposes endpoints map[] (1.024740399s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:04:34.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9343" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:7.470 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":273,"completed":216,"skipped":3698,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:04:34.376: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5655
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 13:04:35.450: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 13:04:38.483: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:04:38.489: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7844-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:04:39.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5655" for this suite.
STEP: Destroying namespace "webhook-5655-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.515 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":273,"completed":217,"skipped":3701,"failed":0}
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:04:39.891: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9624
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:04:40.092: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 21 13:04:40.110: INFO: Number of nodes with available pods: 0
Dec 21 13:04:40.110: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 21 13:04:40.143: INFO: Number of nodes with available pods: 0
Dec 21 13:04:40.143: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:41.147: INFO: Number of nodes with available pods: 0
Dec 21 13:04:41.147: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:42.149: INFO: Number of nodes with available pods: 0
Dec 21 13:04:42.149: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:43.149: INFO: Number of nodes with available pods: 1
Dec 21 13:04:43.149: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 21 13:04:43.186: INFO: Number of nodes with available pods: 0
Dec 21 13:04:43.186: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 21 13:04:43.206: INFO: Number of nodes with available pods: 0
Dec 21 13:04:43.206: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:44.212: INFO: Number of nodes with available pods: 0
Dec 21 13:04:44.212: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:45.212: INFO: Number of nodes with available pods: 0
Dec 21 13:04:45.212: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:46.210: INFO: Number of nodes with available pods: 0
Dec 21 13:04:46.210: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:47.211: INFO: Number of nodes with available pods: 0
Dec 21 13:04:47.211: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:48.211: INFO: Number of nodes with available pods: 0
Dec 21 13:04:48.211: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:49.212: INFO: Number of nodes with available pods: 0
Dec 21 13:04:49.212: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:50.212: INFO: Number of nodes with available pods: 0
Dec 21 13:04:50.212: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:51.218: INFO: Number of nodes with available pods: 0
Dec 21 13:04:51.218: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:52.211: INFO: Number of nodes with available pods: 0
Dec 21 13:04:52.211: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:53.212: INFO: Number of nodes with available pods: 0
Dec 21 13:04:53.212: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:54.212: INFO: Number of nodes with available pods: 0
Dec 21 13:04:54.212: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:55.211: INFO: Number of nodes with available pods: 0
Dec 21 13:04:55.211: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:56.211: INFO: Number of nodes with available pods: 0
Dec 21 13:04:56.211: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:57.213: INFO: Number of nodes with available pods: 0
Dec 21 13:04:57.213: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:58.211: INFO: Number of nodes with available pods: 0
Dec 21 13:04:58.211: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:04:59.211: INFO: Number of nodes with available pods: 1
Dec 21 13:04:59.211: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9624, will wait for the garbage collector to delete the pods
Dec 21 13:04:59.280: INFO: Deleting DaemonSet.extensions daemon-set took: 7.563581ms
Dec 21 13:04:59.880: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.37382ms
Dec 21 13:05:07.385: INFO: Number of nodes with available pods: 0
Dec 21 13:05:07.385: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 13:05:07.397: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9624/daemonsets","resourceVersion":"36048723"},"items":null}

Dec 21 13:05:07.400: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9624/pods","resourceVersion":"36048723"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:05:07.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9624" for this suite.

• [SLOW TEST:27.608 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":273,"completed":218,"skipped":3705,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:05:07.499: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3931
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-d3208432-3888-4515-bace-93ffd968b5cc-6806
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:05:07.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3931" for this suite.
STEP: Destroying namespace "nspatchtest-d3208432-3888-4515-bace-93ffd968b5cc-6806" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":273,"completed":219,"skipped":3710,"failed":0}

------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:05:08.041: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-3598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:05:08.255: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3598
I1221 13:05:08.267233      20 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3598, replica count: 1
I1221 13:05:09.317649      20 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1221 13:05:10.317911      20 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 21 13:05:10.432: INFO: Created: latency-svc-2hkkl
Dec 21 13:05:10.439: INFO: Got endpoints: latency-svc-2hkkl [21.476199ms]
Dec 21 13:05:10.457: INFO: Created: latency-svc-rs5bl
Dec 21 13:05:10.461: INFO: Created: latency-svc-6gj4q
Dec 21 13:05:10.465: INFO: Got endpoints: latency-svc-rs5bl [21.502144ms]
Dec 21 13:05:10.470: INFO: Got endpoints: latency-svc-6gj4q [25.055285ms]
Dec 21 13:05:10.474: INFO: Created: latency-svc-8gr69
Dec 21 13:05:10.481: INFO: Got endpoints: latency-svc-8gr69 [35.87088ms]
Dec 21 13:05:10.482: INFO: Created: latency-svc-ssmx7
Dec 21 13:05:10.488: INFO: Created: latency-svc-nb8rt
Dec 21 13:05:10.491: INFO: Got endpoints: latency-svc-ssmx7 [45.631988ms]
Dec 21 13:05:10.495: INFO: Got endpoints: latency-svc-nb8rt [49.068153ms]
Dec 21 13:05:10.500: INFO: Created: latency-svc-fwgr6
Dec 21 13:05:10.505: INFO: Got endpoints: latency-svc-fwgr6 [59.443929ms]
Dec 21 13:05:10.514: INFO: Created: latency-svc-5jpcn
Dec 21 13:05:10.520: INFO: Created: latency-svc-c8fjh
Dec 21 13:05:10.520: INFO: Got endpoints: latency-svc-5jpcn [73.438645ms]
Dec 21 13:05:10.525: INFO: Created: latency-svc-qm9xk
Dec 21 13:05:10.525: INFO: Got endpoints: latency-svc-c8fjh [79.718895ms]
Dec 21 13:05:10.530: INFO: Got endpoints: latency-svc-qm9xk [83.102909ms]
Dec 21 13:05:10.534: INFO: Created: latency-svc-c8596
Dec 21 13:05:10.540: INFO: Got endpoints: latency-svc-c8596 [94.163038ms]
Dec 21 13:05:10.541: INFO: Created: latency-svc-6bm5w
Dec 21 13:05:10.547: INFO: Created: latency-svc-kbp2w
Dec 21 13:05:10.547: INFO: Got endpoints: latency-svc-6bm5w [99.366194ms]
Dec 21 13:05:10.552: INFO: Created: latency-svc-wqnhx
Dec 21 13:05:10.553: INFO: Got endpoints: latency-svc-kbp2w [105.494258ms]
Dec 21 13:05:10.557: INFO: Created: latency-svc-kp545
Dec 21 13:05:10.562: INFO: Got endpoints: latency-svc-wqnhx [113.405705ms]
Dec 21 13:05:10.564: INFO: Got endpoints: latency-svc-kp545 [114.9327ms]
Dec 21 13:05:10.567: INFO: Created: latency-svc-h9kl6
Dec 21 13:05:10.575: INFO: Created: latency-svc-l2jjm
Dec 21 13:05:10.575: INFO: Got endpoints: latency-svc-h9kl6 [125.965326ms]
Dec 21 13:05:10.580: INFO: Got endpoints: latency-svc-l2jjm [114.608004ms]
Dec 21 13:05:10.581: INFO: Created: latency-svc-qg6vn
Dec 21 13:05:10.589: INFO: Got endpoints: latency-svc-qg6vn [118.470475ms]
Dec 21 13:05:10.594: INFO: Created: latency-svc-chqgj
Dec 21 13:05:10.608: INFO: Created: latency-svc-7dcxb
Dec 21 13:05:10.616: INFO: Got endpoints: latency-svc-7dcxb [125.119923ms]
Dec 21 13:05:10.616: INFO: Got endpoints: latency-svc-chqgj [135.410739ms]
Dec 21 13:05:10.622: INFO: Created: latency-svc-nvxpg
Dec 21 13:05:10.633: INFO: Got endpoints: latency-svc-nvxpg [138.074508ms]
Dec 21 13:05:10.666: INFO: Created: latency-svc-zl4cg
Dec 21 13:05:10.682: INFO: Got endpoints: latency-svc-zl4cg [176.848771ms]
Dec 21 13:05:10.683: INFO: Created: latency-svc-ksl82
Dec 21 13:05:10.714: INFO: Created: latency-svc-q7q7m
Dec 21 13:05:10.715: INFO: Got endpoints: latency-svc-ksl82 [194.141861ms]
Dec 21 13:05:10.718: INFO: Got endpoints: latency-svc-q7q7m [192.438655ms]
Dec 21 13:05:10.721: INFO: Created: latency-svc-zrdck
Dec 21 13:05:10.730: INFO: Created: latency-svc-pznv8
Dec 21 13:05:10.731: INFO: Got endpoints: latency-svc-zrdck [200.998544ms]
Dec 21 13:05:10.750: INFO: Created: latency-svc-ll5d6
Dec 21 13:05:10.752: INFO: Got endpoints: latency-svc-pznv8 [211.64286ms]
Dec 21 13:05:10.758: INFO: Got endpoints: latency-svc-ll5d6 [210.13847ms]
Dec 21 13:05:10.760: INFO: Created: latency-svc-kp2gn
Dec 21 13:05:10.766: INFO: Got endpoints: latency-svc-kp2gn [213.568589ms]
Dec 21 13:05:10.769: INFO: Created: latency-svc-9qzmk
Dec 21 13:05:10.777: INFO: Got endpoints: latency-svc-9qzmk [214.475726ms]
Dec 21 13:05:10.780: INFO: Created: latency-svc-zvj49
Dec 21 13:05:10.785: INFO: Got endpoints: latency-svc-zvj49 [220.505931ms]
Dec 21 13:05:10.794: INFO: Created: latency-svc-d54qv
Dec 21 13:05:10.810: INFO: Got endpoints: latency-svc-d54qv [234.706646ms]
Dec 21 13:05:10.811: INFO: Created: latency-svc-s86rg
Dec 21 13:05:10.817: INFO: Created: latency-svc-w7qqf
Dec 21 13:05:10.836: INFO: Got endpoints: latency-svc-s86rg [256.639472ms]
Dec 21 13:05:10.868: INFO: Got endpoints: latency-svc-w7qqf [278.955959ms]
Dec 21 13:05:10.871: INFO: Created: latency-svc-kfm88
Dec 21 13:05:10.882: INFO: Created: latency-svc-jzt89
Dec 21 13:05:10.884: INFO: Got endpoints: latency-svc-kfm88 [267.839267ms]
Dec 21 13:05:10.894: INFO: Created: latency-svc-jwzp5
Dec 21 13:05:10.895: INFO: Got endpoints: latency-svc-jzt89 [279.279595ms]
Dec 21 13:05:10.907: INFO: Got endpoints: latency-svc-jwzp5 [274.634583ms]
Dec 21 13:05:10.909: INFO: Created: latency-svc-6kswl
Dec 21 13:05:10.921: INFO: Created: latency-svc-2hr42
Dec 21 13:05:10.923: INFO: Got endpoints: latency-svc-6kswl [241.351025ms]
Dec 21 13:05:10.942: INFO: Created: latency-svc-9z7g2
Dec 21 13:05:10.946: INFO: Created: latency-svc-4mdwn
Dec 21 13:05:10.947: INFO: Got endpoints: latency-svc-2hr42 [226.707212ms]
Dec 21 13:05:10.952: INFO: Got endpoints: latency-svc-9z7g2 [231.726439ms]
Dec 21 13:05:10.955: INFO: Got endpoints: latency-svc-4mdwn [224.383119ms]
Dec 21 13:05:10.956: INFO: Created: latency-svc-765zk
Dec 21 13:05:10.977: INFO: Created: latency-svc-x5fl5
Dec 21 13:05:11.003: INFO: Created: latency-svc-lfbfr
Dec 21 13:05:11.012: INFO: Got endpoints: latency-svc-765zk [260.257666ms]
Dec 21 13:05:11.019: INFO: Created: latency-svc-qsx5w
Dec 21 13:05:11.026: INFO: Created: latency-svc-h5k4h
Dec 21 13:05:11.039: INFO: Created: latency-svc-4bfr9
Dec 21 13:05:11.042: INFO: Got endpoints: latency-svc-x5fl5 [283.954687ms]
Dec 21 13:05:11.049: INFO: Created: latency-svc-6dpcf
Dec 21 13:05:11.059: INFO: Created: latency-svc-9z896
Dec 21 13:05:11.065: INFO: Created: latency-svc-4vl6f
Dec 21 13:05:11.068: INFO: Created: latency-svc-7k5fw
Dec 21 13:05:11.074: INFO: Created: latency-svc-qszks
Dec 21 13:05:11.079: INFO: Created: latency-svc-h9lr8
Dec 21 13:05:11.084: INFO: Created: latency-svc-qt8ck
Dec 21 13:05:11.087: INFO: Got endpoints: latency-svc-lfbfr [320.884733ms]
Dec 21 13:05:11.106: INFO: Created: latency-svc-wqjw4
Dec 21 13:05:11.113: INFO: Created: latency-svc-lrhv7
Dec 21 13:05:11.124: INFO: Created: latency-svc-5sjr4
Dec 21 13:05:11.131: INFO: Created: latency-svc-7qbjt
Dec 21 13:05:11.135: INFO: Created: latency-svc-dzpln
Dec 21 13:05:11.137: INFO: Got endpoints: latency-svc-qsx5w [360.436703ms]
Dec 21 13:05:11.149: INFO: Created: latency-svc-29qh2
Dec 21 13:05:11.188: INFO: Got endpoints: latency-svc-h5k4h [402.739573ms]
Dec 21 13:05:11.198: INFO: Created: latency-svc-c6rtv
Dec 21 13:05:11.239: INFO: Got endpoints: latency-svc-4bfr9 [429.286819ms]
Dec 21 13:05:11.249: INFO: Created: latency-svc-h248t
Dec 21 13:05:11.288: INFO: Got endpoints: latency-svc-6dpcf [451.453062ms]
Dec 21 13:05:11.303: INFO: Created: latency-svc-bcr58
Dec 21 13:05:11.347: INFO: Got endpoints: latency-svc-9z896 [479.051448ms]
Dec 21 13:05:11.360: INFO: Created: latency-svc-htbjk
Dec 21 13:05:11.386: INFO: Got endpoints: latency-svc-4vl6f [501.614311ms]
Dec 21 13:05:11.397: INFO: Created: latency-svc-2l6rp
Dec 21 13:05:11.439: INFO: Got endpoints: latency-svc-7k5fw [542.867812ms]
Dec 21 13:05:11.449: INFO: Created: latency-svc-jgsrz
Dec 21 13:05:11.498: INFO: Got endpoints: latency-svc-qszks [589.689016ms]
Dec 21 13:05:11.511: INFO: Created: latency-svc-52vp8
Dec 21 13:05:11.545: INFO: Got endpoints: latency-svc-h9lr8 [621.599581ms]
Dec 21 13:05:11.556: INFO: Created: latency-svc-n9kgq
Dec 21 13:05:11.590: INFO: Got endpoints: latency-svc-qt8ck [642.829475ms]
Dec 21 13:05:11.600: INFO: Created: latency-svc-5k5wm
Dec 21 13:05:11.638: INFO: Got endpoints: latency-svc-wqjw4 [685.328228ms]
Dec 21 13:05:11.657: INFO: Created: latency-svc-56wgw
Dec 21 13:05:11.688: INFO: Got endpoints: latency-svc-lrhv7 [732.386756ms]
Dec 21 13:05:11.704: INFO: Created: latency-svc-b8czq
Dec 21 13:05:11.737: INFO: Got endpoints: latency-svc-5sjr4 [724.871156ms]
Dec 21 13:05:11.760: INFO: Created: latency-svc-28f2j
Dec 21 13:05:11.786: INFO: Got endpoints: latency-svc-7qbjt [743.560117ms]
Dec 21 13:05:11.799: INFO: Created: latency-svc-cwq72
Dec 21 13:05:11.836: INFO: Got endpoints: latency-svc-dzpln [749.076051ms]
Dec 21 13:05:11.849: INFO: Created: latency-svc-247lf
Dec 21 13:05:11.886: INFO: Got endpoints: latency-svc-29qh2 [748.830795ms]
Dec 21 13:05:11.900: INFO: Created: latency-svc-lppcx
Dec 21 13:05:11.937: INFO: Got endpoints: latency-svc-c6rtv [748.816384ms]
Dec 21 13:05:11.957: INFO: Created: latency-svc-zkq92
Dec 21 13:05:11.988: INFO: Got endpoints: latency-svc-h248t [748.544171ms]
Dec 21 13:05:12.000: INFO: Created: latency-svc-2qbqj
Dec 21 13:05:12.041: INFO: Got endpoints: latency-svc-bcr58 [753.179037ms]
Dec 21 13:05:12.054: INFO: Created: latency-svc-hblb4
Dec 21 13:05:12.088: INFO: Got endpoints: latency-svc-htbjk [741.27967ms]
Dec 21 13:05:12.109: INFO: Created: latency-svc-xvddr
Dec 21 13:05:12.140: INFO: Got endpoints: latency-svc-2l6rp [754.061965ms]
Dec 21 13:05:12.156: INFO: Created: latency-svc-gdwq9
Dec 21 13:05:12.188: INFO: Got endpoints: latency-svc-jgsrz [748.740303ms]
Dec 21 13:05:12.202: INFO: Created: latency-svc-tv7b8
Dec 21 13:05:12.240: INFO: Got endpoints: latency-svc-52vp8 [742.000789ms]
Dec 21 13:05:12.255: INFO: Created: latency-svc-z7s47
Dec 21 13:05:12.289: INFO: Got endpoints: latency-svc-n9kgq [743.084028ms]
Dec 21 13:05:12.299: INFO: Created: latency-svc-jjbfp
Dec 21 13:05:12.337: INFO: Got endpoints: latency-svc-5k5wm [747.6693ms]
Dec 21 13:05:12.360: INFO: Created: latency-svc-pb9xk
Dec 21 13:05:12.385: INFO: Got endpoints: latency-svc-56wgw [747.581577ms]
Dec 21 13:05:12.396: INFO: Created: latency-svc-4z7xz
Dec 21 13:05:12.440: INFO: Got endpoints: latency-svc-b8czq [751.928605ms]
Dec 21 13:05:12.451: INFO: Created: latency-svc-pv7jb
Dec 21 13:05:12.489: INFO: Got endpoints: latency-svc-28f2j [752.223775ms]
Dec 21 13:05:12.500: INFO: Created: latency-svc-fh9jq
Dec 21 13:05:12.538: INFO: Got endpoints: latency-svc-cwq72 [752.152677ms]
Dec 21 13:05:12.551: INFO: Created: latency-svc-r67c9
Dec 21 13:05:12.589: INFO: Got endpoints: latency-svc-247lf [752.183685ms]
Dec 21 13:05:12.600: INFO: Created: latency-svc-7jbtr
Dec 21 13:05:12.639: INFO: Got endpoints: latency-svc-lppcx [752.696522ms]
Dec 21 13:05:12.650: INFO: Created: latency-svc-lhk57
Dec 21 13:05:12.690: INFO: Got endpoints: latency-svc-zkq92 [752.678474ms]
Dec 21 13:05:12.702: INFO: Created: latency-svc-rd2nn
Dec 21 13:05:12.737: INFO: Got endpoints: latency-svc-2qbqj [749.41ms]
Dec 21 13:05:12.747: INFO: Created: latency-svc-pw7br
Dec 21 13:05:12.788: INFO: Got endpoints: latency-svc-hblb4 [746.136163ms]
Dec 21 13:05:12.797: INFO: Created: latency-svc-gbkng
Dec 21 13:05:12.836: INFO: Got endpoints: latency-svc-xvddr [748.059213ms]
Dec 21 13:05:12.858: INFO: Created: latency-svc-pfkr4
Dec 21 13:05:12.886: INFO: Got endpoints: latency-svc-gdwq9 [742.259164ms]
Dec 21 13:05:12.897: INFO: Created: latency-svc-zdxdw
Dec 21 13:05:12.936: INFO: Got endpoints: latency-svc-tv7b8 [748.378493ms]
Dec 21 13:05:12.947: INFO: Created: latency-svc-zblzx
Dec 21 13:05:12.987: INFO: Got endpoints: latency-svc-z7s47 [745.100328ms]
Dec 21 13:05:13.003: INFO: Created: latency-svc-hnncs
Dec 21 13:05:13.055: INFO: Got endpoints: latency-svc-jjbfp [765.641349ms]
Dec 21 13:05:13.068: INFO: Created: latency-svc-dtnpq
Dec 21 13:05:13.085: INFO: Got endpoints: latency-svc-pb9xk [747.382524ms]
Dec 21 13:05:13.094: INFO: Created: latency-svc-ljhdg
Dec 21 13:05:13.139: INFO: Got endpoints: latency-svc-4z7xz [753.643069ms]
Dec 21 13:05:13.149: INFO: Created: latency-svc-5qvjt
Dec 21 13:05:13.195: INFO: Got endpoints: latency-svc-pv7jb [754.779675ms]
Dec 21 13:05:13.217: INFO: Created: latency-svc-27zfp
Dec 21 13:05:13.236: INFO: Got endpoints: latency-svc-fh9jq [746.287362ms]
Dec 21 13:05:13.248: INFO: Created: latency-svc-7cbsr
Dec 21 13:05:13.288: INFO: Got endpoints: latency-svc-r67c9 [749.192126ms]
Dec 21 13:05:13.300: INFO: Created: latency-svc-pzhn7
Dec 21 13:05:13.338: INFO: Got endpoints: latency-svc-7jbtr [748.735415ms]
Dec 21 13:05:13.351: INFO: Created: latency-svc-9b9hx
Dec 21 13:05:13.387: INFO: Got endpoints: latency-svc-lhk57 [747.895666ms]
Dec 21 13:05:13.396: INFO: Created: latency-svc-47bgd
Dec 21 13:05:13.438: INFO: Got endpoints: latency-svc-rd2nn [747.676187ms]
Dec 21 13:05:13.448: INFO: Created: latency-svc-nxmds
Dec 21 13:05:13.489: INFO: Got endpoints: latency-svc-pw7br [751.766644ms]
Dec 21 13:05:13.501: INFO: Created: latency-svc-8nv6b
Dec 21 13:05:13.539: INFO: Got endpoints: latency-svc-gbkng [750.764887ms]
Dec 21 13:05:13.552: INFO: Created: latency-svc-k4dwv
Dec 21 13:05:13.588: INFO: Got endpoints: latency-svc-pfkr4 [749.581513ms]
Dec 21 13:05:13.601: INFO: Created: latency-svc-88wks
Dec 21 13:05:13.638: INFO: Got endpoints: latency-svc-zdxdw [752.289162ms]
Dec 21 13:05:13.652: INFO: Created: latency-svc-wk6gp
Dec 21 13:05:13.688: INFO: Got endpoints: latency-svc-zblzx [751.506112ms]
Dec 21 13:05:13.697: INFO: Created: latency-svc-vz9t8
Dec 21 13:05:13.742: INFO: Got endpoints: latency-svc-hnncs [755.24622ms]
Dec 21 13:05:13.755: INFO: Created: latency-svc-x96cr
Dec 21 13:05:13.787: INFO: Got endpoints: latency-svc-dtnpq [731.89239ms]
Dec 21 13:05:13.797: INFO: Created: latency-svc-x46l4
Dec 21 13:05:13.838: INFO: Got endpoints: latency-svc-ljhdg [752.253695ms]
Dec 21 13:05:13.848: INFO: Created: latency-svc-f7hbm
Dec 21 13:05:13.887: INFO: Got endpoints: latency-svc-5qvjt [747.800985ms]
Dec 21 13:05:13.900: INFO: Created: latency-svc-vgwrh
Dec 21 13:05:13.938: INFO: Got endpoints: latency-svc-27zfp [742.970654ms]
Dec 21 13:05:13.951: INFO: Created: latency-svc-sgt9r
Dec 21 13:05:13.986: INFO: Got endpoints: latency-svc-7cbsr [750.292251ms]
Dec 21 13:05:13.996: INFO: Created: latency-svc-ccdz9
Dec 21 13:05:14.039: INFO: Got endpoints: latency-svc-pzhn7 [751.295527ms]
Dec 21 13:05:14.056: INFO: Created: latency-svc-2k48p
Dec 21 13:05:14.092: INFO: Got endpoints: latency-svc-9b9hx [754.027401ms]
Dec 21 13:05:14.106: INFO: Created: latency-svc-6kbwb
Dec 21 13:05:14.148: INFO: Got endpoints: latency-svc-47bgd [760.667107ms]
Dec 21 13:05:14.160: INFO: Created: latency-svc-x45l6
Dec 21 13:05:14.185: INFO: Got endpoints: latency-svc-nxmds [747.83067ms]
Dec 21 13:05:14.197: INFO: Created: latency-svc-56qxh
Dec 21 13:05:14.246: INFO: Got endpoints: latency-svc-8nv6b [757.154121ms]
Dec 21 13:05:14.260: INFO: Created: latency-svc-rhmtc
Dec 21 13:05:14.287: INFO: Got endpoints: latency-svc-k4dwv [747.731234ms]
Dec 21 13:05:14.298: INFO: Created: latency-svc-pc548
Dec 21 13:05:14.338: INFO: Got endpoints: latency-svc-88wks [749.748721ms]
Dec 21 13:05:14.354: INFO: Created: latency-svc-6j9dv
Dec 21 13:05:14.387: INFO: Got endpoints: latency-svc-wk6gp [748.419715ms]
Dec 21 13:05:14.398: INFO: Created: latency-svc-f25vx
Dec 21 13:05:14.439: INFO: Got endpoints: latency-svc-vz9t8 [750.668585ms]
Dec 21 13:05:14.450: INFO: Created: latency-svc-84248
Dec 21 13:05:14.486: INFO: Got endpoints: latency-svc-x96cr [743.946415ms]
Dec 21 13:05:14.496: INFO: Created: latency-svc-7gzn2
Dec 21 13:05:14.538: INFO: Got endpoints: latency-svc-x46l4 [750.676473ms]
Dec 21 13:05:14.550: INFO: Created: latency-svc-lfcwx
Dec 21 13:05:14.586: INFO: Got endpoints: latency-svc-f7hbm [748.004514ms]
Dec 21 13:05:14.597: INFO: Created: latency-svc-djfh8
Dec 21 13:05:14.640: INFO: Got endpoints: latency-svc-vgwrh [749.999379ms]
Dec 21 13:05:14.656: INFO: Created: latency-svc-gr656
Dec 21 13:05:14.686: INFO: Got endpoints: latency-svc-sgt9r [746.748243ms]
Dec 21 13:05:14.695: INFO: Created: latency-svc-ffpbl
Dec 21 13:05:14.742: INFO: Got endpoints: latency-svc-ccdz9 [755.235553ms]
Dec 21 13:05:14.751: INFO: Created: latency-svc-5bj9m
Dec 21 13:05:14.790: INFO: Got endpoints: latency-svc-2k48p [751.024125ms]
Dec 21 13:05:14.800: INFO: Created: latency-svc-5s5d2
Dec 21 13:05:14.845: INFO: Got endpoints: latency-svc-6kbwb [752.881579ms]
Dec 21 13:05:14.864: INFO: Created: latency-svc-6zkcd
Dec 21 13:05:14.886: INFO: Got endpoints: latency-svc-x45l6 [738.384303ms]
Dec 21 13:05:14.898: INFO: Created: latency-svc-xgr75
Dec 21 13:05:14.936: INFO: Got endpoints: latency-svc-56qxh [750.702455ms]
Dec 21 13:05:14.947: INFO: Created: latency-svc-dw8xz
Dec 21 13:05:14.987: INFO: Got endpoints: latency-svc-rhmtc [741.012104ms]
Dec 21 13:05:14.998: INFO: Created: latency-svc-mp8ts
Dec 21 13:05:15.039: INFO: Got endpoints: latency-svc-pc548 [751.330995ms]
Dec 21 13:05:15.050: INFO: Created: latency-svc-kjk5f
Dec 21 13:05:15.088: INFO: Got endpoints: latency-svc-6j9dv [750.205219ms]
Dec 21 13:05:15.098: INFO: Created: latency-svc-jx9dm
Dec 21 13:05:15.147: INFO: Got endpoints: latency-svc-f25vx [759.548118ms]
Dec 21 13:05:15.158: INFO: Created: latency-svc-zksqg
Dec 21 13:05:15.187: INFO: Got endpoints: latency-svc-84248 [747.814075ms]
Dec 21 13:05:15.198: INFO: Created: latency-svc-pc8kj
Dec 21 13:05:15.247: INFO: Got endpoints: latency-svc-7gzn2 [760.396875ms]
Dec 21 13:05:15.281: INFO: Created: latency-svc-jjtjs
Dec 21 13:05:15.287: INFO: Got endpoints: latency-svc-lfcwx [748.711175ms]
Dec 21 13:05:15.307: INFO: Created: latency-svc-mtcmt
Dec 21 13:05:15.339: INFO: Got endpoints: latency-svc-djfh8 [752.697417ms]
Dec 21 13:05:15.366: INFO: Created: latency-svc-qm6wr
Dec 21 13:05:15.386: INFO: Got endpoints: latency-svc-gr656 [744.722448ms]
Dec 21 13:05:15.399: INFO: Created: latency-svc-j8sl9
Dec 21 13:05:15.438: INFO: Got endpoints: latency-svc-ffpbl [752.513061ms]
Dec 21 13:05:15.449: INFO: Created: latency-svc-rs2xh
Dec 21 13:05:15.487: INFO: Got endpoints: latency-svc-5bj9m [745.365674ms]
Dec 21 13:05:15.498: INFO: Created: latency-svc-twfs8
Dec 21 13:05:15.539: INFO: Got endpoints: latency-svc-5s5d2 [748.691691ms]
Dec 21 13:05:15.557: INFO: Created: latency-svc-jckc2
Dec 21 13:05:15.586: INFO: Got endpoints: latency-svc-6zkcd [741.40675ms]
Dec 21 13:05:15.598: INFO: Created: latency-svc-kkpg5
Dec 21 13:05:15.644: INFO: Got endpoints: latency-svc-xgr75 [757.391956ms]
Dec 21 13:05:15.655: INFO: Created: latency-svc-tjx7p
Dec 21 13:05:15.688: INFO: Got endpoints: latency-svc-dw8xz [751.538515ms]
Dec 21 13:05:15.713: INFO: Created: latency-svc-th559
Dec 21 13:05:15.736: INFO: Got endpoints: latency-svc-mp8ts [748.750284ms]
Dec 21 13:05:15.753: INFO: Created: latency-svc-qq72n
Dec 21 13:05:15.797: INFO: Got endpoints: latency-svc-kjk5f [757.815157ms]
Dec 21 13:05:15.808: INFO: Created: latency-svc-5dc7t
Dec 21 13:05:15.844: INFO: Got endpoints: latency-svc-jx9dm [755.854511ms]
Dec 21 13:05:15.857: INFO: Created: latency-svc-gpmvb
Dec 21 13:05:15.886: INFO: Got endpoints: latency-svc-zksqg [739.220227ms]
Dec 21 13:05:15.897: INFO: Created: latency-svc-z2wjm
Dec 21 13:05:15.952: INFO: Got endpoints: latency-svc-pc8kj [764.386114ms]
Dec 21 13:05:15.966: INFO: Created: latency-svc-jzjzr
Dec 21 13:05:15.991: INFO: Got endpoints: latency-svc-jjtjs [744.158599ms]
Dec 21 13:05:16.004: INFO: Created: latency-svc-kszcw
Dec 21 13:05:16.036: INFO: Got endpoints: latency-svc-mtcmt [749.456421ms]
Dec 21 13:05:16.049: INFO: Created: latency-svc-68b89
Dec 21 13:05:16.094: INFO: Got endpoints: latency-svc-qm6wr [754.559564ms]
Dec 21 13:05:16.104: INFO: Created: latency-svc-c9n9s
Dec 21 13:05:16.146: INFO: Got endpoints: latency-svc-j8sl9 [760.380996ms]
Dec 21 13:05:16.163: INFO: Created: latency-svc-sbln9
Dec 21 13:05:16.193: INFO: Got endpoints: latency-svc-rs2xh [754.6843ms]
Dec 21 13:05:16.205: INFO: Created: latency-svc-l4dbw
Dec 21 13:05:16.237: INFO: Got endpoints: latency-svc-twfs8 [749.075115ms]
Dec 21 13:05:16.246: INFO: Created: latency-svc-qpd25
Dec 21 13:05:16.287: INFO: Got endpoints: latency-svc-jckc2 [747.267961ms]
Dec 21 13:05:16.303: INFO: Created: latency-svc-2cxsj
Dec 21 13:05:16.338: INFO: Got endpoints: latency-svc-kkpg5 [751.308486ms]
Dec 21 13:05:16.349: INFO: Created: latency-svc-kbvrf
Dec 21 13:05:16.387: INFO: Got endpoints: latency-svc-tjx7p [743.273155ms]
Dec 21 13:05:16.396: INFO: Created: latency-svc-z6gdh
Dec 21 13:05:16.436: INFO: Got endpoints: latency-svc-th559 [748.153237ms]
Dec 21 13:05:16.446: INFO: Created: latency-svc-pbxq7
Dec 21 13:05:16.488: INFO: Got endpoints: latency-svc-qq72n [751.963868ms]
Dec 21 13:05:16.501: INFO: Created: latency-svc-s2zkw
Dec 21 13:05:16.537: INFO: Got endpoints: latency-svc-5dc7t [740.059695ms]
Dec 21 13:05:16.546: INFO: Created: latency-svc-67z6m
Dec 21 13:05:16.587: INFO: Got endpoints: latency-svc-gpmvb [742.615497ms]
Dec 21 13:05:16.600: INFO: Created: latency-svc-pz9dx
Dec 21 13:05:16.638: INFO: Got endpoints: latency-svc-z2wjm [751.483955ms]
Dec 21 13:05:16.649: INFO: Created: latency-svc-4spx7
Dec 21 13:05:16.687: INFO: Got endpoints: latency-svc-jzjzr [735.500434ms]
Dec 21 13:05:16.697: INFO: Created: latency-svc-6k9gx
Dec 21 13:05:16.751: INFO: Got endpoints: latency-svc-kszcw [759.268063ms]
Dec 21 13:05:16.762: INFO: Created: latency-svc-7pw2p
Dec 21 13:05:16.786: INFO: Got endpoints: latency-svc-68b89 [749.852538ms]
Dec 21 13:05:16.796: INFO: Created: latency-svc-hx4rl
Dec 21 13:05:16.837: INFO: Got endpoints: latency-svc-c9n9s [743.529731ms]
Dec 21 13:05:16.847: INFO: Created: latency-svc-vksx9
Dec 21 13:05:16.886: INFO: Got endpoints: latency-svc-sbln9 [738.831986ms]
Dec 21 13:05:16.895: INFO: Created: latency-svc-5ghjd
Dec 21 13:05:16.938: INFO: Got endpoints: latency-svc-l4dbw [744.460977ms]
Dec 21 13:05:16.948: INFO: Created: latency-svc-2hsgn
Dec 21 13:05:16.987: INFO: Got endpoints: latency-svc-qpd25 [750.278216ms]
Dec 21 13:05:16.996: INFO: Created: latency-svc-x2nqj
Dec 21 13:05:17.039: INFO: Got endpoints: latency-svc-2cxsj [752.084503ms]
Dec 21 13:05:17.051: INFO: Created: latency-svc-ld4zj
Dec 21 13:05:17.087: INFO: Got endpoints: latency-svc-kbvrf [748.758475ms]
Dec 21 13:05:17.097: INFO: Created: latency-svc-6jj6w
Dec 21 13:05:17.135: INFO: Got endpoints: latency-svc-z6gdh [748.004182ms]
Dec 21 13:05:17.146: INFO: Created: latency-svc-8np2m
Dec 21 13:05:17.194: INFO: Got endpoints: latency-svc-pbxq7 [757.422364ms]
Dec 21 13:05:17.210: INFO: Created: latency-svc-z56m4
Dec 21 13:05:17.241: INFO: Got endpoints: latency-svc-s2zkw [752.379004ms]
Dec 21 13:05:17.254: INFO: Created: latency-svc-szkst
Dec 21 13:05:17.290: INFO: Got endpoints: latency-svc-67z6m [752.247053ms]
Dec 21 13:05:17.310: INFO: Created: latency-svc-lcjbx
Dec 21 13:05:17.350: INFO: Got endpoints: latency-svc-pz9dx [762.931574ms]
Dec 21 13:05:17.369: INFO: Created: latency-svc-6t76k
Dec 21 13:05:17.388: INFO: Got endpoints: latency-svc-4spx7 [750.60859ms]
Dec 21 13:05:17.403: INFO: Created: latency-svc-5sxcw
Dec 21 13:05:17.447: INFO: Got endpoints: latency-svc-6k9gx [759.824226ms]
Dec 21 13:05:17.462: INFO: Created: latency-svc-wk64c
Dec 21 13:05:17.488: INFO: Got endpoints: latency-svc-7pw2p [736.815299ms]
Dec 21 13:05:17.500: INFO: Created: latency-svc-zbhwg
Dec 21 13:05:17.540: INFO: Got endpoints: latency-svc-hx4rl [753.786233ms]
Dec 21 13:05:17.551: INFO: Created: latency-svc-vcdbq
Dec 21 13:05:17.588: INFO: Got endpoints: latency-svc-vksx9 [749.919012ms]
Dec 21 13:05:17.597: INFO: Created: latency-svc-k7qv4
Dec 21 13:05:17.637: INFO: Got endpoints: latency-svc-5ghjd [750.767754ms]
Dec 21 13:05:17.648: INFO: Created: latency-svc-wbl6k
Dec 21 13:05:17.686: INFO: Got endpoints: latency-svc-2hsgn [748.055189ms]
Dec 21 13:05:17.696: INFO: Created: latency-svc-gg4nm
Dec 21 13:05:17.736: INFO: Got endpoints: latency-svc-x2nqj [749.056874ms]
Dec 21 13:05:17.754: INFO: Created: latency-svc-jbjh5
Dec 21 13:05:17.787: INFO: Got endpoints: latency-svc-ld4zj [747.259006ms]
Dec 21 13:05:17.816: INFO: Created: latency-svc-sdgtt
Dec 21 13:05:17.841: INFO: Got endpoints: latency-svc-6jj6w [754.029133ms]
Dec 21 13:05:17.857: INFO: Created: latency-svc-r8w5r
Dec 21 13:05:17.886: INFO: Got endpoints: latency-svc-8np2m [750.45203ms]
Dec 21 13:05:17.899: INFO: Created: latency-svc-xp89s
Dec 21 13:05:17.937: INFO: Got endpoints: latency-svc-z56m4 [741.935571ms]
Dec 21 13:05:17.947: INFO: Created: latency-svc-hthbl
Dec 21 13:05:17.990: INFO: Got endpoints: latency-svc-szkst [748.80878ms]
Dec 21 13:05:18.002: INFO: Created: latency-svc-dqxqc
Dec 21 13:05:18.037: INFO: Got endpoints: latency-svc-lcjbx [747.009644ms]
Dec 21 13:05:18.050: INFO: Created: latency-svc-z5mwg
Dec 21 13:05:18.089: INFO: Got endpoints: latency-svc-6t76k [737.979808ms]
Dec 21 13:05:18.103: INFO: Created: latency-svc-wq69g
Dec 21 13:05:18.146: INFO: Got endpoints: latency-svc-5sxcw [757.176351ms]
Dec 21 13:05:18.162: INFO: Created: latency-svc-b2chv
Dec 21 13:05:18.189: INFO: Got endpoints: latency-svc-wk64c [739.306476ms]
Dec 21 13:05:18.207: INFO: Created: latency-svc-rkbwr
Dec 21 13:05:18.240: INFO: Got endpoints: latency-svc-zbhwg [752.35326ms]
Dec 21 13:05:18.257: INFO: Created: latency-svc-jhqkx
Dec 21 13:05:18.288: INFO: Got endpoints: latency-svc-vcdbq [747.673492ms]
Dec 21 13:05:18.339: INFO: Got endpoints: latency-svc-k7qv4 [751.424023ms]
Dec 21 13:05:18.386: INFO: Got endpoints: latency-svc-wbl6k [749.320177ms]
Dec 21 13:05:18.441: INFO: Got endpoints: latency-svc-gg4nm [754.069326ms]
Dec 21 13:05:18.487: INFO: Got endpoints: latency-svc-jbjh5 [747.095119ms]
Dec 21 13:05:18.538: INFO: Got endpoints: latency-svc-sdgtt [751.647866ms]
Dec 21 13:05:18.586: INFO: Got endpoints: latency-svc-r8w5r [743.653901ms]
Dec 21 13:05:18.637: INFO: Got endpoints: latency-svc-xp89s [750.530371ms]
Dec 21 13:05:18.688: INFO: Got endpoints: latency-svc-hthbl [751.667567ms]
Dec 21 13:05:18.737: INFO: Got endpoints: latency-svc-dqxqc [746.136205ms]
Dec 21 13:05:18.788: INFO: Got endpoints: latency-svc-z5mwg [749.862502ms]
Dec 21 13:05:18.840: INFO: Got endpoints: latency-svc-wq69g [751.285816ms]
Dec 21 13:05:18.898: INFO: Got endpoints: latency-svc-b2chv [752.402445ms]
Dec 21 13:05:18.938: INFO: Got endpoints: latency-svc-rkbwr [748.713889ms]
Dec 21 13:05:18.990: INFO: Got endpoints: latency-svc-jhqkx [745.770757ms]
Dec 21 13:05:18.990: INFO: Latencies: [21.502144ms 25.055285ms 35.87088ms 45.631988ms 49.068153ms 59.443929ms 73.438645ms 79.718895ms 83.102909ms 94.163038ms 99.366194ms 105.494258ms 113.405705ms 114.608004ms 114.9327ms 118.470475ms 125.119923ms 125.965326ms 135.410739ms 138.074508ms 176.848771ms 192.438655ms 194.141861ms 200.998544ms 210.13847ms 211.64286ms 213.568589ms 214.475726ms 220.505931ms 224.383119ms 226.707212ms 231.726439ms 234.706646ms 241.351025ms 256.639472ms 260.257666ms 267.839267ms 274.634583ms 278.955959ms 279.279595ms 283.954687ms 320.884733ms 360.436703ms 402.739573ms 429.286819ms 451.453062ms 479.051448ms 501.614311ms 542.867812ms 589.689016ms 621.599581ms 642.829475ms 685.328228ms 724.871156ms 731.89239ms 732.386756ms 735.500434ms 736.815299ms 737.979808ms 738.384303ms 738.831986ms 739.220227ms 739.306476ms 740.059695ms 741.012104ms 741.27967ms 741.40675ms 741.935571ms 742.000789ms 742.259164ms 742.615497ms 742.970654ms 743.084028ms 743.273155ms 743.529731ms 743.560117ms 743.653901ms 743.946415ms 744.158599ms 744.460977ms 744.722448ms 745.100328ms 745.365674ms 745.770757ms 746.136163ms 746.136205ms 746.287362ms 746.748243ms 747.009644ms 747.095119ms 747.259006ms 747.267961ms 747.382524ms 747.581577ms 747.6693ms 747.673492ms 747.676187ms 747.731234ms 747.800985ms 747.814075ms 747.83067ms 747.895666ms 748.004182ms 748.004514ms 748.055189ms 748.059213ms 748.153237ms 748.378493ms 748.419715ms 748.544171ms 748.691691ms 748.711175ms 748.713889ms 748.735415ms 748.740303ms 748.750284ms 748.758475ms 748.80878ms 748.816384ms 748.830795ms 749.056874ms 749.075115ms 749.076051ms 749.192126ms 749.320177ms 749.41ms 749.456421ms 749.581513ms 749.748721ms 749.852538ms 749.862502ms 749.919012ms 749.999379ms 750.205219ms 750.278216ms 750.292251ms 750.45203ms 750.530371ms 750.60859ms 750.668585ms 750.676473ms 750.702455ms 750.764887ms 750.767754ms 751.024125ms 751.285816ms 751.295527ms 751.308486ms 751.330995ms 751.424023ms 751.483955ms 751.506112ms 751.538515ms 751.647866ms 751.667567ms 751.766644ms 751.928605ms 751.963868ms 752.084503ms 752.152677ms 752.183685ms 752.223775ms 752.247053ms 752.253695ms 752.289162ms 752.35326ms 752.379004ms 752.402445ms 752.513061ms 752.678474ms 752.696522ms 752.697417ms 752.881579ms 753.179037ms 753.643069ms 753.786233ms 754.027401ms 754.029133ms 754.061965ms 754.069326ms 754.559564ms 754.6843ms 754.779675ms 755.235553ms 755.24622ms 755.854511ms 757.154121ms 757.176351ms 757.391956ms 757.422364ms 757.815157ms 759.268063ms 759.548118ms 759.824226ms 760.380996ms 760.396875ms 760.667107ms 762.931574ms 764.386114ms 765.641349ms]
Dec 21 13:05:18.990: INFO: 50 %ile: 747.83067ms
Dec 21 13:05:18.990: INFO: 90 %ile: 754.559564ms
Dec 21 13:05:18.990: INFO: 99 %ile: 764.386114ms
Dec 21 13:05:18.990: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:05:18.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3598" for this suite.

• [SLOW TEST:10.965 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":273,"completed":220,"skipped":3710,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:05:19.010: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-217
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 21 13:05:19.191: INFO: Waiting up to 5m0s for pod "pod-c43e885a-87fc-4cb7-8b6a-c90a40ea547c" in namespace "emptydir-217" to be "Succeeded or Failed"
Dec 21 13:05:19.204: INFO: Pod "pod-c43e885a-87fc-4cb7-8b6a-c90a40ea547c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.461805ms
Dec 21 13:05:21.209: INFO: Pod "pod-c43e885a-87fc-4cb7-8b6a-c90a40ea547c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017763076s
STEP: Saw pod success
Dec 21 13:05:21.209: INFO: Pod "pod-c43e885a-87fc-4cb7-8b6a-c90a40ea547c" satisfied condition "Succeeded or Failed"
Dec 21 13:05:21.220: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-c43e885a-87fc-4cb7-8b6a-c90a40ea547c container test-container: <nil>
STEP: delete the pod
Dec 21 13:05:21.255: INFO: Waiting for pod pod-c43e885a-87fc-4cb7-8b6a-c90a40ea547c to disappear
Dec 21 13:05:21.259: INFO: Pod pod-c43e885a-87fc-4cb7-8b6a-c90a40ea547c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:05:21.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-217" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":221,"skipped":3738,"failed":0}
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:05:21.274: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 21 13:05:23.558: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:05:23.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4573" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":273,"completed":222,"skipped":3744,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:05:23.610: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8819
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-3285e28d-c468-4f33-b86c-2128cfe8112d
STEP: Creating a pod to test consume secrets
Dec 21 13:05:23.808: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bbb48eee-5784-4e10-a27b-f128145f0d04" in namespace "projected-8819" to be "Succeeded or Failed"
Dec 21 13:05:23.813: INFO: Pod "pod-projected-secrets-bbb48eee-5784-4e10-a27b-f128145f0d04": Phase="Pending", Reason="", readiness=false. Elapsed: 4.529315ms
Dec 21 13:05:25.820: INFO: Pod "pod-projected-secrets-bbb48eee-5784-4e10-a27b-f128145f0d04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012013753s
STEP: Saw pod success
Dec 21 13:05:25.820: INFO: Pod "pod-projected-secrets-bbb48eee-5784-4e10-a27b-f128145f0d04" satisfied condition "Succeeded or Failed"
Dec 21 13:05:25.831: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-projected-secrets-bbb48eee-5784-4e10-a27b-f128145f0d04 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 13:05:25.892: INFO: Waiting for pod pod-projected-secrets-bbb48eee-5784-4e10-a27b-f128145f0d04 to disappear
Dec 21 13:05:25.895: INFO: Pod pod-projected-secrets-bbb48eee-5784-4e10-a27b-f128145f0d04 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:05:25.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8819" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":273,"completed":223,"skipped":3750,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:05:25.913: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7045
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:05:26.079: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 21 13:05:29.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-7045 create -f -'
Dec 21 13:05:30.501: INFO: stderr: ""
Dec 21 13:05:30.501: INFO: stdout: "e2e-test-crd-publish-openapi-4198-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 21 13:05:30.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-7045 delete e2e-test-crd-publish-openapi-4198-crds test-cr'
Dec 21 13:05:30.621: INFO: stderr: ""
Dec 21 13:05:30.621: INFO: stdout: "e2e-test-crd-publish-openapi-4198-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 21 13:05:30.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-7045 apply -f -'
Dec 21 13:05:30.875: INFO: stderr: ""
Dec 21 13:05:30.875: INFO: stdout: "e2e-test-crd-publish-openapi-4198-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 21 13:05:30.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-7045 delete e2e-test-crd-publish-openapi-4198-crds test-cr'
Dec 21 13:05:30.991: INFO: stderr: ""
Dec 21 13:05:30.991: INFO: stdout: "e2e-test-crd-publish-openapi-4198-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 21 13:05:30.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 explain e2e-test-crd-publish-openapi-4198-crds'
Dec 21 13:05:31.212: INFO: stderr: ""
Dec 21 13:05:31.212: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4198-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:05:34.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7045" for this suite.

• [SLOW TEST:8.930 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":273,"completed":224,"skipped":3760,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:05:34.844: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3130
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-p6jn
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 13:05:35.021: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-p6jn" in namespace "subpath-3130" to be "Succeeded or Failed"
Dec 21 13:05:35.026: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.662426ms
Dec 21 13:05:37.030: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009192826s
Dec 21 13:05:39.035: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 4.013946215s
Dec 21 13:05:41.060: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 6.039221286s
Dec 21 13:05:43.067: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 8.045696372s
Dec 21 13:05:45.073: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 10.051721476s
Dec 21 13:05:47.079: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 12.058228337s
Dec 21 13:05:49.088: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 14.067011722s
Dec 21 13:05:51.094: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 16.073104413s
Dec 21 13:05:53.099: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 18.077594037s
Dec 21 13:05:55.104: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 20.082889848s
Dec 21 13:05:57.110: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Running", Reason="", readiness=true. Elapsed: 22.088646065s
Dec 21 13:05:59.117: INFO: Pod "pod-subpath-test-downwardapi-p6jn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.095745392s
STEP: Saw pod success
Dec 21 13:05:59.117: INFO: Pod "pod-subpath-test-downwardapi-p6jn" satisfied condition "Succeeded or Failed"
Dec 21 13:05:59.123: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-subpath-test-downwardapi-p6jn container test-container-subpath-downwardapi-p6jn: <nil>
STEP: delete the pod
Dec 21 13:05:59.148: INFO: Waiting for pod pod-subpath-test-downwardapi-p6jn to disappear
Dec 21 13:05:59.151: INFO: Pod pod-subpath-test-downwardapi-p6jn no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-p6jn
Dec 21 13:05:59.151: INFO: Deleting pod "pod-subpath-test-downwardapi-p6jn" in namespace "subpath-3130"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:05:59.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3130" for this suite.

• [SLOW TEST:24.322 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":273,"completed":225,"skipped":3809,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:05:59.170: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8211
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 21 13:05:59.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-8211'
Dec 21 13:05:59.437: INFO: stderr: ""
Dec 21 13:05:59.437: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Dec 21 13:05:59.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 delete pods e2e-test-httpd-pod --namespace=kubectl-8211'
Dec 21 13:06:14.753: INFO: stderr: ""
Dec 21 13:06:14.753: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:06:14.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8211" for this suite.

• [SLOW TEST:15.614 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":273,"completed":226,"skipped":3820,"failed":0}
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:06:14.783: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9463
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9463.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9463.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9463.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9463.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9463.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9463.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9463.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9463.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9463.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9463.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9463.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 198.24.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.24.198_udp@PTR;check="$$(dig +tcp +noall +answer +search 198.24.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.24.198_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9463.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9463.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9463.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9463.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9463.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9463.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9463.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9463.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9463.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9463.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9463.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 198.24.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.24.198_udp@PTR;check="$$(dig +tcp +noall +answer +search 198.24.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.24.198_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 21 13:06:17.121: INFO: Unable to read wheezy_udp@dns-test-service.dns-9463.svc.cluster.local from pod dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206: the server could not find the requested resource (get pods dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206)
Dec 21 13:06:17.133: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9463.svc.cluster.local from pod dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206: the server could not find the requested resource (get pods dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206)
Dec 21 13:06:17.177: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local from pod dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206: the server could not find the requested resource (get pods dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206)
Dec 21 13:06:17.184: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local from pod dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206: the server could not find the requested resource (get pods dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206)
Dec 21 13:06:17.403: INFO: Unable to read jessie_udp@dns-test-service.dns-9463.svc.cluster.local from pod dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206: the server could not find the requested resource (get pods dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206)
Dec 21 13:06:17.426: INFO: Unable to read jessie_tcp@dns-test-service.dns-9463.svc.cluster.local from pod dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206: the server could not find the requested resource (get pods dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206)
Dec 21 13:06:17.434: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local from pod dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206: the server could not find the requested resource (get pods dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206)
Dec 21 13:06:17.442: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local from pod dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206: the server could not find the requested resource (get pods dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206)
Dec 21 13:06:17.656: INFO: Lookups using dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206 failed for: [wheezy_udp@dns-test-service.dns-9463.svc.cluster.local wheezy_tcp@dns-test-service.dns-9463.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local jessie_udp@dns-test-service.dns-9463.svc.cluster.local jessie_tcp@dns-test-service.dns-9463.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9463.svc.cluster.local]

Dec 21 13:06:23.475: INFO: DNS probes using dns-9463/dns-test-88a2ce0b-3e69-45dc-9674-27090e5c9206 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:06:23.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9463" for this suite.

• [SLOW TEST:8.786 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":273,"completed":227,"skipped":3827,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:06:23.569: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5648
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-5a42f278-5cfd-46d8-89e9-ed9b6a3f3fa2 in namespace container-probe-5648
Dec 21 13:06:25.793: INFO: Started pod liveness-5a42f278-5cfd-46d8-89e9-ed9b6a3f3fa2 in namespace container-probe-5648
STEP: checking the pod's current state and verifying that restartCount is present
Dec 21 13:06:25.797: INFO: Initial restart count of pod liveness-5a42f278-5cfd-46d8-89e9-ed9b6a3f3fa2 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:10:26.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5648" for this suite.

• [SLOW TEST:243.027 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":273,"completed":228,"skipped":3835,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:10:26.596: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8505
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-6ad89771-67df-4d33-839c-c583c7b52f95
STEP: Creating a pod to test consume configMaps
Dec 21 13:10:26.806: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f10a03e6-555e-419a-9b3c-70dd73f75fa2" in namespace "projected-8505" to be "Succeeded or Failed"
Dec 21 13:10:26.812: INFO: Pod "pod-projected-configmaps-f10a03e6-555e-419a-9b3c-70dd73f75fa2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.067851ms
Dec 21 13:10:28.818: INFO: Pod "pod-projected-configmaps-f10a03e6-555e-419a-9b3c-70dd73f75fa2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011846436s
STEP: Saw pod success
Dec 21 13:10:28.818: INFO: Pod "pod-projected-configmaps-f10a03e6-555e-419a-9b3c-70dd73f75fa2" satisfied condition "Succeeded or Failed"
Dec 21 13:10:28.823: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-projected-configmaps-f10a03e6-555e-419a-9b3c-70dd73f75fa2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 13:10:28.907: INFO: Waiting for pod pod-projected-configmaps-f10a03e6-555e-419a-9b3c-70dd73f75fa2 to disappear
Dec 21 13:10:28.913: INFO: Pod pod-projected-configmaps-f10a03e6-555e-419a-9b3c-70dd73f75fa2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:10:28.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8505" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":273,"completed":229,"skipped":3838,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:10:28.938: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7714
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:10:33.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7714" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":273,"completed":230,"skipped":3893,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:10:33.560: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6096
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:10:33.723: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:10:34.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6096" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":273,"completed":231,"skipped":3932,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:10:34.295: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 13:10:35.000: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 13:10:37.027: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153035, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153035, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153035, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153035, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 13:10:40.049: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:10:40.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1493" for this suite.
STEP: Destroying namespace "webhook-1493-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.429 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":273,"completed":232,"skipped":3934,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:10:40.759: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:10:40.931: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-cf5d6bdb-7818-4c66-bab4-fb07c000e717" in namespace "security-context-test-1974" to be "Succeeded or Failed"
Dec 21 13:10:40.937: INFO: Pod "busybox-readonly-false-cf5d6bdb-7818-4c66-bab4-fb07c000e717": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055005ms
Dec 21 13:10:42.942: INFO: Pod "busybox-readonly-false-cf5d6bdb-7818-4c66-bab4-fb07c000e717": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010411837s
Dec 21 13:10:42.942: INFO: Pod "busybox-readonly-false-cf5d6bdb-7818-4c66-bab4-fb07c000e717" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:10:42.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1974" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":273,"completed":233,"skipped":3986,"failed":0}

------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:10:42.964: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-tj87
STEP: Creating a pod to test atomic-volume-subpath
Dec 21 13:10:43.197: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-tj87" in namespace "subpath-3247" to be "Succeeded or Failed"
Dec 21 13:10:43.206: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Pending", Reason="", readiness=false. Elapsed: 7.967814ms
Dec 21 13:10:45.211: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 2.013159449s
Dec 21 13:10:47.215: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 4.017814093s
Dec 21 13:10:49.221: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 6.023154473s
Dec 21 13:10:51.227: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 8.029382373s
Dec 21 13:10:53.235: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 10.037626646s
Dec 21 13:10:55.240: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 12.042784215s
Dec 21 13:10:57.245: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 14.047756208s
Dec 21 13:10:59.253: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 16.055426089s
Dec 21 13:11:01.258: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 18.060315567s
Dec 21 13:11:03.266: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Running", Reason="", readiness=true. Elapsed: 20.068274225s
Dec 21 13:11:05.275: INFO: Pod "pod-subpath-test-configmap-tj87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.077024635s
STEP: Saw pod success
Dec 21 13:11:05.275: INFO: Pod "pod-subpath-test-configmap-tj87" satisfied condition "Succeeded or Failed"
Dec 21 13:11:05.279: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-subpath-test-configmap-tj87 container test-container-subpath-configmap-tj87: <nil>
STEP: delete the pod
Dec 21 13:11:05.307: INFO: Waiting for pod pod-subpath-test-configmap-tj87 to disappear
Dec 21 13:11:05.310: INFO: Pod pod-subpath-test-configmap-tj87 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-tj87
Dec 21 13:11:05.310: INFO: Deleting pod "pod-subpath-test-configmap-tj87" in namespace "subpath-3247"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:11:05.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3247" for this suite.

• [SLOW TEST:22.367 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":273,"completed":234,"skipped":3986,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:11:05.331: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8687
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-57ae22b5-4f86-49ea-ab2a-f54d9352fec8
STEP: Creating a pod to test consume secrets
Dec 21 13:11:05.502: INFO: Waiting up to 5m0s for pod "pod-secrets-5a5612e8-5702-46d9-84d6-3c06b9c59b27" in namespace "secrets-8687" to be "Succeeded or Failed"
Dec 21 13:11:05.509: INFO: Pod "pod-secrets-5a5612e8-5702-46d9-84d6-3c06b9c59b27": Phase="Pending", Reason="", readiness=false. Elapsed: 7.223571ms
Dec 21 13:11:07.524: INFO: Pod "pod-secrets-5a5612e8-5702-46d9-84d6-3c06b9c59b27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022305112s
STEP: Saw pod success
Dec 21 13:11:07.524: INFO: Pod "pod-secrets-5a5612e8-5702-46d9-84d6-3c06b9c59b27" satisfied condition "Succeeded or Failed"
Dec 21 13:11:07.528: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-secrets-5a5612e8-5702-46d9-84d6-3c06b9c59b27 container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 13:11:07.563: INFO: Waiting for pod pod-secrets-5a5612e8-5702-46d9-84d6-3c06b9c59b27 to disappear
Dec 21 13:11:07.566: INFO: Pod pod-secrets-5a5612e8-5702-46d9-84d6-3c06b9c59b27 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:11:07.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8687" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":235,"skipped":4029,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:11:07.589: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:11:07.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-8115'
Dec 21 13:11:08.042: INFO: stderr: ""
Dec 21 13:11:08.042: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Dec 21 13:11:08.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-8115'
Dec 21 13:11:08.286: INFO: stderr: ""
Dec 21 13:11:08.286: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Dec 21 13:11:09.290: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 13:11:09.290: INFO: Found 0 / 1
Dec 21 13:11:10.290: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 13:11:10.291: INFO: Found 1 / 1
Dec 21 13:11:10.291: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 21 13:11:10.297: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 13:11:10.297: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 21 13:11:10.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 describe pod agnhost-master-p2lv2 --namespace=kubectl-8115'
Dec 21 13:11:10.501: INFO: stderr: ""
Dec 21 13:11:10.501: INFO: stdout: "Name:         agnhost-master-p2lv2\nNamespace:    kubectl-8115\nPriority:     0\nNode:         ip-172-31-232-239.eu-central-1.compute.internal/172.31.232.239\nStart Time:   Mon, 21 Dec 2020 13:11:08 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 172.25.4.194/32\n              cni.projectcalico.org/podIPs: 172.25.4.194/32\nStatus:       Running\nIP:           172.25.4.194\nIPs:\n  IP:           172.25.4.194\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://8fdf95cd379b63700c53e79558d757367eb5ee86bc99c29ae8380382802735bc\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 21 Dec 2020 13:11:09 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-75mll (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-75mll:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-75mll\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                                      Message\n  ----    ------     ----       ----                                                      -------\n  Normal  Scheduled  <unknown>  default-scheduler                                         Successfully assigned kubectl-8115/agnhost-master-p2lv2 to ip-172-31-232-239.eu-central-1.compute.internal\n  Normal  Pulled     1s         kubelet, ip-172-31-232-239.eu-central-1.compute.internal  Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    1s         kubelet, ip-172-31-232-239.eu-central-1.compute.internal  Created container agnhost-master\n  Normal  Started    1s         kubelet, ip-172-31-232-239.eu-central-1.compute.internal  Started container agnhost-master\n"
Dec 21 13:11:10.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 describe rc agnhost-master --namespace=kubectl-8115'
Dec 21 13:11:10.623: INFO: stderr: ""
Dec 21 13:11:10.623: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-8115\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-master-p2lv2\n"
Dec 21 13:11:10.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 describe service agnhost-master --namespace=kubectl-8115'
Dec 21 13:11:10.728: INFO: stderr: ""
Dec 21 13:11:10.728: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-8115\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.240.21.13\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.25.4.194:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 21 13:11:10.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 describe node ip-172-31-183-240.eu-central-1.compute.internal'
Dec 21 13:11:10.893: INFO: stderr: ""
Dec 21 13:11:10.893: INFO: stdout: "Name:               ip-172-31-183-240.eu-central-1.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t3.small\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-central-1\n                    failure-domain.beta.kubernetes.io/zone=eu-central-1b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-183-240\n                    kubernetes.io/os=linux\n                    machine-controller/owned-by=0e1e37fe-ead9-4348-838f-31fd299e5c9d\n                    node.kubernetes.io/instance-type=t3.small\n                    system/cluster=4qzqhmrf5m\n                    system/project=7rq7pnhncm\n                    topology.kubernetes.io/region=eu-central-1\n                    topology.kubernetes.io/zone=eu-central-1b\n                    x-kubernetes.io/distribution=ubuntu\nAnnotations:        cluster.k8s.io/machine: kube-system/nifty-banach-worker-lvxvw-79947cf-69nx2\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"9a:7f:1f:0a:4d:30\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.31.183.240\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.25.3.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 21 Dec 2020 11:46:17 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-183-240.eu-central-1.compute.internal\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 21 Dec 2020 13:11:01 +0000\nConditions:\n  Type                Status  LastHeartbeatTime                 LastTransitionTime                Reason           Message\n  ----                ------  -----------------                 ------------------                ------           -------\n  MetakubeNodeReady   True    Mon, 21 Dec 2020 13:07:35 +0000   Mon, 21 Dec 2020 11:47:24 +0000   MetakubeNodeUp   Server:    169.254.20.10\nAddress:              169.254.20.10#53\n\nName:                  kubernetes.default.svc.c\n  KernelDeadlock       False   Mon, 21 Dec 2020 13:07:35 +0000   Mon, 21 Dec 2020 11:47:09 +0000   KernelHasNoDeadlock          kernel has no deadlock\n  ReadonlyFilesystem   False   Mon, 21 Dec 2020 13:07:35 +0000   Mon, 21 Dec 2020 11:47:09 +0000   FilesystemIsNotReadOnly      Filesystem is not read-only\n  NetworkUnavailable   False   Mon, 21 Dec 2020 11:47:01 +0000   Mon, 21 Dec 2020 11:47:01 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Mon, 21 Dec 2020 13:09:21 +0000   Mon, 21 Dec 2020 11:46:17 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 21 Dec 2020 13:09:21 +0000   Mon, 21 Dec 2020 11:46:17 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 21 Dec 2020 13:09:21 +0000   Mon, 21 Dec 2020 11:46:17 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 21 Dec 2020 13:09:21 +0000   Mon, 21 Dec 2020 11:46:37 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   172.31.183.240\n  ExternalIP:   3.122.118.197\n  Hostname:     ip-172-31-183-240.eu-central-1.compute.internal\n  InternalDNS:  ip-172-31-183-240.eu-central-1.compute.internal\n  ExternalDNS:  ec2-3-122-118-197.eu-central-1.compute.amazonaws.com\nCapacity:\n  attachable-volumes-aws-ebs:  25\n  cpu:                         2\n  ephemeral-storage:           25346000Ki\n  hugepages-1Gi:               0\n  hugepages-2Mi:               0\n  memory:                      1996696Ki\n  pods:                        110\nAllocatable:\n  attachable-volumes-aws-ebs:  25\n  cpu:                         1800m\n  ephemeral-storage:           21211389914\n  hugepages-1Gi:               0\n  hugepages-2Mi:               0\n  memory:                      1689496Ki\n  pods:                        110\nSystem Info:\n  Machine ID:                 ec24218b6c10b692597771903b5407e2\n  System UUID:                ec24218b-6c10-b692-5977-71903b5407e2\n  Boot ID:                    71d48cfe-942f-49f5-b924-2f790ba27718\n  Kernel Version:             5.4.0-1029-aws\n  OS Image:                   Ubuntu 18.04.5 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.9.9\n  Kubelet Version:            v1.18.8\n  Kube-Proxy Version:         v1.18.8\nPodCIDR:                      172.25.3.0/24\nPodCIDRs:                     172.25.3.0/24\nProviderID:                   aws:///eu-central-1b/i-02e8a9f476333df42\nNon-terminated Pods:          (11 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 canal-z66nn                                                350m (19%)    200m (11%)  50Mi (3%)        256Mi (15%)    84m\n  kube-system                 coredns-854998958f-nm6p2                                   100m (5%)     200m (11%)  70Mi (4%)        170Mi (10%)    84m\n  kube-system                 dns-autoscaler-596856b68b-qzt9r                            20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         82m\n  kube-system                 kube-proxy-2s25g                                           75m (4%)      250m (13%)  50Mi (3%)        250Mi (15%)    84m\n  kube-system                 node-exporter-hjpfq                                        3m (0%)       200m (11%)  16Mi (0%)        50Mi (3%)      84m\n  kube-system                 node-local-dns-htgfk                                       50m (2%)      0 (0%)      20Mi (1%)        100Mi (6%)     84m\n  kube-system                 openvpn-client-56dc45fdbd-pvwz9                            30m (1%)      200m (11%)  30Mi (1%)        82Mi (4%)      82m\n  kube-system                 syseleven-node-problem-detector-xwkkt                      10m (0%)      10m (0%)    80Mi (4%)        80Mi (4%)      84m\n  kube-system                 tiller-deploy-5648ccb4b6-c8nqp                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\n  kube-system                 user-ssh-keys-agent-282ml                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         84m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-g9pqh    0 (0%)        0 (0%)      0 (0%)           0 (0%)         60m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests     Limits\n  --------                    --------     ------\n  cpu                         638m (35%)   1060m (58%)\n  memory                      326Mi (19%)  988Mi (59%)\n  ephemeral-storage           0 (0%)       0 (0%)\n  hugepages-1Gi               0 (0%)       0 (0%)\n  hugepages-2Mi               0 (0%)       0 (0%)\n  attachable-volumes-aws-ebs  0            0\nEvents:                       <none>\n"
Dec 21 13:11:10.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 describe namespace kubectl-8115'
Dec 21 13:11:11.028: INFO: stderr: ""
Dec 21 13:11:11.028: INFO: stdout: "Name:         kubectl-8115\nLabels:       e2e-framework=kubectl\n              e2e-run=24ee7c31-e26a-4c7a-9c45-b22d427de6ef\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:11:11.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8115" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":273,"completed":236,"skipped":4062,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:11:11.041: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-5dafa6ff-b5e3-4bf4-9176-ebca64a465ab
STEP: Creating a pod to test consume configMaps
Dec 21 13:11:11.216: INFO: Waiting up to 5m0s for pod "pod-configmaps-b7001a08-10ab-439a-b456-d96b2fcac449" in namespace "configmap-6341" to be "Succeeded or Failed"
Dec 21 13:11:11.222: INFO: Pod "pod-configmaps-b7001a08-10ab-439a-b456-d96b2fcac449": Phase="Pending", Reason="", readiness=false. Elapsed: 6.165766ms
Dec 21 13:11:13.227: INFO: Pod "pod-configmaps-b7001a08-10ab-439a-b456-d96b2fcac449": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010508295s
STEP: Saw pod success
Dec 21 13:11:13.227: INFO: Pod "pod-configmaps-b7001a08-10ab-439a-b456-d96b2fcac449" satisfied condition "Succeeded or Failed"
Dec 21 13:11:13.230: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod pod-configmaps-b7001a08-10ab-439a-b456-d96b2fcac449 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 21 13:11:13.255: INFO: Waiting for pod pod-configmaps-b7001a08-10ab-439a-b456-d96b2fcac449 to disappear
Dec 21 13:11:13.259: INFO: Pod pod-configmaps-b7001a08-10ab-439a-b456-d96b2fcac449 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:11:13.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6341" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":273,"completed":237,"skipped":4106,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:11:13.271: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5569
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 21 13:11:19.510: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 21 13:11:19.516: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 21 13:11:21.517: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 21 13:11:21.528: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 21 13:11:23.517: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 21 13:11:23.521: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:11:23.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5569" for this suite.

• [SLOW TEST:10.274 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":273,"completed":238,"skipped":4115,"failed":0}
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:11:23.546: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-b891e34c-980e-47f4-8a25-57da673d622a
Dec 21 13:11:23.724: INFO: Pod name my-hostname-basic-b891e34c-980e-47f4-8a25-57da673d622a: Found 0 pods out of 1
Dec 21 13:11:28.738: INFO: Pod name my-hostname-basic-b891e34c-980e-47f4-8a25-57da673d622a: Found 1 pods out of 1
Dec 21 13:11:28.738: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b891e34c-980e-47f4-8a25-57da673d622a" are running
Dec 21 13:11:28.750: INFO: Pod "my-hostname-basic-b891e34c-980e-47f4-8a25-57da673d622a-rgncl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-21 13:11:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-21 13:11:25 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-21 13:11:25 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-21 13:11:23 +0000 UTC Reason: Message:}])
Dec 21 13:11:28.750: INFO: Trying to dial the pod
Dec 21 13:11:33.812: INFO: Controller my-hostname-basic-b891e34c-980e-47f4-8a25-57da673d622a: Got expected result from replica 1 [my-hostname-basic-b891e34c-980e-47f4-8a25-57da673d622a-rgncl]: "my-hostname-basic-b891e34c-980e-47f4-8a25-57da673d622a-rgncl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:11:33.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2424" for this suite.

• [SLOW TEST:10.282 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":273,"completed":239,"skipped":4121,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:11:33.831: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-869
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:11:34.001: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Creating first CR 
Dec 21 13:11:34.579: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-21T13:11:34Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-21T13:11:34Z]] name:name1 resourceVersion:36052930 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:07db5fa1-8853-43cd-a8d5-0507547b9020] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 21 13:11:44.592: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-21T13:11:44Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-21T13:11:44Z]] name:name2 resourceVersion:36052991 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9fc2ae68-f59d-4193-afe8-b9311fb5f00e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 21 13:11:54.604: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-21T13:11:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-21T13:11:54Z]] name:name1 resourceVersion:36053035 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:07db5fa1-8853-43cd-a8d5-0507547b9020] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 21 13:12:04.612: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-21T13:11:44Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-21T13:12:04Z]] name:name2 resourceVersion:36053078 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9fc2ae68-f59d-4193-afe8-b9311fb5f00e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 21 13:12:14.622: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-21T13:11:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-21T13:11:54Z]] name:name1 resourceVersion:36053120 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:07db5fa1-8853-43cd-a8d5-0507547b9020] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 21 13:12:24.635: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-21T13:11:44Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-21T13:12:04Z]] name:name2 resourceVersion:36053162 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9fc2ae68-f59d-4193-afe8-b9311fb5f00e] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:12:35.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-869" for this suite.

• [SLOW TEST:61.333 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":273,"completed":240,"skipped":4123,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:12:35.165: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-331
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 13:12:35.732: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 13:12:37.747: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153155, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153155, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153155, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153155, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 13:12:40.778: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:12:40.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-331" for this suite.
STEP: Destroying namespace "webhook-331-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.697 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":273,"completed":241,"skipped":4150,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:12:40.863: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7584
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 13:12:42.041: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 13:12:45.063: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:12:45.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7584" for this suite.
STEP: Destroying namespace "webhook-7584-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":273,"completed":242,"skipped":4163,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:12:45.443: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8042
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:12:45.640: INFO: Waiting up to 5m0s for pod "busybox-user-65534-d607a064-1b10-4956-9676-ad07cd271f77" in namespace "security-context-test-8042" to be "Succeeded or Failed"
Dec 21 13:12:45.653: INFO: Pod "busybox-user-65534-d607a064-1b10-4956-9676-ad07cd271f77": Phase="Pending", Reason="", readiness=false. Elapsed: 12.456798ms
Dec 21 13:12:47.657: INFO: Pod "busybox-user-65534-d607a064-1b10-4956-9676-ad07cd271f77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016534056s
Dec 21 13:12:47.657: INFO: Pod "busybox-user-65534-d607a064-1b10-4956-9676-ad07cd271f77" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:12:47.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8042" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":243,"skipped":4177,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:12:47.677: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-213
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:12:47.898: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"eb71122c-5b0e-4187-91c2-533d6be39528", Controller:(*bool)(0xc00345ed42), BlockOwnerDeletion:(*bool)(0xc00345ed43)}}
Dec 21 13:12:47.908: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"895eeb45-9182-4c9d-b401-08acbd09c107", Controller:(*bool)(0xc00410bfba), BlockOwnerDeletion:(*bool)(0xc00410bfbb)}}
Dec 21 13:12:47.916: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ccdd12c9-0bbd-4bd0-92a2-d17b74ff58c6", Controller:(*bool)(0xc00345ef3a), BlockOwnerDeletion:(*bool)(0xc00345ef3b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:12:52.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-213" for this suite.

• [SLOW TEST:5.267 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":273,"completed":244,"skipped":4189,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:12:52.944: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5777
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:12:53.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5777" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":273,"completed":245,"skipped":4210,"failed":0}
SSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:12:53.112: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8644
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:12:56.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8644" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":273,"completed":246,"skipped":4213,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:12:56.325: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2083
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Dec 21 13:12:59.043: INFO: Successfully updated pod "labelsupdatee257f2c5-7c8c-4983-84a2-34d9f128a01b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:13:01.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2083" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":273,"completed":247,"skipped":4218,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:13:01.148: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7381
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 21 13:13:01.302: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 21 13:13:01.317: INFO: Waiting for terminating namespaces to be deleted...
Dec 21 13:13:01.321: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-183-240.eu-central-1.compute.internal before test
Dec 21 13:13:01.383: INFO: tiller-deploy-5648ccb4b6-c8nqp from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.383: INFO: 	Container tiller ready: true, restart count 0
Dec 21 13:13:01.383: INFO: user-ssh-keys-agent-282ml from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.383: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 13:13:01.383: INFO: syseleven-node-problem-detector-xwkkt from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.383: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 13:13:01.383: INFO: kube-proxy-2s25g from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.383: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 13:13:01.383: INFO: node-exporter-hjpfq from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.383: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 13:13:01.383: INFO: dns-autoscaler-596856b68b-qzt9r from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.383: INFO: 	Container autoscaler ready: true, restart count 0
Dec 21 13:13:01.383: INFO: labelsupdatee257f2c5-7c8c-4983-84a2-34d9f128a01b from downward-api-2083 started at 2020-12-21 13:12:56 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.384: INFO: 	Container client-container ready: true, restart count 0
Dec 21 13:13:01.384: INFO: canal-z66nn from kube-system started at 2020-12-21 11:46:17 +0000 UTC (2 container statuses recorded)
Dec 21 13:13:01.384: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 13:13:01.384: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 13:13:01.384: INFO: node-local-dns-htgfk from kube-system started at 2020-12-21 11:46:17 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.384: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 13:13:01.384: INFO: coredns-854998958f-nm6p2 from kube-system started at 2020-12-21 11:46:38 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.384: INFO: 	Container coredns ready: true, restart count 0
Dec 21 13:13:01.384: INFO: openvpn-client-56dc45fdbd-pvwz9 from kube-system started at 2020-12-21 11:49:06 +0000 UTC (2 container statuses recorded)
Dec 21 13:13:01.384: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 21 13:13:01.384: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 21 13:13:01.384: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-g9pqh from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 13:13:01.384: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 13:13:01.384: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 13:13:01.384: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-232-239.eu-central-1.compute.internal before test
Dec 21 13:13:01.520: INFO: kube-proxy-wmhd2 from kube-system started at 2020-12-21 11:48:44 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 13:13:01.520: INFO: syseleven-node-problem-detector-6vfvr from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 13:13:01.520: INFO: user-ssh-keys-agent-4gr8h from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 13:13:01.520: INFO: pod-adoption from replication-controller-8644 started at 2020-12-21 13:12:53 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container pod-adoption ready: true, restart count 0
Dec 21 13:13:01.520: INFO: node-exporter-8m5jv from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 13:13:01.520: INFO: node-local-dns-qpm75 from kube-system started at 2020-12-21 11:48:45 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 13:13:01.520: INFO: canal-w4p2b from kube-system started at 2020-12-21 11:48:45 +0000 UTC (2 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 13:13:01.520: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 13:13:01.520: INFO: coredns-854998958f-sf9zb from kube-system started at 2020-12-21 11:49:06 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container coredns ready: true, restart count 0
Dec 21 13:13:01.520: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-xp6km from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 13:13:01.520: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 21 13:13:01.520: INFO: cluster-autoscaler-5c8c86777b-9jllr from kube-system started at 2020-12-21 11:52:18 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.520: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 21 13:13:01.520: INFO: 
Logging pods the kubelet thinks is on node ip-172-31-244-13.eu-central-1.compute.internal before test
Dec 21 13:13:01.544: INFO: canal-ljp6n from kube-system started at 2020-12-21 11:51:56 +0000 UTC (2 container statuses recorded)
Dec 21 13:13:01.544: INFO: 	Container calico-node ready: true, restart count 0
Dec 21 13:13:01.544: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 21 13:13:01.544: INFO: node-exporter-hzvfb from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.544: INFO: 	Container node-exporter ready: true, restart count 0
Dec 21 13:13:01.544: INFO: node-local-dns-wqj25 from kube-system started at 2020-12-21 11:51:57 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.544: INFO: 	Container node-cache ready: true, restart count 0
Dec 21 13:13:01.544: INFO: sonobuoy-e2e-job-12016c8e6e68444f from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 13:13:01.544: INFO: 	Container e2e ready: true, restart count 0
Dec 21 13:13:01.544: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 21 13:13:01.544: INFO: user-ssh-keys-agent-jx8sl from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.544: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 21 13:13:01.544: INFO: kube-proxy-rvhxj from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.544: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 21 13:13:01.544: INFO: sonobuoy from sonobuoy started at 2020-12-21 12:10:49 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.544: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 21 13:13:01.544: INFO: syseleven-node-problem-detector-f6dnk from kube-system started at 2020-12-21 11:51:56 +0000 UTC (1 container statuses recorded)
Dec 21 13:13:01.544: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 21 13:13:01.544: INFO: sonobuoy-systemd-logs-daemon-set-2bc5be38fec34946-8p5kx from sonobuoy started at 2020-12-21 12:10:57 +0000 UTC (2 container statuses recorded)
Dec 21 13:13:01.544: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 21 13:13:01.544: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1652bd81aee9efe8], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1652bd81af9c3af7], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:13:02.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7381" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":273,"completed":248,"skipped":4262,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:13:02.627: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5724
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 21 13:13:04.853: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:13:04.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5724" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":273,"completed":249,"skipped":4282,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:13:04.888: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4174
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 21 13:13:05.054: INFO: Waiting up to 5m0s for pod "pod-9012684d-b824-46e7-a0bd-00934500f77c" in namespace "emptydir-4174" to be "Succeeded or Failed"
Dec 21 13:13:05.067: INFO: Pod "pod-9012684d-b824-46e7-a0bd-00934500f77c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.87645ms
Dec 21 13:13:07.072: INFO: Pod "pod-9012684d-b824-46e7-a0bd-00934500f77c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017492108s
STEP: Saw pod success
Dec 21 13:13:07.072: INFO: Pod "pod-9012684d-b824-46e7-a0bd-00934500f77c" satisfied condition "Succeeded or Failed"
Dec 21 13:13:07.075: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-9012684d-b824-46e7-a0bd-00934500f77c container test-container: <nil>
STEP: delete the pod
Dec 21 13:13:07.100: INFO: Waiting for pod pod-9012684d-b824-46e7-a0bd-00934500f77c to disappear
Dec 21 13:13:07.104: INFO: Pod pod-9012684d-b824-46e7-a0bd-00934500f77c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:13:07.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4174" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":250,"skipped":4314,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:13:07.116: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1557
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-ae60d6dd-32d8-44f9-b13f-7e66ac9f62e5
STEP: Creating a pod to test consume secrets
Dec 21 13:13:07.286: INFO: Waiting up to 5m0s for pod "pod-secrets-5749572b-600b-4e66-b9ff-9af44cdb30f4" in namespace "secrets-1557" to be "Succeeded or Failed"
Dec 21 13:13:07.296: INFO: Pod "pod-secrets-5749572b-600b-4e66-b9ff-9af44cdb30f4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.970237ms
Dec 21 13:13:09.301: INFO: Pod "pod-secrets-5749572b-600b-4e66-b9ff-9af44cdb30f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015247754s
STEP: Saw pod success
Dec 21 13:13:09.302: INFO: Pod "pod-secrets-5749572b-600b-4e66-b9ff-9af44cdb30f4" satisfied condition "Succeeded or Failed"
Dec 21 13:13:09.306: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-secrets-5749572b-600b-4e66-b9ff-9af44cdb30f4 container secret-volume-test: <nil>
STEP: delete the pod
Dec 21 13:13:09.349: INFO: Waiting for pod pod-secrets-5749572b-600b-4e66-b9ff-9af44cdb30f4 to disappear
Dec 21 13:13:09.357: INFO: Pod pod-secrets-5749572b-600b-4e66-b9ff-9af44cdb30f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:13:09.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1557" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":273,"completed":251,"skipped":4317,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:13:09.377: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 13:13:09.555: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f0825f24-60f4-4612-99b4-69556cc541a2" in namespace "projected-4866" to be "Succeeded or Failed"
Dec 21 13:13:09.564: INFO: Pod "downwardapi-volume-f0825f24-60f4-4612-99b4-69556cc541a2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.796024ms
Dec 21 13:13:11.571: INFO: Pod "downwardapi-volume-f0825f24-60f4-4612-99b4-69556cc541a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016710454s
STEP: Saw pod success
Dec 21 13:13:11.571: INFO: Pod "downwardapi-volume-f0825f24-60f4-4612-99b4-69556cc541a2" satisfied condition "Succeeded or Failed"
Dec 21 13:13:11.581: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-f0825f24-60f4-4612-99b4-69556cc541a2 container client-container: <nil>
STEP: delete the pod
Dec 21 13:13:11.641: INFO: Waiting for pod downwardapi-volume-f0825f24-60f4-4612-99b4-69556cc541a2 to disappear
Dec 21 13:13:11.645: INFO: Pod downwardapi-volume-f0825f24-60f4-4612-99b4-69556cc541a2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:13:11.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4866" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":273,"completed":252,"skipped":4324,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:13:11.687: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 21 13:13:11.865: INFO: Waiting up to 5m0s for pod "downward-api-c2f00eb2-4e24-477f-9d1f-0c70293c2153" in namespace "downward-api-4277" to be "Succeeded or Failed"
Dec 21 13:13:11.871: INFO: Pod "downward-api-c2f00eb2-4e24-477f-9d1f-0c70293c2153": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044653ms
Dec 21 13:13:13.876: INFO: Pod "downward-api-c2f00eb2-4e24-477f-9d1f-0c70293c2153": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010884659s
Dec 21 13:13:15.882: INFO: Pod "downward-api-c2f00eb2-4e24-477f-9d1f-0c70293c2153": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017317412s
STEP: Saw pod success
Dec 21 13:13:15.882: INFO: Pod "downward-api-c2f00eb2-4e24-477f-9d1f-0c70293c2153" satisfied condition "Succeeded or Failed"
Dec 21 13:13:15.886: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downward-api-c2f00eb2-4e24-477f-9d1f-0c70293c2153 container dapi-container: <nil>
STEP: delete the pod
Dec 21 13:13:15.910: INFO: Waiting for pod downward-api-c2f00eb2-4e24-477f-9d1f-0c70293c2153 to disappear
Dec 21 13:13:15.914: INFO: Pod downward-api-c2f00eb2-4e24-477f-9d1f-0c70293c2153 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:13:15.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4277" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":273,"completed":253,"skipped":4373,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:13:15.928: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 13:13:16.086: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86167011-eeca-43ec-a665-8ee88e4b9ced" in namespace "downward-api-748" to be "Succeeded or Failed"
Dec 21 13:13:16.091: INFO: Pod "downwardapi-volume-86167011-eeca-43ec-a665-8ee88e4b9ced": Phase="Pending", Reason="", readiness=false. Elapsed: 4.673946ms
Dec 21 13:13:18.095: INFO: Pod "downwardapi-volume-86167011-eeca-43ec-a665-8ee88e4b9ced": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008920623s
Dec 21 13:13:20.101: INFO: Pod "downwardapi-volume-86167011-eeca-43ec-a665-8ee88e4b9ced": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014268839s
STEP: Saw pod success
Dec 21 13:13:20.101: INFO: Pod "downwardapi-volume-86167011-eeca-43ec-a665-8ee88e4b9ced" satisfied condition "Succeeded or Failed"
Dec 21 13:13:20.105: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod downwardapi-volume-86167011-eeca-43ec-a665-8ee88e4b9ced container client-container: <nil>
STEP: delete the pod
Dec 21 13:13:20.128: INFO: Waiting for pod downwardapi-volume-86167011-eeca-43ec-a665-8ee88e4b9ced to disappear
Dec 21 13:13:20.131: INFO: Pod downwardapi-volume-86167011-eeca-43ec-a665-8ee88e4b9ced no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:13:20.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-748" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":273,"completed":254,"skipped":4384,"failed":0}
SS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:13:20.146: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-294
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-294, will wait for the garbage collector to delete the pods
Dec 21 13:13:24.382: INFO: Deleting Job.batch foo took: 10.760824ms
Dec 21 13:13:27.082: INFO: Terminating Job.batch foo pods took: 2.700264119s
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:14:07.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-294" for this suite.

• [SLOW TEST:47.259 seconds]
[sig-apps] Job
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":273,"completed":255,"skipped":4386,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:14:07.406: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 13:14:07.897: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 13:14:09.914: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153247, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153247, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153247, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153247, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 13:14:12.932: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:14:12.936: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6271-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:14:14.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4379" for this suite.
STEP: Destroying namespace "webhook-4379-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.878 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":273,"completed":256,"skipped":4424,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:14:14.285: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4468
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 21 13:14:14.454: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b605bd2-7d89-42a4-a887-017f8a4a14ac" in namespace "downward-api-4468" to be "Succeeded or Failed"
Dec 21 13:14:14.459: INFO: Pod "downwardapi-volume-0b605bd2-7d89-42a4-a887-017f8a4a14ac": Phase="Pending", Reason="", readiness=false. Elapsed: 4.390321ms
Dec 21 13:14:16.463: INFO: Pod "downwardapi-volume-0b605bd2-7d89-42a4-a887-017f8a4a14ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008573007s
Dec 21 13:14:18.469: INFO: Pod "downwardapi-volume-0b605bd2-7d89-42a4-a887-017f8a4a14ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014713747s
STEP: Saw pod success
Dec 21 13:14:18.469: INFO: Pod "downwardapi-volume-0b605bd2-7d89-42a4-a887-017f8a4a14ac" satisfied condition "Succeeded or Failed"
Dec 21 13:14:18.472: INFO: Trying to get logs from node ip-172-31-183-240.eu-central-1.compute.internal pod downwardapi-volume-0b605bd2-7d89-42a4-a887-017f8a4a14ac container client-container: <nil>
STEP: delete the pod
Dec 21 13:14:18.502: INFO: Waiting for pod downwardapi-volume-0b605bd2-7d89-42a4-a887-017f8a4a14ac to disappear
Dec 21 13:14:18.505: INFO: Pod downwardapi-volume-0b605bd2-7d89-42a4-a887-017f8a4a14ac no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:14:18.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4468" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":273,"completed":257,"skipped":4430,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:14:18.517: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-732
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 13:14:19.127: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 21 13:14:21.138: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153259, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153259, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153259, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153259, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 13:14:24.153: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:14:24.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-732" for this suite.
STEP: Destroying namespace "webhook-732-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.941 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":273,"completed":258,"skipped":4444,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:14:24.460: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3138
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 21 13:14:25.165: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 13:14:28.196: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:14:28.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3138" for this suite.
STEP: Destroying namespace "webhook-3138-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":273,"completed":259,"skipped":4448,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:14:28.524: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-826
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Dec 21 13:14:28.711: INFO: Found 0 stateful pods, waiting for 3
Dec 21 13:14:38.722: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 13:14:38.722: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 13:14:38.722: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 21 13:14:38.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-826 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 13:14:39.137: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 13:14:39.137: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 13:14:39.137: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 21 13:14:49.182: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 21 13:14:59.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-826 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 13:14:59.658: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 13:14:59.659: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 13:14:59.659: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 13:15:09.696: INFO: Waiting for StatefulSet statefulset-826/ss2 to complete update
Dec 21 13:15:09.696: INFO: Waiting for Pod statefulset-826/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 13:15:09.696: INFO: Waiting for Pod statefulset-826/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 13:15:19.712: INFO: Waiting for StatefulSet statefulset-826/ss2 to complete update
Dec 21 13:15:19.712: INFO: Waiting for Pod statefulset-826/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 21 13:15:29.705: INFO: Waiting for StatefulSet statefulset-826/ss2 to complete update
STEP: Rolling back to a previous revision
Dec 21 13:15:39.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-826 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 21 13:15:40.382: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 21 13:15:40.382: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 21 13:15:40.382: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 21 13:15:50.429: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 21 13:16:00.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 exec --namespace=statefulset-826 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 21 13:16:00.935: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 21 13:16:00.935: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 21 13:16:00.935: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 21 13:16:20.964: INFO: Waiting for StatefulSet statefulset-826/ss2 to complete update
Dec 21 13:16:20.964: INFO: Waiting for Pod statefulset-826/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 21 13:16:30.972: INFO: Deleting all statefulset in ns statefulset-826
Dec 21 13:16:30.976: INFO: Scaling statefulset ss2 to 0
Dec 21 13:16:41.006: INFO: Waiting for statefulset status.replicas updated to 0
Dec 21 13:16:41.010: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:16:41.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-826" for this suite.

• [SLOW TEST:132.533 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":273,"completed":260,"skipped":4513,"failed":0}
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:16:41.060: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4587
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-e66413ab-aaef-48d8-91ab-5580ed2cbeb2
STEP: Creating a pod to test consume secrets
Dec 21 13:16:41.221: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-95b26c65-ac96-4a88-bd7d-ee362cadc3f4" in namespace "projected-4587" to be "Succeeded or Failed"
Dec 21 13:16:41.224: INFO: Pod "pod-projected-secrets-95b26c65-ac96-4a88-bd7d-ee362cadc3f4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.671439ms
Dec 21 13:16:43.229: INFO: Pod "pod-projected-secrets-95b26c65-ac96-4a88-bd7d-ee362cadc3f4": Phase="Running", Reason="", readiness=true. Elapsed: 2.008397491s
Dec 21 13:16:45.236: INFO: Pod "pod-projected-secrets-95b26c65-ac96-4a88-bd7d-ee362cadc3f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015418039s
STEP: Saw pod success
Dec 21 13:16:45.236: INFO: Pod "pod-projected-secrets-95b26c65-ac96-4a88-bd7d-ee362cadc3f4" satisfied condition "Succeeded or Failed"
Dec 21 13:16:45.240: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-projected-secrets-95b26c65-ac96-4a88-bd7d-ee362cadc3f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 21 13:16:45.314: INFO: Waiting for pod pod-projected-secrets-95b26c65-ac96-4a88-bd7d-ee362cadc3f4 to disappear
Dec 21 13:16:45.317: INFO: Pod pod-projected-secrets-95b26c65-ac96-4a88-bd7d-ee362cadc3f4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:16:45.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4587" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":261,"skipped":4513,"failed":0}

------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:16:45.330: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1201
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-1201/configmap-test-c604ee75-c5d9-4980-9fed-1fdbcd15c238
STEP: Creating a pod to test consume configMaps
Dec 21 13:16:45.503: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d0673ec-a645-4361-ae7a-a5f620804a35" in namespace "configmap-1201" to be "Succeeded or Failed"
Dec 21 13:16:45.509: INFO: Pod "pod-configmaps-7d0673ec-a645-4361-ae7a-a5f620804a35": Phase="Pending", Reason="", readiness=false. Elapsed: 5.574206ms
Dec 21 13:16:47.513: INFO: Pod "pod-configmaps-7d0673ec-a645-4361-ae7a-a5f620804a35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009887921s
Dec 21 13:16:49.524: INFO: Pod "pod-configmaps-7d0673ec-a645-4361-ae7a-a5f620804a35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021091554s
STEP: Saw pod success
Dec 21 13:16:49.524: INFO: Pod "pod-configmaps-7d0673ec-a645-4361-ae7a-a5f620804a35" satisfied condition "Succeeded or Failed"
Dec 21 13:16:49.528: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-configmaps-7d0673ec-a645-4361-ae7a-a5f620804a35 container env-test: <nil>
STEP: delete the pod
Dec 21 13:16:49.550: INFO: Waiting for pod pod-configmaps-7d0673ec-a645-4361-ae7a-a5f620804a35 to disappear
Dec 21 13:16:49.552: INFO: Pod pod-configmaps-7d0673ec-a645-4361-ae7a-a5f620804a35 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:16:49.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1201" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":273,"completed":262,"skipped":4513,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:16:49.565: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3221
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:16:49.755: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 21 13:16:53.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-3221 create -f -'
Dec 21 13:16:53.696: INFO: stderr: ""
Dec 21 13:16:53.696: INFO: stdout: "e2e-test-crd-publish-openapi-4201-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 21 13:16:53.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-3221 delete e2e-test-crd-publish-openapi-4201-crds test-foo'
Dec 21 13:16:53.777: INFO: stderr: ""
Dec 21 13:16:53.777: INFO: stdout: "e2e-test-crd-publish-openapi-4201-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 21 13:16:53.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-3221 apply -f -'
Dec 21 13:16:53.944: INFO: stderr: ""
Dec 21 13:16:53.944: INFO: stdout: "e2e-test-crd-publish-openapi-4201-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 21 13:16:53.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-3221 delete e2e-test-crd-publish-openapi-4201-crds test-foo'
Dec 21 13:16:54.029: INFO: stderr: ""
Dec 21 13:16:54.029: INFO: stdout: "e2e-test-crd-publish-openapi-4201-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 21 13:16:54.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-3221 create -f -'
Dec 21 13:16:54.179: INFO: rc: 1
Dec 21 13:16:54.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-3221 apply -f -'
Dec 21 13:16:54.347: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 21 13:16:54.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-3221 create -f -'
Dec 21 13:16:54.499: INFO: rc: 1
Dec 21 13:16:54.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 --namespace=crd-publish-openapi-3221 apply -f -'
Dec 21 13:16:54.655: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 21 13:16:54.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 explain e2e-test-crd-publish-openapi-4201-crds'
Dec 21 13:16:54.828: INFO: stderr: ""
Dec 21 13:16:54.828: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4201-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 21 13:16:54.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 explain e2e-test-crd-publish-openapi-4201-crds.metadata'
Dec 21 13:16:55.006: INFO: stderr: ""
Dec 21 13:16:55.006: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4201-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 21 13:16:55.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 explain e2e-test-crd-publish-openapi-4201-crds.spec'
Dec 21 13:16:55.163: INFO: stderr: ""
Dec 21 13:16:55.163: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4201-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 21 13:16:55.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 explain e2e-test-crd-publish-openapi-4201-crds.spec.bars'
Dec 21 13:16:55.347: INFO: stderr: ""
Dec 21 13:16:55.347: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4201-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 21 13:16:55.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 explain e2e-test-crd-publish-openapi-4201-crds.spec.bars2'
Dec 21 13:16:55.516: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:16:59.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3221" for this suite.

• [SLOW TEST:9.485 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":273,"completed":263,"skipped":4535,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:16:59.050: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2572
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 21 13:16:59.227: INFO: Waiting up to 5m0s for pod "pod-964c6c78-9e03-4476-9fd6-8a5a8bbe7b43" in namespace "emptydir-2572" to be "Succeeded or Failed"
Dec 21 13:16:59.234: INFO: Pod "pod-964c6c78-9e03-4476-9fd6-8a5a8bbe7b43": Phase="Pending", Reason="", readiness=false. Elapsed: 7.158397ms
Dec 21 13:17:01.239: INFO: Pod "pod-964c6c78-9e03-4476-9fd6-8a5a8bbe7b43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01209816s
STEP: Saw pod success
Dec 21 13:17:01.239: INFO: Pod "pod-964c6c78-9e03-4476-9fd6-8a5a8bbe7b43" satisfied condition "Succeeded or Failed"
Dec 21 13:17:01.244: INFO: Trying to get logs from node ip-172-31-232-239.eu-central-1.compute.internal pod pod-964c6c78-9e03-4476-9fd6-8a5a8bbe7b43 container test-container: <nil>
STEP: delete the pod
Dec 21 13:17:01.301: INFO: Waiting for pod pod-964c6c78-9e03-4476-9fd6-8a5a8bbe7b43 to disappear
Dec 21 13:17:01.305: INFO: Pod pod-964c6c78-9e03-4476-9fd6-8a5a8bbe7b43 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:17:01.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2572" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":264,"skipped":4539,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:17:01.326: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6166
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 21 13:17:07.533: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 13:17:07.542: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 21 13:17:09.543: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 13:17:09.550: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 21 13:17:11.543: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 13:17:11.548: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 21 13:17:13.543: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 13:17:13.551: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 21 13:17:15.543: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 13:17:15.548: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 21 13:17:17.543: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 21 13:17:17.550: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:17:17.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6166" for this suite.

• [SLOW TEST:16.325 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":273,"completed":265,"skipped":4546,"failed":0}
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:17:17.653: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:17:17.924: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 21 13:17:22.930: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 21 13:17:22.930: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 21 13:17:24.935: INFO: Creating deployment "test-rollover-deployment"
Dec 21 13:17:24.948: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 21 13:17:26.957: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 21 13:17:26.965: INFO: Ensure that both replica sets have 1 created replica
Dec 21 13:17:26.973: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 21 13:17:26.982: INFO: Updating deployment test-rollover-deployment
Dec 21 13:17:26.982: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 21 13:17:28.991: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 21 13:17:29.001: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 21 13:17:29.010: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 13:17:29.010: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153448, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153444, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 13:17:31.019: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 13:17:31.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153448, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153444, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 13:17:33.019: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 13:17:33.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153448, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153444, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 13:17:35.026: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 13:17:35.026: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153448, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153444, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 13:17:37.020: INFO: all replica sets need to contain the pod-template-hash label
Dec 21 13:17:37.020: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153445, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153448, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153444, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 21 13:17:39.023: INFO: 
Dec 21 13:17:39.023: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 21 13:17:39.036: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5504 /apis/apps/v1/namespaces/deployment-5504/deployments/test-rollover-deployment 041e4d3d-91ff-4d4f-baaf-22533b89ad98 36056094 2 2020-12-21 13:17:24 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-12-21 13:17:26 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-21 13:17:38 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004145b98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-12-21 13:17:25 +0000 UTC,LastTransitionTime:2020-12-21 13:17:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-12-21 13:17:38 +0000 UTC,LastTransitionTime:2020-12-21 13:17:24 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 21 13:17:39.039: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-5504 /apis/apps/v1/namespaces/deployment-5504/replicasets/test-rollover-deployment-84f7f6f64b a24d1da1-7e35-425d-a6ec-7327d9bc2c4f 36056082 2 2020-12-21 13:17:26 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 041e4d3d-91ff-4d4f-baaf-22533b89ad98 0xc0040f6337 0xc0040f6338}] []  [{kube-controller-manager Update apps/v1 2020-12-21 13:17:38 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 49 101 52 100 51 100 45 57 49 102 102 45 52 100 52 102 45 98 97 97 102 45 50 50 53 51 51 98 56 57 97 100 57 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0040f63c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 21 13:17:39.040: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 21 13:17:39.040: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5504 /apis/apps/v1/namespaces/deployment-5504/replicasets/test-rollover-controller d3cf7786-6e95-4d34-a6c6-0344162707b3 36056093 2 2020-12-21 13:17:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 041e4d3d-91ff-4d4f-baaf-22533b89ad98 0xc0040f6127 0xc0040f6128}] []  [{e2e.test Update apps/v1 2020-12-21 13:17:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-21 13:17:38 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 49 101 52 100 51 100 45 57 49 102 102 45 52 100 52 102 45 98 97 97 102 45 50 50 53 51 51 98 56 57 97 100 57 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0040f61c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 13:17:39.040: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-5504 /apis/apps/v1/namespaces/deployment-5504/replicasets/test-rollover-deployment-5686c4cfd5 60d510da-b4a3-48c8-a705-4c21cc3ac78a 36056016 2 2020-12-21 13:17:24 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 041e4d3d-91ff-4d4f-baaf-22533b89ad98 0xc0040f6237 0xc0040f6238}] []  [{kube-controller-manager Update apps/v1 2020-12-21 13:17:27 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 52 49 101 52 100 51 100 45 57 49 102 102 45 52 100 52 102 45 98 97 97 102 45 50 50 53 51 51 98 56 57 97 100 57 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0040f62c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 21 13:17:39.044: INFO: Pod "test-rollover-deployment-84f7f6f64b-bmjfs" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-bmjfs test-rollover-deployment-84f7f6f64b- deployment-5504 /api/v1/namespaces/deployment-5504/pods/test-rollover-deployment-84f7f6f64b-bmjfs 9e92eff7-3a77-4a82-89e5-4484242e209f 36056037 0 2020-12-21 13:17:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[cni.projectcalico.org/podIP:172.25.5.76/32 cni.projectcalico.org/podIPs:172.25.5.76/32] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b a24d1da1-7e35-425d-a6ec-7327d9bc2c4f 0xc0040f6ae7 0xc0040f6ae8}] []  [{calico Update v1 2020-12-21 13:17:27 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kube-controller-manager Update v1 2020-12-21 13:17:27 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 50 52 100 49 100 97 49 45 55 101 51 53 45 52 50 53 100 45 97 54 101 99 45 55 51 50 55 100 57 98 99 50 99 52 102 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-21 13:17:28 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 53 46 55 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-x6f7d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-x6f7d,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-x6f7d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-244-13.eu-central-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 13:17:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 13:17:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 13:17:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-21 13:17:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.244.13,PodIP:172.25.5.76,StartTime:2020-12-21 13:17:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-21 13:17:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://a172f084b6f2d8b79a44e59773e8159f48158f82de68316fec312a847f102bfa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.5.76,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:17:39.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5504" for this suite.

• [SLOW TEST:21.405 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":273,"completed":266,"skipped":4547,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:17:39.058: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3365
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Dec 21 13:17:39.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 create -f - --namespace=kubectl-3365'
Dec 21 13:17:39.464: INFO: stderr: ""
Dec 21 13:17:39.464: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Dec 21 13:17:40.469: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 13:17:40.469: INFO: Found 0 / 1
Dec 21 13:17:41.470: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 13:17:41.470: INFO: Found 1 / 1
Dec 21 13:17:41.470: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 21 13:17:41.476: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 13:17:41.476: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 21 13:17:41.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-796893939 patch pod agnhost-master-z9plr --namespace=kubectl-3365 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 21 13:17:41.600: INFO: stderr: ""
Dec 21 13:17:41.600: INFO: stdout: "pod/agnhost-master-z9plr patched\n"
STEP: checking annotations
Dec 21 13:17:41.606: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 21 13:17:41.606: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:17:41.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3365" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":273,"completed":267,"skipped":4554,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:17:41.623: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9691
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:17:41.823: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 21 13:17:41.846: INFO: Number of nodes with available pods: 0
Dec 21 13:17:41.846: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:17:42.862: INFO: Number of nodes with available pods: 0
Dec 21 13:17:42.862: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:17:43.857: INFO: Number of nodes with available pods: 2
Dec 21 13:17:43.857: INFO: Node ip-172-31-183-240.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:17:44.857: INFO: Number of nodes with available pods: 3
Dec 21 13:17:44.857: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 21 13:17:44.905: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:44.905: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:44.905: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:45.921: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:45.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:45.921: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:46.921: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:46.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:46.921: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:47.922: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:47.922: INFO: Pod daemon-set-4p2n8 is not available
Dec 21 13:17:47.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:47.922: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:48.921: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:48.921: INFO: Pod daemon-set-4p2n8 is not available
Dec 21 13:17:48.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:48.921: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:49.921: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:49.921: INFO: Pod daemon-set-4p2n8 is not available
Dec 21 13:17:49.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:49.921: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:50.923: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:50.923: INFO: Pod daemon-set-4p2n8 is not available
Dec 21 13:17:50.923: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:50.923: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:51.922: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:51.922: INFO: Pod daemon-set-4p2n8 is not available
Dec 21 13:17:51.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:51.922: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:52.923: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:52.923: INFO: Pod daemon-set-4p2n8 is not available
Dec 21 13:17:52.924: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:52.924: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:53.923: INFO: Wrong image for pod: daemon-set-4p2n8. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:53.923: INFO: Pod daemon-set-4p2n8 is not available
Dec 21 13:17:53.923: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:53.923: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:54.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:54.922: INFO: Pod daemon-set-d2qc6 is not available
Dec 21 13:17:54.922: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:55.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:55.921: INFO: Pod daemon-set-d2qc6 is not available
Dec 21 13:17:55.921: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:56.920: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:56.920: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:57.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:57.922: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:57.922: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:17:58.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:58.922: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:58.922: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:17:59.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:59.922: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:17:59.922: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:18:00.923: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:00.923: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:00.923: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:18:01.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:01.922: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:01.922: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:18:02.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:02.921: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:02.921: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:18:03.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:03.921: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:03.921: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:18:04.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:04.922: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:04.922: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:18:05.923: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:05.923: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:05.923: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:18:06.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:06.921: INFO: Wrong image for pod: daemon-set-l89fn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:06.921: INFO: Pod daemon-set-l89fn is not available
Dec 21 13:18:07.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:07.922: INFO: Pod daemon-set-wl9x6 is not available
Dec 21 13:18:08.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:08.922: INFO: Pod daemon-set-wl9x6 is not available
Dec 21 13:18:09.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:09.921: INFO: Pod daemon-set-wl9x6 is not available
Dec 21 13:18:10.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:11.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:11.922: INFO: Pod daemon-set-cj6lb is not available
Dec 21 13:18:12.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:12.922: INFO: Pod daemon-set-cj6lb is not available
Dec 21 13:18:13.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:13.921: INFO: Pod daemon-set-cj6lb is not available
Dec 21 13:18:14.922: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:14.922: INFO: Pod daemon-set-cj6lb is not available
Dec 21 13:18:15.921: INFO: Wrong image for pod: daemon-set-cj6lb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 21 13:18:15.921: INFO: Pod daemon-set-cj6lb is not available
Dec 21 13:18:16.923: INFO: Pod daemon-set-n4g7x is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 21 13:18:16.961: INFO: Number of nodes with available pods: 2
Dec 21 13:18:16.961: INFO: Node ip-172-31-244-13.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:18:17.972: INFO: Number of nodes with available pods: 2
Dec 21 13:18:17.972: INFO: Node ip-172-31-244-13.eu-central-1.compute.internal is running more than one daemon pod
Dec 21 13:18:18.971: INFO: Number of nodes with available pods: 3
Dec 21 13:18:18.971: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9691, will wait for the garbage collector to delete the pods
Dec 21 13:18:19.063: INFO: Deleting DaemonSet.extensions daemon-set took: 9.947458ms
Dec 21 13:18:19.764: INFO: Terminating DaemonSet.extensions daemon-set pods took: 701.444741ms
Dec 21 13:18:27.369: INFO: Number of nodes with available pods: 0
Dec 21 13:18:27.369: INFO: Number of running nodes: 0, number of available pods: 0
Dec 21 13:18:27.374: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9691/daemonsets","resourceVersion":"36056505"},"items":null}

Dec 21 13:18:27.380: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9691/pods","resourceVersion":"36056505"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:18:27.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9691" for this suite.

• [SLOW TEST:45.790 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":273,"completed":268,"skipped":4562,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:18:27.415: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3997
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 21 13:18:30.118: INFO: Successfully updated pod "pod-update-f80d6bd6-0ed0-4c0b-afa1-c3d9c22403e4"
STEP: verifying the updated pod is in kubernetes
Dec 21 13:18:30.125: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:18:30.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3997" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":273,"completed":269,"skipped":4577,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:18:30.138: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4155
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:18:30.287: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:18:31.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4155" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":273,"completed":270,"skipped":4592,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:18:31.327: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4335
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Dec 21 13:18:31.470: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-796893939 proxy --unix-socket=/tmp/kubectl-proxy-unix856991090/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:18:31.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4335" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":273,"completed":271,"skipped":4595,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:18:31.613: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6988
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 21 13:18:31.801: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed f592c953-2a7b-4ad4-8959-07deec5a7ed5 36056583 0 2020-12-21 13:18:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-21 13:18:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 13:18:31.801: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed f592c953-2a7b-4ad4-8959-07deec5a7ed5 36056584 0 2020-12-21 13:18:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-21 13:18:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 13:18:31.801: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed f592c953-2a7b-4ad4-8959-07deec5a7ed5 36056585 0 2020-12-21 13:18:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-21 13:18:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 21 13:18:41.846: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed f592c953-2a7b-4ad4-8959-07deec5a7ed5 36056711 0 2020-12-21 13:18:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-21 13:18:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 13:18:41.846: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed f592c953-2a7b-4ad4-8959-07deec5a7ed5 36056712 0 2020-12-21 13:18:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-21 13:18:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 21 13:18:41.846: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6988 /api/v1/namespaces/watch-6988/configmaps/e2e-watch-test-label-changed f592c953-2a7b-4ad4-8959-07deec5a7ed5 36056713 0 2020-12-21 13:18:31 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-21 13:18:41 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:18:41.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6988" for this suite.

• [SLOW TEST:10.246 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":273,"completed":272,"skipped":4702,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 21 13:18:41.860: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-4194
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 21 13:18:42.277: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 21 13:18:44.291: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153522, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153522, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153522, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63744153522, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 21 13:18:47.306: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 21 13:18:47.310: INFO: >>> kubeConfig: /tmp/kubeconfig-796893939
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 21 13:18:48.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4194" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:6.895 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":273,"completed":273,"skipped":4713,"failed":0}
SSSSSSDec 21 13:18:48.756: INFO: Running AfterSuite actions on all nodes
Dec 21 13:18:48.760: INFO: Running AfterSuite actions on node 1
Dec 21 13:18:48.760: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":273,"completed":273,"skipped":4719,"failed":0}

Ran 273 of 4992 Specs in 4053.425 seconds
SUCCESS! -- 273 Passed | 0 Failed | 0 Pending | 4719 Skipped
PASS

Ginkgo ran 1 suite in 1h7m35.068297963s
Test Suite Passed

I1218 11:49:45.623167      21 test_context.go:410] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-185975894
I1218 11:49:45.623191      21 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I1218 11:49:45.623355      21 e2e.go:124] Starting e2e run "306eca60-14a6-4e55-8a47-2e4f210f0796" on Ginkgo node 1
{"msg":"Test Suite starting","total":273,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1608292183 - Will randomize all specs
Will run 273 of 4992 specs

Dec 18 11:49:45.737: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 11:49:45.739: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 18 11:49:45.778: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 18 11:49:45.857: INFO: 28 / 28 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 18 11:49:45.857: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Dec 18 11:49:45.857: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 18 11:49:45.882: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Dec 18 11:49:45.882: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'csi-cinder-nodeplugin-coreos' (0 seconds elapsed)
Dec 18 11:49:45.882: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'csi-cinder-nodeplugin-flatcat' (0 seconds elapsed)
Dec 18 11:49:45.882: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-cinder-nodeplugin-ubuntu' (0 seconds elapsed)
Dec 18 11:49:45.882: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 18 11:49:45.882: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Dec 18 11:49:45.882: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Dec 18 11:49:45.882: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'syseleven-node-problem-detector' (0 seconds elapsed)
Dec 18 11:49:45.882: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'user-ssh-keys-agent' (0 seconds elapsed)
Dec 18 11:49:45.882: INFO: e2e test version: v1.18.8
Dec 18 11:49:45.885: INFO: kube-apiserver version: v1.18.8
Dec 18 11:49:45.885: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 11:49:45.894: INFO: Cluster IP family: ipv4
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:49:45.895: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
Dec 18 11:49:45.982: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec 18 11:49:46.010: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5691
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 18 11:49:46.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-5691'
Dec 18 11:49:49.161: INFO: stderr: ""
Dec 18 11:49:49.161: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 18 11:50:04.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pod e2e-test-httpd-pod --namespace=kubectl-5691 -o json'
Dec 18 11:50:04.338: INFO: stderr: ""
Dec 18 11:50:04.338: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"172.25.1.37/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.25.1.37/32\"\n        },\n        \"creationTimestamp\": \"2020-12-18T11:49:49Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-12-18T11:49:49Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \".\": {},\n                            \"f:cni.projectcalico.org/podIP\": {},\n                            \"f:cni.projectcalico.org/podIPs\": {}\n                        }\n                    }\n                },\n                \"manager\": \"calico\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-12-18T11:49:57Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"172.25.1.37\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-12-18T11:50:00Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5691\",\n        \"resourceVersion\": \"75118\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5691/pods/e2e-test-httpd-pod\",\n        \"uid\": \"42dfbb8d-a2e5-4dd8-8aed-eac9a7b1c573\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xjxtq\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"stoic-bose-worker-s2lnv-655cc5dcbf-t45gl\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xjxtq\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xjxtq\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-12-18T11:49:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-12-18T11:50:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-12-18T11:50:00Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-12-18T11:49:49Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://4e555e5592c559ad76af61122d0a45fe8e7efefe84782428a075fd95d2dbd71f\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-12-18T11:49:59Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.1.2\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.25.1.37\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.25.1.37\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-12-18T11:49:53Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 18 11:50:04.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 replace -f - --namespace=kubectl-5691'
Dec 18 11:50:06.614: INFO: stderr: ""
Dec 18 11:50:06.614: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec 18 11:50:06.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete pods e2e-test-httpd-pod --namespace=kubectl-5691'
Dec 18 11:50:16.188: INFO: stderr: ""
Dec 18 11:50:16.189: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:50:16.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5691" for this suite.

• [SLOW TEST:30.347 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1450
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":273,"completed":1,"skipped":9,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:50:16.244: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3291
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 18 11:50:23.604: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:50:23.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3291" for this suite.

• [SLOW TEST:7.422 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":273,"completed":2,"skipped":43,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:50:23.666: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9204
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Dec 18 11:50:30.533: INFO: Successfully updated pod "annotationupdate94bc6da0-f921-4e75-9e04-8ff75428051b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:50:32.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9204" for this suite.

• [SLOW TEST:8.970 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":273,"completed":3,"skipped":44,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:50:32.636: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 11:50:33.356: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 11:50:35.381: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889033, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889033, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889033, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889033, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:50:37.391: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889033, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889033, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889033, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889033, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 11:50:40.422: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:50:40.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7043" for this suite.
STEP: Destroying namespace "webhook-7043-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.010 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":273,"completed":4,"skipped":47,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:50:40.647: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1617
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-82c4250e-cf4d-4802-8ed6-0afc64c6871a
STEP: Creating a pod to test consume configMaps
Dec 18 11:50:40.895: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f" in namespace "projected-1617" to be "Succeeded or Failed"
Dec 18 11:50:40.902: INFO: Pod "pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.059109ms
Dec 18 11:50:42.916: INFO: Pod "pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020233565s
Dec 18 11:50:44.925: INFO: Pod "pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029055756s
Dec 18 11:50:46.940: INFO: Pod "pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044407363s
Dec 18 11:50:48.949: INFO: Pod "pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.053444993s
STEP: Saw pod success
Dec 18 11:50:48.949: INFO: Pod "pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f" satisfied condition "Succeeded or Failed"
Dec 18 11:50:48.956: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 11:50:49.005: INFO: Waiting for pod pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f to disappear
Dec 18 11:50:49.014: INFO: Pod pod-projected-configmaps-561f1ecd-b25c-47ca-b42a-d335b7d2f68f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:50:49.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1617" for this suite.

• [SLOW TEST:8.394 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":273,"completed":5,"skipped":50,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:50:49.049: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Dec 18 11:50:49.280: INFO: Waiting up to 5m0s for pod "var-expansion-c5c8264f-47d2-4837-8cf8-c705fd66b9e7" in namespace "var-expansion-610" to be "Succeeded or Failed"
Dec 18 11:50:49.289: INFO: Pod "var-expansion-c5c8264f-47d2-4837-8cf8-c705fd66b9e7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.47164ms
Dec 18 11:50:51.298: INFO: Pod "var-expansion-c5c8264f-47d2-4837-8cf8-c705fd66b9e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018263029s
Dec 18 11:50:53.306: INFO: Pod "var-expansion-c5c8264f-47d2-4837-8cf8-c705fd66b9e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025768919s
Dec 18 11:50:55.314: INFO: Pod "var-expansion-c5c8264f-47d2-4837-8cf8-c705fd66b9e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033730301s
STEP: Saw pod success
Dec 18 11:50:55.314: INFO: Pod "var-expansion-c5c8264f-47d2-4837-8cf8-c705fd66b9e7" satisfied condition "Succeeded or Failed"
Dec 18 11:50:55.321: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod var-expansion-c5c8264f-47d2-4837-8cf8-c705fd66b9e7 container dapi-container: <nil>
STEP: delete the pod
Dec 18 11:50:55.372: INFO: Waiting for pod var-expansion-c5c8264f-47d2-4837-8cf8-c705fd66b9e7 to disappear
Dec 18 11:50:55.380: INFO: Pod var-expansion-c5c8264f-47d2-4837-8cf8-c705fd66b9e7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:50:55.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-610" for this suite.

• [SLOW TEST:6.356 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":273,"completed":6,"skipped":80,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:50:55.412: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-431
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-2fde5be7-c3f1-4a10-91c3-8a3f5c501a4e
STEP: Creating configMap with name cm-test-opt-upd-f4d4436f-11a5-495e-b30a-d6d5707edcc6
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2fde5be7-c3f1-4a10-91c3-8a3f5c501a4e
STEP: Updating configmap cm-test-opt-upd-f4d4436f-11a5-495e-b30a-d6d5707edcc6
STEP: Creating configMap with name cm-test-opt-create-491f548f-bacf-4082-adcc-c9661693315b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:52:13.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-431" for this suite.

• [SLOW TEST:77.933 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":7,"skipped":90,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:52:13.347: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3940
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 11:52:13.611: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af999882-723f-4cbf-a8bf-9437ff342bd9" in namespace "projected-3940" to be "Succeeded or Failed"
Dec 18 11:52:13.619: INFO: Pod "downwardapi-volume-af999882-723f-4cbf-a8bf-9437ff342bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.443118ms
Dec 18 11:52:15.630: INFO: Pod "downwardapi-volume-af999882-723f-4cbf-a8bf-9437ff342bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019426197s
Dec 18 11:52:17.639: INFO: Pod "downwardapi-volume-af999882-723f-4cbf-a8bf-9437ff342bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028207304s
Dec 18 11:52:19.649: INFO: Pod "downwardapi-volume-af999882-723f-4cbf-a8bf-9437ff342bd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037635807s
STEP: Saw pod success
Dec 18 11:52:19.649: INFO: Pod "downwardapi-volume-af999882-723f-4cbf-a8bf-9437ff342bd9" satisfied condition "Succeeded or Failed"
Dec 18 11:52:19.657: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r pod downwardapi-volume-af999882-723f-4cbf-a8bf-9437ff342bd9 container client-container: <nil>
STEP: delete the pod
Dec 18 11:52:19.711: INFO: Waiting for pod downwardapi-volume-af999882-723f-4cbf-a8bf-9437ff342bd9 to disappear
Dec 18 11:52:19.718: INFO: Pod downwardapi-volume-af999882-723f-4cbf-a8bf-9437ff342bd9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:52:19.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3940" for this suite.

• [SLOW TEST:6.407 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":273,"completed":8,"skipped":106,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:52:19.755: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5720
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Dec 18 11:52:19.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-5720'
Dec 18 11:52:20.584: INFO: stderr: ""
Dec 18 11:52:20.584: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 18 11:52:20.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5720'
Dec 18 11:52:20.717: INFO: stderr: ""
Dec 18 11:52:20.717: INFO: stdout: "update-demo-nautilus-qhk2x update-demo-nautilus-vdtvn "
Dec 18 11:52:20.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-qhk2x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5720'
Dec 18 11:52:20.821: INFO: stderr: ""
Dec 18 11:52:20.821: INFO: stdout: ""
Dec 18 11:52:20.821: INFO: update-demo-nautilus-qhk2x is created but not running
Dec 18 11:52:25.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5720'
Dec 18 11:52:25.938: INFO: stderr: ""
Dec 18 11:52:25.938: INFO: stdout: "update-demo-nautilus-qhk2x update-demo-nautilus-vdtvn "
Dec 18 11:52:25.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-qhk2x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5720'
Dec 18 11:52:26.047: INFO: stderr: ""
Dec 18 11:52:26.047: INFO: stdout: ""
Dec 18 11:52:26.047: INFO: update-demo-nautilus-qhk2x is created but not running
Dec 18 11:52:31.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5720'
Dec 18 11:52:31.182: INFO: stderr: ""
Dec 18 11:52:31.182: INFO: stdout: "update-demo-nautilus-qhk2x update-demo-nautilus-vdtvn "
Dec 18 11:52:31.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-qhk2x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5720'
Dec 18 11:52:31.301: INFO: stderr: ""
Dec 18 11:52:31.301: INFO: stdout: "true"
Dec 18 11:52:31.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-qhk2x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5720'
Dec 18 11:52:31.412: INFO: stderr: ""
Dec 18 11:52:31.412: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 18 11:52:31.412: INFO: validating pod update-demo-nautilus-qhk2x
Dec 18 11:52:31.485: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 18 11:52:31.485: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 18 11:52:31.486: INFO: update-demo-nautilus-qhk2x is verified up and running
Dec 18 11:52:31.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-vdtvn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5720'
Dec 18 11:52:31.595: INFO: stderr: ""
Dec 18 11:52:31.595: INFO: stdout: "true"
Dec 18 11:52:31.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-vdtvn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5720'
Dec 18 11:52:31.725: INFO: stderr: ""
Dec 18 11:52:31.726: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 18 11:52:31.726: INFO: validating pod update-demo-nautilus-vdtvn
Dec 18 11:52:31.845: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 18 11:52:31.845: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 18 11:52:31.845: INFO: update-demo-nautilus-vdtvn is verified up and running
STEP: using delete to clean up resources
Dec 18 11:52:31.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete --grace-period=0 --force -f - --namespace=kubectl-5720'
Dec 18 11:52:31.969: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 18 11:52:31.969: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 18 11:52:31.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5720'
Dec 18 11:52:32.095: INFO: stderr: "No resources found in kubectl-5720 namespace.\n"
Dec 18 11:52:32.095: INFO: stdout: ""
Dec 18 11:52:32.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -l name=update-demo --namespace=kubectl-5720 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 18 11:52:35.221: INFO: stderr: ""
Dec 18 11:52:35.221: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:52:35.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5720" for this suite.

• [SLOW TEST:15.498 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":273,"completed":9,"skipped":110,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:52:35.255: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-af113146-6b20-42a4-b949-2cec5135f684
STEP: Creating a pod to test consume secrets
Dec 18 11:52:35.490: INFO: Waiting up to 5m0s for pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607" in namespace "secrets-8541" to be "Succeeded or Failed"
Dec 18 11:52:35.498: INFO: Pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607": Phase="Pending", Reason="", readiness=false. Elapsed: 8.064303ms
Dec 18 11:52:37.507: INFO: Pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016431145s
Dec 18 11:52:39.517: INFO: Pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026426272s
Dec 18 11:52:41.529: INFO: Pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039065458s
Dec 18 11:52:43.539: INFO: Pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607": Phase="Pending", Reason="", readiness=false. Elapsed: 8.049218214s
Dec 18 11:52:45.548: INFO: Pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607": Phase="Pending", Reason="", readiness=false. Elapsed: 10.057656978s
Dec 18 11:52:47.557: INFO: Pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607": Phase="Pending", Reason="", readiness=false. Elapsed: 12.067135254s
Dec 18 11:52:49.568: INFO: Pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.078090255s
STEP: Saw pod success
Dec 18 11:52:49.568: INFO: Pod "pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607" satisfied condition "Succeeded or Failed"
Dec 18 11:52:49.577: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607 container secret-volume-test: <nil>
STEP: delete the pod
Dec 18 11:52:49.681: INFO: Waiting for pod pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607 to disappear
Dec 18 11:52:49.689: INFO: Pod pod-secrets-3ed49576-83e7-4677-86d3-eaf376c5f607 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:52:49.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8541" for this suite.

• [SLOW TEST:14.459 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":273,"completed":10,"skipped":134,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:52:49.721: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9720
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 11:52:50.524: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 11:52:52.557: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889170, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889170, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889170, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889170, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:52:54.567: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889170, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889170, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889170, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889170, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 11:52:57.591: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:52:58.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9720" for this suite.
STEP: Destroying namespace "webhook-9720-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.412 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":273,"completed":11,"skipped":146,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:52:59.136: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8812
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-97203707-4ac9-4dac-a53f-fff57512f2eb in namespace container-probe-8812
Dec 18 11:53:11.363: INFO: Started pod busybox-97203707-4ac9-4dac-a53f-fff57512f2eb in namespace container-probe-8812
STEP: checking the pod's current state and verifying that restartCount is present
Dec 18 11:53:11.370: INFO: Initial restart count of pod busybox-97203707-4ac9-4dac-a53f-fff57512f2eb is 0
Dec 18 11:54:01.616: INFO: Restart count of pod container-probe-8812/busybox-97203707-4ac9-4dac-a53f-fff57512f2eb is now 1 (50.245346022s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:54:01.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8812" for this suite.

• [SLOW TEST:62.531 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":273,"completed":12,"skipped":187,"failed":0}
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:54:01.667: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6389
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-2p6mj in namespace proxy-6389
I1218 11:54:01.918607      21 runners.go:190] Created replication controller with name: proxy-service-2p6mj, namespace: proxy-6389, replica count: 1
I1218 11:54:02.969762      21 runners.go:190] proxy-service-2p6mj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 11:54:03.970861      21 runners.go:190] proxy-service-2p6mj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 11:54:04.971302      21 runners.go:190] proxy-service-2p6mj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 11:54:05.971746      21 runners.go:190] proxy-service-2p6mj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 11:54:06.972221      21 runners.go:190] proxy-service-2p6mj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 11:54:07.972615      21 runners.go:190] proxy-service-2p6mj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1218 11:54:08.972935      21 runners.go:190] proxy-service-2p6mj Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 18 11:54:08.981: INFO: setup took 7.109457904s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 18 11:54:08.998: INFO: (0) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 15.790839ms)
Dec 18 11:54:09.005: INFO: (0) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 23.092898ms)
Dec 18 11:54:09.005: INFO: (0) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 22.930223ms)
Dec 18 11:54:09.005: INFO: (0) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 23.577452ms)
Dec 18 11:54:09.006: INFO: (0) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 23.655112ms)
Dec 18 11:54:09.005: INFO: (0) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 23.475807ms)
Dec 18 11:54:09.006: INFO: (0) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 23.551884ms)
Dec 18 11:54:09.010: INFO: (0) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 28.832789ms)
Dec 18 11:54:09.014: INFO: (0) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 32.196631ms)
Dec 18 11:54:09.014: INFO: (0) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 32.653505ms)
Dec 18 11:54:09.018: INFO: (0) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 35.817619ms)
Dec 18 11:54:09.018: INFO: (0) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 36.083211ms)
Dec 18 11:54:09.033: INFO: (0) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 50.703468ms)
Dec 18 11:54:09.033: INFO: (0) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 50.705176ms)
Dec 18 11:54:09.033: INFO: (0) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 50.877129ms)
Dec 18 11:54:09.034: INFO: (0) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 52.168092ms)
Dec 18 11:54:09.048: INFO: (1) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 12.835953ms)
Dec 18 11:54:09.049: INFO: (1) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 13.292853ms)
Dec 18 11:54:09.081: INFO: (1) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 44.552931ms)
Dec 18 11:54:09.087: INFO: (1) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 51.797969ms)
Dec 18 11:54:09.087: INFO: (1) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 52.226591ms)
Dec 18 11:54:09.087: INFO: (1) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 51.205783ms)
Dec 18 11:54:09.087: INFO: (1) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 51.545726ms)
Dec 18 11:54:09.087: INFO: (1) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 52.304875ms)
Dec 18 11:54:09.087: INFO: (1) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 51.65256ms)
Dec 18 11:54:09.088: INFO: (1) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 51.950375ms)
Dec 18 11:54:09.087: INFO: (1) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 51.905193ms)
Dec 18 11:54:09.087: INFO: (1) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 51.32869ms)
Dec 18 11:54:09.092: INFO: (1) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 56.325804ms)
Dec 18 11:54:09.130: INFO: (1) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 94.334332ms)
Dec 18 11:54:09.130: INFO: (1) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 94.180659ms)
Dec 18 11:54:09.130: INFO: (1) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 94.919373ms)
Dec 18 11:54:09.146: INFO: (2) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 15.601824ms)
Dec 18 11:54:09.146: INFO: (2) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 15.78434ms)
Dec 18 11:54:09.146: INFO: (2) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 15.812399ms)
Dec 18 11:54:09.146: INFO: (2) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 15.635411ms)
Dec 18 11:54:09.153: INFO: (2) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 21.612643ms)
Dec 18 11:54:09.158: INFO: (2) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 26.932862ms)
Dec 18 11:54:09.158: INFO: (2) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 27.011942ms)
Dec 18 11:54:09.158: INFO: (2) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 27.153131ms)
Dec 18 11:54:09.158: INFO: (2) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 27.389099ms)
Dec 18 11:54:09.158: INFO: (2) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 27.018954ms)
Dec 18 11:54:09.158: INFO: (2) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 27.651076ms)
Dec 18 11:54:09.158: INFO: (2) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 27.207651ms)
Dec 18 11:54:09.160: INFO: (2) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 29.153239ms)
Dec 18 11:54:09.206: INFO: (2) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 75.720614ms)
Dec 18 11:54:09.207: INFO: (2) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 75.976269ms)
Dec 18 11:54:09.207: INFO: (2) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 76.306159ms)
Dec 18 11:54:09.221: INFO: (3) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 13.171589ms)
Dec 18 11:54:09.221: INFO: (3) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 13.586385ms)
Dec 18 11:54:09.221: INFO: (3) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 13.419224ms)
Dec 18 11:54:09.221: INFO: (3) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 13.424943ms)
Dec 18 11:54:09.221: INFO: (3) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 13.670345ms)
Dec 18 11:54:09.221: INFO: (3) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 13.659896ms)
Dec 18 11:54:09.222: INFO: (3) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 14.113796ms)
Dec 18 11:54:09.222: INFO: (3) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 14.050505ms)
Dec 18 11:54:09.222: INFO: (3) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 15.101964ms)
Dec 18 11:54:09.222: INFO: (3) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 15.275843ms)
Dec 18 11:54:09.223: INFO: (3) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 15.833063ms)
Dec 18 11:54:09.225: INFO: (3) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 17.480585ms)
Dec 18 11:54:09.225: INFO: (3) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 17.537659ms)
Dec 18 11:54:09.225: INFO: (3) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 17.531049ms)
Dec 18 11:54:09.269: INFO: (3) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 61.821633ms)
Dec 18 11:54:09.270: INFO: (3) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 61.983433ms)
Dec 18 11:54:09.291: INFO: (4) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 19.892612ms)
Dec 18 11:54:09.291: INFO: (4) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 20.963092ms)
Dec 18 11:54:09.291: INFO: (4) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 20.389877ms)
Dec 18 11:54:09.291: INFO: (4) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 20.96529ms)
Dec 18 11:54:09.291: INFO: (4) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 20.67938ms)
Dec 18 11:54:09.292: INFO: (4) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 20.914807ms)
Dec 18 11:54:09.292: INFO: (4) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 21.215736ms)
Dec 18 11:54:09.292: INFO: (4) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 20.754409ms)
Dec 18 11:54:09.292: INFO: (4) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 21.448403ms)
Dec 18 11:54:09.292: INFO: (4) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 22.18426ms)
Dec 18 11:54:09.292: INFO: (4) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 21.900754ms)
Dec 18 11:54:09.293: INFO: (4) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 21.870763ms)
Dec 18 11:54:09.296: INFO: (4) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 25.458ms)
Dec 18 11:54:09.296: INFO: (4) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 25.227809ms)
Dec 18 11:54:09.334: INFO: (4) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 62.877631ms)
Dec 18 11:54:09.334: INFO: (4) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 63.190195ms)
Dec 18 11:54:09.347: INFO: (5) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 12.31939ms)
Dec 18 11:54:09.348: INFO: (5) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 13.83565ms)
Dec 18 11:54:09.348: INFO: (5) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 13.852645ms)
Dec 18 11:54:09.348: INFO: (5) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 14.20388ms)
Dec 18 11:54:09.349: INFO: (5) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 14.096773ms)
Dec 18 11:54:09.349: INFO: (5) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 14.81298ms)
Dec 18 11:54:09.350: INFO: (5) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 15.380572ms)
Dec 18 11:54:09.350: INFO: (5) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 15.970636ms)
Dec 18 11:54:09.351: INFO: (5) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 16.646794ms)
Dec 18 11:54:09.351: INFO: (5) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 16.910241ms)
Dec 18 11:54:09.351: INFO: (5) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 17.541653ms)
Dec 18 11:54:09.351: INFO: (5) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 17.203587ms)
Dec 18 11:54:09.352: INFO: (5) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 17.853196ms)
Dec 18 11:54:09.354: INFO: (5) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 19.133723ms)
Dec 18 11:54:09.356: INFO: (5) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 21.832364ms)
Dec 18 11:54:09.359: INFO: (5) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 24.804839ms)
Dec 18 11:54:09.370: INFO: (6) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 10.919682ms)
Dec 18 11:54:09.371: INFO: (6) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 10.778611ms)
Dec 18 11:54:09.372: INFO: (6) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 12.957253ms)
Dec 18 11:54:09.372: INFO: (6) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 12.9092ms)
Dec 18 11:54:09.373: INFO: (6) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 13.508604ms)
Dec 18 11:54:09.374: INFO: (6) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 14.290535ms)
Dec 18 11:54:09.375: INFO: (6) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 15.013516ms)
Dec 18 11:54:09.375: INFO: (6) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 15.37231ms)
Dec 18 11:54:09.375: INFO: (6) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 15.366344ms)
Dec 18 11:54:09.375: INFO: (6) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 15.713023ms)
Dec 18 11:54:09.376: INFO: (6) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 15.838535ms)
Dec 18 11:54:09.376: INFO: (6) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 16.880284ms)
Dec 18 11:54:09.377: INFO: (6) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 17.152985ms)
Dec 18 11:54:09.380: INFO: (6) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 20.696214ms)
Dec 18 11:54:09.381: INFO: (6) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 20.939648ms)
Dec 18 11:54:09.381: INFO: (6) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 21.256612ms)
Dec 18 11:54:09.392: INFO: (7) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 10.216734ms)
Dec 18 11:54:09.393: INFO: (7) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 11.817229ms)
Dec 18 11:54:09.394: INFO: (7) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 12.093663ms)
Dec 18 11:54:09.394: INFO: (7) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 12.610914ms)
Dec 18 11:54:09.394: INFO: (7) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 12.368997ms)
Dec 18 11:54:09.395: INFO: (7) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 13.45671ms)
Dec 18 11:54:09.395: INFO: (7) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 13.681665ms)
Dec 18 11:54:09.395: INFO: (7) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 14.031705ms)
Dec 18 11:54:09.395: INFO: (7) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 13.628123ms)
Dec 18 11:54:09.396: INFO: (7) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 14.583577ms)
Dec 18 11:54:09.396: INFO: (7) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 14.510558ms)
Dec 18 11:54:09.397: INFO: (7) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 15.684086ms)
Dec 18 11:54:09.397: INFO: (7) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 15.614675ms)
Dec 18 11:54:09.438: INFO: (7) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 55.992465ms)
Dec 18 11:54:09.438: INFO: (7) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 56.877698ms)
Dec 18 11:54:09.438: INFO: (7) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 56.643167ms)
Dec 18 11:54:09.451: INFO: (8) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 11.49875ms)
Dec 18 11:54:09.451: INFO: (8) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 12.441193ms)
Dec 18 11:54:09.451: INFO: (8) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 12.67801ms)
Dec 18 11:54:09.452: INFO: (8) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 13.066249ms)
Dec 18 11:54:09.452: INFO: (8) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 13.441351ms)
Dec 18 11:54:09.454: INFO: (8) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 15.063336ms)
Dec 18 11:54:09.454: INFO: (8) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 14.681935ms)
Dec 18 11:54:09.454: INFO: (8) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 15.918941ms)
Dec 18 11:54:09.456: INFO: (8) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 17.288707ms)
Dec 18 11:54:09.457: INFO: (8) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 18.154043ms)
Dec 18 11:54:09.459: INFO: (8) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 19.99162ms)
Dec 18 11:54:09.459: INFO: (8) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 20.05162ms)
Dec 18 11:54:09.459: INFO: (8) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 20.450877ms)
Dec 18 11:54:09.459: INFO: (8) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 20.209448ms)
Dec 18 11:54:09.460: INFO: (8) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 21.089734ms)
Dec 18 11:54:09.461: INFO: (8) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 22.129077ms)
Dec 18 11:54:09.483: INFO: (9) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 22.21711ms)
Dec 18 11:54:09.484: INFO: (9) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 22.950508ms)
Dec 18 11:54:09.484: INFO: (9) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 22.992592ms)
Dec 18 11:54:09.484: INFO: (9) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 22.887421ms)
Dec 18 11:54:09.484: INFO: (9) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 23.023939ms)
Dec 18 11:54:09.484: INFO: (9) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 22.92851ms)
Dec 18 11:54:09.484: INFO: (9) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 23.275457ms)
Dec 18 11:54:09.484: INFO: (9) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 23.117013ms)
Dec 18 11:54:09.484: INFO: (9) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 22.88679ms)
Dec 18 11:54:09.484: INFO: (9) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 23.21221ms)
Dec 18 11:54:09.536: INFO: (9) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 75.341222ms)
Dec 18 11:54:09.537: INFO: (9) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 76.03942ms)
Dec 18 11:54:09.537: INFO: (9) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 75.735114ms)
Dec 18 11:54:09.537: INFO: (9) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 75.88319ms)
Dec 18 11:54:09.537: INFO: (9) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 76.041576ms)
Dec 18 11:54:09.537: INFO: (9) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 76.186084ms)
Dec 18 11:54:09.554: INFO: (10) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 17.178264ms)
Dec 18 11:54:09.554: INFO: (10) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 16.837416ms)
Dec 18 11:54:09.554: INFO: (10) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 16.754915ms)
Dec 18 11:54:09.554: INFO: (10) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 17.05527ms)
Dec 18 11:54:09.555: INFO: (10) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 17.069893ms)
Dec 18 11:54:09.555: INFO: (10) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 17.561492ms)
Dec 18 11:54:09.555: INFO: (10) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 17.978988ms)
Dec 18 11:54:09.555: INFO: (10) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 17.577894ms)
Dec 18 11:54:09.556: INFO: (10) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 18.060654ms)
Dec 18 11:54:09.606: INFO: (10) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 68.312864ms)
Dec 18 11:54:09.606: INFO: (10) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 68.292377ms)
Dec 18 11:54:09.606: INFO: (10) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 67.924235ms)
Dec 18 11:54:09.606: INFO: (10) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 68.445457ms)
Dec 18 11:54:09.606: INFO: (10) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 68.582884ms)
Dec 18 11:54:09.606: INFO: (10) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 69.067131ms)
Dec 18 11:54:09.608: INFO: (10) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 70.711708ms)
Dec 18 11:54:09.621: INFO: (11) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 12.151615ms)
Dec 18 11:54:09.621: INFO: (11) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 12.484189ms)
Dec 18 11:54:09.622: INFO: (11) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 12.397536ms)
Dec 18 11:54:09.622: INFO: (11) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 13.085929ms)
Dec 18 11:54:09.622: INFO: (11) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 13.44017ms)
Dec 18 11:54:09.622: INFO: (11) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 13.723721ms)
Dec 18 11:54:09.623: INFO: (11) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 14.068022ms)
Dec 18 11:54:09.623: INFO: (11) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 14.126675ms)
Dec 18 11:54:09.624: INFO: (11) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 15.085134ms)
Dec 18 11:54:09.624: INFO: (11) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 15.668162ms)
Dec 18 11:54:09.625: INFO: (11) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 15.695883ms)
Dec 18 11:54:09.627: INFO: (11) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 18.279767ms)
Dec 18 11:54:09.627: INFO: (11) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 18.247965ms)
Dec 18 11:54:09.627: INFO: (11) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 18.064158ms)
Dec 18 11:54:09.627: INFO: (11) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 18.296454ms)
Dec 18 11:54:09.629: INFO: (11) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 20.483201ms)
Dec 18 11:54:09.641: INFO: (12) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 11.506564ms)
Dec 18 11:54:09.642: INFO: (12) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 11.73047ms)
Dec 18 11:54:09.642: INFO: (12) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 12.008114ms)
Dec 18 11:54:09.642: INFO: (12) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 12.601756ms)
Dec 18 11:54:09.642: INFO: (12) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 12.821756ms)
Dec 18 11:54:09.643: INFO: (12) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 13.345624ms)
Dec 18 11:54:09.643: INFO: (12) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 13.081015ms)
Dec 18 11:54:09.643: INFO: (12) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 13.211078ms)
Dec 18 11:54:09.644: INFO: (12) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 14.326132ms)
Dec 18 11:54:09.644: INFO: (12) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 14.419487ms)
Dec 18 11:54:09.645: INFO: (12) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 14.79356ms)
Dec 18 11:54:09.646: INFO: (12) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 16.024783ms)
Dec 18 11:54:09.685: INFO: (12) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 55.402135ms)
Dec 18 11:54:09.685: INFO: (12) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 55.522279ms)
Dec 18 11:54:09.685: INFO: (12) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 55.5814ms)
Dec 18 11:54:09.685: INFO: (12) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 55.382429ms)
Dec 18 11:54:09.711: INFO: (13) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 25.028408ms)
Dec 18 11:54:09.711: INFO: (13) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 25.234725ms)
Dec 18 11:54:09.711: INFO: (13) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 25.403729ms)
Dec 18 11:54:09.712: INFO: (13) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 26.114943ms)
Dec 18 11:54:09.712: INFO: (13) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 25.811178ms)
Dec 18 11:54:09.712: INFO: (13) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 26.091055ms)
Dec 18 11:54:09.712: INFO: (13) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 26.672309ms)
Dec 18 11:54:09.714: INFO: (13) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 27.276819ms)
Dec 18 11:54:09.714: INFO: (13) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 28.209115ms)
Dec 18 11:54:09.714: INFO: (13) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 27.987529ms)
Dec 18 11:54:09.714: INFO: (13) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 28.082958ms)
Dec 18 11:54:09.715: INFO: (13) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 28.788537ms)
Dec 18 11:54:09.717: INFO: (13) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 30.600819ms)
Dec 18 11:54:09.721: INFO: (13) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 34.803887ms)
Dec 18 11:54:09.722: INFO: (13) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 36.073852ms)
Dec 18 11:54:09.722: INFO: (13) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 36.316712ms)
Dec 18 11:54:09.739: INFO: (14) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 15.96147ms)
Dec 18 11:54:09.739: INFO: (14) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 15.851039ms)
Dec 18 11:54:09.739: INFO: (14) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 16.262657ms)
Dec 18 11:54:09.739: INFO: (14) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 16.517407ms)
Dec 18 11:54:09.739: INFO: (14) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 15.96763ms)
Dec 18 11:54:09.740: INFO: (14) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 16.478555ms)
Dec 18 11:54:09.740: INFO: (14) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 16.623805ms)
Dec 18 11:54:09.740: INFO: (14) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 16.634412ms)
Dec 18 11:54:09.741: INFO: (14) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 17.342443ms)
Dec 18 11:54:09.741: INFO: (14) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 17.144803ms)
Dec 18 11:54:09.746: INFO: (14) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 22.552847ms)
Dec 18 11:54:09.746: INFO: (14) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 22.620461ms)
Dec 18 11:54:09.746: INFO: (14) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 23.650047ms)
Dec 18 11:54:09.746: INFO: (14) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 22.784182ms)
Dec 18 11:54:09.747: INFO: (14) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 23.418606ms)
Dec 18 11:54:09.750: INFO: (14) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 26.737496ms)
Dec 18 11:54:09.763: INFO: (15) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 12.712151ms)
Dec 18 11:54:09.764: INFO: (15) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 13.506978ms)
Dec 18 11:54:09.764: INFO: (15) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 13.36991ms)
Dec 18 11:54:09.764: INFO: (15) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 13.364883ms)
Dec 18 11:54:09.764: INFO: (15) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 13.700083ms)
Dec 18 11:54:09.765: INFO: (15) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 14.75459ms)
Dec 18 11:54:09.767: INFO: (15) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 16.307004ms)
Dec 18 11:54:09.767: INFO: (15) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 16.591177ms)
Dec 18 11:54:09.767: INFO: (15) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 16.612632ms)
Dec 18 11:54:09.767: INFO: (15) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 16.438664ms)
Dec 18 11:54:09.768: INFO: (15) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 17.730657ms)
Dec 18 11:54:09.769: INFO: (15) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 18.044906ms)
Dec 18 11:54:09.769: INFO: (15) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 18.271125ms)
Dec 18 11:54:09.781: INFO: (15) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 30.543688ms)
Dec 18 11:54:09.781: INFO: (15) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 31.160881ms)
Dec 18 11:54:09.782: INFO: (15) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 31.070449ms)
Dec 18 11:54:09.794: INFO: (16) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 11.981618ms)
Dec 18 11:54:09.794: INFO: (16) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 12.294453ms)
Dec 18 11:54:09.794: INFO: (16) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 11.128613ms)
Dec 18 11:54:09.794: INFO: (16) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 11.587469ms)
Dec 18 11:54:09.794: INFO: (16) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 11.9963ms)
Dec 18 11:54:09.796: INFO: (16) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 13.174558ms)
Dec 18 11:54:09.797: INFO: (16) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 14.146287ms)
Dec 18 11:54:09.797: INFO: (16) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 14.497327ms)
Dec 18 11:54:09.797: INFO: (16) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 14.615248ms)
Dec 18 11:54:09.797: INFO: (16) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 15.371821ms)
Dec 18 11:54:09.797: INFO: (16) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 14.344141ms)
Dec 18 11:54:09.797: INFO: (16) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 15.146012ms)
Dec 18 11:54:09.797: INFO: (16) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 15.275941ms)
Dec 18 11:54:09.843: INFO: (16) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 61.074871ms)
Dec 18 11:54:09.869: INFO: (16) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 87.513296ms)
Dec 18 11:54:09.870: INFO: (16) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 87.757932ms)
Dec 18 11:54:09.882: INFO: (17) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 11.454647ms)
Dec 18 11:54:09.882: INFO: (17) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 11.951423ms)
Dec 18 11:54:09.885: INFO: (17) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 14.404834ms)
Dec 18 11:54:09.885: INFO: (17) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 15.451701ms)
Dec 18 11:54:09.886: INFO: (17) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 15.521305ms)
Dec 18 11:54:09.885: INFO: (17) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 15.334177ms)
Dec 18 11:54:09.886: INFO: (17) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 15.906573ms)
Dec 18 11:54:09.886: INFO: (17) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 15.991028ms)
Dec 18 11:54:09.886: INFO: (17) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 16.334345ms)
Dec 18 11:54:09.890: INFO: (17) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 19.99896ms)
Dec 18 11:54:09.891: INFO: (17) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 21.187261ms)
Dec 18 11:54:09.891: INFO: (17) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 21.285383ms)
Dec 18 11:54:09.893: INFO: (17) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 22.317219ms)
Dec 18 11:54:09.929: INFO: (17) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 58.981404ms)
Dec 18 11:54:09.930: INFO: (17) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 59.788376ms)
Dec 18 11:54:09.930: INFO: (17) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 59.582044ms)
Dec 18 11:54:09.946: INFO: (18) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 15.976941ms)
Dec 18 11:54:09.946: INFO: (18) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 16.077096ms)
Dec 18 11:54:09.946: INFO: (18) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 16.445325ms)
Dec 18 11:54:09.946: INFO: (18) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 16.35115ms)
Dec 18 11:54:09.946: INFO: (18) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 16.529122ms)
Dec 18 11:54:09.946: INFO: (18) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 16.205212ms)
Dec 18 11:54:09.946: INFO: (18) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 16.191688ms)
Dec 18 11:54:09.947: INFO: (18) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 16.431485ms)
Dec 18 11:54:09.947: INFO: (18) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 16.659522ms)
Dec 18 11:54:09.947: INFO: (18) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 16.429116ms)
Dec 18 11:54:09.949: INFO: (18) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 18.656223ms)
Dec 18 11:54:09.949: INFO: (18) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 18.603148ms)
Dec 18 11:54:09.949: INFO: (18) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 19.463905ms)
Dec 18 11:54:09.953: INFO: (18) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 22.332481ms)
Dec 18 11:54:09.953: INFO: (18) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 22.332337ms)
Dec 18 11:54:09.953: INFO: (18) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 22.853428ms)
Dec 18 11:54:09.972: INFO: (19) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:460/proxy/: tls baz (200; 18.605922ms)
Dec 18 11:54:09.972: INFO: (19) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">... (200; 18.769571ms)
Dec 18 11:54:09.972: INFO: (19) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 18.527415ms)
Dec 18 11:54:09.972: INFO: (19) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:443/proxy/tlsrewritem... (200; 18.907097ms)
Dec 18 11:54:09.972: INFO: (19) /api/v1/namespaces/proxy-6389/pods/https:proxy-service-2p6mj-2rc9l:462/proxy/: tls qux (200; 18.465908ms)
Dec 18 11:54:09.972: INFO: (19) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:1080/proxy/rewriteme">test<... (200; 19.02621ms)
Dec 18 11:54:09.972: INFO: (19) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 19.013865ms)
Dec 18 11:54:09.974: INFO: (19) /api/v1/namespaces/proxy-6389/pods/http:proxy-service-2p6mj-2rc9l:160/proxy/: foo (200; 20.839422ms)
Dec 18 11:54:09.981: INFO: (19) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/: <a href="/api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l/proxy/rewriteme">test</a> (200; 27.228516ms)
Dec 18 11:54:09.981: INFO: (19) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname2/proxy/: bar (200; 27.694829ms)
Dec 18 11:54:09.981: INFO: (19) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname2/proxy/: tls qux (200; 27.515871ms)
Dec 18 11:54:09.981: INFO: (19) /api/v1/namespaces/proxy-6389/services/https:proxy-service-2p6mj:tlsportname1/proxy/: tls baz (200; 27.644932ms)
Dec 18 11:54:09.983: INFO: (19) /api/v1/namespaces/proxy-6389/services/proxy-service-2p6mj:portname1/proxy/: foo (200; 29.429983ms)
Dec 18 11:54:09.983: INFO: (19) /api/v1/namespaces/proxy-6389/pods/proxy-service-2p6mj-2rc9l:162/proxy/: bar (200; 29.273216ms)
Dec 18 11:54:09.983: INFO: (19) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname1/proxy/: foo (200; 29.735248ms)
Dec 18 11:54:09.986: INFO: (19) /api/v1/namespaces/proxy-6389/services/http:proxy-service-2p6mj:portname2/proxy/: bar (200; 32.497677ms)
STEP: deleting ReplicationController proxy-service-2p6mj in namespace proxy-6389, will wait for the garbage collector to delete the pods
Dec 18 11:54:10.067: INFO: Deleting ReplicationController proxy-service-2p6mj took: 21.191541ms
Dec 18 11:54:10.667: INFO: Terminating ReplicationController proxy-service-2p6mj pods took: 600.530453ms
[AfterEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:54:19.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6389" for this suite.

• [SLOW TEST:18.024 seconds]
[sig-network] Proxy
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":273,"completed":13,"skipped":188,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:54:19.693: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7868
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Dec 18 11:54:26.503: INFO: Successfully updated pod "annotationupdate78007c63-0e15-40c8-914e-7798c96b7e4d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:54:28.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7868" for this suite.

• [SLOW TEST:8.925 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":273,"completed":14,"skipped":201,"failed":0}
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:54:28.620: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 18 11:54:35.453: INFO: Successfully updated pod "pod-update-activedeadlineseconds-53ed8ba0-b4c0-4f15-bbdf-819383089451"
Dec 18 11:54:35.453: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-53ed8ba0-b4c0-4f15-bbdf-819383089451" in namespace "pods-748" to be "terminated due to deadline exceeded"
Dec 18 11:54:35.460: INFO: Pod "pod-update-activedeadlineseconds-53ed8ba0-b4c0-4f15-bbdf-819383089451": Phase="Running", Reason="", readiness=true. Elapsed: 7.596309ms
Dec 18 11:54:37.469: INFO: Pod "pod-update-activedeadlineseconds-53ed8ba0-b4c0-4f15-bbdf-819383089451": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.016667186s
Dec 18 11:54:37.470: INFO: Pod "pod-update-activedeadlineseconds-53ed8ba0-b4c0-4f15-bbdf-819383089451" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:54:37.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-748" for this suite.

• [SLOW TEST:8.879 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":273,"completed":15,"skipped":206,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:54:37.508: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5638
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 18 11:54:43.794: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-5638 PodName:pod-sharedvolume-47430606-e99d-466e-a280-f2197c6abe31 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 11:54:43.794: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 11:54:44.079: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:54:44.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5638" for this suite.

• [SLOW TEST:6.600 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":273,"completed":16,"skipped":234,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:54:44.113: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4872
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-2a3b5aca-82e7-4421-b77d-87293ab2bf50
STEP: Creating secret with name s-test-opt-upd-f7ad16b3-0448-4918-8617-6a4469118b0e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2a3b5aca-82e7-4421-b77d-87293ab2bf50
STEP: Updating secret s-test-opt-upd-f7ad16b3-0448-4918-8617-6a4469118b0e
STEP: Creating secret with name s-test-opt-create-f27fa595-2d55-491f-b74b-2c9c522e2134
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:55:55.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4872" for this suite.

• [SLOW TEST:71.498 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":17,"skipped":256,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:55:55.616: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3032
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 18 11:56:07.995: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 18 11:56:08.006: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 18 11:56:10.007: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 18 11:56:10.022: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 18 11:56:12.007: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 18 11:56:12.015: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 18 11:56:14.007: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 18 11:56:14.021: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 18 11:56:16.007: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 18 11:56:16.016: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 18 11:56:18.007: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 18 11:56:18.015: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 18 11:56:20.007: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 18 11:56:20.019: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:56:20.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3032" for this suite.

• [SLOW TEST:24.426 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":273,"completed":18,"skipped":343,"failed":0}
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:56:20.042: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3562
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-c302ab60-ff0b-4860-b00a-78c9695a62a5
STEP: Creating a pod to test consume configMaps
Dec 18 11:56:20.289: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e78cf7b5-582c-46e4-9018-01950e8df89f" in namespace "projected-3562" to be "Succeeded or Failed"
Dec 18 11:56:20.297: INFO: Pod "pod-projected-configmaps-e78cf7b5-582c-46e4-9018-01950e8df89f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012781ms
Dec 18 11:56:22.307: INFO: Pod "pod-projected-configmaps-e78cf7b5-582c-46e4-9018-01950e8df89f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018535715s
Dec 18 11:56:24.317: INFO: Pod "pod-projected-configmaps-e78cf7b5-582c-46e4-9018-01950e8df89f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027698062s
Dec 18 11:56:26.325: INFO: Pod "pod-projected-configmaps-e78cf7b5-582c-46e4-9018-01950e8df89f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036019307s
STEP: Saw pod success
Dec 18 11:56:26.325: INFO: Pod "pod-projected-configmaps-e78cf7b5-582c-46e4-9018-01950e8df89f" satisfied condition "Succeeded or Failed"
Dec 18 11:56:26.338: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-configmaps-e78cf7b5-582c-46e4-9018-01950e8df89f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 11:56:26.402: INFO: Waiting for pod pod-projected-configmaps-e78cf7b5-582c-46e4-9018-01950e8df89f to disappear
Dec 18 11:56:26.409: INFO: Pod pod-projected-configmaps-e78cf7b5-582c-46e4-9018-01950e8df89f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:56:26.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3562" for this suite.

• [SLOW TEST:6.390 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":273,"completed":19,"skipped":343,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:56:26.433: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-7fbbbce1-0900-4c94-95f6-e532930e1ad6
STEP: Creating a pod to test consume secrets
Dec 18 11:56:26.663: INFO: Waiting up to 5m0s for pod "pod-secrets-35b5da20-86eb-4d67-a73e-0270effdd191" in namespace "secrets-9855" to be "Succeeded or Failed"
Dec 18 11:56:26.669: INFO: Pod "pod-secrets-35b5da20-86eb-4d67-a73e-0270effdd191": Phase="Pending", Reason="", readiness=false. Elapsed: 6.240624ms
Dec 18 11:56:28.677: INFO: Pod "pod-secrets-35b5da20-86eb-4d67-a73e-0270effdd191": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013890975s
Dec 18 11:56:30.690: INFO: Pod "pod-secrets-35b5da20-86eb-4d67-a73e-0270effdd191": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026914562s
Dec 18 11:56:32.698: INFO: Pod "pod-secrets-35b5da20-86eb-4d67-a73e-0270effdd191": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035362756s
STEP: Saw pod success
Dec 18 11:56:32.698: INFO: Pod "pod-secrets-35b5da20-86eb-4d67-a73e-0270effdd191" satisfied condition "Succeeded or Failed"
Dec 18 11:56:32.706: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-secrets-35b5da20-86eb-4d67-a73e-0270effdd191 container secret-volume-test: <nil>
STEP: delete the pod
Dec 18 11:56:32.760: INFO: Waiting for pod pod-secrets-35b5da20-86eb-4d67-a73e-0270effdd191 to disappear
Dec 18 11:56:32.767: INFO: Pod pod-secrets-35b5da20-86eb-4d67-a73e-0270effdd191 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:56:32.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9855" for this suite.

• [SLOW TEST:6.359 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":20,"skipped":345,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:56:32.796: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-17
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 11:56:33.710: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 18 11:56:35.738: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889393, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889393, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889393, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889393, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:56:37.748: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889393, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889393, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889393, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889393, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 11:56:40.771: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 18 11:56:40.910: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:56:41.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-17" for this suite.
STEP: Destroying namespace "webhook-17-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.410 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":273,"completed":21,"skipped":351,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:56:41.207: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7542
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 11:56:41.420: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 18 11:56:45.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7542 create -f -'
Dec 18 11:56:48.171: INFO: stderr: ""
Dec 18 11:56:48.171: INFO: stdout: "e2e-test-crd-publish-openapi-4303-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 18 11:56:48.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7542 delete e2e-test-crd-publish-openapi-4303-crds test-cr'
Dec 18 11:56:48.637: INFO: stderr: ""
Dec 18 11:56:48.637: INFO: stdout: "e2e-test-crd-publish-openapi-4303-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 18 11:56:48.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7542 apply -f -'
Dec 18 11:56:49.050: INFO: stderr: ""
Dec 18 11:56:49.050: INFO: stdout: "e2e-test-crd-publish-openapi-4303-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 18 11:56:49.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7542 delete e2e-test-crd-publish-openapi-4303-crds test-cr'
Dec 18 11:56:49.439: INFO: stderr: ""
Dec 18 11:56:49.439: INFO: stdout: "e2e-test-crd-publish-openapi-4303-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 18 11:56:49.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 explain e2e-test-crd-publish-openapi-4303-crds'
Dec 18 11:56:49.754: INFO: stderr: ""
Dec 18 11:56:49.754: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4303-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:56:53.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7542" for this suite.

• [SLOW TEST:12.336 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":273,"completed":22,"skipped":368,"failed":0}
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:56:53.545: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3853
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 11:56:53.763: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 18 11:56:58.773: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 18 11:56:58.773: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 18 11:57:00.799: INFO: Creating deployment "test-rollover-deployment"
Dec 18 11:57:00.951: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 18 11:57:02.969: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 18 11:57:02.984: INFO: Ensure that both replica sets have 1 created replica
Dec 18 11:57:02.997: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 18 11:57:03.188: INFO: Updating deployment test-rollover-deployment
Dec 18 11:57:03.188: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 18 11:57:05.205: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 18 11:57:05.233: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 18 11:57:05.250: INFO: all replica sets need to contain the pod-template-hash label
Dec 18 11:57:05.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889424, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889420, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:57:07.268: INFO: all replica sets need to contain the pod-template-hash label
Dec 18 11:57:07.269: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889424, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889420, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:57:09.285: INFO: all replica sets need to contain the pod-template-hash label
Dec 18 11:57:09.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889424, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889420, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:57:11.267: INFO: all replica sets need to contain the pod-template-hash label
Dec 18 11:57:11.267: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889430, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889420, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:57:13.266: INFO: all replica sets need to contain the pod-template-hash label
Dec 18 11:57:13.266: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889430, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889420, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:57:15.271: INFO: all replica sets need to contain the pod-template-hash label
Dec 18 11:57:15.271: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889430, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889420, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:57:17.265: INFO: all replica sets need to contain the pod-template-hash label
Dec 18 11:57:17.265: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889430, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889420, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:57:19.268: INFO: all replica sets need to contain the pod-template-hash label
Dec 18 11:57:19.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889421, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889430, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889420, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:57:21.269: INFO: 
Dec 18 11:57:21.269: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 18 11:57:21.289: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-3853 /apis/apps/v1/namespaces/deployment-3853/deployments/test-rollover-deployment 9150b8b1-94b9-47f9-a1da-6674d7bcbbf0 78464 2 2020-12-18 11:57:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-12-18 11:57:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-18 11:57:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047ad818 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-12-18 11:57:01 +0000 UTC,LastTransitionTime:2020-12-18 11:57:01 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-12-18 11:57:20 +0000 UTC,LastTransitionTime:2020-12-18 11:57:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 18 11:57:21.304: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-3853 /apis/apps/v1/namespaces/deployment-3853/replicasets/test-rollover-deployment-84f7f6f64b bf419379-c2be-4e9c-a298-f20a658cd5b9 78451 2 2020-12-18 11:57:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 9150b8b1-94b9-47f9-a1da-6674d7bcbbf0 0xc0047adea7 0xc0047adea8}] []  [{kube-controller-manager Update apps/v1 2020-12-18 11:57:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 49 53 48 98 56 98 49 45 57 52 98 57 45 52 55 102 57 45 97 49 100 97 45 54 54 55 52 100 55 98 99 98 98 102 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047adf48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 18 11:57:21.304: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 18 11:57:21.305: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3853 /apis/apps/v1/namespaces/deployment-3853/replicasets/test-rollover-controller 07dfb147-e3c6-4ec6-adc1-4a9347b29ae8 78463 2 2020-12-18 11:56:53 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 9150b8b1-94b9-47f9-a1da-6674d7bcbbf0 0xc0047adc67 0xc0047adc68}] []  [{e2e.test Update apps/v1 2020-12-18 11:56:53 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-18 11:57:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 49 53 48 98 56 98 49 45 57 52 98 57 45 52 55 102 57 45 97 49 100 97 45 54 54 55 52 100 55 98 99 98 98 102 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0047add08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 18 11:57:21.305: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-3853 /apis/apps/v1/namespaces/deployment-3853/replicasets/test-rollover-deployment-5686c4cfd5 15337f1b-fce6-4f9a-80f5-14349cfec2d3 78359 2 2020-12-18 11:57:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 9150b8b1-94b9-47f9-a1da-6674d7bcbbf0 0xc0047add77 0xc0047add78}] []  [{kube-controller-manager Update apps/v1 2020-12-18 11:57:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 57 49 53 48 98 56 98 49 45 57 52 98 57 45 52 55 102 57 45 97 49 100 97 45 54 54 55 52 100 55 98 99 98 98 102 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047ade08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 18 11:57:21.313: INFO: Pod "test-rollover-deployment-84f7f6f64b-glbcw" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-glbcw test-rollover-deployment-84f7f6f64b- deployment-3853 /api/v1/namespaces/deployment-3853/pods/test-rollover-deployment-84f7f6f64b-glbcw acf41106-81b2-41d8-89d9-bf1320342819 78399 0 2020-12-18 11:57:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[cni.projectcalico.org/podIP:172.25.1.58/32 cni.projectcalico.org/podIPs:172.25.1.58/32] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b bf419379-c2be-4e9c-a298-f20a658cd5b9 0xc004835a47 0xc004835a48}] []  [{kube-controller-manager Update v1 2020-12-18 11:57:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 102 52 49 57 51 55 57 45 99 50 98 101 45 52 101 57 99 45 97 50 57 56 45 102 50 48 97 54 53 56 99 100 53 98 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 11:57:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 11:57:10 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 49 46 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-v4z52,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-v4z52,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-v4z52,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 11:57:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 11:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 11:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 11:57:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:172.25.1.58,StartTime:2020-12-18 11:57:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 11:57:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://86c88c404a9c56a744b0f97f18c52c7da477fd2abc47335b0ae5448fb678b223,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:57:21.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3853" for this suite.

• [SLOW TEST:27.793 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":273,"completed":23,"skipped":368,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:57:21.339: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4414
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-126b3f71-d2da-4792-93cd-c7aa7da0288a
STEP: Creating a pod to test consume secrets
Dec 18 11:57:21.570: INFO: Waiting up to 5m0s for pod "pod-secrets-bf7ba62b-ee39-438d-8e9f-70b4691ba7d3" in namespace "secrets-4414" to be "Succeeded or Failed"
Dec 18 11:57:21.577: INFO: Pod "pod-secrets-bf7ba62b-ee39-438d-8e9f-70b4691ba7d3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.543312ms
Dec 18 11:57:23.589: INFO: Pod "pod-secrets-bf7ba62b-ee39-438d-8e9f-70b4691ba7d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01824612s
Dec 18 11:57:25.598: INFO: Pod "pod-secrets-bf7ba62b-ee39-438d-8e9f-70b4691ba7d3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027174045s
Dec 18 11:57:27.611: INFO: Pod "pod-secrets-bf7ba62b-ee39-438d-8e9f-70b4691ba7d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040353319s
STEP: Saw pod success
Dec 18 11:57:27.611: INFO: Pod "pod-secrets-bf7ba62b-ee39-438d-8e9f-70b4691ba7d3" satisfied condition "Succeeded or Failed"
Dec 18 11:57:27.628: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-secrets-bf7ba62b-ee39-438d-8e9f-70b4691ba7d3 container secret-volume-test: <nil>
STEP: delete the pod
Dec 18 11:57:27.695: INFO: Waiting for pod pod-secrets-bf7ba62b-ee39-438d-8e9f-70b4691ba7d3 to disappear
Dec 18 11:57:27.702: INFO: Pod pod-secrets-bf7ba62b-ee39-438d-8e9f-70b4691ba7d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:57:27.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4414" for this suite.

• [SLOW TEST:6.391 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":273,"completed":24,"skipped":424,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:57:27.737: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 18 11:57:40.035: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 18 11:57:40.045: INFO: Pod pod-with-poststart-http-hook still exists
Dec 18 11:57:42.046: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 18 11:57:42.054: INFO: Pod pod-with-poststart-http-hook still exists
Dec 18 11:57:44.046: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 18 11:57:44.053: INFO: Pod pod-with-poststart-http-hook still exists
Dec 18 11:57:46.046: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 18 11:57:46.055: INFO: Pod pod-with-poststart-http-hook still exists
Dec 18 11:57:48.046: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 18 11:57:48.055: INFO: Pod pod-with-poststart-http-hook still exists
Dec 18 11:57:50.046: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 18 11:57:50.055: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:57:50.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7458" for this suite.

• [SLOW TEST:22.343 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":273,"completed":25,"skipped":436,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:57:50.080: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2091
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 18 11:57:50.406: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2091 /api/v1/namespaces/watch-2091/configmaps/e2e-watch-test-label-changed 94644664-a1ab-4b38-b212-8b9b39d581dc 78730 0 2020-12-18 11:57:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-18 11:57:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 11:57:50.407: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2091 /api/v1/namespaces/watch-2091/configmaps/e2e-watch-test-label-changed 94644664-a1ab-4b38-b212-8b9b39d581dc 78731 0 2020-12-18 11:57:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-18 11:57:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 11:57:50.409: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2091 /api/v1/namespaces/watch-2091/configmaps/e2e-watch-test-label-changed 94644664-a1ab-4b38-b212-8b9b39d581dc 78732 0 2020-12-18 11:57:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-18 11:57:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 18 11:58:00.498: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2091 /api/v1/namespaces/watch-2091/configmaps/e2e-watch-test-label-changed 94644664-a1ab-4b38-b212-8b9b39d581dc 78805 0 2020-12-18 11:57:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-18 11:58:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 11:58:00.499: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2091 /api/v1/namespaces/watch-2091/configmaps/e2e-watch-test-label-changed 94644664-a1ab-4b38-b212-8b9b39d581dc 78806 0 2020-12-18 11:57:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-18 11:58:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 11:58:00.499: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2091 /api/v1/namespaces/watch-2091/configmaps/e2e-watch-test-label-changed 94644664-a1ab-4b38-b212-8b9b39d581dc 78807 0 2020-12-18 11:57:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-12-18 11:58:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:58:00.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2091" for this suite.

• [SLOW TEST:10.444 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":273,"completed":26,"skipped":437,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:58:00.525: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8322
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-79e0ea0a-996e-4007-a2e8-a06dfe43e545
STEP: Creating a pod to test consume configMaps
Dec 18 11:58:00.763: INFO: Waiting up to 5m0s for pod "pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2" in namespace "configmap-8322" to be "Succeeded or Failed"
Dec 18 11:58:00.772: INFO: Pod "pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.177404ms
Dec 18 11:58:02.779: INFO: Pod "pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015899449s
Dec 18 11:58:04.787: INFO: Pod "pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02403035s
Dec 18 11:58:06.806: INFO: Pod "pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04260573s
Dec 18 11:58:08.814: INFO: Pod "pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.050696283s
STEP: Saw pod success
Dec 18 11:58:08.814: INFO: Pod "pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2" satisfied condition "Succeeded or Failed"
Dec 18 11:58:08.824: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 11:58:08.872: INFO: Waiting for pod pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2 to disappear
Dec 18 11:58:08.878: INFO: Pod pod-configmaps-061fc614-f241-4353-b876-1f48f35efdb2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:58:08.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8322" for this suite.

• [SLOW TEST:8.381 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":273,"completed":27,"skipped":438,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:58:08.908: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1123
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 11:58:09.109: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:58:09.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1123" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":273,"completed":28,"skipped":451,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:58:09.712: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Dec 18 11:58:09.989: INFO: Waiting up to 5m0s for pod "client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f" in namespace "containers-8795" to be "Succeeded or Failed"
Dec 18 11:58:09.996: INFO: Pod "client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.081783ms
Dec 18 11:58:12.005: INFO: Pod "client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016185239s
Dec 18 11:58:14.018: INFO: Pod "client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029569083s
Dec 18 11:58:16.026: INFO: Pod "client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037366365s
Dec 18 11:58:18.166: INFO: Pod "client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.176693584s
STEP: Saw pod success
Dec 18 11:58:18.166: INFO: Pod "client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f" satisfied condition "Succeeded or Failed"
Dec 18 11:58:18.179: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f container test-container: <nil>
STEP: delete the pod
Dec 18 11:58:18.262: INFO: Waiting for pod client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f to disappear
Dec 18 11:58:18.270: INFO: Pod client-containers-141e6c9e-511f-4ea2-b236-558077f5b75f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:58:18.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8795" for this suite.

• [SLOW TEST:8.581 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":273,"completed":29,"skipped":471,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:58:18.295: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8314
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 18 11:58:18.680: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 11:58:22.574: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:58:37.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8314" for this suite.

• [SLOW TEST:19.546 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":273,"completed":30,"skipped":489,"failed":0}
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:58:37.841: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7303
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:58:44.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7303" for this suite.

• [SLOW TEST:6.520 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":273,"completed":31,"skipped":490,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:58:44.362: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 11:58:45.346: INFO: Waiting up to 5m0s for pod "downwardapi-volume-869a4ac4-8a8d-466a-b05f-69db2af3c36c" in namespace "downward-api-6643" to be "Succeeded or Failed"
Dec 18 11:58:45.357: INFO: Pod "downwardapi-volume-869a4ac4-8a8d-466a-b05f-69db2af3c36c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.689914ms
Dec 18 11:58:47.368: INFO: Pod "downwardapi-volume-869a4ac4-8a8d-466a-b05f-69db2af3c36c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02169205s
Dec 18 11:58:49.378: INFO: Pod "downwardapi-volume-869a4ac4-8a8d-466a-b05f-69db2af3c36c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031624487s
Dec 18 11:58:51.389: INFO: Pod "downwardapi-volume-869a4ac4-8a8d-466a-b05f-69db2af3c36c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04212528s
STEP: Saw pod success
Dec 18 11:58:51.389: INFO: Pod "downwardapi-volume-869a4ac4-8a8d-466a-b05f-69db2af3c36c" satisfied condition "Succeeded or Failed"
Dec 18 11:58:51.397: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-869a4ac4-8a8d-466a-b05f-69db2af3c36c container client-container: <nil>
STEP: delete the pod
Dec 18 11:58:51.446: INFO: Waiting for pod downwardapi-volume-869a4ac4-8a8d-466a-b05f-69db2af3c36c to disappear
Dec 18 11:58:51.457: INFO: Pod downwardapi-volume-869a4ac4-8a8d-466a-b05f-69db2af3c36c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:58:51.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6643" for this suite.

• [SLOW TEST:7.125 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":273,"completed":32,"skipped":507,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:58:51.489: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7409
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 11:58:52.632: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 11:58:54.658: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889532, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889532, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889532, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889532, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:58:56.665: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889532, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889532, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889532, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889532, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 11:58:59.694: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 11:58:59.702: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1096-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:59:00.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7409" for this suite.
STEP: Destroying namespace "webhook-7409-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.630 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":273,"completed":33,"skipped":551,"failed":0}
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:59:01.119: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 11:59:01.390: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605" in namespace "projected-1031" to be "Succeeded or Failed"
Dec 18 11:59:01.402: INFO: Pod "downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605": Phase="Pending", Reason="", readiness=false. Elapsed: 12.499673ms
Dec 18 11:59:03.415: INFO: Pod "downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024815303s
Dec 18 11:59:05.422: INFO: Pod "downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032099944s
Dec 18 11:59:07.430: INFO: Pod "downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039937018s
Dec 18 11:59:09.438: INFO: Pod "downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.047891242s
STEP: Saw pod success
Dec 18 11:59:09.438: INFO: Pod "downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605" satisfied condition "Succeeded or Failed"
Dec 18 11:59:09.452: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605 container client-container: <nil>
STEP: delete the pod
Dec 18 11:59:09.511: INFO: Waiting for pod downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605 to disappear
Dec 18 11:59:09.520: INFO: Pod downwardapi-volume-e53b328e-254f-4bdc-abea-0df25a3ec605 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:59:09.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1031" for this suite.

• [SLOW TEST:8.431 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":273,"completed":34,"skipped":551,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:59:09.559: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8839
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 18 11:59:09.811: INFO: Waiting up to 5m0s for pod "pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1" in namespace "emptydir-8839" to be "Succeeded or Failed"
Dec 18 11:59:09.820: INFO: Pod "pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.848911ms
Dec 18 11:59:11.827: INFO: Pod "pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015895699s
Dec 18 11:59:13.834: INFO: Pod "pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023221183s
Dec 18 11:59:15.843: INFO: Pod "pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032356228s
Dec 18 11:59:17.851: INFO: Pod "pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.039751808s
STEP: Saw pod success
Dec 18 11:59:17.851: INFO: Pod "pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1" satisfied condition "Succeeded or Failed"
Dec 18 11:59:17.858: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1 container test-container: <nil>
STEP: delete the pod
Dec 18 11:59:17.901: INFO: Waiting for pod pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1 to disappear
Dec 18 11:59:17.907: INFO: Pod pod-3607c900-7f18-441b-ba38-4fbe6bc8c4f1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:59:17.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8839" for this suite.

• [SLOW TEST:8.384 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":35,"skipped":566,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:59:17.949: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2855
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 11:59:18.740: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 11:59:20.772: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:59:22.782: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 11:59:24.780: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889558, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 11:59:27.803: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 11:59:40.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2855" for this suite.
STEP: Destroying namespace "webhook-2855-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:22.665 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":273,"completed":36,"skipped":624,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 11:59:40.620: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7940
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:00:29.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7940" for this suite.

• [SLOW TEST:48.813 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    when starting a container that exits
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":273,"completed":37,"skipped":634,"failed":0}
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:00:29.433: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Dec 18 12:00:35.693: INFO: Pod pod-hostip-7205f3f8-bde5-4ecc-b638-88914487a88f has hostIP: 192.168.1.2
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:00:35.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9450" for this suite.

• [SLOW TEST:6.313 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":273,"completed":38,"skipped":634,"failed":0}
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:00:35.747: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6063
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Dec 18 12:00:35.948: INFO: PodSpec: initContainers in spec.initContainers
Dec 18 12:01:31.147: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ba58401f-5551-4a11-b065-d5c4706010d1", GenerateName:"", Namespace:"init-container-6063", SelfLink:"/api/v1/namespaces/init-container-6063/pods/pod-init-ba58401f-5551-4a11-b065-d5c4706010d1", UID:"0490d363-94b2-4537-96b8-21a8f7a9478a", ResourceVersion:"80484", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63743889635, loc:(*time.Location)(0x7b565c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"947515600"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"172.25.1.74/32", "cni.projectcalico.org/podIPs":"172.25.1.74/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003b6e080), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003b6e0a0)}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003b6e0c0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003b6e0e0)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003b6e100), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003b6e120)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gqz6g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00549e000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gqz6g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gqz6g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gqz6g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003ea00c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"stoic-bose-worker-s2lnv-655cc5dcbf-t45gl", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002930000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003ea0140)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003ea0160)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003ea0168), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003ea016c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889636, loc:(*time.Location)(0x7b565c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889636, loc:(*time.Location)(0x7b565c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889636, loc:(*time.Location)(0x7b565c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889635, loc:(*time.Location)(0x7b565c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.1.2", PodIP:"172.25.1.74", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.25.1.74"}}, StartTime:(*v1.Time)(0xc003b6e140), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0029300e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002930150)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://54eca83300ed892583d586f3ddef17029cef485d2d1b01bc7a3bf35a998c3650", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003b6e180), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003b6e160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc003ea01ef)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:01:31.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6063" for this suite.

• [SLOW TEST:55.448 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":273,"completed":39,"skipped":639,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:01:31.198: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1659
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:01:31.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-1659'
Dec 18 12:01:31.882: INFO: stderr: ""
Dec 18 12:01:31.882: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Dec 18 12:01:31.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-1659'
Dec 18 12:01:32.305: INFO: stderr: ""
Dec 18 12:01:32.305: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Dec 18 12:01:33.315: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:01:33.315: INFO: Found 0 / 1
Dec 18 12:01:34.315: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:01:34.315: INFO: Found 0 / 1
Dec 18 12:01:35.313: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:01:35.313: INFO: Found 0 / 1
Dec 18 12:01:36.506: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:01:36.506: INFO: Found 0 / 1
Dec 18 12:01:37.313: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:01:37.313: INFO: Found 0 / 1
Dec 18 12:01:38.313: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:01:38.313: INFO: Found 1 / 1
Dec 18 12:01:38.313: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 18 12:01:38.318: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:01:38.318: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 18 12:01:38.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 describe pod agnhost-master-lmdjq --namespace=kubectl-1659'
Dec 18 12:01:38.455: INFO: stderr: ""
Dec 18 12:01:38.455: INFO: stdout: "Name:         agnhost-master-lmdjq\nNamespace:    kubectl-1659\nPriority:     0\nNode:         stoic-bose-worker-s2lnv-655cc5dcbf-t45gl/192.168.1.2\nStart Time:   Fri, 18 Dec 2020 12:01:31 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 172.25.1.75/32\n              cni.projectcalico.org/podIPs: 172.25.1.75/32\nStatus:       Running\nIP:           172.25.1.75\nIPs:\n  IP:           172.25.1.75\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://5df8f8b06ff96635b253210fd05ae95acf7fa5b66f242ef39fecb2890572685f\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 18 Dec 2020 12:01:36 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5b4qw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-5b4qw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-5b4qw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                               Message\n  ----    ------     ----       ----                                               -------\n  Normal  Scheduled  <unknown>  default-scheduler                                  Successfully assigned kubectl-1659/agnhost-master-lmdjq to stoic-bose-worker-s2lnv-655cc5dcbf-t45gl\n  Normal  Pulled     3s         kubelet, stoic-bose-worker-s2lnv-655cc5dcbf-t45gl  Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    2s         kubelet, stoic-bose-worker-s2lnv-655cc5dcbf-t45gl  Created container agnhost-master\n  Normal  Started    1s         kubelet, stoic-bose-worker-s2lnv-655cc5dcbf-t45gl  Started container agnhost-master\n"
Dec 18 12:01:38.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 describe rc agnhost-master --namespace=kubectl-1659'
Dec 18 12:01:38.614: INFO: stderr: ""
Dec 18 12:01:38.614: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-1659\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  7s    replication-controller  Created pod: agnhost-master-lmdjq\n"
Dec 18 12:01:38.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 describe service agnhost-master --namespace=kubectl-1659'
Dec 18 12:01:38.740: INFO: stderr: ""
Dec 18 12:01:38.740: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-1659\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.240.16.230\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.25.1.75:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 18 12:01:38.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 describe node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r'
Dec 18 12:01:38.938: INFO: stderr: ""
Dec 18 12:01:38.938: INFO: stdout: "Name:               stoic-bose-worker-s2lnv-655cc5dcbf-4p69r\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b9430a9f-7f6d-44cf-a608-ea43a606b67f\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=dbl\n                    failure-domain.beta.kubernetes.io/zone=dbl1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=stoic-bose-worker-s2lnv-655cc5dcbf-4p69r\n                    kubernetes.io/os=linux\n                    machine-controller/host-id=356e39378db6505b1f097337c59649bc6cfd59199a94cfc84c338206\n                    machine-controller/owned-by=9ecf4a66-2311-46d1-b745-6c7f428560d2\n                    machine-controller/physical-host-id=356e39378db6505b1f097337c59649bc6cfd59199a94cfc84c338206\n                    node.kubernetes.io/instance-type=b9430a9f-7f6d-44cf-a608-ea43a606b67f\n                    system/cluster=527kq55vs9\n                    system/project=7rq7pnhncm\n                    topology.cinder.csi.openstack.org/zone=dbl1\n                    topology.kubernetes.io/region=dbl\n                    topology.kubernetes.io/zone=dbl1\n                    x-kubernetes.io/distribution=ubuntu\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 192.168.1.7\n                    cluster.k8s.io/machine: kube-system/stoic-bose-worker-s2lnv-655cc5dcbf-4p69r\n                    csi.volume.kubernetes.io/nodeid: {\"cinder.csi.openstack.org\":\"a21cd147-6c17-4ce9-a2ab-e6ae6105ad57\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"da:18:d1:f2:35:3b\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.1.7\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.25.2.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 18 Dec 2020 08:51:24 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 18 Dec 2020 12:01:31 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                    Message\n  ----                 ------  -----------------                 ------------------                ------                    -------\n  KernelDeadlock       False   Fri, 18 Dec 2020 11:59:37 +0000   Fri, 18 Dec 2020 08:53:50 +0000   KernelHasNoDeadlock       kernel has no deadlock\n  ReadonlyFilesystem   False   Fri, 18 Dec 2020 11:59:37 +0000   Fri, 18 Dec 2020 08:53:50 +0000   FilesystemIsNotReadOnly   Filesystem is not read-only\n  MetakubeNodeReady    True    Fri, 18 Dec 2020 11:59:37 +0000   Fri, 18 Dec 2020 08:54:14 +0000   MetakubeNodeUp            Server:    169.254.20.10\nAddress:               169.254.20.10#53\n\nName:                  kubernetes.default.svc.c\n  NetworkUnavailable   False   Fri, 18 Dec 2020 08:53:15 +0000   Fri, 18 Dec 2020 08:53:15 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Fri, 18 Dec 2020 11:56:48 +0000   Fri, 18 Dec 2020 08:51:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 18 Dec 2020 11:56:48 +0000   Fri, 18 Dec 2020 08:51:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 18 Dec 2020 11:56:48 +0000   Fri, 18 Dec 2020 08:51:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 18 Dec 2020 11:56:48 +0000   Fri, 18 Dec 2020 08:52:04 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.1.7\n  ExternalIP:  195.192.129.234\n  Hostname:    stoic-bose-worker-s2lnv-655cc5dcbf-4p69r\nCapacity:\n  cpu:                4\n  ephemeral-storage:  50633164Ki\n  hugepages-2Mi:      0\n  memory:             8167540Ki\n  pods:               110\nAllocatable:\n  cpu:                3800m\n  ephemeral-storage:  44516040218\n  hugepages-2Mi:      0\n  memory:             7860340Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 a21cd1476c174ce9a2abe6ae6105ad57\n  System UUID:                A21CD147-6C17-4CE9-A2AB-E6AE6105AD57\n  Boot ID:                    c79b5a68-a3f2-40ac-90d7-4f14b032090f\n  Kernel Version:             4.15.0-124-generic\n  OS Image:                   Ubuntu 18.04.5 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.9.9\n  Kubelet Version:            v1.18.8\n  Kube-Proxy Version:         v1.18.8\nPodCIDR:                      172.25.2.0/24\nPodCIDRs:                     172.25.2.0/24\nProviderID:                   openstack:///a21cd147-6c17-4ce9-a2ab-e6ae6105ad57\nNon-terminated Pods:          (11 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 canal-hrvbb                                                350m (9%)     200m (5%)   50Mi (0%)        256Mi (3%)     3h10m\n  kube-system                 coredns-854998958f-grdws                                   100m (2%)     200m (5%)   70Mi (0%)        170Mi (2%)     3h7m\n  kube-system                 csi-cinder-nodeplugin-ubuntu-xgvkm                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h10m\n  kube-system                 kube-proxy-lhksn                                           75m (1%)      250m (6%)   50Mi (0%)        250Mi (3%)     3h10m\n  kube-system                 node-exporter-9db9x                                        3m (0%)       200m (5%)   16Mi (0%)        50Mi (0%)      3h10m\n  kube-system                 node-local-dns-b8hqm                                       50m (1%)      0 (0%)      20Mi (0%)        100Mi (1%)     3h10m\n  kube-system                 syseleven-node-problem-detector-njhnw                      10m (0%)      10m (0%)    80Mi (1%)        80Mi (1%)      3h10m\n  kube-system                 user-ssh-keys-agent-c7l5b                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h10m\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m\n  sonobuoy                    sonobuoy-e2e-job-e8b5ba8e22894e5b                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-a793f22683684929-f897c    0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                588m (15%)  860m (22%)\n  memory             286Mi (3%)  906Mi (11%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
Dec 18 12:01:38.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 describe namespace kubectl-1659'
Dec 18 12:01:39.097: INFO: stderr: ""
Dec 18 12:01:39.097: INFO: stdout: "Name:         kubectl-1659\nLabels:       e2e-framework=kubectl\n              e2e-run=306eca60-14a6-4e55-8a47-2e4f210f0796\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:01:39.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1659" for this suite.

• [SLOW TEST:7.937 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:978
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":273,"completed":40,"skipped":655,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:01:39.137: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:01:50.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2416" for this suite.

• [SLOW TEST:11.324 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":273,"completed":41,"skipped":701,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:01:50.461: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7204
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 18 12:01:50.695: INFO: Waiting up to 5m0s for pod "pod-d8271535-f1f7-4717-80c5-825503032491" in namespace "emptydir-7204" to be "Succeeded or Failed"
Dec 18 12:01:50.705: INFO: Pod "pod-d8271535-f1f7-4717-80c5-825503032491": Phase="Pending", Reason="", readiness=false. Elapsed: 9.604516ms
Dec 18 12:01:52.714: INFO: Pod "pod-d8271535-f1f7-4717-80c5-825503032491": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018896568s
Dec 18 12:01:54.724: INFO: Pod "pod-d8271535-f1f7-4717-80c5-825503032491": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028310692s
Dec 18 12:01:56.735: INFO: Pod "pod-d8271535-f1f7-4717-80c5-825503032491": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039591082s
Dec 18 12:01:58.749: INFO: Pod "pod-d8271535-f1f7-4717-80c5-825503032491": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.053225472s
STEP: Saw pod success
Dec 18 12:01:58.749: INFO: Pod "pod-d8271535-f1f7-4717-80c5-825503032491" satisfied condition "Succeeded or Failed"
Dec 18 12:01:58.756: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-d8271535-f1f7-4717-80c5-825503032491 container test-container: <nil>
STEP: delete the pod
Dec 18 12:01:58.860: INFO: Waiting for pod pod-d8271535-f1f7-4717-80c5-825503032491 to disappear
Dec 18 12:01:58.873: INFO: Pod pod-d8271535-f1f7-4717-80c5-825503032491 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:01:58.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7204" for this suite.

• [SLOW TEST:8.435 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":42,"skipped":702,"failed":0}
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:01:58.896: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1107
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Dec 18 12:01:59.155: INFO: Waiting up to 5m0s for pod "client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb" in namespace "containers-1107" to be "Succeeded or Failed"
Dec 18 12:01:59.161: INFO: Pod "client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.248784ms
Dec 18 12:02:01.177: INFO: Pod "client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021837224s
Dec 18 12:02:03.190: INFO: Pod "client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034900514s
Dec 18 12:02:05.205: INFO: Pod "client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.049589696s
Dec 18 12:02:07.211: INFO: Pod "client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.056422262s
STEP: Saw pod success
Dec 18 12:02:07.211: INFO: Pod "client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb" satisfied condition "Succeeded or Failed"
Dec 18 12:02:07.218: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb container test-container: <nil>
STEP: delete the pod
Dec 18 12:02:07.300: INFO: Waiting for pod client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb to disappear
Dec 18 12:02:07.311: INFO: Pod client-containers-6c0f715c-a888-40c1-8aa3-4e759db17ffb no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:02:07.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1107" for this suite.

• [SLOW TEST:8.533 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":273,"completed":43,"skipped":702,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:02:07.432: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Dec 18 12:02:08.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-7694'
Dec 18 12:02:08.961: INFO: stderr: ""
Dec 18 12:02:08.961: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Dec 18 12:02:09.971: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:02:09.971: INFO: Found 0 / 1
Dec 18 12:02:10.969: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:02:10.969: INFO: Found 0 / 1
Dec 18 12:02:11.971: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:02:11.971: INFO: Found 0 / 1
Dec 18 12:02:12.969: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:02:12.969: INFO: Found 0 / 1
Dec 18 12:02:13.983: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:02:13.983: INFO: Found 1 / 1
Dec 18 12:02:13.983: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 18 12:02:13.992: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:02:13.992: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 18 12:02:13.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 patch pod agnhost-master-9w827 --namespace=kubectl-7694 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 18 12:02:17.137: INFO: stderr: ""
Dec 18 12:02:17.137: INFO: stdout: "pod/agnhost-master-9w827 patched\n"
STEP: checking annotations
Dec 18 12:02:17.144: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 12:02:17.144: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:02:17.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7694" for this suite.

• [SLOW TEST:9.745 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1363
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":273,"completed":44,"skipped":708,"failed":0}
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:02:17.177: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7462
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:02:17.435: INFO: Create a RollingUpdate DaemonSet
Dec 18 12:02:17.449: INFO: Check that daemon pods launch on every node of the cluster
Dec 18 12:02:17.482: INFO: Number of nodes with available pods: 0
Dec 18 12:02:17.483: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:02:18.504: INFO: Number of nodes with available pods: 0
Dec 18 12:02:18.504: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:02:19.523: INFO: Number of nodes with available pods: 0
Dec 18 12:02:19.523: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:02:20.507: INFO: Number of nodes with available pods: 0
Dec 18 12:02:20.508: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:02:21.503: INFO: Number of nodes with available pods: 0
Dec 18 12:02:21.503: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:02:22.506: INFO: Number of nodes with available pods: 1
Dec 18 12:02:22.506: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 12:02:23.510: INFO: Number of nodes with available pods: 3
Dec 18 12:02:23.510: INFO: Number of running nodes: 3, number of available pods: 3
Dec 18 12:02:23.511: INFO: Update the DaemonSet to trigger a rollout
Dec 18 12:02:23.533: INFO: Updating DaemonSet daemon-set
Dec 18 12:02:27.581: INFO: Roll back the DaemonSet before rollout is complete
Dec 18 12:02:27.603: INFO: Updating DaemonSet daemon-set
Dec 18 12:02:27.603: INFO: Make sure DaemonSet rollback is complete
Dec 18 12:02:27.611: INFO: Wrong image for pod: daemon-set-xs2t6. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 18 12:02:27.611: INFO: Pod daemon-set-xs2t6 is not available
Dec 18 12:02:28.632: INFO: Wrong image for pod: daemon-set-xs2t6. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 18 12:02:28.633: INFO: Pod daemon-set-xs2t6 is not available
Dec 18 12:02:29.637: INFO: Wrong image for pod: daemon-set-xs2t6. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 18 12:02:29.637: INFO: Pod daemon-set-xs2t6 is not available
Dec 18 12:02:30.631: INFO: Pod daemon-set-kqccv is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7462, will wait for the garbage collector to delete the pods
Dec 18 12:02:30.741: INFO: Deleting DaemonSet.extensions daemon-set took: 25.594291ms
Dec 18 12:02:31.342: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.481754ms
Dec 18 12:02:39.664: INFO: Number of nodes with available pods: 0
Dec 18 12:02:39.664: INFO: Number of running nodes: 0, number of available pods: 0
Dec 18 12:02:39.676: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7462/daemonsets","resourceVersion":"81147"},"items":null}

Dec 18 12:02:39.692: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7462/pods","resourceVersion":"81147"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:02:39.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7462" for this suite.

• [SLOW TEST:22.566 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":273,"completed":45,"skipped":709,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:02:39.746: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-bc956066-ce52-45b9-8c37-53fe1edb8cce
STEP: Creating a pod to test consume configMaps
Dec 18 12:02:39.983: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-161924f3-19b5-431b-bcc8-5b3f46fe2e67" in namespace "projected-5239" to be "Succeeded or Failed"
Dec 18 12:02:39.989: INFO: Pod "pod-projected-configmaps-161924f3-19b5-431b-bcc8-5b3f46fe2e67": Phase="Pending", Reason="", readiness=false. Elapsed: 6.347955ms
Dec 18 12:02:41.996: INFO: Pod "pod-projected-configmaps-161924f3-19b5-431b-bcc8-5b3f46fe2e67": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012960157s
Dec 18 12:02:44.005: INFO: Pod "pod-projected-configmaps-161924f3-19b5-431b-bcc8-5b3f46fe2e67": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022217354s
Dec 18 12:02:46.018: INFO: Pod "pod-projected-configmaps-161924f3-19b5-431b-bcc8-5b3f46fe2e67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035483712s
STEP: Saw pod success
Dec 18 12:02:46.019: INFO: Pod "pod-projected-configmaps-161924f3-19b5-431b-bcc8-5b3f46fe2e67" satisfied condition "Succeeded or Failed"
Dec 18 12:02:46.025: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-configmaps-161924f3-19b5-431b-bcc8-5b3f46fe2e67 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 12:02:46.091: INFO: Waiting for pod pod-projected-configmaps-161924f3-19b5-431b-bcc8-5b3f46fe2e67 to disappear
Dec 18 12:02:46.096: INFO: Pod pod-projected-configmaps-161924f3-19b5-431b-bcc8-5b3f46fe2e67 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:02:46.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5239" for this suite.

• [SLOW TEST:6.388 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":46,"skipped":726,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:02:46.136: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5619
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5619
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5619
STEP: creating replication controller externalsvc in namespace services-5619
I1218 12:02:46.405530      21 runners.go:190] Created replication controller with name: externalsvc, namespace: services-5619, replica count: 2
I1218 12:02:49.456267      21 runners.go:190] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 12:02:52.456539      21 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 18 12:02:52.517: INFO: Creating new exec pod
Dec 18 12:02:58.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=services-5619 execpodw2lhj -- /bin/sh -x -c nslookup clusterip-service'
Dec 18 12:02:59.033: INFO: stderr: "+ nslookup clusterip-service\n"
Dec 18 12:02:59.033: INFO: stdout: "Server:\t\t169.254.20.10\nAddress:\t169.254.20.10#53\n\nclusterip-service.services-5619.svc.cluster.local\tcanonical name = externalsvc.services-5619.svc.cluster.local.\nName:\texternalsvc.services-5619.svc.cluster.local\nAddress: 10.240.26.171\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5619, will wait for the garbage collector to delete the pods
Dec 18 12:02:59.108: INFO: Deleting ReplicationController externalsvc took: 17.179246ms
Dec 18 12:02:59.708: INFO: Terminating ReplicationController externalsvc pods took: 600.279786ms
Dec 18 12:03:09.754: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:03:09.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5619" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:23.680 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":273,"completed":47,"skipped":780,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:03:09.820: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-618
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Dec 18 12:03:10.012: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:03:30.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-618" for this suite.

• [SLOW TEST:20.279 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":273,"completed":48,"skipped":791,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:03:30.099: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-56741b47-357e-4332-a99b-6ec44333f021
STEP: Creating a pod to test consume secrets
Dec 18 12:03:30.354: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524" in namespace "projected-4176" to be "Succeeded or Failed"
Dec 18 12:03:30.361: INFO: Pod "pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524": Phase="Pending", Reason="", readiness=false. Elapsed: 6.725911ms
Dec 18 12:03:32.368: INFO: Pod "pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0137483s
Dec 18 12:03:34.378: INFO: Pod "pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024050743s
Dec 18 12:03:36.400: INFO: Pod "pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524": Phase="Pending", Reason="", readiness=false. Elapsed: 6.045977997s
Dec 18 12:03:38.409: INFO: Pod "pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.054858411s
STEP: Saw pod success
Dec 18 12:03:38.409: INFO: Pod "pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524" satisfied condition "Succeeded or Failed"
Dec 18 12:03:38.438: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 18 12:03:38.678: INFO: Waiting for pod pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524 to disappear
Dec 18 12:03:38.828: INFO: Pod pod-projected-secrets-b52c4888-b2de-4282-beb6-0155d96ed524 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:03:38.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4176" for this suite.

• [SLOW TEST:8.930 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":49,"skipped":798,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:03:39.031: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:03:39.583: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-12506375-bbf1-4f6b-b680-01ea84a47e31" in namespace "security-context-test-6927" to be "Succeeded or Failed"
Dec 18 12:03:39.594: INFO: Pod "busybox-readonly-false-12506375-bbf1-4f6b-b680-01ea84a47e31": Phase="Pending", Reason="", readiness=false. Elapsed: 11.444289ms
Dec 18 12:03:41.606: INFO: Pod "busybox-readonly-false-12506375-bbf1-4f6b-b680-01ea84a47e31": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023223281s
Dec 18 12:03:43.616: INFO: Pod "busybox-readonly-false-12506375-bbf1-4f6b-b680-01ea84a47e31": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032974689s
Dec 18 12:03:45.627: INFO: Pod "busybox-readonly-false-12506375-bbf1-4f6b-b680-01ea84a47e31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044313872s
Dec 18 12:03:45.627: INFO: Pod "busybox-readonly-false-12506375-bbf1-4f6b-b680-01ea84a47e31" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:03:45.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6927" for this suite.

• [SLOW TEST:6.631 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:166
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":273,"completed":50,"skipped":833,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:03:45.664: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9871
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:03:52.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9871" for this suite.

• [SLOW TEST:6.608 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox command in a pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:41
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":273,"completed":51,"skipped":891,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:03:52.278: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1194
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 18 12:03:52.507: INFO: Waiting up to 5m0s for pod "pod-f7aa0673-031b-471e-917c-87df6ac6a73c" in namespace "emptydir-1194" to be "Succeeded or Failed"
Dec 18 12:03:52.519: INFO: Pod "pod-f7aa0673-031b-471e-917c-87df6ac6a73c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.657015ms
Dec 18 12:03:54.527: INFO: Pod "pod-f7aa0673-031b-471e-917c-87df6ac6a73c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019262984s
Dec 18 12:03:56.550: INFO: Pod "pod-f7aa0673-031b-471e-917c-87df6ac6a73c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043054588s
Dec 18 12:03:58.562: INFO: Pod "pod-f7aa0673-031b-471e-917c-87df6ac6a73c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054298068s
STEP: Saw pod success
Dec 18 12:03:58.562: INFO: Pod "pod-f7aa0673-031b-471e-917c-87df6ac6a73c" satisfied condition "Succeeded or Failed"
Dec 18 12:03:58.571: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-f7aa0673-031b-471e-917c-87df6ac6a73c container test-container: <nil>
STEP: delete the pod
Dec 18 12:03:58.625: INFO: Waiting for pod pod-f7aa0673-031b-471e-917c-87df6ac6a73c to disappear
Dec 18 12:03:58.630: INFO: Pod pod-f7aa0673-031b-471e-917c-87df6ac6a73c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:03:58.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1194" for this suite.

• [SLOW TEST:6.377 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":52,"skipped":901,"failed":0}
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:03:58.655: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-1c6116d9-b625-4983-9ffb-d8d536cffeab
STEP: Creating a pod to test consume secrets
Dec 18 12:03:58.899: INFO: Waiting up to 5m0s for pod "pod-secrets-f7054c50-3c3e-407b-891e-572e23dcfbd2" in namespace "secrets-7915" to be "Succeeded or Failed"
Dec 18 12:03:58.909: INFO: Pod "pod-secrets-f7054c50-3c3e-407b-891e-572e23dcfbd2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.261033ms
Dec 18 12:04:00.925: INFO: Pod "pod-secrets-f7054c50-3c3e-407b-891e-572e23dcfbd2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025860408s
Dec 18 12:04:02.939: INFO: Pod "pod-secrets-f7054c50-3c3e-407b-891e-572e23dcfbd2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040244029s
Dec 18 12:04:04.950: INFO: Pod "pod-secrets-f7054c50-3c3e-407b-891e-572e23dcfbd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050789079s
STEP: Saw pod success
Dec 18 12:04:04.951: INFO: Pod "pod-secrets-f7054c50-3c3e-407b-891e-572e23dcfbd2" satisfied condition "Succeeded or Failed"
Dec 18 12:04:04.959: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-secrets-f7054c50-3c3e-407b-891e-572e23dcfbd2 container secret-env-test: <nil>
STEP: delete the pod
Dec 18 12:04:05.040: INFO: Waiting for pod pod-secrets-f7054c50-3c3e-407b-891e-572e23dcfbd2 to disappear
Dec 18 12:04:05.049: INFO: Pod pod-secrets-f7054c50-3c3e-407b-891e-572e23dcfbd2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:04:05.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7915" for this suite.

• [SLOW TEST:6.428 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:35
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":273,"completed":53,"skipped":901,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:04:05.084: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2389
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-df7a8b15-8245-4d62-b1ec-6f43edf5f742
STEP: Creating secret with name secret-projected-all-test-volume-dbbd1386-6de5-4555-94d5-19150dbee5b3
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 18 12:04:05.334: INFO: Waiting up to 5m0s for pod "projected-volume-43470f18-6572-4388-872b-a6c83c3d9389" in namespace "projected-2389" to be "Succeeded or Failed"
Dec 18 12:04:05.346: INFO: Pod "projected-volume-43470f18-6572-4388-872b-a6c83c3d9389": Phase="Pending", Reason="", readiness=false. Elapsed: 11.612217ms
Dec 18 12:04:07.360: INFO: Pod "projected-volume-43470f18-6572-4388-872b-a6c83c3d9389": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025656211s
Dec 18 12:04:09.369: INFO: Pod "projected-volume-43470f18-6572-4388-872b-a6c83c3d9389": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034984216s
Dec 18 12:04:11.377: INFO: Pod "projected-volume-43470f18-6572-4388-872b-a6c83c3d9389": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043241812s
Dec 18 12:04:13.387: INFO: Pod "projected-volume-43470f18-6572-4388-872b-a6c83c3d9389": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.052636308s
STEP: Saw pod success
Dec 18 12:04:13.387: INFO: Pod "projected-volume-43470f18-6572-4388-872b-a6c83c3d9389" satisfied condition "Succeeded or Failed"
Dec 18 12:04:13.411: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod projected-volume-43470f18-6572-4388-872b-a6c83c3d9389 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 18 12:04:13.516: INFO: Waiting for pod projected-volume-43470f18-6572-4388-872b-a6c83c3d9389 to disappear
Dec 18 12:04:13.526: INFO: Pod projected-volume-43470f18-6572-4388-872b-a6c83c3d9389 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:04:13.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2389" for this suite.

• [SLOW TEST:8.467 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":273,"completed":54,"skipped":906,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:04:13.552: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6116
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 18 12:04:13.762: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 18 12:04:28.404: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:04:32.249: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:04:47.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6116" for this suite.

• [SLOW TEST:33.557 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":273,"completed":55,"skipped":908,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:04:47.113: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-00a51adc-a870-4cc5-b4c6-2a8d40458dc8
STEP: Creating a pod to test consume secrets
Dec 18 12:04:47.337: INFO: Waiting up to 5m0s for pod "pod-secrets-ccc1a721-0b7e-4316-801c-136e3faf7482" in namespace "secrets-394" to be "Succeeded or Failed"
Dec 18 12:04:47.344: INFO: Pod "pod-secrets-ccc1a721-0b7e-4316-801c-136e3faf7482": Phase="Pending", Reason="", readiness=false. Elapsed: 6.413761ms
Dec 18 12:04:49.351: INFO: Pod "pod-secrets-ccc1a721-0b7e-4316-801c-136e3faf7482": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014251054s
Dec 18 12:04:51.359: INFO: Pod "pod-secrets-ccc1a721-0b7e-4316-801c-136e3faf7482": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021761592s
Dec 18 12:04:53.368: INFO: Pod "pod-secrets-ccc1a721-0b7e-4316-801c-136e3faf7482": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030490017s
STEP: Saw pod success
Dec 18 12:04:53.368: INFO: Pod "pod-secrets-ccc1a721-0b7e-4316-801c-136e3faf7482" satisfied condition "Succeeded or Failed"
Dec 18 12:04:53.375: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-secrets-ccc1a721-0b7e-4316-801c-136e3faf7482 container secret-volume-test: <nil>
STEP: delete the pod
Dec 18 12:04:53.423: INFO: Waiting for pod pod-secrets-ccc1a721-0b7e-4316-801c-136e3faf7482 to disappear
Dec 18 12:04:53.429: INFO: Pod pod-secrets-ccc1a721-0b7e-4316-801c-136e3faf7482 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:04:53.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-394" for this suite.

• [SLOW TEST:6.353 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":56,"skipped":956,"failed":0}
S
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:04:53.466: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-5423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Dec 18 12:04:53.665: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Dec 18 12:04:54.591: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 18 12:04:56.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:04:58.689: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:05:00.697: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743889894, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:05:03.874: INFO: Waited 1.170008511s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:05:04.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5423" for this suite.

• [SLOW TEST:11.275 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":273,"completed":57,"skipped":957,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:05:04.749: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:06:04.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5802" for this suite.

• [SLOW TEST:60.265 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":273,"completed":58,"skipped":973,"failed":0}
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:06:05.014: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8496
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-f7hp
STEP: Creating a pod to test atomic-volume-subpath
Dec 18 12:06:05.262: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-f7hp" in namespace "subpath-8496" to be "Succeeded or Failed"
Dec 18 12:06:05.270: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Pending", Reason="", readiness=false. Elapsed: 7.265587ms
Dec 18 12:06:07.281: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018118432s
Dec 18 12:06:09.290: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027296466s
Dec 18 12:06:11.304: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 6.041225095s
Dec 18 12:06:13.312: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 8.04962598s
Dec 18 12:06:15.320: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 10.058100009s
Dec 18 12:06:17.329: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 12.06659458s
Dec 18 12:06:19.621: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 14.359050775s
Dec 18 12:06:21.632: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 16.369370265s
Dec 18 12:06:23.647: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 18.384185649s
Dec 18 12:06:25.658: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 20.395154041s
Dec 18 12:06:27.668: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 22.405605337s
Dec 18 12:06:29.682: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Running", Reason="", readiness=true. Elapsed: 24.419570968s
Dec 18 12:06:31.692: INFO: Pod "pod-subpath-test-secret-f7hp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.429596103s
STEP: Saw pod success
Dec 18 12:06:31.692: INFO: Pod "pod-subpath-test-secret-f7hp" satisfied condition "Succeeded or Failed"
Dec 18 12:06:31.701: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-subpath-test-secret-f7hp container test-container-subpath-secret-f7hp: <nil>
STEP: delete the pod
Dec 18 12:06:31.843: INFO: Waiting for pod pod-subpath-test-secret-f7hp to disappear
Dec 18 12:06:31.850: INFO: Pod pod-subpath-test-secret-f7hp no longer exists
STEP: Deleting pod pod-subpath-test-secret-f7hp
Dec 18 12:06:31.850: INFO: Deleting pod "pod-subpath-test-secret-f7hp" in namespace "subpath-8496"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:06:31.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8496" for this suite.

• [SLOW TEST:26.871 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":273,"completed":59,"skipped":973,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:06:31.889: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Dec 18 12:06:32.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-5383'
Dec 18 12:06:32.556: INFO: stderr: ""
Dec 18 12:06:32.556: INFO: stdout: "pod/pause created\n"
Dec 18 12:06:32.556: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 18 12:06:32.557: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5383" to be "running and ready"
Dec 18 12:06:32.565: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.667291ms
Dec 18 12:06:34.575: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018730145s
Dec 18 12:06:36.583: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026612573s
Dec 18 12:06:38.592: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 6.035716081s
Dec 18 12:06:38.592: INFO: Pod "pause" satisfied condition "running and ready"
Dec 18 12:06:38.592: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 18 12:06:38.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 label pods pause testing-label=testing-label-value --namespace=kubectl-5383'
Dec 18 12:06:38.726: INFO: stderr: ""
Dec 18 12:06:38.726: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 18 12:06:38.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pod pause -L testing-label --namespace=kubectl-5383'
Dec 18 12:06:38.853: INFO: stderr: ""
Dec 18 12:06:38.853: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          6s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 18 12:06:38.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 label pods pause testing-label- --namespace=kubectl-5383'
Dec 18 12:06:38.988: INFO: stderr: ""
Dec 18 12:06:38.988: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 18 12:06:38.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pod pause -L testing-label --namespace=kubectl-5383'
Dec 18 12:06:39.108: INFO: stderr: ""
Dec 18 12:06:39.108: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          7s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Dec 18 12:06:39.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete --grace-period=0 --force -f - --namespace=kubectl-5383'
Dec 18 12:06:39.270: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 18 12:06:39.270: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 18 12:06:39.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get rc,svc -l name=pause --no-headers --namespace=kubectl-5383'
Dec 18 12:06:39.395: INFO: stderr: "No resources found in kubectl-5383 namespace.\n"
Dec 18 12:06:39.395: INFO: stdout: ""
Dec 18 12:06:39.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -l name=pause --namespace=kubectl-5383 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 18 12:06:39.519: INFO: stderr: ""
Dec 18 12:06:39.519: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:06:39.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5383" for this suite.

• [SLOW TEST:7.663 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1203
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":273,"completed":60,"skipped":977,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:06:39.553: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8467
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-3ac60a3b-5566-4a2d-abc6-8d1508972554
STEP: Creating a pod to test consume configMaps
Dec 18 12:06:39.777: INFO: Waiting up to 5m0s for pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93" in namespace "configmap-8467" to be "Succeeded or Failed"
Dec 18 12:06:39.784: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 6.617197ms
Dec 18 12:06:41.799: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021132869s
Dec 18 12:06:43.816: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038643847s
Dec 18 12:06:45.829: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051529236s
Dec 18 12:06:47.845: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 8.067855495s
Dec 18 12:06:49.855: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 10.077549609s
Dec 18 12:06:51.867: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 12.08914403s
Dec 18 12:06:53.878: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 14.100797398s
Dec 18 12:06:55.886: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 16.108874249s
Dec 18 12:06:57.894: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Pending", Reason="", readiness=false. Elapsed: 18.116703503s
Dec 18 12:06:59.904: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 20.126295706s
STEP: Saw pod success
Dec 18 12:06:59.904: INFO: Pod "pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93" satisfied condition "Succeeded or Failed"
Dec 18 12:06:59.916: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 12:06:59.972: INFO: Waiting for pod pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93 to disappear
Dec 18 12:06:59.979: INFO: Pod pod-configmaps-41a397a2-63a9-4657-ab4a-2992516dae93 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:06:59.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8467" for this suite.

• [SLOW TEST:20.453 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":273,"completed":61,"skipped":988,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:07:00.009: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-2820
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 18 12:07:14.390: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:14.390: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:14.655: INFO: Exec stderr: ""
Dec 18 12:07:14.655: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:14.655: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:15.060: INFO: Exec stderr: ""
Dec 18 12:07:15.060: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:15.060: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:15.360: INFO: Exec stderr: ""
Dec 18 12:07:15.360: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:15.360: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:15.753: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 18 12:07:15.753: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:15.753: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:16.021: INFO: Exec stderr: ""
Dec 18 12:07:16.021: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:16.022: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:16.423: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 18 12:07:16.423: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:16.423: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:16.849: INFO: Exec stderr: ""
Dec 18 12:07:16.849: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:16.849: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:17.269: INFO: Exec stderr: ""
Dec 18 12:07:17.269: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:17.269: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:17.627: INFO: Exec stderr: ""
Dec 18 12:07:17.627: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2820 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:07:17.627: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:07:17.954: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:07:17.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2820" for this suite.

• [SLOW TEST:17.969 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":62,"skipped":1008,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:07:17.980: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4810
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Dec 18 12:07:18.405: INFO: Waiting up to 5m0s for pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1" in namespace "var-expansion-4810" to be "Succeeded or Failed"
Dec 18 12:07:18.476: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Pending", Reason="", readiness=false. Elapsed: 71.071452ms
Dec 18 12:07:20.491: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086254743s
Dec 18 12:07:22.502: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.096560483s
Dec 18 12:07:24.519: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.113774192s
Dec 18 12:07:26.528: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.122633698s
Dec 18 12:07:28.537: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.131692806s
Dec 18 12:07:30.545: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.140071591s
Dec 18 12:07:32.556: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.150411909s
Dec 18 12:07:34.563: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.157382346s
Dec 18 12:07:36.572: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.166410954s
STEP: Saw pod success
Dec 18 12:07:36.572: INFO: Pod "var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1" satisfied condition "Succeeded or Failed"
Dec 18 12:07:36.578: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1 container dapi-container: <nil>
STEP: delete the pod
Dec 18 12:07:36.640: INFO: Waiting for pod var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1 to disappear
Dec 18 12:07:36.648: INFO: Pod var-expansion-d08f23ed-5ed5-460d-a2dd-bf007efd40d1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:07:36.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4810" for this suite.

• [SLOW TEST:18.695 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":273,"completed":63,"skipped":1037,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:07:36.675: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:07:37.557: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 12:07:39.580: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:07:41.599: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:07:43.588: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890057, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:07:46.615: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
Dec 18 12:07:46.685: INFO: Waiting for webhook configuration to be ready...
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:07:47.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-302" for this suite.
STEP: Destroying namespace "webhook-302-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:10.542 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":273,"completed":64,"skipped":1062,"failed":0}
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:07:47.222: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4315
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-4315/configmap-test-8106a7bd-c5fb-47ec-9e8a-ae62ff61ebed
STEP: Creating a pod to test consume configMaps
Dec 18 12:07:47.454: INFO: Waiting up to 5m0s for pod "pod-configmaps-daf6e219-74a4-4e8b-9f57-b0eb509cdac6" in namespace "configmap-4315" to be "Succeeded or Failed"
Dec 18 12:07:47.467: INFO: Pod "pod-configmaps-daf6e219-74a4-4e8b-9f57-b0eb509cdac6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.309699ms
Dec 18 12:07:49.477: INFO: Pod "pod-configmaps-daf6e219-74a4-4e8b-9f57-b0eb509cdac6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022514028s
Dec 18 12:07:51.488: INFO: Pod "pod-configmaps-daf6e219-74a4-4e8b-9f57-b0eb509cdac6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033405096s
Dec 18 12:07:53.497: INFO: Pod "pod-configmaps-daf6e219-74a4-4e8b-9f57-b0eb509cdac6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04296208s
STEP: Saw pod success
Dec 18 12:07:53.498: INFO: Pod "pod-configmaps-daf6e219-74a4-4e8b-9f57-b0eb509cdac6" satisfied condition "Succeeded or Failed"
Dec 18 12:07:53.506: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r pod pod-configmaps-daf6e219-74a4-4e8b-9f57-b0eb509cdac6 container env-test: <nil>
STEP: delete the pod
Dec 18 12:07:53.638: INFO: Waiting for pod pod-configmaps-daf6e219-74a4-4e8b-9f57-b0eb509cdac6 to disappear
Dec 18 12:07:53.646: INFO: Pod pod-configmaps-daf6e219-74a4-4e8b-9f57-b0eb509cdac6 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:07:53.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4315" for this suite.

• [SLOW TEST:6.455 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:34
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":273,"completed":65,"skipped":1063,"failed":0}
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:07:53.678: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6557
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 18 12:07:53.883: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 18 12:07:53.923: INFO: Waiting for terminating namespaces to be deleted...
Dec 18 12:07:53.936: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r before test
Dec 18 12:07:53.977: INFO: coredns-854998958f-grdws from kube-system started at 2020-12-18 08:54:22 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container coredns ready: true, restart count 0
Dec 18 12:07:53.977: INFO: node-exporter-9db9x from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 12:07:53.977: INFO: sonobuoy-e2e-job-e8b5ba8e22894e5b from sonobuoy started at 2020-12-18 11:49:39 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container e2e ready: true, restart count 0
Dec 18 12:07:53.977: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:07:53.977: INFO: test-host-network-pod from e2e-kubelet-etc-hosts-2820 started at 2020-12-18 12:07:08 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container busybox-1 ready: true, restart count 0
Dec 18 12:07:53.977: INFO: 	Container busybox-2 ready: true, restart count 0
Dec 18 12:07:53.977: INFO: user-ssh-keys-agent-c7l5b from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 12:07:53.977: INFO: kube-proxy-lhksn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 12:07:53.977: INFO: canal-hrvbb from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 12:07:53.977: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 12:07:53.977: INFO: syseleven-node-problem-detector-njhnw from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 12:07:53.977: INFO: node-local-dns-b8hqm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 12:07:53.977: INFO: csi-cinder-nodeplugin-ubuntu-xgvkm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:07:53.977: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 12:07:53.977: INFO: sonobuoy from sonobuoy started at 2020-12-18 11:49:35 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 18 12:07:53.977: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-f897c from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:53.977: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:07:53.977: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 12:07:53.977: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 before test
Dec 18 12:07:54.087: INFO: node-exporter-sxvt4 from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 12:07:54.087: INFO: csi-cinder-nodeplugin-ubuntu-mgs7f from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:07:54.087: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 12:07:54.087: INFO: dns-autoscaler-596856b68b-sdb66 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container autoscaler ready: true, restart count 0
Dec 18 12:07:54.087: INFO: node-local-dns-hd82q from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 12:07:54.087: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-26dcz from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:07:54.087: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 12:07:54.087: INFO: syseleven-node-problem-detector-scggf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 12:07:54.087: INFO: kube-proxy-xljhw from kube-system started at 2020-12-18 08:51:26 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 12:07:54.087: INFO: canal-x2srj from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 12:07:54.087: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 12:07:54.087: INFO: user-ssh-keys-agent-9dgcw from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 12:07:54.087: INFO: coredns-854998958f-xqqnb from kube-system started at 2020-12-18 08:52:04 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container coredns ready: true, restart count 0
Dec 18 12:07:54.087: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (5 container statuses recorded)
Dec 18 12:07:54.087: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:07:54.087: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 18 12:07:54.087: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 18 12:07:54.087: INFO: 	Container csi-resizer ready: true, restart count 0
Dec 18 12:07:54.087: INFO: 	Container csi-snapshotter ready: true, restart count 0
Dec 18 12:07:54.087: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl before test
Dec 18 12:07:54.188: INFO: node-exporter-7rrpc from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.189: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 12:07:54.189: INFO: syseleven-node-problem-detector-t5b9t from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.189: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 12:07:54.189: INFO: user-ssh-keys-agent-s8rkn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.189: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 12:07:54.189: INFO: canal-fwhcf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:54.189: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 12:07:54.190: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 12:07:54.190: INFO: node-local-dns-2xjfh from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.190: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 12:07:54.190: INFO: openvpn-client-56dc45fdbd-hlz4z from kube-system started at 2020-12-18 08:54:10 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:54.190: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 18 12:07:54.190: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 18 12:07:54.190: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-t59nh from sonobuoy started at 2020-12-18 11:49:41 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:54.191: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:07:54.191: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 12:07:54.191: INFO: kube-proxy-sgz6s from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.191: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 12:07:54.192: INFO: csi-cinder-nodeplugin-ubuntu-crqmv from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:07:54.192: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:07:54.192: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 12:07:54.192: INFO: cluster-autoscaler-5c8c86777b-zbqbq from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.192: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 18 12:07:54.192: INFO: tiller-deploy-5648ccb4b6-28wjd from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 12:07:54.192: INFO: 	Container tiller ready: true, restart count 0
Dec 18 12:07:54.192: INFO: test-pod from e2e-kubelet-etc-hosts-2820 started at 2020-12-18 12:07:00 +0000 UTC (3 container statuses recorded)
Dec 18 12:07:54.192: INFO: 	Container busybox-1 ready: true, restart count 0
Dec 18 12:07:54.192: INFO: 	Container busybox-2 ready: true, restart count 0
Dec 18 12:07:54.192: INFO: 	Container busybox-3 ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5abe6f03-eee7-492c-9024-34d04659aff0 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-5abe6f03-eee7-492c-9024-34d04659aff0 off the node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5abe6f03-eee7-492c-9024-34d04659aff0
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:13:12.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6557" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:318.763 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":273,"completed":66,"skipped":1071,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:13:12.442: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7784
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 18 12:13:12.667: INFO: Waiting up to 5m0s for pod "pod-c68d4b7f-6e91-4f15-900a-8d7938669e05" in namespace "emptydir-7784" to be "Succeeded or Failed"
Dec 18 12:13:12.676: INFO: Pod "pod-c68d4b7f-6e91-4f15-900a-8d7938669e05": Phase="Pending", Reason="", readiness=false. Elapsed: 9.581736ms
Dec 18 12:13:14.684: INFO: Pod "pod-c68d4b7f-6e91-4f15-900a-8d7938669e05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016961646s
Dec 18 12:13:16.691: INFO: Pod "pod-c68d4b7f-6e91-4f15-900a-8d7938669e05": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024507217s
Dec 18 12:13:18.705: INFO: Pod "pod-c68d4b7f-6e91-4f15-900a-8d7938669e05": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038601608s
Dec 18 12:13:20.715: INFO: Pod "pod-c68d4b7f-6e91-4f15-900a-8d7938669e05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04786713s
STEP: Saw pod success
Dec 18 12:13:20.715: INFO: Pod "pod-c68d4b7f-6e91-4f15-900a-8d7938669e05" satisfied condition "Succeeded or Failed"
Dec 18 12:13:20.728: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-c68d4b7f-6e91-4f15-900a-8d7938669e05 container test-container: <nil>
STEP: delete the pod
Dec 18 12:13:20.833: INFO: Waiting for pod pod-c68d4b7f-6e91-4f15-900a-8d7938669e05 to disappear
Dec 18 12:13:20.841: INFO: Pod pod-c68d4b7f-6e91-4f15-900a-8d7938669e05 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:13:20.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7784" for this suite.

• [SLOW TEST:8.441 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":67,"skipped":1099,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:13:20.883: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8191
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 18 12:13:21.098: INFO: Waiting up to 5m0s for pod "pod-41c7b93e-6e96-49ad-857f-023a944c89cb" in namespace "emptydir-8191" to be "Succeeded or Failed"
Dec 18 12:13:21.108: INFO: Pod "pod-41c7b93e-6e96-49ad-857f-023a944c89cb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.12068ms
Dec 18 12:13:23.118: INFO: Pod "pod-41c7b93e-6e96-49ad-857f-023a944c89cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01948047s
Dec 18 12:13:25.128: INFO: Pod "pod-41c7b93e-6e96-49ad-857f-023a944c89cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029478721s
Dec 18 12:13:27.140: INFO: Pod "pod-41c7b93e-6e96-49ad-857f-023a944c89cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042027875s
STEP: Saw pod success
Dec 18 12:13:27.141: INFO: Pod "pod-41c7b93e-6e96-49ad-857f-023a944c89cb" satisfied condition "Succeeded or Failed"
Dec 18 12:13:27.151: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-41c7b93e-6e96-49ad-857f-023a944c89cb container test-container: <nil>
STEP: delete the pod
Dec 18 12:13:27.197: INFO: Waiting for pod pod-41c7b93e-6e96-49ad-857f-023a944c89cb to disappear
Dec 18 12:13:27.206: INFO: Pod pod-41c7b93e-6e96-49ad-857f-023a944c89cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:13:27.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8191" for this suite.

• [SLOW TEST:6.353 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":68,"skipped":1102,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:13:27.240: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9590
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-9590
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9590 to expose endpoints map[]
Dec 18 12:13:27.483: INFO: Get endpoints failed (10.765079ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 18 12:13:28.491: INFO: successfully validated that service endpoint-test2 in namespace services-9590 exposes endpoints map[] (1.01919s elapsed)
STEP: Creating pod pod1 in namespace services-9590
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9590 to expose endpoints map[pod1:[80]]
Dec 18 12:13:32.617: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.102202849s elapsed, will retry)
Dec 18 12:13:33.639: INFO: successfully validated that service endpoint-test2 in namespace services-9590 exposes endpoints map[pod1:[80]] (5.124513623s elapsed)
STEP: Creating pod pod2 in namespace services-9590
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9590 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 18 12:13:37.771: INFO: Unexpected endpoints: found map[e27e848f-14e6-4d4d-a4aa-887e1765b16d:[80]], expected map[pod1:[80] pod2:[80]] (4.116634269s elapsed, will retry)
Dec 18 12:13:38.792: INFO: successfully validated that service endpoint-test2 in namespace services-9590 exposes endpoints map[pod1:[80] pod2:[80]] (5.13719778s elapsed)
STEP: Deleting pod pod1 in namespace services-9590
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9590 to expose endpoints map[pod2:[80]]
Dec 18 12:13:39.841: INFO: successfully validated that service endpoint-test2 in namespace services-9590 exposes endpoints map[pod2:[80]] (1.033406812s elapsed)
STEP: Deleting pod pod2 in namespace services-9590
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9590 to expose endpoints map[]
Dec 18 12:13:39.872: INFO: successfully validated that service endpoint-test2 in namespace services-9590 exposes endpoints map[] (10.563104ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:13:39.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9590" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:12.698 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":273,"completed":69,"skipped":1177,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:13:39.939: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2054
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:13:44.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2054" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":273,"completed":70,"skipped":1188,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:13:44.585: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5529
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 18 12:13:56.973: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 18 12:13:56.980: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 18 12:13:58.981: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 18 12:13:58.989: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 18 12:14:00.981: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 18 12:14:00.988: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 18 12:14:02.981: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 18 12:14:02.990: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 18 12:14:04.981: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 18 12:14:04.998: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 18 12:14:06.981: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 18 12:14:06.990: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 18 12:14:08.981: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 18 12:14:08.990: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 18 12:14:10.981: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 18 12:14:10.988: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:14:11.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5529" for this suite.

• [SLOW TEST:26.487 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":273,"completed":71,"skipped":1207,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:14:11.073: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6990
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:14:18.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6990" for this suite.

• [SLOW TEST:7.530 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":273,"completed":72,"skipped":1216,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:14:18.605: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5998
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 12:14:18.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b" in namespace "downward-api-5998" to be "Succeeded or Failed"
Dec 18 12:14:18.902: INFO: Pod "downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.230933ms
Dec 18 12:14:20.912: INFO: Pod "downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02145403s
Dec 18 12:14:22.921: INFO: Pod "downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030769536s
Dec 18 12:14:24.932: INFO: Pod "downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041354674s
Dec 18 12:14:26.944: INFO: Pod "downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.05312955s
STEP: Saw pod success
Dec 18 12:14:26.944: INFO: Pod "downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b" satisfied condition "Succeeded or Failed"
Dec 18 12:14:26.952: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b container client-container: <nil>
STEP: delete the pod
Dec 18 12:14:27.009: INFO: Waiting for pod downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b to disappear
Dec 18 12:14:27.019: INFO: Pod downwardapi-volume-47cb5e0c-6593-4df8-9ed9-cb4d5b526c6b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:14:27.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5998" for this suite.

• [SLOW TEST:8.437 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":273,"completed":73,"skipped":1260,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:14:27.043: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5162
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:14:27.998: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 12:14:30.023: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890468, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890468, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890468, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890467, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:14:32.032: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890468, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890468, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890468, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890467, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:14:34.044: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890468, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890468, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890468, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890467, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:14:37.049: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:14:47.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5162" for this suite.
STEP: Destroying namespace "webhook-5162-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:20.668 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":273,"completed":74,"skipped":1275,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:14:47.712: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5525
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 18 12:14:47.997: INFO: Waiting up to 5m0s for pod "pod-96cd2103-02db-4693-9906-2415553ab361" in namespace "emptydir-5525" to be "Succeeded or Failed"
Dec 18 12:14:48.003: INFO: Pod "pod-96cd2103-02db-4693-9906-2415553ab361": Phase="Pending", Reason="", readiness=false. Elapsed: 6.121742ms
Dec 18 12:14:50.014: INFO: Pod "pod-96cd2103-02db-4693-9906-2415553ab361": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017198544s
Dec 18 12:14:52.027: INFO: Pod "pod-96cd2103-02db-4693-9906-2415553ab361": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029808909s
Dec 18 12:14:54.039: INFO: Pod "pod-96cd2103-02db-4693-9906-2415553ab361": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042431871s
STEP: Saw pod success
Dec 18 12:14:54.039: INFO: Pod "pod-96cd2103-02db-4693-9906-2415553ab361" satisfied condition "Succeeded or Failed"
Dec 18 12:14:54.045: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-96cd2103-02db-4693-9906-2415553ab361 container test-container: <nil>
STEP: delete the pod
Dec 18 12:14:54.116: INFO: Waiting for pod pod-96cd2103-02db-4693-9906-2415553ab361 to disappear
Dec 18 12:14:54.136: INFO: Pod pod-96cd2103-02db-4693-9906-2415553ab361 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:14:54.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5525" for this suite.

• [SLOW TEST:6.471 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":75,"skipped":1288,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:14:54.184: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3093
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:14:54.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3093" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":273,"completed":76,"skipped":1304,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:14:54.489: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-5879
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:14:54.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5879" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":273,"completed":77,"skipped":1316,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:14:54.733: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7377
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Dec 18 12:14:54.958: INFO: Waiting up to 5m0s for pod "client-containers-abea83e7-a0fe-4ab0-88ba-c10a92b0d9ee" in namespace "containers-7377" to be "Succeeded or Failed"
Dec 18 12:14:54.971: INFO: Pod "client-containers-abea83e7-a0fe-4ab0-88ba-c10a92b0d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 13.19869ms
Dec 18 12:14:56.979: INFO: Pod "client-containers-abea83e7-a0fe-4ab0-88ba-c10a92b0d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021594319s
Dec 18 12:14:58.989: INFO: Pod "client-containers-abea83e7-a0fe-4ab0-88ba-c10a92b0d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031441073s
Dec 18 12:15:00.997: INFO: Pod "client-containers-abea83e7-a0fe-4ab0-88ba-c10a92b0d9ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039844669s
STEP: Saw pod success
Dec 18 12:15:00.998: INFO: Pod "client-containers-abea83e7-a0fe-4ab0-88ba-c10a92b0d9ee" satisfied condition "Succeeded or Failed"
Dec 18 12:15:01.004: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod client-containers-abea83e7-a0fe-4ab0-88ba-c10a92b0d9ee container test-container: <nil>
STEP: delete the pod
Dec 18 12:15:01.070: INFO: Waiting for pod client-containers-abea83e7-a0fe-4ab0-88ba-c10a92b0d9ee to disappear
Dec 18 12:15:01.077: INFO: Pod client-containers-abea83e7-a0fe-4ab0-88ba-c10a92b0d9ee no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:15:01.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7377" for this suite.

• [SLOW TEST:6.373 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":273,"completed":78,"skipped":1323,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:15:01.106: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3757
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 18 12:15:01.361: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 18 12:15:01.402: INFO: Waiting for terminating namespaces to be deleted...
Dec 18 12:15:01.409: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r before test
Dec 18 12:15:01.474: INFO: kube-proxy-lhksn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.474: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 12:15:01.474: INFO: canal-hrvbb from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.474: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 12:15:01.474: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 12:15:01.474: INFO: user-ssh-keys-agent-c7l5b from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.474: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 12:15:01.474: INFO: node-local-dns-b8hqm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.474: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 12:15:01.474: INFO: csi-cinder-nodeplugin-ubuntu-xgvkm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.474: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:15:01.474: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 12:15:01.474: INFO: sonobuoy from sonobuoy started at 2020-12-18 11:49:35 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.474: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 18 12:15:01.474: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-f897c from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.475: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:15:01.475: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 12:15:01.475: INFO: syseleven-node-problem-detector-njhnw from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.475: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 12:15:01.475: INFO: coredns-854998958f-grdws from kube-system started at 2020-12-18 08:54:22 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.475: INFO: 	Container coredns ready: true, restart count 0
Dec 18 12:15:01.475: INFO: sonobuoy-e2e-job-e8b5ba8e22894e5b from sonobuoy started at 2020-12-18 11:49:39 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.475: INFO: 	Container e2e ready: true, restart count 0
Dec 18 12:15:01.475: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:15:01.475: INFO: node-exporter-9db9x from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.475: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 12:15:01.475: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 before test
Dec 18 12:15:01.587: INFO: node-exporter-sxvt4 from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 12:15:01.588: INFO: csi-cinder-nodeplugin-ubuntu-mgs7f from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:15:01.588: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 12:15:01.588: INFO: dns-autoscaler-596856b68b-sdb66 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container autoscaler ready: true, restart count 0
Dec 18 12:15:01.588: INFO: node-local-dns-hd82q from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 12:15:01.588: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-26dcz from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:15:01.588: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 12:15:01.588: INFO: user-ssh-keys-agent-9dgcw from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 12:15:01.588: INFO: coredns-854998958f-xqqnb from kube-system started at 2020-12-18 08:52:04 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container coredns ready: true, restart count 0
Dec 18 12:15:01.588: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (5 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:15:01.588: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 18 12:15:01.588: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 18 12:15:01.588: INFO: 	Container csi-resizer ready: true, restart count 0
Dec 18 12:15:01.588: INFO: 	Container csi-snapshotter ready: true, restart count 0
Dec 18 12:15:01.588: INFO: syseleven-node-problem-detector-scggf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 12:15:01.588: INFO: kube-proxy-xljhw from kube-system started at 2020-12-18 08:51:26 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 12:15:01.588: INFO: canal-x2srj from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.588: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 12:15:01.588: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 12:15:01.588: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl before test
Dec 18 12:15:01.626: INFO: node-local-dns-2xjfh from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.626: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 12:15:01.626: INFO: openvpn-client-56dc45fdbd-hlz4z from kube-system started at 2020-12-18 08:54:10 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.626: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 18 12:15:01.626: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 18 12:15:01.626: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-t59nh from sonobuoy started at 2020-12-18 11:49:41 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.626: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:15:01.627: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 12:15:01.627: INFO: canal-fwhcf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.627: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 12:15:01.627: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 12:15:01.627: INFO: csi-cinder-nodeplugin-ubuntu-crqmv from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:01.627: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:15:01.627: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 12:15:01.627: INFO: cluster-autoscaler-5c8c86777b-zbqbq from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.627: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 18 12:15:01.627: INFO: tiller-deploy-5648ccb4b6-28wjd from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.627: INFO: 	Container tiller ready: true, restart count 0
Dec 18 12:15:01.627: INFO: kube-proxy-sgz6s from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.627: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 12:15:01.627: INFO: node-exporter-7rrpc from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.627: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 12:15:01.627: INFO: user-ssh-keys-agent-s8rkn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.627: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 12:15:01.627: INFO: syseleven-node-problem-detector-t5b9t from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:01.627: INFO: 	Container node-problem-detector ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-256dbbc2-c2ed-44d7-80b4-892cb39bc239 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-256dbbc2-c2ed-44d7-80b4-892cb39bc239 off the node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
STEP: verifying the node doesn't have the label kubernetes.io/e2e-256dbbc2-c2ed-44d7-80b4-892cb39bc239
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:15:35.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3757" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:34.757 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":273,"completed":79,"skipped":1325,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:15:35.864: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6256
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:15:36.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6256" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":273,"completed":80,"skipped":1337,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:15:36.166: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8669
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:15:52.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8669" for this suite.

• [SLOW TEST:16.383 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":273,"completed":81,"skipped":1345,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:15:52.551: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-4187
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:15:53.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-4187" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":273,"completed":82,"skipped":1386,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:15:53.259: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2469
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:15:53.510: INFO: (0) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 23.735238ms)
Dec 18 12:15:53.523: INFO: (1) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.511363ms)
Dec 18 12:15:53.536: INFO: (2) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.380806ms)
Dec 18 12:15:53.582: INFO: (3) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 45.927505ms)
Dec 18 12:15:53.599: INFO: (4) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.774178ms)
Dec 18 12:15:53.612: INFO: (5) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.203731ms)
Dec 18 12:15:53.623: INFO: (6) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.025149ms)
Dec 18 12:15:53.642: INFO: (7) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.070267ms)
Dec 18 12:15:53.654: INFO: (8) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.018471ms)
Dec 18 12:15:53.665: INFO: (9) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.375971ms)
Dec 18 12:15:53.677: INFO: (10) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.624ms)
Dec 18 12:15:53.694: INFO: (11) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 17.517402ms)
Dec 18 12:15:53.710: INFO: (12) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.780216ms)
Dec 18 12:15:53.729: INFO: (13) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.146855ms)
Dec 18 12:15:53.743: INFO: (14) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.183598ms)
Dec 18 12:15:53.756: INFO: (15) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.961492ms)
Dec 18 12:15:53.767: INFO: (16) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.719542ms)
Dec 18 12:15:53.780: INFO: (17) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.85659ms)
Dec 18 12:15:53.791: INFO: (18) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 10.940255ms)
Dec 18 12:15:53.803: INFO: (19) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-t45gl:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.863532ms)
[AfterEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:15:53.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2469" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":273,"completed":83,"skipped":1400,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:15:53.827: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8411
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 18 12:15:54.030: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 18 12:15:54.057: INFO: Waiting for terminating namespaces to be deleted...
Dec 18 12:15:54.065: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r before test
Dec 18 12:15:54.097: INFO: node-exporter-9db9x from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.097: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 12:15:54.098: INFO: sonobuoy-e2e-job-e8b5ba8e22894e5b from sonobuoy started at 2020-12-18 11:49:39 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.098: INFO: 	Container e2e ready: true, restart count 0
Dec 18 12:15:54.098: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:15:54.098: INFO: user-ssh-keys-agent-c7l5b from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.098: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 12:15:54.098: INFO: kube-proxy-lhksn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.098: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 12:15:54.098: INFO: canal-hrvbb from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.098: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 12:15:54.098: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 12:15:54.098: INFO: syseleven-node-problem-detector-njhnw from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.098: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 12:15:54.098: INFO: node-local-dns-b8hqm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.098: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 12:15:54.098: INFO: csi-cinder-nodeplugin-ubuntu-xgvkm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.098: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:15:54.098: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 12:15:54.099: INFO: sonobuoy from sonobuoy started at 2020-12-18 11:49:35 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.099: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 18 12:15:54.099: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-f897c from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.099: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:15:54.099: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 12:15:54.099: INFO: coredns-854998958f-grdws from kube-system started at 2020-12-18 08:54:22 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.099: INFO: 	Container coredns ready: true, restart count 0
Dec 18 12:15:54.099: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 before test
Dec 18 12:15:54.195: INFO: csi-cinder-nodeplugin-ubuntu-mgs7f from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.195: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:15:54.195: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 12:15:54.195: INFO: dns-autoscaler-596856b68b-sdb66 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.195: INFO: 	Container autoscaler ready: true, restart count 0
Dec 18 12:15:54.195: INFO: node-local-dns-hd82q from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.195: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 12:15:54.195: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-26dcz from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.196: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:15:54.196: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 12:15:54.196: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (5 container statuses recorded)
Dec 18 12:15:54.196: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:15:54.196: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 18 12:15:54.196: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 18 12:15:54.196: INFO: 	Container csi-resizer ready: true, restart count 0
Dec 18 12:15:54.196: INFO: 	Container csi-snapshotter ready: true, restart count 0
Dec 18 12:15:54.196: INFO: syseleven-node-problem-detector-scggf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.196: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 12:15:54.197: INFO: kube-proxy-xljhw from kube-system started at 2020-12-18 08:51:26 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.197: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 12:15:54.197: INFO: canal-x2srj from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.197: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 12:15:54.197: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 12:15:54.197: INFO: user-ssh-keys-agent-9dgcw from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.197: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 12:15:54.197: INFO: coredns-854998958f-xqqnb from kube-system started at 2020-12-18 08:52:04 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.197: INFO: 	Container coredns ready: true, restart count 0
Dec 18 12:15:54.198: INFO: node-exporter-sxvt4 from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.198: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 12:15:54.198: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl before test
Dec 18 12:15:54.291: INFO: kube-proxy-sgz6s from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 12:15:54.291: INFO: csi-cinder-nodeplugin-ubuntu-crqmv from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 12:15:54.291: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 12:15:54.291: INFO: cluster-autoscaler-5c8c86777b-zbqbq from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 18 12:15:54.291: INFO: tiller-deploy-5648ccb4b6-28wjd from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container tiller ready: true, restart count 0
Dec 18 12:15:54.291: INFO: node-exporter-7rrpc from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 12:15:54.291: INFO: syseleven-node-problem-detector-t5b9t from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 12:15:54.291: INFO: user-ssh-keys-agent-s8rkn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 12:15:54.291: INFO: canal-fwhcf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 12:15:54.291: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 12:15:54.291: INFO: node-local-dns-2xjfh from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 12:15:54.291: INFO: openvpn-client-56dc45fdbd-hlz4z from kube-system started at 2020-12-18 08:54:10 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 18 12:15:54.291: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 18 12:15:54.291: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-t59nh from sonobuoy started at 2020-12-18 11:49:41 +0000 UTC (2 container statuses recorded)
Dec 18 12:15:54.291: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 12:15:54.291: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dfd32638-49f8-45cd-93b3-65e9d5810d25 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-dfd32638-49f8-45cd-93b3-65e9d5810d25 off the node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dfd32638-49f8-45cd-93b3-65e9d5810d25
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:16:06.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8411" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:12.781 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":273,"completed":84,"skipped":1427,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:16:06.609: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-9497
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:16:07.403: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Creating first CR 
Dec 18 12:16:08.251: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-18T12:16:08Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-18T12:16:08Z]] name:name1 resourceVersion:87123 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cb40696f-2d2b-4fa4-a937-6e79e96c756d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 18 12:16:18.267: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-18T12:16:18Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-18T12:16:18Z]] name:name2 resourceVersion:87193 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9b570249-6b80-40a3-acfb-5bba7068c8e2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 18 12:16:28.286: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-18T12:16:08Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-18T12:16:28Z]] name:name1 resourceVersion:87247 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cb40696f-2d2b-4fa4-a937-6e79e96c756d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 18 12:16:38.300: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-18T12:16:18Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-18T12:16:38Z]] name:name2 resourceVersion:87299 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9b570249-6b80-40a3-acfb-5bba7068c8e2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 18 12:16:48.324: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-18T12:16:08Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-18T12:16:28Z]] name:name1 resourceVersion:87348 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cb40696f-2d2b-4fa4-a937-6e79e96c756d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 18 12:16:58.346: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-12-18T12:16:18Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-12-18T12:16:38Z]] name:name2 resourceVersion:87401 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9b570249-6b80-40a3-acfb-5bba7068c8e2] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:17:08.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-9497" for this suite.

• [SLOW TEST:62.287 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":273,"completed":85,"skipped":1428,"failed":0}
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:17:08.896: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8087
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8087.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8087.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8087.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8087.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8087.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8087.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 18 12:17:21.528: INFO: DNS probes using dns-8087/dns-test-68dbcb6c-57cf-4a5d-a6c0-3fd214aa2202 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:17:21.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8087" for this suite.

• [SLOW TEST:12.787 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":273,"completed":86,"skipped":1428,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:17:21.685: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1515
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 18 12:17:21.946: INFO: Waiting up to 5m0s for pod "pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac" in namespace "emptydir-1515" to be "Succeeded or Failed"
Dec 18 12:17:21.953: INFO: Pod "pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac": Phase="Pending", Reason="", readiness=false. Elapsed: 6.693205ms
Dec 18 12:17:23.961: INFO: Pod "pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014311288s
Dec 18 12:17:25.968: INFO: Pod "pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021511621s
Dec 18 12:17:27.977: INFO: Pod "pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030177405s
Dec 18 12:17:29.984: INFO: Pod "pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.03792735s
STEP: Saw pod success
Dec 18 12:17:29.985: INFO: Pod "pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac" satisfied condition "Succeeded or Failed"
Dec 18 12:17:29.991: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac container test-container: <nil>
STEP: delete the pod
Dec 18 12:17:30.269: INFO: Waiting for pod pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac to disappear
Dec 18 12:17:30.278: INFO: Pod pod-5fbb4dd3-3059-4f41-8a87-85fff47e71ac no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:17:30.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1515" for this suite.

• [SLOW TEST:8.844 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":87,"skipped":1438,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:17:30.530: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7157
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:17:42.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7157" for this suite.

• [SLOW TEST:11.876 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":273,"completed":88,"skipped":1443,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:17:42.408: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9187
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:17:42.679: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 18 12:17:42.718: INFO: Number of nodes with available pods: 0
Dec 18 12:17:42.718: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:43.739: INFO: Number of nodes with available pods: 0
Dec 18 12:17:43.739: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:44.745: INFO: Number of nodes with available pods: 0
Dec 18 12:17:44.745: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:45.738: INFO: Number of nodes with available pods: 0
Dec 18 12:17:45.738: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:46.752: INFO: Number of nodes with available pods: 0
Dec 18 12:17:46.752: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:47.747: INFO: Number of nodes with available pods: 1
Dec 18 12:17:47.747: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:48.741: INFO: Number of nodes with available pods: 1
Dec 18 12:17:48.741: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:49.738: INFO: Number of nodes with available pods: 1
Dec 18 12:17:49.738: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:50.741: INFO: Number of nodes with available pods: 1
Dec 18 12:17:50.741: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:51.762: INFO: Number of nodes with available pods: 1
Dec 18 12:17:51.762: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:17:52.737: INFO: Number of nodes with available pods: 3
Dec 18 12:17:52.737: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 18 12:17:52.811: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:52.811: INFO: Wrong image for pod: daemon-set-sfl5r. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:52.811: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:53.831: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:53.831: INFO: Wrong image for pod: daemon-set-sfl5r. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:53.831: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:54.829: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:54.829: INFO: Wrong image for pod: daemon-set-sfl5r. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:54.829: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:55.830: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:55.830: INFO: Wrong image for pod: daemon-set-sfl5r. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:55.830: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:56.831: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:56.831: INFO: Wrong image for pod: daemon-set-sfl5r. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:56.831: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:57.831: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:57.831: INFO: Wrong image for pod: daemon-set-sfl5r. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:57.831: INFO: Pod daemon-set-sfl5r is not available
Dec 18 12:17:57.831: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:58.834: INFO: Pod daemon-set-b6whv is not available
Dec 18 12:17:58.834: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:58.834: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:59.829: INFO: Pod daemon-set-b6whv is not available
Dec 18 12:17:59.829: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:17:59.829: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:00.835: INFO: Pod daemon-set-b6whv is not available
Dec 18 12:18:00.835: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:00.835: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:01.830: INFO: Pod daemon-set-b6whv is not available
Dec 18 12:18:01.830: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:01.830: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:02.837: INFO: Pod daemon-set-b6whv is not available
Dec 18 12:18:02.837: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:02.837: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:03.831: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:03.831: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:04.832: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:04.832: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:05.833: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:05.833: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:06.831: INFO: Wrong image for pod: daemon-set-hfpcn. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:06.832: INFO: Pod daemon-set-hfpcn is not available
Dec 18 12:18:06.832: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:07.829: INFO: Pod daemon-set-x4zf5 is not available
Dec 18 12:18:07.830: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:08.829: INFO: Pod daemon-set-x4zf5 is not available
Dec 18 12:18:08.829: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:09.831: INFO: Pod daemon-set-x4zf5 is not available
Dec 18 12:18:09.831: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:10.848: INFO: Pod daemon-set-x4zf5 is not available
Dec 18 12:18:10.849: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:11.832: INFO: Pod daemon-set-x4zf5 is not available
Dec 18 12:18:11.832: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:12.893: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:13.835: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:14.830: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:15.828: INFO: Wrong image for pod: daemon-set-zt4qk. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Dec 18 12:18:15.828: INFO: Pod daemon-set-zt4qk is not available
Dec 18 12:18:16.831: INFO: Pod daemon-set-g4pmn is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 18 12:18:16.859: INFO: Number of nodes with available pods: 2
Dec 18 12:18:16.859: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl is running more than one daemon pod
Dec 18 12:18:17.877: INFO: Number of nodes with available pods: 2
Dec 18 12:18:17.877: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl is running more than one daemon pod
Dec 18 12:18:18.878: INFO: Number of nodes with available pods: 2
Dec 18 12:18:18.879: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl is running more than one daemon pod
Dec 18 12:18:19.882: INFO: Number of nodes with available pods: 2
Dec 18 12:18:19.882: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl is running more than one daemon pod
Dec 18 12:18:20.888: INFO: Number of nodes with available pods: 2
Dec 18 12:18:20.889: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl is running more than one daemon pod
Dec 18 12:18:21.885: INFO: Number of nodes with available pods: 3
Dec 18 12:18:21.885: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9187, will wait for the garbage collector to delete the pods
Dec 18 12:18:22.036: INFO: Deleting DaemonSet.extensions daemon-set took: 45.484806ms
Dec 18 12:18:22.637: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.451526ms
Dec 18 12:18:26.549: INFO: Number of nodes with available pods: 0
Dec 18 12:18:26.549: INFO: Number of running nodes: 0, number of available pods: 0
Dec 18 12:18:26.563: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9187/daemonsets","resourceVersion":"88117"},"items":null}

Dec 18 12:18:26.575: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9187/pods","resourceVersion":"88117"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:18:26.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9187" for this suite.

• [SLOW TEST:44.264 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":273,"completed":89,"skipped":1452,"failed":0}
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:18:26.675: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1671
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-1671/configmap-test-7cf1bb8e-60c1-40b1-b257-6b7a48228e32
STEP: Creating a pod to test consume configMaps
Dec 18 12:18:26.934: INFO: Waiting up to 5m0s for pod "pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420" in namespace "configmap-1671" to be "Succeeded or Failed"
Dec 18 12:18:26.940: INFO: Pod "pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420": Phase="Pending", Reason="", readiness=false. Elapsed: 6.540053ms
Dec 18 12:18:28.949: INFO: Pod "pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015563895s
Dec 18 12:18:30.965: INFO: Pod "pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031301384s
Dec 18 12:18:32.973: INFO: Pod "pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039145559s
Dec 18 12:18:34.982: INFO: Pod "pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04860227s
STEP: Saw pod success
Dec 18 12:18:34.983: INFO: Pod "pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420" satisfied condition "Succeeded or Failed"
Dec 18 12:18:34.990: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420 container env-test: <nil>
STEP: delete the pod
Dec 18 12:18:35.043: INFO: Waiting for pod pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420 to disappear
Dec 18 12:18:35.048: INFO: Pod pod-configmaps-6bd2ffc9-f7e9-4d0a-90d6-fe5da9e51420 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:18:35.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1671" for this suite.

• [SLOW TEST:8.399 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:34
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":273,"completed":90,"skipped":1460,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:18:35.075: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3090
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:18:35.734: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 18 12:18:37.763: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890715, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890715, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890715, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890715, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:18:39.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890715, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890715, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890715, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890715, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:18:42.807: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:18:43.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3090" for this suite.
STEP: Destroying namespace "webhook-3090-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.113 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":273,"completed":91,"skipped":1496,"failed":0}
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:18:43.188: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-846
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-846.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-846.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-846.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-846.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-846.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-846.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-846.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-846.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-846.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-846.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 18 12:18:53.518: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local from pod dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70: the server could not find the requested resource (get pods dns-test-2025c580-3bb8-43ce-a451-329ebc252f70)
Dec 18 12:18:53.530: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local from pod dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70: the server could not find the requested resource (get pods dns-test-2025c580-3bb8-43ce-a451-329ebc252f70)
Dec 18 12:18:53.540: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-846.svc.cluster.local from pod dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70: the server could not find the requested resource (get pods dns-test-2025c580-3bb8-43ce-a451-329ebc252f70)
Dec 18 12:18:53.585: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-846.svc.cluster.local from pod dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70: the server could not find the requested resource (get pods dns-test-2025c580-3bb8-43ce-a451-329ebc252f70)
Dec 18 12:18:53.699: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local from pod dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70: the server could not find the requested resource (get pods dns-test-2025c580-3bb8-43ce-a451-329ebc252f70)
Dec 18 12:18:53.714: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local from pod dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70: the server could not find the requested resource (get pods dns-test-2025c580-3bb8-43ce-a451-329ebc252f70)
Dec 18 12:18:53.725: INFO: Unable to read jessie_udp@dns-test-service-2.dns-846.svc.cluster.local from pod dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70: the server could not find the requested resource (get pods dns-test-2025c580-3bb8-43ce-a451-329ebc252f70)
Dec 18 12:18:53.737: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-846.svc.cluster.local from pod dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70: the server could not find the requested resource (get pods dns-test-2025c580-3bb8-43ce-a451-329ebc252f70)
Dec 18 12:18:53.842: INFO: Lookups using dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local wheezy_udp@dns-test-service-2.dns-846.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-846.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-846.svc.cluster.local jessie_udp@dns-test-service-2.dns-846.svc.cluster.local jessie_tcp@dns-test-service-2.dns-846.svc.cluster.local]

Dec 18 12:18:59.279: INFO: DNS probes using dns-846/dns-test-2025c580-3bb8-43ce-a451-329ebc252f70 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:18:59.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-846" for this suite.

• [SLOW TEST:16.189 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":273,"completed":92,"skipped":1496,"failed":0}
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:18:59.378: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-9c8646f9-30e8-4f95-9f3a-fe0eb9d318b6-140
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:18:59.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8209" for this suite.
STEP: Destroying namespace "nspatchtest-9c8646f9-30e8-4f95-9f3a-fe0eb9d318b6-140" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":273,"completed":93,"skipped":1497,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:18:59.935: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6655
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 12:19:00.148: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262" in namespace "downward-api-6655" to be "Succeeded or Failed"
Dec 18 12:19:00.157: INFO: Pod "downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262": Phase="Pending", Reason="", readiness=false. Elapsed: 9.032459ms
Dec 18 12:19:02.166: INFO: Pod "downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01757704s
Dec 18 12:19:04.178: INFO: Pod "downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029735964s
Dec 18 12:19:06.185: INFO: Pod "downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262": Phase="Pending", Reason="", readiness=false. Elapsed: 6.036675653s
Dec 18 12:19:08.196: INFO: Pod "downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04755726s
STEP: Saw pod success
Dec 18 12:19:08.196: INFO: Pod "downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262" satisfied condition "Succeeded or Failed"
Dec 18 12:19:08.209: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262 container client-container: <nil>
STEP: delete the pod
Dec 18 12:19:08.271: INFO: Waiting for pod downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262 to disappear
Dec 18 12:19:08.282: INFO: Pod downwardapi-volume-5279a3a3-23e0-4dc2-b2ae-ba4a8e954262 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:19:08.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6655" for this suite.

• [SLOW TEST:8.382 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":273,"completed":94,"skipped":1534,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:19:08.318: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7943
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-8fe08ed7-73b8-4d56-b1d3-b019eece6653
STEP: Creating a pod to test consume secrets
Dec 18 12:19:08.559: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a" in namespace "projected-7943" to be "Succeeded or Failed"
Dec 18 12:19:08.571: INFO: Pod "pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.722481ms
Dec 18 12:19:10.582: INFO: Pod "pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022160591s
Dec 18 12:19:12.600: INFO: Pod "pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040120592s
Dec 18 12:19:14.611: INFO: Pod "pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051662366s
Dec 18 12:19:16.620: INFO: Pod "pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.060404469s
Dec 18 12:19:18.631: INFO: Pod "pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.070899854s
STEP: Saw pod success
Dec 18 12:19:18.631: INFO: Pod "pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a" satisfied condition "Succeeded or Failed"
Dec 18 12:19:18.639: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 18 12:19:18.699: INFO: Waiting for pod pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a to disappear
Dec 18 12:19:18.706: INFO: Pod pod-projected-secrets-2cbca159-57e3-44b9-91d0-be0c2cb5df1a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:19:18.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7943" for this suite.

• [SLOW TEST:10.417 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":95,"skipped":1551,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:19:18.737: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-881
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:19:19.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-881" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":273,"completed":96,"skipped":1584,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:19:19.055: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 12:19:19.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126" in namespace "projected-4091" to be "Succeeded or Failed"
Dec 18 12:19:19.358: INFO: Pod "downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126": Phase="Pending", Reason="", readiness=false. Elapsed: 16.144219ms
Dec 18 12:19:21.369: INFO: Pod "downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028051473s
Dec 18 12:19:23.379: INFO: Pod "downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037623272s
Dec 18 12:19:25.388: INFO: Pod "downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126": Phase="Pending", Reason="", readiness=false. Elapsed: 6.046714114s
Dec 18 12:19:27.396: INFO: Pod "downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.054215965s
STEP: Saw pod success
Dec 18 12:19:27.396: INFO: Pod "downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126" satisfied condition "Succeeded or Failed"
Dec 18 12:19:27.403: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126 container client-container: <nil>
STEP: delete the pod
Dec 18 12:19:27.464: INFO: Waiting for pod downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126 to disappear
Dec 18 12:19:27.472: INFO: Pod downwardapi-volume-06388440-c6d5-4ae7-a237-b45b84b3e126 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:19:27.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4091" for this suite.

• [SLOW TEST:8.440 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":273,"completed":97,"skipped":1596,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:19:27.498: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3932
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:19:27.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3932" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":273,"completed":98,"skipped":1634,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:19:27.750: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8907
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-70994ed2-ab5c-4a54-9931-9a487ca795fe
STEP: Creating a pod to test consume secrets
Dec 18 12:19:27.992: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731" in namespace "projected-8907" to be "Succeeded or Failed"
Dec 18 12:19:27.999: INFO: Pod "pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731": Phase="Pending", Reason="", readiness=false. Elapsed: 6.682658ms
Dec 18 12:19:30.009: INFO: Pod "pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017360175s
Dec 18 12:19:32.020: INFO: Pod "pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027865029s
Dec 18 12:19:34.027: INFO: Pod "pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035256082s
Dec 18 12:19:36.037: INFO: Pod "pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731": Phase="Pending", Reason="", readiness=false. Elapsed: 8.045586209s
Dec 18 12:19:38.045: INFO: Pod "pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.053356811s
STEP: Saw pod success
Dec 18 12:19:38.045: INFO: Pod "pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731" satisfied condition "Succeeded or Failed"
Dec 18 12:19:38.053: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 18 12:19:38.183: INFO: Waiting for pod pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731 to disappear
Dec 18 12:19:38.250: INFO: Pod pod-projected-secrets-9d3da2dc-f31d-415d-99c8-97419089b731 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:19:38.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8907" for this suite.

• [SLOW TEST:10.538 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":273,"completed":99,"skipped":1693,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:19:38.294: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:19:55.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1124" for this suite.

• [SLOW TEST:16.990 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":273,"completed":100,"skipped":1715,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:19:55.286: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3186
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3186
I1218 12:19:55.532359      21 runners.go:190] Created replication controller with name: externalname-service, namespace: services-3186, replica count: 2
I1218 12:19:58.583081      21 runners.go:190] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 18 12:20:01.583: INFO: Creating new exec pod
I1218 12:20:01.583511      21 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 18 12:20:10.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=services-3186 execpods92h5 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 18 12:20:13.086: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 18 12:20:13.086: INFO: stdout: ""
Dec 18 12:20:13.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=services-3186 execpods92h5 -- /bin/sh -x -c nc -zv -t -w 2 10.240.29.190 80'
Dec 18 12:20:13.542: INFO: stderr: "+ nc -zv -t -w 2 10.240.29.190 80\nConnection to 10.240.29.190 80 port [tcp/http] succeeded!\n"
Dec 18 12:20:13.542: INFO: stdout: ""
Dec 18 12:20:13.542: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:20:13.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3186" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:18.328 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":273,"completed":101,"skipped":1743,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:20:13.620: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-554
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:20:14.792: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 18 12:20:16.829: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:20:18.840: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:20:20.838: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890814, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:20:23.865: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:20:23.872: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:20:25.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-554" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.227 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":273,"completed":102,"skipped":1801,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:20:25.849: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-5ccc
STEP: Creating a pod to test atomic-volume-subpath
Dec 18 12:20:26.136: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-5ccc" in namespace "subpath-2116" to be "Succeeded or Failed"
Dec 18 12:20:26.151: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.914971ms
Dec 18 12:20:28.160: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024124862s
Dec 18 12:20:30.167: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03142856s
Dec 18 12:20:32.181: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 6.045714928s
Dec 18 12:20:34.190: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 8.053895936s
Dec 18 12:20:36.199: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 10.063446631s
Dec 18 12:20:38.208: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 12.072545663s
Dec 18 12:20:40.215: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 14.079768564s
Dec 18 12:20:42.223: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 16.087697308s
Dec 18 12:20:44.233: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 18.097073794s
Dec 18 12:20:46.240: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 20.103800312s
Dec 18 12:20:48.252: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 22.116381885s
Dec 18 12:20:50.269: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 24.13303054s
Dec 18 12:20:52.297: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Running", Reason="", readiness=true. Elapsed: 26.161183165s
Dec 18 12:20:54.331: INFO: Pod "pod-subpath-test-projected-5ccc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.195735113s
STEP: Saw pod success
Dec 18 12:20:54.332: INFO: Pod "pod-subpath-test-projected-5ccc" satisfied condition "Succeeded or Failed"
Dec 18 12:20:54.338: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-subpath-test-projected-5ccc container test-container-subpath-projected-5ccc: <nil>
STEP: delete the pod
Dec 18 12:20:54.713: INFO: Waiting for pod pod-subpath-test-projected-5ccc to disappear
Dec 18 12:20:54.720: INFO: Pod pod-subpath-test-projected-5ccc no longer exists
STEP: Deleting pod pod-subpath-test-projected-5ccc
Dec 18 12:20:54.720: INFO: Deleting pod "pod-subpath-test-projected-5ccc" in namespace "subpath-2116"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:20:54.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2116" for this suite.

• [SLOW TEST:29.022 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":273,"completed":103,"skipped":1831,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:20:54.872: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6260
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:20:56.932: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-779fdc84d9\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:20:58.940: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890857, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:21:00.940: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890857, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890856, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:21:03.955: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:21:03.962: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3241-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:21:05.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6260" for this suite.
STEP: Destroying namespace "webhook-6260-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:10.682 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":273,"completed":104,"skipped":1858,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:21:05.555: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 18 12:21:14.849: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:21:15.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2878" for this suite.

• [SLOW TEST:10.355 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":273,"completed":105,"skipped":1875,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:21:15.911: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-5153
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-5153
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5153
STEP: Deleting pre-stop pod
Dec 18 12:21:33.234: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:21:33.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5153" for this suite.

• [SLOW TEST:17.391 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":273,"completed":106,"skipped":1885,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:21:33.303: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5134
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 18 12:21:33.555: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:21:49.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5134" for this suite.

• [SLOW TEST:16.364 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":273,"completed":107,"skipped":1900,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:21:49.671: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6203
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-29f621da-2bde-4bb8-82dc-ae13f5441346
STEP: Creating a pod to test consume secrets
Dec 18 12:21:49.947: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b5addf4a-c80a-4182-99c2-2e697d62b643" in namespace "projected-6203" to be "Succeeded or Failed"
Dec 18 12:21:49.961: INFO: Pod "pod-projected-secrets-b5addf4a-c80a-4182-99c2-2e697d62b643": Phase="Pending", Reason="", readiness=false. Elapsed: 14.538915ms
Dec 18 12:21:51.972: INFO: Pod "pod-projected-secrets-b5addf4a-c80a-4182-99c2-2e697d62b643": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025491787s
Dec 18 12:21:53.981: INFO: Pod "pod-projected-secrets-b5addf4a-c80a-4182-99c2-2e697d62b643": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034457995s
Dec 18 12:21:55.990: INFO: Pod "pod-projected-secrets-b5addf4a-c80a-4182-99c2-2e697d62b643": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042803316s
STEP: Saw pod success
Dec 18 12:21:55.990: INFO: Pod "pod-projected-secrets-b5addf4a-c80a-4182-99c2-2e697d62b643" satisfied condition "Succeeded or Failed"
Dec 18 12:21:55.997: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-secrets-b5addf4a-c80a-4182-99c2-2e697d62b643 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 18 12:21:56.040: INFO: Waiting for pod pod-projected-secrets-b5addf4a-c80a-4182-99c2-2e697d62b643 to disappear
Dec 18 12:21:56.047: INFO: Pod pod-projected-secrets-b5addf4a-c80a-4182-99c2-2e697d62b643 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:21:56.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6203" for this suite.

• [SLOW TEST:6.417 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":108,"skipped":1910,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:21:56.092: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1313
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:21:57.082: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 12:21:59.112: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:22:01.121: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:22:03.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743890917, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:22:06.142: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:22:06.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1313" for this suite.
STEP: Destroying namespace "webhook-1313-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:10.456 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":273,"completed":109,"skipped":1934,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:22:06.549: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4482
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:22:06.866: INFO: Waiting up to 5m0s for pod "busybox-user-65534-102da19c-9764-44b3-83f4-09fabc05af0c" in namespace "security-context-test-4482" to be "Succeeded or Failed"
Dec 18 12:22:06.872: INFO: Pod "busybox-user-65534-102da19c-9764-44b3-83f4-09fabc05af0c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.195375ms
Dec 18 12:22:08.879: INFO: Pod "busybox-user-65534-102da19c-9764-44b3-83f4-09fabc05af0c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013229783s
Dec 18 12:22:10.898: INFO: Pod "busybox-user-65534-102da19c-9764-44b3-83f4-09fabc05af0c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032565519s
Dec 18 12:22:12.907: INFO: Pod "busybox-user-65534-102da19c-9764-44b3-83f4-09fabc05af0c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040868851s
Dec 18 12:22:14.921: INFO: Pod "busybox-user-65534-102da19c-9764-44b3-83f4-09fabc05af0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.055243848s
Dec 18 12:22:14.921: INFO: Pod "busybox-user-65534-102da19c-9764-44b3-83f4-09fabc05af0c" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:22:14.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4482" for this suite.

• [SLOW TEST:8.409 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  When creating a container with runAsUser
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:45
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":110,"skipped":1955,"failed":0}
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:22:14.959: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-4437
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 18 12:22:21.229: INFO: &Pod{ObjectMeta:{send-events-3b6af8b7-4b5c-4c23-99ef-07e1ed348ad7  events-4437 /api/v1/namespaces/events-4437/pods/send-events-3b6af8b7-4b5c-4c23-99ef-07e1ed348ad7 a4b0290e-38aa-40ce-9b81-21fa41387702 90432 0 2020-12-18 12:22:15 +0000 UTC <nil> <nil> map[name:foo time:174124122] map[cni.projectcalico.org/podIP:172.25.1.140/32 cni.projectcalico.org/podIPs:172.25.1.140/32] [] []  [{e2e.test Update v1 2020-12-18 12:22:15 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:22:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:22:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 49 46 49 52 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-t4fvz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-t4fvz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-t4fvz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:22:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:22:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:22:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:22:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:172.25.1.140,StartTime:2020-12-18 12:22:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:22:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://1b98e8d99dcb76ddf6889a57d1643e35f21b57f9a3fbd2adb2e077e8bc811e57,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.140,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec 18 12:22:23.241: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 18 12:22:25.255: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:22:25.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4437" for this suite.

• [SLOW TEST:10.341 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":273,"completed":111,"skipped":1961,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:22:25.301: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:22:31.579: INFO: Waiting up to 5m0s for pod "client-envvars-ab6beb31-9b13-4d83-a43c-54013a9a3cc5" in namespace "pods-725" to be "Succeeded or Failed"
Dec 18 12:22:31.588: INFO: Pod "client-envvars-ab6beb31-9b13-4d83-a43c-54013a9a3cc5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.116739ms
Dec 18 12:22:33.599: INFO: Pod "client-envvars-ab6beb31-9b13-4d83-a43c-54013a9a3cc5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019902193s
Dec 18 12:22:35.608: INFO: Pod "client-envvars-ab6beb31-9b13-4d83-a43c-54013a9a3cc5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028951383s
Dec 18 12:22:37.618: INFO: Pod "client-envvars-ab6beb31-9b13-4d83-a43c-54013a9a3cc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03836876s
STEP: Saw pod success
Dec 18 12:22:37.618: INFO: Pod "client-envvars-ab6beb31-9b13-4d83-a43c-54013a9a3cc5" satisfied condition "Succeeded or Failed"
Dec 18 12:22:37.623: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r pod client-envvars-ab6beb31-9b13-4d83-a43c-54013a9a3cc5 container env3cont: <nil>
STEP: delete the pod
Dec 18 12:22:37.750: INFO: Waiting for pod client-envvars-ab6beb31-9b13-4d83-a43c-54013a9a3cc5 to disappear
Dec 18 12:22:37.759: INFO: Pod client-envvars-ab6beb31-9b13-4d83-a43c-54013a9a3cc5 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:22:37.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-725" for this suite.

• [SLOW TEST:12.483 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":273,"completed":112,"skipped":1988,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:22:37.786: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6785
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-848638fa-db0e-4a1a-8949-e1ff12c132b0
STEP: Creating a pod to test consume configMaps
Dec 18 12:22:38.010: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1fe7f578-9570-430f-b965-6dd656d97504" in namespace "projected-6785" to be "Succeeded or Failed"
Dec 18 12:22:38.020: INFO: Pod "pod-projected-configmaps-1fe7f578-9570-430f-b965-6dd656d97504": Phase="Pending", Reason="", readiness=false. Elapsed: 10.152965ms
Dec 18 12:22:40.035: INFO: Pod "pod-projected-configmaps-1fe7f578-9570-430f-b965-6dd656d97504": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025888482s
Dec 18 12:22:42.043: INFO: Pod "pod-projected-configmaps-1fe7f578-9570-430f-b965-6dd656d97504": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033116974s
Dec 18 12:22:44.051: INFO: Pod "pod-projected-configmaps-1fe7f578-9570-430f-b965-6dd656d97504": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041782009s
STEP: Saw pod success
Dec 18 12:22:44.052: INFO: Pod "pod-projected-configmaps-1fe7f578-9570-430f-b965-6dd656d97504" satisfied condition "Succeeded or Failed"
Dec 18 12:22:44.060: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r pod pod-projected-configmaps-1fe7f578-9570-430f-b965-6dd656d97504 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 12:22:44.111: INFO: Waiting for pod pod-projected-configmaps-1fe7f578-9570-430f-b965-6dd656d97504 to disappear
Dec 18 12:22:44.119: INFO: Pod pod-projected-configmaps-1fe7f578-9570-430f-b965-6dd656d97504 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:22:44.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6785" for this suite.

• [SLOW TEST:6.375 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":273,"completed":113,"skipped":2007,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:22:44.163: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 12:22:44.382: INFO: Waiting up to 5m0s for pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065" in namespace "projected-6588" to be "Succeeded or Failed"
Dec 18 12:22:44.390: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 7.432677ms
Dec 18 12:22:46.397: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015141161s
Dec 18 12:22:48.436: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05406248s
Dec 18 12:22:50.445: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 6.062367397s
Dec 18 12:22:52.456: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 8.073568467s
Dec 18 12:22:54.465: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 10.08228137s
Dec 18 12:22:56.475: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 12.092503379s
Dec 18 12:22:58.484: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 14.101885565s
Dec 18 12:23:00.492: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 16.10933941s
Dec 18 12:23:02.501: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 18.118607973s
Dec 18 12:23:04.511: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Pending", Reason="", readiness=false. Elapsed: 20.128491552s
Dec 18 12:23:06.557: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.174484507s
STEP: Saw pod success
Dec 18 12:23:06.557: INFO: Pod "downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065" satisfied condition "Succeeded or Failed"
Dec 18 12:23:06.566: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r pod downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065 container client-container: <nil>
STEP: delete the pod
Dec 18 12:23:07.073: INFO: Waiting for pod downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065 to disappear
Dec 18 12:23:07.081: INFO: Pod downwardapi-volume-512ae10e-8a64-4450-a4f5-8541626de065 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:23:07.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6588" for this suite.

• [SLOW TEST:22.948 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":273,"completed":114,"skipped":2032,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:23:07.112: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2847
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-5a86a949-f9a7-4c58-9fb1-577989f11aa6
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:23:07.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2847" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":273,"completed":115,"skipped":2054,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:23:07.419: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7394
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Dec 18 12:23:07.639: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:23:28.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7394" for this suite.

• [SLOW TEST:20.963 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":273,"completed":116,"skipped":2055,"failed":0}
SS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:23:28.382: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1859
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:23:58.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1859" for this suite.

• [SLOW TEST:30.342 seconds]
[sig-apps] Job
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":273,"completed":117,"skipped":2057,"failed":0}
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:23:58.725: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9341
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Dec 18 12:23:58.925: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:24:09.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9341" for this suite.

• [SLOW TEST:10.576 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":273,"completed":118,"skipped":2059,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:24:09.306: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5093
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-5093
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 18 12:24:09.504: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 18 12:24:09.588: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:24:11.597: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:24:13.598: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:24:15.600: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:24:17.597: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:24:19.597: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:24:21.597: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:24:23.598: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:24:25.596: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 18 12:24:25.613: INFO: The status of Pod netserver-1 is Running (Ready = false)
Dec 18 12:24:27.620: INFO: The status of Pod netserver-1 is Running (Ready = true)
Dec 18 12:24:27.634: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Dec 18 12:24:33.692: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.148:8080/dial?request=hostname&protocol=http&host=172.25.2.91&port=8080&tries=1'] Namespace:pod-network-test-5093 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:24:33.692: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:24:34.083: INFO: Waiting for responses: map[]
Dec 18 12:24:34.091: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.148:8080/dial?request=hostname&protocol=http&host=172.25.0.48&port=8080&tries=1'] Namespace:pod-network-test-5093 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:24:34.091: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:24:34.442: INFO: Waiting for responses: map[]
Dec 18 12:24:34.449: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.148:8080/dial?request=hostname&protocol=http&host=172.25.1.147&port=8080&tries=1'] Namespace:pod-network-test-5093 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:24:34.449: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:24:34.737: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:24:34.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5093" for this suite.

• [SLOW TEST:25.457 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":273,"completed":119,"skipped":2124,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:24:34.765: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9670
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9670, will wait for the garbage collector to delete the pods
Dec 18 12:24:45.067: INFO: Deleting Job.batch foo took: 17.624999ms
Dec 18 12:24:45.667: INFO: Terminating Job.batch foo pods took: 600.329172ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:25:29.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9670" for this suite.

• [SLOW TEST:54.958 seconds]
[sig-apps] Job
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":273,"completed":120,"skipped":2165,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:25:29.729: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:25:29.937: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 18 12:25:31.033: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:25:31.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-620" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":273,"completed":121,"skipped":2223,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:25:31.068: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:25:39.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9005" for this suite.

• [SLOW TEST:8.383 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:137
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":122,"skipped":2233,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:25:39.453: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-306
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec 18 12:26:19.792: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1218 12:26:19.792679      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:26:19.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-306" for this suite.

• [SLOW TEST:40.363 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":273,"completed":123,"skipped":2246,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:26:19.824: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7081
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 18 12:26:32.151: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 18 12:26:32.158: INFO: Pod pod-with-prestop-http-hook still exists
Dec 18 12:26:34.158: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 18 12:26:34.168: INFO: Pod pod-with-prestop-http-hook still exists
Dec 18 12:26:36.158: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 18 12:26:36.169: INFO: Pod pod-with-prestop-http-hook still exists
Dec 18 12:26:38.158: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 18 12:26:38.176: INFO: Pod pod-with-prestop-http-hook still exists
Dec 18 12:26:40.158: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 18 12:26:40.168: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:26:40.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7081" for this suite.

• [SLOW TEST:20.390 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":273,"completed":124,"skipped":2270,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:26:40.220: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:26:40.440: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 18 12:26:45.452: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 18 12:26:47.640: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 18 12:26:47.750: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2515 /apis/apps/v1/namespaces/deployment-2515/deployments/test-cleanup-deployment 22788dca-6479-4113-a2d3-ee8c2fedc999 92682 1 2020-12-18 12:26:47 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2020-12-18 12:26:47 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00061b668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec 18 12:26:47.867: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec 18 12:26:47.867: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 18 12:26:47.868: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-2515 /apis/apps/v1/namespaces/deployment-2515/replicasets/test-cleanup-controller d81d6650-8668-42e5-95c7-6808e3a0adbc 92683 1 2020-12-18 12:26:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 22788dca-6479-4113-a2d3-ee8c2fedc999 0xc00061ba67 0xc00061ba68}] []  [{e2e.test Update apps/v1 2020-12-18 12:26:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-18 12:26:47 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 50 55 56 56 100 99 97 45 54 52 55 57 45 52 49 49 51 45 97 50 100 51 45 101 101 56 99 50 102 101 100 99 57 57 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00061bb08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 18 12:26:47.897: INFO: Pod "test-cleanup-controller-9mz8v" is available:
&Pod{ObjectMeta:{test-cleanup-controller-9mz8v test-cleanup-controller- deployment-2515 /api/v1/namespaces/deployment-2515/pods/test-cleanup-controller-9mz8v 02abdf41-594b-4354-94cb-9eb2dcf6831e 92670 0 2020-12-18 12:26:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:172.25.1.158/32 cni.projectcalico.org/podIPs:172.25.1.158/32] [{apps/v1 ReplicaSet test-cleanup-controller d81d6650-8668-42e5-95c7-6808e3a0adbc 0xc001a19157 0xc001a19158}] []  [{kube-controller-manager Update v1 2020-12-18 12:26:40 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 56 49 100 54 54 53 48 45 56 54 54 56 45 52 50 101 53 45 57 53 99 55 45 54 56 48 56 101 51 97 48 97 100 98 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:26:43 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:26:46 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 49 46 49 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4qdz2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4qdz2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4qdz2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:26:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:26:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:26:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:26:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:172.25.1.158,StartTime:2020-12-18 12:26:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:26:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://21d8098dffcc78794943326f3bc9cafeacac70589eed684a3b5dbae0bffdbf33,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:26:47.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2515" for this suite.

• [SLOW TEST:7.927 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":273,"completed":125,"skipped":2304,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:26:48.147: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 18 12:26:48.576: INFO: Waiting up to 5m0s for pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49" in namespace "emptydir-4837" to be "Succeeded or Failed"
Dec 18 12:26:48.588: INFO: Pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49": Phase="Pending", Reason="", readiness=false. Elapsed: 12.237613ms
Dec 18 12:26:50.595: INFO: Pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0190848s
Dec 18 12:26:52.605: INFO: Pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029049715s
Dec 18 12:26:54.616: INFO: Pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040641778s
Dec 18 12:26:56.628: INFO: Pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49": Phase="Pending", Reason="", readiness=false. Elapsed: 8.052214669s
Dec 18 12:26:58.636: INFO: Pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49": Phase="Pending", Reason="", readiness=false. Elapsed: 10.060268709s
Dec 18 12:27:00.644: INFO: Pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49": Phase="Pending", Reason="", readiness=false. Elapsed: 12.068030871s
Dec 18 12:27:02.653: INFO: Pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.077502989s
STEP: Saw pod success
Dec 18 12:27:02.653: INFO: Pod "pod-82c24c37-0740-457b-b2bc-bf8486643a49" satisfied condition "Succeeded or Failed"
Dec 18 12:27:02.665: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-82c24c37-0740-457b-b2bc-bf8486643a49 container test-container: <nil>
STEP: delete the pod
Dec 18 12:27:02.739: INFO: Waiting for pod pod-82c24c37-0740-457b-b2bc-bf8486643a49 to disappear
Dec 18 12:27:02.750: INFO: Pod pod-82c24c37-0740-457b-b2bc-bf8486643a49 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:27:02.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4837" for this suite.

• [SLOW TEST:14.626 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":126,"skipped":2328,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:27:02.774: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5060
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:27:03.118: INFO: (0) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 82.416167ms)
Dec 18 12:27:03.163: INFO: (1) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 44.590328ms)
Dec 18 12:27:03.180: INFO: (2) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.420325ms)
Dec 18 12:27:03.195: INFO: (3) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.034739ms)
Dec 18 12:27:03.224: INFO: (4) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 29.093309ms)
Dec 18 12:27:03.236: INFO: (5) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.587865ms)
Dec 18 12:27:03.249: INFO: (6) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.039631ms)
Dec 18 12:27:03.265: INFO: (7) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.538872ms)
Dec 18 12:27:03.280: INFO: (8) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.458936ms)
Dec 18 12:27:03.304: INFO: (9) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 24.322874ms)
Dec 18 12:27:03.320: INFO: (10) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.164598ms)
Dec 18 12:27:03.333: INFO: (11) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.210481ms)
Dec 18 12:27:03.348: INFO: (12) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.212145ms)
Dec 18 12:27:03.363: INFO: (13) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.630147ms)
Dec 18 12:27:03.378: INFO: (14) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.871039ms)
Dec 18 12:27:03.394: INFO: (15) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.332033ms)
Dec 18 12:27:03.408: INFO: (16) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.096778ms)
Dec 18 12:27:03.422: INFO: (17) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.115424ms)
Dec 18 12:27:03.434: INFO: (18) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.665316ms)
Dec 18 12:27:03.447: INFO: (19) /api/v1/nodes/stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.202253ms)
[AfterEach] version v1
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:27:03.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5060" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":273,"completed":127,"skipped":2348,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:27:03.472: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-754
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 18 12:27:03.695: INFO: Waiting up to 5m0s for pod "pod-9ce05224-d073-4c22-8d57-231ebc2667f0" in namespace "emptydir-754" to be "Succeeded or Failed"
Dec 18 12:27:03.702: INFO: Pod "pod-9ce05224-d073-4c22-8d57-231ebc2667f0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.904224ms
Dec 18 12:27:05.709: INFO: Pod "pod-9ce05224-d073-4c22-8d57-231ebc2667f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014261052s
Dec 18 12:27:07.717: INFO: Pod "pod-9ce05224-d073-4c22-8d57-231ebc2667f0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02223388s
Dec 18 12:27:09.726: INFO: Pod "pod-9ce05224-d073-4c22-8d57-231ebc2667f0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031096171s
Dec 18 12:27:11.739: INFO: Pod "pod-9ce05224-d073-4c22-8d57-231ebc2667f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.044407032s
STEP: Saw pod success
Dec 18 12:27:11.739: INFO: Pod "pod-9ce05224-d073-4c22-8d57-231ebc2667f0" satisfied condition "Succeeded or Failed"
Dec 18 12:27:11.748: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-9ce05224-d073-4c22-8d57-231ebc2667f0 container test-container: <nil>
STEP: delete the pod
Dec 18 12:27:11.815: INFO: Waiting for pod pod-9ce05224-d073-4c22-8d57-231ebc2667f0 to disappear
Dec 18 12:27:11.826: INFO: Pod pod-9ce05224-d073-4c22-8d57-231ebc2667f0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:27:11.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-754" for this suite.

• [SLOW TEST:8.387 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":128,"skipped":2384,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:27:11.859: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9106
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Dec 18 12:27:12.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 api-versions'
Dec 18 12:27:12.384: INFO: stderr: ""
Dec 18 12:27:12.384: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncluster.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetakube.syseleven.de/v1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:27:12.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9106" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":273,"completed":129,"skipped":2399,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:27:12.410: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3382
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 18 12:27:12.678: INFO: Waiting up to 5m0s for pod "pod-39c19460-534f-45dc-80d9-aaeb7f86766c" in namespace "emptydir-3382" to be "Succeeded or Failed"
Dec 18 12:27:12.686: INFO: Pod "pod-39c19460-534f-45dc-80d9-aaeb7f86766c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.36546ms
Dec 18 12:27:14.700: INFO: Pod "pod-39c19460-534f-45dc-80d9-aaeb7f86766c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022001156s
Dec 18 12:27:16.709: INFO: Pod "pod-39c19460-534f-45dc-80d9-aaeb7f86766c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030985833s
Dec 18 12:27:18.717: INFO: Pod "pod-39c19460-534f-45dc-80d9-aaeb7f86766c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039170992s
Dec 18 12:27:20.731: INFO: Pod "pod-39c19460-534f-45dc-80d9-aaeb7f86766c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.052917571s
STEP: Saw pod success
Dec 18 12:27:20.731: INFO: Pod "pod-39c19460-534f-45dc-80d9-aaeb7f86766c" satisfied condition "Succeeded or Failed"
Dec 18 12:27:20.740: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-39c19460-534f-45dc-80d9-aaeb7f86766c container test-container: <nil>
STEP: delete the pod
Dec 18 12:27:20.794: INFO: Waiting for pod pod-39c19460-534f-45dc-80d9-aaeb7f86766c to disappear
Dec 18 12:27:20.812: INFO: Pod pod-39c19460-534f-45dc-80d9-aaeb7f86766c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:27:20.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3382" for this suite.

• [SLOW TEST:8.428 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":130,"skipped":2431,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:27:20.838: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-4e9e4ecf-7cae-411c-955f-285becef587d
STEP: Creating a pod to test consume secrets
Dec 18 12:27:21.124: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e622409-aeb5-48ed-b171-01a41e358b4e" in namespace "projected-9691" to be "Succeeded or Failed"
Dec 18 12:27:21.138: INFO: Pod "pod-projected-secrets-1e622409-aeb5-48ed-b171-01a41e358b4e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.083518ms
Dec 18 12:27:23.147: INFO: Pod "pod-projected-secrets-1e622409-aeb5-48ed-b171-01a41e358b4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023210745s
Dec 18 12:27:25.155: INFO: Pod "pod-projected-secrets-1e622409-aeb5-48ed-b171-01a41e358b4e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03097659s
Dec 18 12:27:27.164: INFO: Pod "pod-projected-secrets-1e622409-aeb5-48ed-b171-01a41e358b4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039914732s
STEP: Saw pod success
Dec 18 12:27:27.164: INFO: Pod "pod-projected-secrets-1e622409-aeb5-48ed-b171-01a41e358b4e" satisfied condition "Succeeded or Failed"
Dec 18 12:27:27.171: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-secrets-1e622409-aeb5-48ed-b171-01a41e358b4e container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 18 12:27:27.210: INFO: Waiting for pod pod-projected-secrets-1e622409-aeb5-48ed-b171-01a41e358b4e to disappear
Dec 18 12:27:27.216: INFO: Pod pod-projected-secrets-1e622409-aeb5-48ed-b171-01a41e358b4e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:27:27.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9691" for this suite.

• [SLOW TEST:6.400 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":273,"completed":131,"skipped":2441,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:27:27.238: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6331
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-8be3cab4-4905-4294-a3b8-727791084f86
STEP: Creating a pod to test consume configMaps
Dec 18 12:27:27.455: INFO: Waiting up to 5m0s for pod "pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a" in namespace "configmap-6331" to be "Succeeded or Failed"
Dec 18 12:27:27.463: INFO: Pod "pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.498171ms
Dec 18 12:27:29.471: INFO: Pod "pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014947689s
Dec 18 12:27:31.480: INFO: Pod "pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024198037s
Dec 18 12:27:33.489: INFO: Pod "pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0329602s
Dec 18 12:27:35.502: INFO: Pod "pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.045919371s
STEP: Saw pod success
Dec 18 12:27:35.502: INFO: Pod "pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a" satisfied condition "Succeeded or Failed"
Dec 18 12:27:35.511: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a container configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 12:27:35.581: INFO: Waiting for pod pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a to disappear
Dec 18 12:27:35.599: INFO: Pod pod-configmaps-0fb82592-6163-47fd-ab4c-76091533140a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:27:35.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6331" for this suite.

• [SLOW TEST:8.401 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":273,"completed":132,"skipped":2449,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:27:35.640: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-2gmk
STEP: Creating a pod to test atomic-volume-subpath
Dec 18 12:27:35.913: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2gmk" in namespace "subpath-6960" to be "Succeeded or Failed"
Dec 18 12:27:35.920: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Pending", Reason="", readiness=false. Elapsed: 6.85348ms
Dec 18 12:27:37.929: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016283128s
Dec 18 12:27:39.940: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02714558s
Dec 18 12:27:41.949: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 6.035959004s
Dec 18 12:27:43.979: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 8.066622598s
Dec 18 12:27:45.989: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 10.076181496s
Dec 18 12:27:47.997: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 12.0843271s
Dec 18 12:27:50.028: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 14.115039432s
Dec 18 12:27:52.044: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 16.131561779s
Dec 18 12:27:54.058: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 18.145468987s
Dec 18 12:27:56.087: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 20.17408493s
Dec 18 12:27:58.095: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 22.182097012s
Dec 18 12:28:00.103: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 24.190600675s
Dec 18 12:28:02.115: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Running", Reason="", readiness=true. Elapsed: 26.20202753s
Dec 18 12:28:04.129: INFO: Pod "pod-subpath-test-configmap-2gmk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.21636855s
STEP: Saw pod success
Dec 18 12:28:04.129: INFO: Pod "pod-subpath-test-configmap-2gmk" satisfied condition "Succeeded or Failed"
Dec 18 12:28:04.136: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-subpath-test-configmap-2gmk container test-container-subpath-configmap-2gmk: <nil>
STEP: delete the pod
Dec 18 12:28:04.185: INFO: Waiting for pod pod-subpath-test-configmap-2gmk to disappear
Dec 18 12:28:04.196: INFO: Pod pod-subpath-test-configmap-2gmk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2gmk
Dec 18 12:28:04.196: INFO: Deleting pod "pod-subpath-test-configmap-2gmk" in namespace "subpath-6960"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:28:04.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6960" for this suite.

• [SLOW TEST:28.614 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":273,"completed":133,"skipped":2457,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:28:04.255: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4309
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47
Dec 18 12:28:04.455: INFO: Pod name my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47: Found 0 pods out of 1
Dec 18 12:28:09.464: INFO: Pod name my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47: Found 1 pods out of 1
Dec 18 12:28:09.464: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47" are running
Dec 18 12:28:11.484: INFO: Pod "my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47-z8w95" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-18 12:28:04 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-18 12:28:04 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-18 12:28:04 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-18 12:28:04 +0000 UTC Reason: Message:}])
Dec 18 12:28:11.484: INFO: Trying to dial the pod
Dec 18 12:28:16.605: INFO: Controller my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47: Got expected result from replica 1 [my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47-z8w95]: "my-hostname-basic-6a2970cc-a087-4673-8d73-d51d0a83df47-z8w95", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:28:16.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4309" for this suite.

• [SLOW TEST:12.386 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":273,"completed":134,"skipped":2466,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:28:16.641: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8170
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-nqgw
STEP: Creating a pod to test atomic-volume-subpath
Dec 18 12:28:16.922: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nqgw" in namespace "subpath-8170" to be "Succeeded or Failed"
Dec 18 12:28:16.932: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Pending", Reason="", readiness=false. Elapsed: 10.548347ms
Dec 18 12:28:18.942: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020063037s
Dec 18 12:28:20.950: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028632892s
Dec 18 12:28:22.961: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 6.039072539s
Dec 18 12:28:24.968: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 8.046570236s
Dec 18 12:28:26.979: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 10.057129089s
Dec 18 12:28:28.986: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 12.064459157s
Dec 18 12:28:30.996: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 14.074457634s
Dec 18 12:28:33.005: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 16.083087655s
Dec 18 12:28:35.012: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 18.09031623s
Dec 18 12:28:37.024: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 20.10242835s
Dec 18 12:28:39.034: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 22.11241733s
Dec 18 12:28:41.044: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Running", Reason="", readiness=true. Elapsed: 24.12206832s
Dec 18 12:28:43.055: INFO: Pod "pod-subpath-test-configmap-nqgw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.133013277s
STEP: Saw pod success
Dec 18 12:28:43.055: INFO: Pod "pod-subpath-test-configmap-nqgw" satisfied condition "Succeeded or Failed"
Dec 18 12:28:43.062: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-subpath-test-configmap-nqgw container test-container-subpath-configmap-nqgw: <nil>
STEP: delete the pod
Dec 18 12:28:43.118: INFO: Waiting for pod pod-subpath-test-configmap-nqgw to disappear
Dec 18 12:28:43.125: INFO: Pod pod-subpath-test-configmap-nqgw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nqgw
Dec 18 12:28:43.125: INFO: Deleting pod "pod-subpath-test-configmap-nqgw" in namespace "subpath-8170"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:28:43.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8170" for this suite.

• [SLOW TEST:26.541 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":273,"completed":135,"skipped":2474,"failed":0}
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:28:43.187: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-351
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-351
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-351
Dec 18 12:28:43.444: INFO: Found 0 stateful pods, waiting for 1
Dec 18 12:28:53.455: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 18 12:28:53.518: INFO: Deleting all statefulset in ns statefulset-351
Dec 18 12:28:53.529: INFO: Scaling statefulset ss to 0
Dec 18 12:29:03.672: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 12:29:03.683: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:29:03.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-351" for this suite.

• [SLOW TEST:20.555 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":273,"completed":136,"skipped":2480,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:29:03.744: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8486
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 18 12:29:05.061: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:29:05.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1218 12:29:05.061705      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8486" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":273,"completed":137,"skipped":2521,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:29:05.091: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5526
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:29:05.859: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 12:29:07.884: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:29:09.893: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:29:11.895: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:29:13.896: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891345, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:29:16.929: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:29:17.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5526" for this suite.
STEP: Destroying namespace "webhook-5526-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:12.312 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":273,"completed":138,"skipped":2528,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:29:17.406: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-cabb6138-e099-4208-9e80-a8ce798fe6d7 in namespace container-probe-1588
Dec 18 12:29:23.788: INFO: Started pod liveness-cabb6138-e099-4208-9e80-a8ce798fe6d7 in namespace container-probe-1588
STEP: checking the pod's current state and verifying that restartCount is present
Dec 18 12:29:23.795: INFO: Initial restart count of pod liveness-cabb6138-e099-4208-9e80-a8ce798fe6d7 is 0
Dec 18 12:29:39.874: INFO: Restart count of pod container-probe-1588/liveness-cabb6138-e099-4208-9e80-a8ce798fe6d7 is now 1 (16.079104728s elapsed)
Dec 18 12:29:59.971: INFO: Restart count of pod container-probe-1588/liveness-cabb6138-e099-4208-9e80-a8ce798fe6d7 is now 2 (36.175930847s elapsed)
Dec 18 12:30:22.105: INFO: Restart count of pod container-probe-1588/liveness-cabb6138-e099-4208-9e80-a8ce798fe6d7 is now 3 (58.309655451s elapsed)
Dec 18 12:30:40.467: INFO: Restart count of pod container-probe-1588/liveness-cabb6138-e099-4208-9e80-a8ce798fe6d7 is now 4 (1m16.671917495s elapsed)
Dec 18 12:31:48.968: INFO: Restart count of pod container-probe-1588/liveness-cabb6138-e099-4208-9e80-a8ce798fe6d7 is now 5 (2m25.173453131s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:31:49.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1588" for this suite.

• [SLOW TEST:151.683 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":273,"completed":139,"skipped":2571,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:31:49.090: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3941
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:31:49.813: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 18 12:31:51.842: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891509, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891509, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891509, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891509, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:31:53.850: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891509, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891509, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891509, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891509, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:31:56.879: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:31:57.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3941" for this suite.
STEP: Destroying namespace "webhook-3941-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.137 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":273,"completed":140,"skipped":2574,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:31:57.232: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-459
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 18 12:31:57.425: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 18 12:31:57.494: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:31:59.502: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:32:01.501: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:32:03.503: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:32:05.511: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:32:07.543: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:32:09.504: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:32:11.503: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:32:13.507: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:32:15.501: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:32:17.503: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 18 12:32:17.523: INFO: The status of Pod netserver-1 is Running (Ready = true)
Dec 18 12:32:17.548: INFO: The status of Pod netserver-2 is Running (Ready = false)
Dec 18 12:32:19.556: INFO: The status of Pod netserver-2 is Running (Ready = false)
Dec 18 12:32:21.560: INFO: The status of Pod netserver-2 is Running (Ready = false)
Dec 18 12:32:23.556: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Dec 18 12:32:29.612: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.174:8080/dial?request=hostname&protocol=udp&host=172.25.2.100&port=8081&tries=1'] Namespace:pod-network-test-459 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:32:29.613: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:32:30.029: INFO: Waiting for responses: map[]
Dec 18 12:32:30.035: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.174:8080/dial?request=hostname&protocol=udp&host=172.25.0.52&port=8081&tries=1'] Namespace:pod-network-test-459 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:32:30.036: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:32:30.508: INFO: Waiting for responses: map[]
Dec 18 12:32:30.520: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.1.174:8080/dial?request=hostname&protocol=udp&host=172.25.1.173&port=8081&tries=1'] Namespace:pod-network-test-459 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:32:30.521: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:32:30.952: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:32:30.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-459" for this suite.

• [SLOW TEST:33.743 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":273,"completed":141,"skipped":2610,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:32:30.975: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6512
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:32:31.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6512" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":273,"completed":142,"skipped":2622,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:32:31.504: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4249
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:32:32.481: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 12:32:34.508: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891552, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891552, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891552, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891552, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:32:36.540: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891552, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891552, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891552, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891552, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:32:39.547: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:32:39.559: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:32:41.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4249" for this suite.
STEP: Destroying namespace "webhook-4249-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.770 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":273,"completed":143,"skipped":2649,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:32:41.280: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7550
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:32:41.476: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 18 12:32:45.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7550 create -f -'
Dec 18 12:33:03.181: INFO: stderr: ""
Dec 18 12:33:03.181: INFO: stdout: "e2e-test-crd-publish-openapi-4688-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 18 12:33:03.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7550 delete e2e-test-crd-publish-openapi-4688-crds test-foo'
Dec 18 12:33:03.785: INFO: stderr: ""
Dec 18 12:33:03.785: INFO: stdout: "e2e-test-crd-publish-openapi-4688-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 18 12:33:03.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7550 apply -f -'
Dec 18 12:33:04.169: INFO: stderr: ""
Dec 18 12:33:04.169: INFO: stdout: "e2e-test-crd-publish-openapi-4688-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 18 12:33:04.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7550 delete e2e-test-crd-publish-openapi-4688-crds test-foo'
Dec 18 12:33:04.294: INFO: stderr: ""
Dec 18 12:33:04.294: INFO: stdout: "e2e-test-crd-publish-openapi-4688-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 18 12:33:04.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7550 create -f -'
Dec 18 12:33:04.755: INFO: rc: 1
Dec 18 12:33:04.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7550 apply -f -'
Dec 18 12:33:05.121: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 18 12:33:05.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7550 create -f -'
Dec 18 12:33:05.613: INFO: rc: 1
Dec 18 12:33:05.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-7550 apply -f -'
Dec 18 12:33:06.027: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 18 12:33:06.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 explain e2e-test-crd-publish-openapi-4688-crds'
Dec 18 12:33:06.374: INFO: stderr: ""
Dec 18 12:33:06.374: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4688-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 18 12:33:06.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 explain e2e-test-crd-publish-openapi-4688-crds.metadata'
Dec 18 12:33:06.847: INFO: stderr: ""
Dec 18 12:33:06.847: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4688-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 18 12:33:06.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 explain e2e-test-crd-publish-openapi-4688-crds.spec'
Dec 18 12:33:07.295: INFO: stderr: ""
Dec 18 12:33:07.295: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4688-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 18 12:33:07.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 explain e2e-test-crd-publish-openapi-4688-crds.spec.bars'
Dec 18 12:33:07.719: INFO: stderr: ""
Dec 18 12:33:07.719: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4688-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 18 12:33:07.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 explain e2e-test-crd-publish-openapi-4688-crds.spec.bars2'
Dec 18 12:33:11.020: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:33:14.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7550" for this suite.

• [SLOW TEST:33.535 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":273,"completed":144,"skipped":2651,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:33:14.816: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7472
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 18 12:33:15.044: INFO: Waiting up to 5m0s for pod "downward-api-24ecfb49-4253-449c-b001-d69446f13cf0" in namespace "downward-api-7472" to be "Succeeded or Failed"
Dec 18 12:33:15.058: INFO: Pod "downward-api-24ecfb49-4253-449c-b001-d69446f13cf0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.607694ms
Dec 18 12:33:17.071: INFO: Pod "downward-api-24ecfb49-4253-449c-b001-d69446f13cf0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026593375s
Dec 18 12:33:19.077: INFO: Pod "downward-api-24ecfb49-4253-449c-b001-d69446f13cf0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033263669s
Dec 18 12:33:21.087: INFO: Pod "downward-api-24ecfb49-4253-449c-b001-d69446f13cf0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042593483s
Dec 18 12:33:23.094: INFO: Pod "downward-api-24ecfb49-4253-449c-b001-d69446f13cf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.050349773s
STEP: Saw pod success
Dec 18 12:33:23.094: INFO: Pod "downward-api-24ecfb49-4253-449c-b001-d69446f13cf0" satisfied condition "Succeeded or Failed"
Dec 18 12:33:23.103: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downward-api-24ecfb49-4253-449c-b001-d69446f13cf0 container dapi-container: <nil>
STEP: delete the pod
Dec 18 12:33:23.189: INFO: Waiting for pod downward-api-24ecfb49-4253-449c-b001-d69446f13cf0 to disappear
Dec 18 12:33:23.196: INFO: Pod downward-api-24ecfb49-4253-449c-b001-d69446f13cf0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:33:23.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7472" for this suite.

• [SLOW TEST:8.407 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":273,"completed":145,"skipped":2661,"failed":0}
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:33:23.223: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7560
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-7560/secret-test-0ce2691b-bd84-417c-8a1e-aa291487b54f
STEP: Creating a pod to test consume secrets
Dec 18 12:33:23.450: INFO: Waiting up to 5m0s for pod "pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741" in namespace "secrets-7560" to be "Succeeded or Failed"
Dec 18 12:33:23.459: INFO: Pod "pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741": Phase="Pending", Reason="", readiness=false. Elapsed: 8.914133ms
Dec 18 12:33:25.468: INFO: Pod "pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017982179s
Dec 18 12:33:27.479: INFO: Pod "pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02915439s
Dec 18 12:33:29.485: INFO: Pod "pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035639954s
Dec 18 12:33:31.504: INFO: Pod "pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.054205644s
STEP: Saw pod success
Dec 18 12:33:31.504: INFO: Pod "pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741" satisfied condition "Succeeded or Failed"
Dec 18 12:33:31.511: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741 container env-test: <nil>
STEP: delete the pod
Dec 18 12:33:31.651: INFO: Waiting for pod pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741 to disappear
Dec 18 12:33:31.659: INFO: Pod pod-configmaps-82318af4-e802-4b1d-aa6b-72872be9a741 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:33:31.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7560" for this suite.

• [SLOW TEST:8.471 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:35
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":273,"completed":146,"skipped":2663,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:33:31.707: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3160
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-3160
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-3160
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3160
Dec 18 12:33:31.941: INFO: Found 0 stateful pods, waiting for 1
Dec 18 12:33:41.952: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 18 12:33:41.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-3160 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 12:33:42.508: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 12:33:42.508: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 12:33:42.508: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 18 12:33:42.515: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 18 12:33:52.532: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 18 12:33:52.532: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 12:33:52.717: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999138s
Dec 18 12:33:53.725: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.846486424s
Dec 18 12:33:54.742: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.83832672s
Dec 18 12:33:55.752: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.82210108s
Dec 18 12:33:56.762: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.811272373s
Dec 18 12:33:57.772: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.801583138s
Dec 18 12:33:58.785: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.792061426s
Dec 18 12:33:59.796: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.779102455s
Dec 18 12:34:00.804: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.76764033s
Dec 18 12:34:01.816: INFO: Verifying statefulset ss doesn't scale past 1 for another 759.712339ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3160
Dec 18 12:34:02.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-3160 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 12:34:03.360: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 18 12:34:03.361: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 18 12:34:03.361: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 18 12:34:03.378: INFO: Found 1 stateful pods, waiting for 3
Dec 18 12:34:13.389: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:34:13.389: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:34:13.389: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=false
Dec 18 12:34:23.395: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:34:23.395: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:34:23.395: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 18 12:34:23.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-3160 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 12:34:23.836: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 12:34:23.836: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 12:34:23.836: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 18 12:34:23.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-3160 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 12:34:24.317: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 12:34:24.317: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 12:34:24.317: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 18 12:34:24.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-3160 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 12:34:24.822: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 12:34:24.822: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 12:34:24.822: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 18 12:34:24.822: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 12:34:24.829: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 18 12:34:34.909: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 18 12:34:34.909: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 18 12:34:34.909: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 18 12:34:35.136: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998968s
Dec 18 12:34:36.146: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98976694s
Dec 18 12:34:37.155: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979732112s
Dec 18 12:34:38.164: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.971042379s
Dec 18 12:34:39.176: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.961885444s
Dec 18 12:34:40.269: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.950497952s
Dec 18 12:34:41.283: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.856935335s
Dec 18 12:34:42.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.842577161s
Dec 18 12:34:43.313: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.823050705s
Dec 18 12:34:44.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 812.631819ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3160
Dec 18 12:34:45.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-3160 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 12:34:45.796: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 18 12:34:45.796: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 18 12:34:45.796: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 18 12:34:45.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-3160 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 12:34:46.227: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 18 12:34:46.227: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 18 12:34:46.227: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 18 12:34:46.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-3160 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 12:34:46.708: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 18 12:34:46.708: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 18 12:34:46.708: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 18 12:34:46.708: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 18 12:35:06.751: INFO: Deleting all statefulset in ns statefulset-3160
Dec 18 12:35:06.759: INFO: Scaling statefulset ss to 0
Dec 18 12:35:06.782: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 12:35:06.788: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:35:06.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3160" for this suite.

• [SLOW TEST:95.141 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":273,"completed":147,"skipped":2701,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:35:06.850: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3116
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Dec 18 12:35:07.056: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:35:29.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3116" for this suite.

• [SLOW TEST:22.672 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":273,"completed":148,"skipped":2716,"failed":0}
SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:35:29.523: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6457
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 18 12:35:29.756: INFO: Waiting up to 5m0s for pod "downward-api-05fd6248-efe5-418f-b599-64f6a3fdd2ea" in namespace "downward-api-6457" to be "Succeeded or Failed"
Dec 18 12:35:29.762: INFO: Pod "downward-api-05fd6248-efe5-418f-b599-64f6a3fdd2ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.567048ms
Dec 18 12:35:31.772: INFO: Pod "downward-api-05fd6248-efe5-418f-b599-64f6a3fdd2ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015824892s
Dec 18 12:35:33.780: INFO: Pod "downward-api-05fd6248-efe5-418f-b599-64f6a3fdd2ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023825657s
Dec 18 12:35:35.789: INFO: Pod "downward-api-05fd6248-efe5-418f-b599-64f6a3fdd2ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033164365s
STEP: Saw pod success
Dec 18 12:35:35.790: INFO: Pod "downward-api-05fd6248-efe5-418f-b599-64f6a3fdd2ea" satisfied condition "Succeeded or Failed"
Dec 18 12:35:35.796: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downward-api-05fd6248-efe5-418f-b599-64f6a3fdd2ea container dapi-container: <nil>
STEP: delete the pod
Dec 18 12:35:35.862: INFO: Waiting for pod downward-api-05fd6248-efe5-418f-b599-64f6a3fdd2ea to disappear
Dec 18 12:35:35.868: INFO: Pod downward-api-05fd6248-efe5-418f-b599-64f6a3fdd2ea no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:35:35.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6457" for this suite.

• [SLOW TEST:6.368 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":273,"completed":149,"skipped":2720,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:35:35.893: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2625
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-f1380e76-3609-4a25-a63e-ee413259a721
STEP: Creating a pod to test consume configMaps
Dec 18 12:35:36.160: INFO: Waiting up to 5m0s for pod "pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32" in namespace "configmap-2625" to be "Succeeded or Failed"
Dec 18 12:35:36.173: INFO: Pod "pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32": Phase="Pending", Reason="", readiness=false. Elapsed: 13.089825ms
Dec 18 12:35:38.182: INFO: Pod "pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022054428s
Dec 18 12:35:40.190: INFO: Pod "pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030569782s
Dec 18 12:35:42.198: INFO: Pod "pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038836903s
Dec 18 12:35:44.207: INFO: Pod "pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047138467s
Dec 18 12:35:46.220: INFO: Pod "pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.060427657s
STEP: Saw pod success
Dec 18 12:35:46.220: INFO: Pod "pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32" satisfied condition "Succeeded or Failed"
Dec 18 12:35:46.228: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 12:35:46.273: INFO: Waiting for pod pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32 to disappear
Dec 18 12:35:46.279: INFO: Pod pod-configmaps-3268e653-22ab-49c0-b2ba-a5b1e404ea32 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:35:46.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2625" for this suite.

• [SLOW TEST:10.409 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":150,"skipped":2750,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:35:46.304: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8917
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:35:47.158: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 12:35:49.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891747, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891747, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891747, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891747, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:35:51.210: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891747, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891747, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891747, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891747, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:35:54.249: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:35:54.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8917" for this suite.
STEP: Destroying namespace "webhook-8917-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.631 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":273,"completed":151,"skipped":2779,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:35:54.943: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6237
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-b519714d-3cfe-421c-978b-e8791379eb6d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b519714d-3cfe-421c-978b-e8791379eb6d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:36:05.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6237" for this suite.

• [SLOW TEST:10.692 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":152,"skipped":2800,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:36:05.638: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-7027
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:36:06.037: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7027
I1218 12:36:06.091984      21 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7027, replica count: 1
I1218 12:36:07.143229      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 12:36:08.143588      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 12:36:09.143950      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 12:36:10.144342      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 12:36:11.144761      21 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 18 12:36:11.292: INFO: Created: latency-svc-vbtjx
Dec 18 12:36:11.311: INFO: Got endpoints: latency-svc-vbtjx [65.869681ms]
Dec 18 12:36:11.352: INFO: Created: latency-svc-bckz2
Dec 18 12:36:11.370: INFO: Got endpoints: latency-svc-bckz2 [59.287362ms]
Dec 18 12:36:11.371: INFO: Created: latency-svc-424s5
Dec 18 12:36:11.380: INFO: Got endpoints: latency-svc-424s5 [68.582161ms]
Dec 18 12:36:11.386: INFO: Created: latency-svc-5v7md
Dec 18 12:36:11.400: INFO: Got endpoints: latency-svc-5v7md [88.389818ms]
Dec 18 12:36:11.404: INFO: Created: latency-svc-z89zp
Dec 18 12:36:11.411: INFO: Created: latency-svc-v7wv7
Dec 18 12:36:11.416: INFO: Got endpoints: latency-svc-z89zp [104.084987ms]
Dec 18 12:36:11.427: INFO: Got endpoints: latency-svc-v7wv7 [115.453198ms]
Dec 18 12:36:11.428: INFO: Created: latency-svc-zj8cs
Dec 18 12:36:11.437: INFO: Got endpoints: latency-svc-zj8cs [125.099289ms]
Dec 18 12:36:11.444: INFO: Created: latency-svc-sg7p4
Dec 18 12:36:11.455: INFO: Created: latency-svc-24vfl
Dec 18 12:36:11.459: INFO: Got endpoints: latency-svc-sg7p4 [146.558984ms]
Dec 18 12:36:11.478: INFO: Created: latency-svc-5h9gr
Dec 18 12:36:11.480: INFO: Got endpoints: latency-svc-24vfl [167.844407ms]
Dec 18 12:36:11.483: INFO: Created: latency-svc-nvqnf
Dec 18 12:36:11.495: INFO: Got endpoints: latency-svc-5h9gr [183.12383ms]
Dec 18 12:36:11.501: INFO: Created: latency-svc-fkmn6
Dec 18 12:36:11.502: INFO: Got endpoints: latency-svc-nvqnf [43.496718ms]
Dec 18 12:36:11.513: INFO: Got endpoints: latency-svc-fkmn6 [200.617168ms]
Dec 18 12:36:11.517: INFO: Created: latency-svc-6gv5x
Dec 18 12:36:11.532: INFO: Created: latency-svc-xx745
Dec 18 12:36:11.543: INFO: Got endpoints: latency-svc-xx745 [230.67566ms]
Dec 18 12:36:11.548: INFO: Created: latency-svc-qqwps
Dec 18 12:36:11.548: INFO: Got endpoints: latency-svc-6gv5x [236.109916ms]
Dec 18 12:36:11.563: INFO: Got endpoints: latency-svc-qqwps [250.360072ms]
Dec 18 12:36:11.567: INFO: Created: latency-svc-cvs7d
Dec 18 12:36:11.579: INFO: Got endpoints: latency-svc-cvs7d [266.515419ms]
Dec 18 12:36:11.590: INFO: Created: latency-svc-5z7t2
Dec 18 12:36:11.602: INFO: Created: latency-svc-2g9hd
Dec 18 12:36:11.618: INFO: Got endpoints: latency-svc-5z7t2 [306.215863ms]
Dec 18 12:36:11.634: INFO: Got endpoints: latency-svc-2g9hd [263.497989ms]
Dec 18 12:36:11.643: INFO: Created: latency-svc-6pvjt
Dec 18 12:36:11.662: INFO: Created: latency-svc-rpxhr
Dec 18 12:36:11.663: INFO: Got endpoints: latency-svc-6pvjt [282.346522ms]
Dec 18 12:36:11.672: INFO: Got endpoints: latency-svc-rpxhr [271.508728ms]
Dec 18 12:36:11.676: INFO: Created: latency-svc-kzr9t
Dec 18 12:36:11.692: INFO: Got endpoints: latency-svc-kzr9t [276.053498ms]
Dec 18 12:36:11.697: INFO: Created: latency-svc-7jpx2
Dec 18 12:36:11.717: INFO: Got endpoints: latency-svc-7jpx2 [290.428168ms]
Dec 18 12:36:11.725: INFO: Created: latency-svc-jmtfj
Dec 18 12:36:11.740: INFO: Created: latency-svc-8dtb6
Dec 18 12:36:11.740: INFO: Got endpoints: latency-svc-jmtfj [302.485526ms]
Dec 18 12:36:11.757: INFO: Got endpoints: latency-svc-8dtb6 [277.072634ms]
Dec 18 12:36:11.759: INFO: Created: latency-svc-zghr8
Dec 18 12:36:11.771: INFO: Got endpoints: latency-svc-zghr8 [276.117353ms]
Dec 18 12:36:11.777: INFO: Created: latency-svc-x9864
Dec 18 12:36:11.800: INFO: Created: latency-svc-dpzs5
Dec 18 12:36:11.803: INFO: Got endpoints: latency-svc-x9864 [300.515436ms]
Dec 18 12:36:11.817: INFO: Got endpoints: latency-svc-dpzs5 [304.244857ms]
Dec 18 12:36:11.829: INFO: Created: latency-svc-dbv7c
Dec 18 12:36:11.833: INFO: Created: latency-svc-l47st
Dec 18 12:36:11.839: INFO: Got endpoints: latency-svc-dbv7c [296.492754ms]
Dec 18 12:36:11.848: INFO: Got endpoints: latency-svc-l47st [299.769956ms]
Dec 18 12:36:11.850: INFO: Created: latency-svc-4lccw
Dec 18 12:36:11.877: INFO: Got endpoints: latency-svc-4lccw [314.802308ms]
Dec 18 12:36:11.878: INFO: Created: latency-svc-zdxx8
Dec 18 12:36:11.888: INFO: Got endpoints: latency-svc-zdxx8 [309.316408ms]
Dec 18 12:36:11.893: INFO: Created: latency-svc-nldng
Dec 18 12:36:11.910: INFO: Created: latency-svc-5j8cf
Dec 18 12:36:11.910: INFO: Got endpoints: latency-svc-nldng [291.87551ms]
Dec 18 12:36:11.928: INFO: Got endpoints: latency-svc-5j8cf [294.254029ms]
Dec 18 12:36:11.936: INFO: Created: latency-svc-ns9cl
Dec 18 12:36:11.948: INFO: Got endpoints: latency-svc-ns9cl [285.352401ms]
Dec 18 12:36:11.950: INFO: Created: latency-svc-8pbmk
Dec 18 12:36:11.960: INFO: Created: latency-svc-q7nf4
Dec 18 12:36:11.972: INFO: Got endpoints: latency-svc-8pbmk [300.104952ms]
Dec 18 12:36:11.975: INFO: Got endpoints: latency-svc-q7nf4 [283.052269ms]
Dec 18 12:36:11.981: INFO: Created: latency-svc-mp9t8
Dec 18 12:36:11.995: INFO: Created: latency-svc-8c9zb
Dec 18 12:36:11.996: INFO: Got endpoints: latency-svc-mp9t8 [278.823903ms]
Dec 18 12:36:12.006: INFO: Got endpoints: latency-svc-8c9zb [266.4224ms]
Dec 18 12:36:12.010: INFO: Created: latency-svc-rb8m5
Dec 18 12:36:12.030: INFO: Got endpoints: latency-svc-rb8m5 [273.17348ms]
Dec 18 12:36:12.046: INFO: Created: latency-svc-wqm2x
Dec 18 12:36:12.061: INFO: Got endpoints: latency-svc-wqm2x [289.486742ms]
Dec 18 12:36:12.062: INFO: Created: latency-svc-jrlb9
Dec 18 12:36:12.071: INFO: Got endpoints: latency-svc-jrlb9 [268.310104ms]
Dec 18 12:36:12.076: INFO: Created: latency-svc-pr7w2
Dec 18 12:36:12.089: INFO: Got endpoints: latency-svc-pr7w2 [271.6208ms]
Dec 18 12:36:12.104: INFO: Created: latency-svc-pc8jt
Dec 18 12:36:12.132: INFO: Got endpoints: latency-svc-pc8jt [292.977049ms]
Dec 18 12:36:12.134: INFO: Created: latency-svc-s269d
Dec 18 12:36:12.148: INFO: Created: latency-svc-q7s4v
Dec 18 12:36:12.148: INFO: Got endpoints: latency-svc-s269d [300.052727ms]
Dec 18 12:36:12.161: INFO: Got endpoints: latency-svc-q7s4v [283.943978ms]
Dec 18 12:36:12.166: INFO: Created: latency-svc-cz2bf
Dec 18 12:36:12.174: INFO: Created: latency-svc-58xr9
Dec 18 12:36:12.176: INFO: Got endpoints: latency-svc-cz2bf [287.698936ms]
Dec 18 12:36:12.183: INFO: Created: latency-svc-knb8p
Dec 18 12:36:12.184: INFO: Got endpoints: latency-svc-58xr9 [273.55581ms]
Dec 18 12:36:12.196: INFO: Created: latency-svc-7v7xg
Dec 18 12:36:12.205: INFO: Created: latency-svc-7c8xj
Dec 18 12:36:12.218: INFO: Got endpoints: latency-svc-knb8p [289.744684ms]
Dec 18 12:36:12.219: INFO: Created: latency-svc-jq4nf
Dec 18 12:36:12.242: INFO: Created: latency-svc-v78ff
Dec 18 12:36:12.250: INFO: Created: latency-svc-x8wvn
Dec 18 12:36:12.263: INFO: Created: latency-svc-5qx72
Dec 18 12:36:12.268: INFO: Got endpoints: latency-svc-7v7xg [319.869081ms]
Dec 18 12:36:12.280: INFO: Created: latency-svc-fwh5g
Dec 18 12:36:12.297: INFO: Created: latency-svc-bwlg7
Dec 18 12:36:12.313: INFO: Created: latency-svc-249lf
Dec 18 12:36:12.315: INFO: Got endpoints: latency-svc-7c8xj [342.828081ms]
Dec 18 12:36:12.320: INFO: Created: latency-svc-cnkl6
Dec 18 12:36:12.332: INFO: Created: latency-svc-csns8
Dec 18 12:36:12.345: INFO: Created: latency-svc-h69ns
Dec 18 12:36:12.365: INFO: Created: latency-svc-n8dtj
Dec 18 12:36:12.377: INFO: Got endpoints: latency-svc-jq4nf [401.684486ms]
Dec 18 12:36:12.393: INFO: Created: latency-svc-wz9z6
Dec 18 12:36:12.397: INFO: Created: latency-svc-79wth
Dec 18 12:36:12.414: INFO: Got endpoints: latency-svc-v78ff [418.201338ms]
Dec 18 12:36:12.423: INFO: Created: latency-svc-nsz7s
Dec 18 12:36:12.435: INFO: Created: latency-svc-v6gvq
Dec 18 12:36:12.446: INFO: Created: latency-svc-mc7bq
Dec 18 12:36:12.460: INFO: Created: latency-svc-h6r2n
Dec 18 12:36:12.466: INFO: Got endpoints: latency-svc-x8wvn [460.051125ms]
Dec 18 12:36:12.501: INFO: Created: latency-svc-rk54m
Dec 18 12:36:12.515: INFO: Got endpoints: latency-svc-5qx72 [484.884075ms]
Dec 18 12:36:12.542: INFO: Created: latency-svc-5xkfw
Dec 18 12:36:12.565: INFO: Got endpoints: latency-svc-fwh5g [504.294412ms]
Dec 18 12:36:12.586: INFO: Created: latency-svc-2c46r
Dec 18 12:36:12.615: INFO: Got endpoints: latency-svc-bwlg7 [543.464158ms]
Dec 18 12:36:12.638: INFO: Created: latency-svc-wwh5h
Dec 18 12:36:12.668: INFO: Got endpoints: latency-svc-249lf [578.959033ms]
Dec 18 12:36:12.693: INFO: Created: latency-svc-9rfft
Dec 18 12:36:12.725: INFO: Got endpoints: latency-svc-cnkl6 [592.054921ms]
Dec 18 12:36:12.745: INFO: Created: latency-svc-fgxxp
Dec 18 12:36:12.766: INFO: Got endpoints: latency-svc-csns8 [617.476258ms]
Dec 18 12:36:12.791: INFO: Created: latency-svc-xhgvx
Dec 18 12:36:12.823: INFO: Got endpoints: latency-svc-h69ns [661.674425ms]
Dec 18 12:36:12.843: INFO: Created: latency-svc-tjq28
Dec 18 12:36:12.864: INFO: Got endpoints: latency-svc-n8dtj [688.064472ms]
Dec 18 12:36:12.891: INFO: Created: latency-svc-mtmnh
Dec 18 12:36:12.915: INFO: Got endpoints: latency-svc-wz9z6 [730.99241ms]
Dec 18 12:36:12.946: INFO: Created: latency-svc-zb7sr
Dec 18 12:36:12.963: INFO: Got endpoints: latency-svc-79wth [745.160447ms]
Dec 18 12:36:12.986: INFO: Created: latency-svc-vgrts
Dec 18 12:36:13.014: INFO: Got endpoints: latency-svc-nsz7s [745.718093ms]
Dec 18 12:36:13.036: INFO: Created: latency-svc-mhkww
Dec 18 12:36:13.068: INFO: Got endpoints: latency-svc-v6gvq [752.547599ms]
Dec 18 12:36:13.099: INFO: Created: latency-svc-gdj4c
Dec 18 12:36:13.117: INFO: Got endpoints: latency-svc-mc7bq [739.962469ms]
Dec 18 12:36:13.141: INFO: Created: latency-svc-j7ls8
Dec 18 12:36:13.165: INFO: Got endpoints: latency-svc-h6r2n [750.768528ms]
Dec 18 12:36:13.195: INFO: Created: latency-svc-z5dp5
Dec 18 12:36:13.216: INFO: Got endpoints: latency-svc-rk54m [749.728645ms]
Dec 18 12:36:13.255: INFO: Created: latency-svc-9gvmq
Dec 18 12:36:13.266: INFO: Got endpoints: latency-svc-5xkfw [751.023997ms]
Dec 18 12:36:13.299: INFO: Created: latency-svc-2m7sg
Dec 18 12:36:13.314: INFO: Got endpoints: latency-svc-2c46r [748.603956ms]
Dec 18 12:36:13.340: INFO: Created: latency-svc-lxff4
Dec 18 12:36:13.366: INFO: Got endpoints: latency-svc-wwh5h [751.142317ms]
Dec 18 12:36:13.390: INFO: Created: latency-svc-t2fmf
Dec 18 12:36:13.414: INFO: Got endpoints: latency-svc-9rfft [745.757147ms]
Dec 18 12:36:13.438: INFO: Created: latency-svc-vr5tv
Dec 18 12:36:13.463: INFO: Got endpoints: latency-svc-fgxxp [738.898119ms]
Dec 18 12:36:13.490: INFO: Created: latency-svc-w5svn
Dec 18 12:36:13.516: INFO: Got endpoints: latency-svc-xhgvx [749.438356ms]
Dec 18 12:36:13.554: INFO: Created: latency-svc-s9g98
Dec 18 12:36:13.568: INFO: Got endpoints: latency-svc-tjq28 [744.369468ms]
Dec 18 12:36:13.600: INFO: Created: latency-svc-jbm52
Dec 18 12:36:13.612: INFO: Got endpoints: latency-svc-mtmnh [747.819345ms]
Dec 18 12:36:13.639: INFO: Created: latency-svc-gdm7r
Dec 18 12:36:13.666: INFO: Got endpoints: latency-svc-zb7sr [750.693561ms]
Dec 18 12:36:13.690: INFO: Created: latency-svc-mqpkh
Dec 18 12:36:13.715: INFO: Got endpoints: latency-svc-vgrts [751.725934ms]
Dec 18 12:36:13.750: INFO: Created: latency-svc-phw8n
Dec 18 12:36:13.763: INFO: Got endpoints: latency-svc-mhkww [748.527111ms]
Dec 18 12:36:13.790: INFO: Created: latency-svc-wf9g6
Dec 18 12:36:13.814: INFO: Got endpoints: latency-svc-gdj4c [746.419236ms]
Dec 18 12:36:13.837: INFO: Created: latency-svc-cbwzg
Dec 18 12:36:13.867: INFO: Got endpoints: latency-svc-j7ls8 [750.136822ms]
Dec 18 12:36:13.892: INFO: Created: latency-svc-9l54h
Dec 18 12:36:13.922: INFO: Got endpoints: latency-svc-z5dp5 [756.902984ms]
Dec 18 12:36:13.944: INFO: Created: latency-svc-hvwqh
Dec 18 12:36:13.972: INFO: Got endpoints: latency-svc-9gvmq [756.121781ms]
Dec 18 12:36:13.995: INFO: Created: latency-svc-spjq9
Dec 18 12:36:14.019: INFO: Got endpoints: latency-svc-2m7sg [753.286348ms]
Dec 18 12:36:14.045: INFO: Created: latency-svc-478dl
Dec 18 12:36:14.065: INFO: Got endpoints: latency-svc-lxff4 [751.200769ms]
Dec 18 12:36:14.086: INFO: Created: latency-svc-29w67
Dec 18 12:36:14.121: INFO: Got endpoints: latency-svc-t2fmf [754.817411ms]
Dec 18 12:36:14.149: INFO: Created: latency-svc-zxf6q
Dec 18 12:36:14.165: INFO: Got endpoints: latency-svc-vr5tv [751.69488ms]
Dec 18 12:36:14.190: INFO: Created: latency-svc-lc7rc
Dec 18 12:36:14.222: INFO: Got endpoints: latency-svc-w5svn [758.903541ms]
Dec 18 12:36:14.245: INFO: Created: latency-svc-96zlg
Dec 18 12:36:14.266: INFO: Got endpoints: latency-svc-s9g98 [750.556695ms]
Dec 18 12:36:14.291: INFO: Created: latency-svc-kqg4b
Dec 18 12:36:14.316: INFO: Got endpoints: latency-svc-jbm52 [748.239189ms]
Dec 18 12:36:14.342: INFO: Created: latency-svc-vpjhh
Dec 18 12:36:14.368: INFO: Got endpoints: latency-svc-gdm7r [755.975435ms]
Dec 18 12:36:14.391: INFO: Created: latency-svc-7rnrs
Dec 18 12:36:14.417: INFO: Got endpoints: latency-svc-mqpkh [750.719302ms]
Dec 18 12:36:14.445: INFO: Created: latency-svc-5pcft
Dec 18 12:36:14.469: INFO: Got endpoints: latency-svc-phw8n [754.172819ms]
Dec 18 12:36:14.503: INFO: Created: latency-svc-lhrv8
Dec 18 12:36:14.523: INFO: Got endpoints: latency-svc-wf9g6 [760.28312ms]
Dec 18 12:36:14.550: INFO: Created: latency-svc-dq2ql
Dec 18 12:36:14.562: INFO: Got endpoints: latency-svc-cbwzg [747.984981ms]
Dec 18 12:36:14.581: INFO: Created: latency-svc-q7c4l
Dec 18 12:36:14.616: INFO: Got endpoints: latency-svc-9l54h [748.790241ms]
Dec 18 12:36:14.641: INFO: Created: latency-svc-vh75f
Dec 18 12:36:14.670: INFO: Got endpoints: latency-svc-hvwqh [747.332482ms]
Dec 18 12:36:14.703: INFO: Created: latency-svc-fltzt
Dec 18 12:36:14.714: INFO: Got endpoints: latency-svc-spjq9 [741.855559ms]
Dec 18 12:36:14.731: INFO: Created: latency-svc-n76mz
Dec 18 12:36:14.769: INFO: Got endpoints: latency-svc-478dl [749.594333ms]
Dec 18 12:36:14.791: INFO: Created: latency-svc-5vgh7
Dec 18 12:36:14.817: INFO: Got endpoints: latency-svc-29w67 [750.959294ms]
Dec 18 12:36:14.837: INFO: Created: latency-svc-6qkkp
Dec 18 12:36:14.865: INFO: Got endpoints: latency-svc-zxf6q [744.074349ms]
Dec 18 12:36:14.887: INFO: Created: latency-svc-lhdzq
Dec 18 12:36:14.916: INFO: Got endpoints: latency-svc-lc7rc [750.77892ms]
Dec 18 12:36:14.935: INFO: Created: latency-svc-5lgkp
Dec 18 12:36:14.985: INFO: Got endpoints: latency-svc-96zlg [762.395147ms]
Dec 18 12:36:15.013: INFO: Created: latency-svc-dh5ct
Dec 18 12:36:15.026: INFO: Got endpoints: latency-svc-kqg4b [759.954509ms]
Dec 18 12:36:15.045: INFO: Created: latency-svc-g592w
Dec 18 12:36:15.066: INFO: Got endpoints: latency-svc-vpjhh [749.515203ms]
Dec 18 12:36:15.097: INFO: Created: latency-svc-8kjq9
Dec 18 12:36:15.113: INFO: Got endpoints: latency-svc-7rnrs [744.94103ms]
Dec 18 12:36:15.134: INFO: Created: latency-svc-2k24q
Dec 18 12:36:15.164: INFO: Got endpoints: latency-svc-5pcft [746.57295ms]
Dec 18 12:36:15.183: INFO: Created: latency-svc-g9t8j
Dec 18 12:36:15.216: INFO: Got endpoints: latency-svc-lhrv8 [746.391235ms]
Dec 18 12:36:15.240: INFO: Created: latency-svc-mrmn5
Dec 18 12:36:15.264: INFO: Got endpoints: latency-svc-dq2ql [740.495495ms]
Dec 18 12:36:15.298: INFO: Created: latency-svc-klzdp
Dec 18 12:36:15.315: INFO: Got endpoints: latency-svc-q7c4l [752.442759ms]
Dec 18 12:36:15.334: INFO: Created: latency-svc-5q9mv
Dec 18 12:36:15.369: INFO: Got endpoints: latency-svc-vh75f [750.543598ms]
Dec 18 12:36:15.395: INFO: Created: latency-svc-tk872
Dec 18 12:36:15.416: INFO: Got endpoints: latency-svc-fltzt [746.140016ms]
Dec 18 12:36:15.433: INFO: Created: latency-svc-fhrkm
Dec 18 12:36:15.463: INFO: Got endpoints: latency-svc-n76mz [748.792805ms]
Dec 18 12:36:15.491: INFO: Created: latency-svc-crw4h
Dec 18 12:36:15.517: INFO: Got endpoints: latency-svc-5vgh7 [748.327694ms]
Dec 18 12:36:15.544: INFO: Created: latency-svc-mshr9
Dec 18 12:36:15.566: INFO: Got endpoints: latency-svc-6qkkp [749.008807ms]
Dec 18 12:36:15.586: INFO: Created: latency-svc-dds7h
Dec 18 12:36:15.615: INFO: Got endpoints: latency-svc-lhdzq [749.605109ms]
Dec 18 12:36:15.630: INFO: Created: latency-svc-fjxxq
Dec 18 12:36:15.666: INFO: Got endpoints: latency-svc-5lgkp [749.861468ms]
Dec 18 12:36:15.687: INFO: Created: latency-svc-7frpp
Dec 18 12:36:15.719: INFO: Got endpoints: latency-svc-dh5ct [733.873314ms]
Dec 18 12:36:15.739: INFO: Created: latency-svc-pzlfc
Dec 18 12:36:15.764: INFO: Got endpoints: latency-svc-g592w [737.586195ms]
Dec 18 12:36:15.783: INFO: Created: latency-svc-7wzhg
Dec 18 12:36:15.821: INFO: Got endpoints: latency-svc-8kjq9 [755.247752ms]
Dec 18 12:36:15.845: INFO: Created: latency-svc-bxcqk
Dec 18 12:36:15.864: INFO: Got endpoints: latency-svc-2k24q [750.909842ms]
Dec 18 12:36:15.882: INFO: Created: latency-svc-gj6fn
Dec 18 12:36:15.925: INFO: Got endpoints: latency-svc-g9t8j [761.136457ms]
Dec 18 12:36:15.944: INFO: Created: latency-svc-ztdkp
Dec 18 12:36:15.966: INFO: Got endpoints: latency-svc-mrmn5 [750.317538ms]
Dec 18 12:36:15.989: INFO: Created: latency-svc-l55kq
Dec 18 12:36:16.014: INFO: Got endpoints: latency-svc-klzdp [750.302682ms]
Dec 18 12:36:16.036: INFO: Created: latency-svc-vmj66
Dec 18 12:36:16.064: INFO: Got endpoints: latency-svc-5q9mv [749.094481ms]
Dec 18 12:36:16.085: INFO: Created: latency-svc-9fhvb
Dec 18 12:36:16.114: INFO: Got endpoints: latency-svc-tk872 [744.444159ms]
Dec 18 12:36:16.146: INFO: Created: latency-svc-dgmwb
Dec 18 12:36:16.167: INFO: Got endpoints: latency-svc-fhrkm [751.407982ms]
Dec 18 12:36:16.191: INFO: Created: latency-svc-985w9
Dec 18 12:36:16.215: INFO: Got endpoints: latency-svc-crw4h [751.622164ms]
Dec 18 12:36:16.237: INFO: Created: latency-svc-md4c4
Dec 18 12:36:16.273: INFO: Got endpoints: latency-svc-mshr9 [755.180108ms]
Dec 18 12:36:16.297: INFO: Created: latency-svc-87hfw
Dec 18 12:36:16.320: INFO: Got endpoints: latency-svc-dds7h [754.178803ms]
Dec 18 12:36:16.371: INFO: Created: latency-svc-ppm4f
Dec 18 12:36:16.371: INFO: Got endpoints: latency-svc-fjxxq [755.949763ms]
Dec 18 12:36:16.396: INFO: Created: latency-svc-94j67
Dec 18 12:36:16.414: INFO: Got endpoints: latency-svc-7frpp [748.254436ms]
Dec 18 12:36:16.441: INFO: Created: latency-svc-zs955
Dec 18 12:36:16.467: INFO: Got endpoints: latency-svc-pzlfc [747.589086ms]
Dec 18 12:36:16.498: INFO: Created: latency-svc-gcbcp
Dec 18 12:36:16.521: INFO: Got endpoints: latency-svc-7wzhg [756.68289ms]
Dec 18 12:36:16.542: INFO: Created: latency-svc-5xh7s
Dec 18 12:36:16.570: INFO: Got endpoints: latency-svc-bxcqk [748.693062ms]
Dec 18 12:36:16.595: INFO: Created: latency-svc-z4qdk
Dec 18 12:36:16.618: INFO: Got endpoints: latency-svc-gj6fn [754.05023ms]
Dec 18 12:36:16.637: INFO: Created: latency-svc-rxcmf
Dec 18 12:36:16.666: INFO: Got endpoints: latency-svc-ztdkp [741.212798ms]
Dec 18 12:36:16.690: INFO: Created: latency-svc-b8rfc
Dec 18 12:36:16.716: INFO: Got endpoints: latency-svc-l55kq [749.424078ms]
Dec 18 12:36:16.748: INFO: Created: latency-svc-zfj5w
Dec 18 12:36:16.763: INFO: Got endpoints: latency-svc-vmj66 [748.599005ms]
Dec 18 12:36:16.780: INFO: Created: latency-svc-549mr
Dec 18 12:36:16.814: INFO: Got endpoints: latency-svc-9fhvb [750.172283ms]
Dec 18 12:36:16.837: INFO: Created: latency-svc-6dzj6
Dec 18 12:36:16.866: INFO: Got endpoints: latency-svc-dgmwb [751.738004ms]
Dec 18 12:36:16.891: INFO: Created: latency-svc-tf75b
Dec 18 12:36:16.914: INFO: Got endpoints: latency-svc-985w9 [746.318622ms]
Dec 18 12:36:16.932: INFO: Created: latency-svc-kdcrh
Dec 18 12:36:16.965: INFO: Got endpoints: latency-svc-md4c4 [750.258578ms]
Dec 18 12:36:16.983: INFO: Created: latency-svc-m6cxf
Dec 18 12:36:17.014: INFO: Got endpoints: latency-svc-87hfw [740.39303ms]
Dec 18 12:36:17.063: INFO: Created: latency-svc-wlzjk
Dec 18 12:36:17.094: INFO: Got endpoints: latency-svc-ppm4f [774.025329ms]
Dec 18 12:36:17.117: INFO: Created: latency-svc-tpzzf
Dec 18 12:36:17.118: INFO: Got endpoints: latency-svc-94j67 [746.708534ms]
Dec 18 12:36:17.138: INFO: Created: latency-svc-tmgq4
Dec 18 12:36:17.171: INFO: Got endpoints: latency-svc-zs955 [756.276305ms]
Dec 18 12:36:17.195: INFO: Created: latency-svc-ms2kr
Dec 18 12:36:17.225: INFO: Got endpoints: latency-svc-gcbcp [757.931426ms]
Dec 18 12:36:17.245: INFO: Created: latency-svc-vvkw6
Dec 18 12:36:17.263: INFO: Got endpoints: latency-svc-5xh7s [742.002538ms]
Dec 18 12:36:17.282: INFO: Created: latency-svc-p4gts
Dec 18 12:36:17.321: INFO: Got endpoints: latency-svc-z4qdk [751.320114ms]
Dec 18 12:36:17.361: INFO: Created: latency-svc-8cz94
Dec 18 12:36:17.372: INFO: Got endpoints: latency-svc-rxcmf [753.50844ms]
Dec 18 12:36:17.400: INFO: Created: latency-svc-tzpdx
Dec 18 12:36:17.415: INFO: Got endpoints: latency-svc-b8rfc [748.315013ms]
Dec 18 12:36:17.443: INFO: Created: latency-svc-6bv26
Dec 18 12:36:17.470: INFO: Got endpoints: latency-svc-zfj5w [753.557961ms]
Dec 18 12:36:17.498: INFO: Created: latency-svc-tlp8z
Dec 18 12:36:17.516: INFO: Got endpoints: latency-svc-549mr [752.660669ms]
Dec 18 12:36:17.536: INFO: Created: latency-svc-q7725
Dec 18 12:36:17.566: INFO: Got endpoints: latency-svc-6dzj6 [751.747883ms]
Dec 18 12:36:17.592: INFO: Created: latency-svc-st9p6
Dec 18 12:36:17.612: INFO: Got endpoints: latency-svc-tf75b [746.287504ms]
Dec 18 12:36:17.637: INFO: Created: latency-svc-d5fbb
Dec 18 12:36:17.664: INFO: Got endpoints: latency-svc-kdcrh [750.338191ms]
Dec 18 12:36:17.685: INFO: Created: latency-svc-ljvs9
Dec 18 12:36:17.716: INFO: Got endpoints: latency-svc-m6cxf [750.519715ms]
Dec 18 12:36:17.745: INFO: Created: latency-svc-z6x5v
Dec 18 12:36:17.763: INFO: Got endpoints: latency-svc-wlzjk [749.608859ms]
Dec 18 12:36:17.787: INFO: Created: latency-svc-zwhqb
Dec 18 12:36:17.816: INFO: Got endpoints: latency-svc-tpzzf [721.691181ms]
Dec 18 12:36:17.838: INFO: Created: latency-svc-qqspc
Dec 18 12:36:17.868: INFO: Got endpoints: latency-svc-tmgq4 [749.618362ms]
Dec 18 12:36:17.890: INFO: Created: latency-svc-g4ztd
Dec 18 12:36:17.917: INFO: Got endpoints: latency-svc-ms2kr [745.906967ms]
Dec 18 12:36:17.945: INFO: Created: latency-svc-94jkq
Dec 18 12:36:17.968: INFO: Got endpoints: latency-svc-vvkw6 [743.38306ms]
Dec 18 12:36:17.990: INFO: Created: latency-svc-wh7bv
Dec 18 12:36:18.022: INFO: Got endpoints: latency-svc-p4gts [758.983368ms]
Dec 18 12:36:18.048: INFO: Created: latency-svc-cx469
Dec 18 12:36:18.066: INFO: Got endpoints: latency-svc-8cz94 [745.256911ms]
Dec 18 12:36:18.089: INFO: Created: latency-svc-nfjxt
Dec 18 12:36:18.117: INFO: Got endpoints: latency-svc-tzpdx [745.523731ms]
Dec 18 12:36:18.137: INFO: Created: latency-svc-zld25
Dec 18 12:36:18.168: INFO: Got endpoints: latency-svc-6bv26 [752.871867ms]
Dec 18 12:36:18.190: INFO: Created: latency-svc-xkqgf
Dec 18 12:36:18.214: INFO: Got endpoints: latency-svc-tlp8z [743.987946ms]
Dec 18 12:36:18.236: INFO: Created: latency-svc-5ds9x
Dec 18 12:36:18.264: INFO: Got endpoints: latency-svc-q7725 [747.938216ms]
Dec 18 12:36:18.283: INFO: Created: latency-svc-k5pjl
Dec 18 12:36:18.331: INFO: Got endpoints: latency-svc-st9p6 [764.781412ms]
Dec 18 12:36:18.351: INFO: Created: latency-svc-69gk2
Dec 18 12:36:18.367: INFO: Got endpoints: latency-svc-d5fbb [755.421235ms]
Dec 18 12:36:18.397: INFO: Created: latency-svc-8bkfw
Dec 18 12:36:18.422: INFO: Got endpoints: latency-svc-ljvs9 [758.062335ms]
Dec 18 12:36:18.443: INFO: Created: latency-svc-7cxvx
Dec 18 12:36:18.467: INFO: Got endpoints: latency-svc-z6x5v [751.524673ms]
Dec 18 12:36:18.500: INFO: Created: latency-svc-p5v7x
Dec 18 12:36:18.515: INFO: Got endpoints: latency-svc-zwhqb [751.459544ms]
Dec 18 12:36:18.538: INFO: Created: latency-svc-h4jsx
Dec 18 12:36:18.564: INFO: Got endpoints: latency-svc-qqspc [748.19554ms]
Dec 18 12:36:18.588: INFO: Created: latency-svc-2cmvc
Dec 18 12:36:18.624: INFO: Got endpoints: latency-svc-g4ztd [756.191309ms]
Dec 18 12:36:18.644: INFO: Created: latency-svc-h78t4
Dec 18 12:36:18.666: INFO: Got endpoints: latency-svc-94jkq [749.453666ms]
Dec 18 12:36:18.696: INFO: Created: latency-svc-ptz6q
Dec 18 12:36:18.719: INFO: Got endpoints: latency-svc-wh7bv [750.879014ms]
Dec 18 12:36:18.747: INFO: Created: latency-svc-jlffd
Dec 18 12:36:18.771: INFO: Got endpoints: latency-svc-cx469 [748.886532ms]
Dec 18 12:36:18.821: INFO: Created: latency-svc-fs8f7
Dec 18 12:36:18.821: INFO: Got endpoints: latency-svc-nfjxt [754.881817ms]
Dec 18 12:36:18.855: INFO: Created: latency-svc-xs5f9
Dec 18 12:36:18.867: INFO: Got endpoints: latency-svc-zld25 [749.436641ms]
Dec 18 12:36:18.888: INFO: Created: latency-svc-9hwgv
Dec 18 12:36:18.916: INFO: Got endpoints: latency-svc-xkqgf [747.822519ms]
Dec 18 12:36:18.950: INFO: Created: latency-svc-w2gl9
Dec 18 12:36:18.971: INFO: Got endpoints: latency-svc-5ds9x [757.711534ms]
Dec 18 12:36:19.014: INFO: Created: latency-svc-ws7pr
Dec 18 12:36:19.022: INFO: Got endpoints: latency-svc-k5pjl [757.968642ms]
Dec 18 12:36:19.060: INFO: Created: latency-svc-mgfhv
Dec 18 12:36:19.089: INFO: Got endpoints: latency-svc-69gk2 [757.571027ms]
Dec 18 12:36:19.121: INFO: Got endpoints: latency-svc-8bkfw [753.473472ms]
Dec 18 12:36:19.130: INFO: Created: latency-svc-crkzm
Dec 18 12:36:19.165: INFO: Created: latency-svc-mb4dd
Dec 18 12:36:19.168: INFO: Got endpoints: latency-svc-7cxvx [744.830316ms]
Dec 18 12:36:19.216: INFO: Got endpoints: latency-svc-p5v7x [748.322753ms]
Dec 18 12:36:19.275: INFO: Got endpoints: latency-svc-h4jsx [760.427783ms]
Dec 18 12:36:19.319: INFO: Got endpoints: latency-svc-2cmvc [754.685563ms]
Dec 18 12:36:19.370: INFO: Got endpoints: latency-svc-h78t4 [745.498661ms]
Dec 18 12:36:19.416: INFO: Got endpoints: latency-svc-ptz6q [750.110036ms]
Dec 18 12:36:19.469: INFO: Got endpoints: latency-svc-jlffd [749.961827ms]
Dec 18 12:36:19.516: INFO: Got endpoints: latency-svc-fs8f7 [744.946956ms]
Dec 18 12:36:19.566: INFO: Got endpoints: latency-svc-xs5f9 [744.585825ms]
Dec 18 12:36:19.615: INFO: Got endpoints: latency-svc-9hwgv [748.486389ms]
Dec 18 12:36:19.667: INFO: Got endpoints: latency-svc-w2gl9 [751.164602ms]
Dec 18 12:36:19.718: INFO: Got endpoints: latency-svc-ws7pr [746.213115ms]
Dec 18 12:36:19.766: INFO: Got endpoints: latency-svc-mgfhv [743.756299ms]
Dec 18 12:36:19.818: INFO: Got endpoints: latency-svc-crkzm [729.648185ms]
Dec 18 12:36:19.887: INFO: Got endpoints: latency-svc-mb4dd [765.821239ms]
Dec 18 12:36:19.887: INFO: Latencies: [43.496718ms 59.287362ms 68.582161ms 88.389818ms 104.084987ms 115.453198ms 125.099289ms 146.558984ms 167.844407ms 183.12383ms 200.617168ms 230.67566ms 236.109916ms 250.360072ms 263.497989ms 266.4224ms 266.515419ms 268.310104ms 271.508728ms 271.6208ms 273.17348ms 273.55581ms 276.053498ms 276.117353ms 277.072634ms 278.823903ms 282.346522ms 283.052269ms 283.943978ms 285.352401ms 287.698936ms 289.486742ms 289.744684ms 290.428168ms 291.87551ms 292.977049ms 294.254029ms 296.492754ms 299.769956ms 300.052727ms 300.104952ms 300.515436ms 302.485526ms 304.244857ms 306.215863ms 309.316408ms 314.802308ms 319.869081ms 342.828081ms 401.684486ms 418.201338ms 460.051125ms 484.884075ms 504.294412ms 543.464158ms 578.959033ms 592.054921ms 617.476258ms 661.674425ms 688.064472ms 721.691181ms 729.648185ms 730.99241ms 733.873314ms 737.586195ms 738.898119ms 739.962469ms 740.39303ms 740.495495ms 741.212798ms 741.855559ms 742.002538ms 743.38306ms 743.756299ms 743.987946ms 744.074349ms 744.369468ms 744.444159ms 744.585825ms 744.830316ms 744.94103ms 744.946956ms 745.160447ms 745.256911ms 745.498661ms 745.523731ms 745.718093ms 745.757147ms 745.906967ms 746.140016ms 746.213115ms 746.287504ms 746.318622ms 746.391235ms 746.419236ms 746.57295ms 746.708534ms 747.332482ms 747.589086ms 747.819345ms 747.822519ms 747.938216ms 747.984981ms 748.19554ms 748.239189ms 748.254436ms 748.315013ms 748.322753ms 748.327694ms 748.486389ms 748.527111ms 748.599005ms 748.603956ms 748.693062ms 748.790241ms 748.792805ms 748.886532ms 749.008807ms 749.094481ms 749.424078ms 749.436641ms 749.438356ms 749.453666ms 749.515203ms 749.594333ms 749.605109ms 749.608859ms 749.618362ms 749.728645ms 749.861468ms 749.961827ms 750.110036ms 750.136822ms 750.172283ms 750.258578ms 750.302682ms 750.317538ms 750.338191ms 750.519715ms 750.543598ms 750.556695ms 750.693561ms 750.719302ms 750.768528ms 750.77892ms 750.879014ms 750.909842ms 750.959294ms 751.023997ms 751.142317ms 751.164602ms 751.200769ms 751.320114ms 751.407982ms 751.459544ms 751.524673ms 751.622164ms 751.69488ms 751.725934ms 751.738004ms 751.747883ms 752.442759ms 752.547599ms 752.660669ms 752.871867ms 753.286348ms 753.473472ms 753.50844ms 753.557961ms 754.05023ms 754.172819ms 754.178803ms 754.685563ms 754.817411ms 754.881817ms 755.180108ms 755.247752ms 755.421235ms 755.949763ms 755.975435ms 756.121781ms 756.191309ms 756.276305ms 756.68289ms 756.902984ms 757.571027ms 757.711534ms 757.931426ms 757.968642ms 758.062335ms 758.903541ms 758.983368ms 759.954509ms 760.28312ms 760.427783ms 761.136457ms 762.395147ms 764.781412ms 765.821239ms 774.025329ms]
Dec 18 12:36:19.887: INFO: 50 %ile: 747.822519ms
Dec 18 12:36:19.887: INFO: 90 %ile: 756.121781ms
Dec 18 12:36:19.887: INFO: 99 %ile: 765.821239ms
Dec 18 12:36:19.887: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:36:19.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7027" for this suite.

• [SLOW TEST:14.293 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":273,"completed":153,"skipped":2826,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:36:19.932: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9900
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:36:20.210: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a6cdce81-5189-4316-9dc3-d1d714ead4b5", Controller:(*bool)(0xc00409b86a), BlockOwnerDeletion:(*bool)(0xc00409b86b)}}
Dec 18 12:36:20.225: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"7349e720-c93a-4d30-9732-a20b21c7edb3", Controller:(*bool)(0xc0063c9376), BlockOwnerDeletion:(*bool)(0xc0063c9377)}}
Dec 18 12:36:20.237: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"98a821b2-17dc-4d03-8c33-8c30f6ae080f", Controller:(*bool)(0xc0042cebee), BlockOwnerDeletion:(*bool)(0xc0042cebef)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:36:25.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9900" for this suite.

• [SLOW TEST:5.378 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":273,"completed":154,"skipped":2831,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:36:25.310: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1594
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1594.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1594.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1594.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1594.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 18 12:36:41.670: INFO: DNS probes using dns-test-4e2bb0bd-a55f-4277-8c20-6568d6f4b89e succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1594.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1594.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1594.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1594.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 18 12:36:49.869: INFO: DNS probes using dns-test-71c90462-46a5-4801-854f-806637d1f1ff succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1594.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1594.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1594.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1594.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 18 12:37:00.445: INFO: DNS probes using dns-test-295510c1-aec1-43a4-bff2-f8602515b068 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:37:00.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1594" for this suite.

• [SLOW TEST:35.256 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":273,"completed":155,"skipped":2833,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:37:00.569: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2315
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:37:07.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2315" for this suite.

• [SLOW TEST:7.354 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":273,"completed":156,"skipped":2835,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:37:07.925: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1733
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1218 12:37:14.206848      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 18 12:37:14.207: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:37:14.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1733" for this suite.

• [SLOW TEST:6.304 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":273,"completed":157,"skipped":2840,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:37:14.230: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-291
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:37:14.423: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:37:24.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-291" for this suite.

• [SLOW TEST:10.333 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":273,"completed":158,"skipped":2869,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:37:24.564: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-745
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-745.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-745.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 18 12:37:35.316: INFO: DNS probes using dns-745/dns-test-aad5b611-709e-4765-9e8c-86374e875c75 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:37:35.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-745" for this suite.

• [SLOW TEST:10.824 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":273,"completed":159,"skipped":2887,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:37:35.389: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6485
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-48dc931d-24f9-4657-9145-22cdba270e5b
STEP: Creating a pod to test consume configMaps
Dec 18 12:37:35.635: INFO: Waiting up to 5m0s for pod "pod-configmaps-23db9106-97d5-4913-977c-e02825081832" in namespace "configmap-6485" to be "Succeeded or Failed"
Dec 18 12:37:35.644: INFO: Pod "pod-configmaps-23db9106-97d5-4913-977c-e02825081832": Phase="Pending", Reason="", readiness=false. Elapsed: 9.05532ms
Dec 18 12:37:37.651: INFO: Pod "pod-configmaps-23db9106-97d5-4913-977c-e02825081832": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01637841s
Dec 18 12:37:39.703: INFO: Pod "pod-configmaps-23db9106-97d5-4913-977c-e02825081832": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068192708s
Dec 18 12:37:41.715: INFO: Pod "pod-configmaps-23db9106-97d5-4913-977c-e02825081832": Phase="Pending", Reason="", readiness=false. Elapsed: 6.079476853s
Dec 18 12:37:43.722: INFO: Pod "pod-configmaps-23db9106-97d5-4913-977c-e02825081832": Phase="Pending", Reason="", readiness=false. Elapsed: 8.087177079s
Dec 18 12:37:45.731: INFO: Pod "pod-configmaps-23db9106-97d5-4913-977c-e02825081832": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.095976296s
STEP: Saw pod success
Dec 18 12:37:45.731: INFO: Pod "pod-configmaps-23db9106-97d5-4913-977c-e02825081832" satisfied condition "Succeeded or Failed"
Dec 18 12:37:45.739: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-configmaps-23db9106-97d5-4913-977c-e02825081832 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 12:37:45.941: INFO: Waiting for pod pod-configmaps-23db9106-97d5-4913-977c-e02825081832 to disappear
Dec 18 12:37:45.948: INFO: Pod pod-configmaps-23db9106-97d5-4913-977c-e02825081832 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:37:45.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6485" for this suite.

• [SLOW TEST:10.587 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":273,"completed":160,"skipped":2888,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:37:45.976: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3655
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 12:37:46.199: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0" in namespace "downward-api-3655" to be "Succeeded or Failed"
Dec 18 12:37:46.212: INFO: Pod "downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.01792ms
Dec 18 12:37:48.221: INFO: Pod "downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021713734s
Dec 18 12:37:50.231: INFO: Pod "downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031251678s
Dec 18 12:37:52.244: INFO: Pod "downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044270916s
Dec 18 12:37:54.252: INFO: Pod "downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.052454741s
STEP: Saw pod success
Dec 18 12:37:54.252: INFO: Pod "downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0" satisfied condition "Succeeded or Failed"
Dec 18 12:37:54.260: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0 container client-container: <nil>
STEP: delete the pod
Dec 18 12:37:54.305: INFO: Waiting for pod downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0 to disappear
Dec 18 12:37:54.312: INFO: Pod downwardapi-volume-37a08b08-e102-4c0f-9f2d-b398a83a43a0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:37:54.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3655" for this suite.

• [SLOW TEST:8.363 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":161,"skipped":2906,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:37:54.343: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7808
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:37:54.555: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 18 12:37:54.576: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 18 12:37:59.588: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 18 12:37:59.588: INFO: Creating deployment "test-rolling-update-deployment"
Dec 18 12:37:59.598: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 18 12:37:59.791: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 18 12:38:01.816: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 18 12:38:01.826: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891880, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891880, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891880, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891879, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:38:03.841: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891880, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891880, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891880, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743891879, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:38:05.836: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 18 12:38:05.990: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7808 /apis/apps/v1/namespaces/deployment-7808/deployments/test-rolling-update-deployment ca55b98d-67a2-47b3-bf8c-5a0b3a7a73ba 99964 1 2020-12-18 12:37:59 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-12-18 12:37:59 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-18 12:38:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002ef7b68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-12-18 12:38:00 +0000 UTC,LastTransitionTime:2020-12-18 12:38:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-12-18 12:38:05 +0000 UTC,LastTransitionTime:2020-12-18 12:37:59 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 18 12:38:06.007: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-7808 /apis/apps/v1/namespaces/deployment-7808/replicasets/test-rolling-update-deployment-59d5cb45c7 1171da2e-0bdb-42c5-8763-bc67e165848f 99947 1 2020-12-18 12:37:59 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment ca55b98d-67a2-47b3-bf8c-5a0b3a7a73ba 0xc00454a117 0xc00454a118}] []  [{kube-controller-manager Update apps/v1 2020-12-18 12:38:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 97 53 53 98 57 56 100 45 54 55 97 50 45 52 55 98 51 45 98 102 56 99 45 53 97 48 98 51 97 55 97 55 51 98 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00454a1c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 18 12:38:06.007: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 18 12:38:06.008: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7808 /apis/apps/v1/namespaces/deployment-7808/replicasets/test-rolling-update-controller 7bfcd171-7a1a-4866-ac62-fdd6d50a79ad 99962 2 2020-12-18 12:37:54 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment ca55b98d-67a2-47b3-bf8c-5a0b3a7a73ba 0xc00454a007 0xc00454a008}] []  [{e2e.test Update apps/v1 2020-12-18 12:37:54 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-18 12:38:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 97 53 53 98 57 56 100 45 54 55 97 50 45 52 55 98 51 45 98 102 56 99 45 53 97 48 98 51 97 55 97 55 51 98 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00454a0a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 18 12:38:06.022: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-kjx99" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-kjx99 test-rolling-update-deployment-59d5cb45c7- deployment-7808 /api/v1/namespaces/deployment-7808/pods/test-rolling-update-deployment-59d5cb45c7-kjx99 b8fc29b3-e4c9-4855-bea7-30b57ba07fda 99946 0 2020-12-18 12:37:59 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[cni.projectcalico.org/podIP:172.25.2.107/32 cni.projectcalico.org/podIPs:172.25.2.107/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 1171da2e-0bdb-42c5-8763-bc67e165848f 0xc00454a6f7 0xc00454a6f8}] []  [{kube-controller-manager Update v1 2020-12-18 12:37:59 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 49 55 49 100 97 50 101 45 48 98 100 98 45 52 50 99 53 45 56 55 54 51 45 98 99 54 55 101 49 54 53 56 52 56 102 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:38:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:38:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 50 46 49 48 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ww2s4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ww2s4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ww2s4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:38:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:38:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:38:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:37:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:172.25.2.107,StartTime:2020-12-18 12:38:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:38:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://9b43d894d809cd0e9a3c497d8950e8c3e9640e62c22fa09460f91cfc20cbc978,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.2.107,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:38:06.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7808" for this suite.

• [SLOW TEST:11.715 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":273,"completed":162,"skipped":2940,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:38:06.060: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5131
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:38:23.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5131" for this suite.

• [SLOW TEST:17.751 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":273,"completed":163,"skipped":2948,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:38:23.811: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3589
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:38:24.113: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:38:26.125: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:38:28.120: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:38:30.128: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = false)
Dec 18 12:38:32.134: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = false)
Dec 18 12:38:34.123: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = false)
Dec 18 12:38:36.126: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = false)
Dec 18 12:38:38.121: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = false)
Dec 18 12:38:40.123: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = false)
Dec 18 12:38:42.121: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = false)
Dec 18 12:38:44.123: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = false)
Dec 18 12:38:46.122: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = false)
Dec 18 12:38:48.125: INFO: The status of Pod test-webserver-a0df0364-bafc-4dd8-9a5b-cb3523a69f5e is Running (Ready = true)
Dec 18 12:38:48.133: INFO: Container started at 2020-12-18 12:38:28 +0000 UTC, pod became ready at 2020-12-18 12:38:47 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:38:48.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3589" for this suite.

• [SLOW TEST:24.349 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":273,"completed":164,"skipped":2949,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:38:48.163: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1411
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-ed0fda0b-87d0-4ae9-a94d-4189534c7a66
STEP: Creating a pod to test consume configMaps
Dec 18 12:38:48.391: INFO: Waiting up to 5m0s for pod "pod-configmaps-01240fb2-cadd-4151-9455-4379089f947a" in namespace "configmap-1411" to be "Succeeded or Failed"
Dec 18 12:38:48.397: INFO: Pod "pod-configmaps-01240fb2-cadd-4151-9455-4379089f947a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.987831ms
Dec 18 12:38:50.405: INFO: Pod "pod-configmaps-01240fb2-cadd-4151-9455-4379089f947a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014144907s
Dec 18 12:38:52.414: INFO: Pod "pod-configmaps-01240fb2-cadd-4151-9455-4379089f947a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023068729s
Dec 18 12:38:54.423: INFO: Pod "pod-configmaps-01240fb2-cadd-4151-9455-4379089f947a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031799318s
STEP: Saw pod success
Dec 18 12:38:54.423: INFO: Pod "pod-configmaps-01240fb2-cadd-4151-9455-4379089f947a" satisfied condition "Succeeded or Failed"
Dec 18 12:38:54.432: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-configmaps-01240fb2-cadd-4151-9455-4379089f947a container configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 12:38:54.486: INFO: Waiting for pod pod-configmaps-01240fb2-cadd-4151-9455-4379089f947a to disappear
Dec 18 12:38:54.501: INFO: Pod pod-configmaps-01240fb2-cadd-4151-9455-4379089f947a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:38:54.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1411" for this suite.

• [SLOW TEST:6.364 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":165,"skipped":2956,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:38:54.529: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8191
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:38:54.720: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 18 12:38:59.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-8191 create -f -'
Dec 18 12:39:02.958: INFO: stderr: ""
Dec 18 12:39:02.958: INFO: stdout: "e2e-test-crd-publish-openapi-2711-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 18 12:39:02.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-8191 delete e2e-test-crd-publish-openapi-2711-crds test-cr'
Dec 18 12:39:03.175: INFO: stderr: ""
Dec 18 12:39:03.175: INFO: stdout: "e2e-test-crd-publish-openapi-2711-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 18 12:39:03.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-8191 apply -f -'
Dec 18 12:39:04.337: INFO: stderr: ""
Dec 18 12:39:04.337: INFO: stdout: "e2e-test-crd-publish-openapi-2711-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 18 12:39:04.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-8191 delete e2e-test-crd-publish-openapi-2711-crds test-cr'
Dec 18 12:39:07.480: INFO: stderr: ""
Dec 18 12:39:07.480: INFO: stdout: "e2e-test-crd-publish-openapi-2711-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 18 12:39:07.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 explain e2e-test-crd-publish-openapi-2711-crds'
Dec 18 12:39:07.957: INFO: stderr: ""
Dec 18 12:39:07.957: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2711-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:39:11.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8191" for this suite.

• [SLOW TEST:17.278 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":273,"completed":166,"skipped":2992,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:39:11.809: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2107
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 12:39:12.035: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0" in namespace "downward-api-2107" to be "Succeeded or Failed"
Dec 18 12:39:12.041: INFO: Pod "downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.413419ms
Dec 18 12:39:14.049: INFO: Pod "downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014131207s
Dec 18 12:39:16.057: INFO: Pod "downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022157228s
Dec 18 12:39:18.067: INFO: Pod "downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031834735s
Dec 18 12:39:20.077: INFO: Pod "downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042108465s
STEP: Saw pod success
Dec 18 12:39:20.077: INFO: Pod "downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0" satisfied condition "Succeeded or Failed"
Dec 18 12:39:20.084: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0 container client-container: <nil>
STEP: delete the pod
Dec 18 12:39:20.149: INFO: Waiting for pod downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0 to disappear
Dec 18 12:39:20.154: INFO: Pod downwardapi-volume-d2b2da8f-cf03-4278-8516-b56d865cb6d0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:39:20.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2107" for this suite.

• [SLOW TEST:8.376 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":167,"skipped":3039,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:39:20.186: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4496
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 18 12:39:27.454: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:39:27.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4496" for this suite.

• [SLOW TEST:7.323 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":273,"completed":168,"skipped":3063,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:39:27.513: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6776
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 18 12:39:27.820: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6776 /api/v1/namespaces/watch-6776/configmaps/e2e-watch-test-resource-version 779ef121-d8fd-4b85-be9c-93565adfe1a6 100603 0 2020-12-18 12:39:27 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-12-18 12:39:27 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 12:39:27.820: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6776 /api/v1/namespaces/watch-6776/configmaps/e2e-watch-test-resource-version 779ef121-d8fd-4b85-be9c-93565adfe1a6 100604 0 2020-12-18 12:39:27 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-12-18 12:39:27 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:39:27.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6776" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":273,"completed":169,"skipped":3083,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:39:27.841: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-274
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Dec 18 12:39:28.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 cluster-info'
Dec 18 12:39:28.141: INFO: stderr: ""
Dec 18 12:39:28.141: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.240.16.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.240.16.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:39:28.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-274" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":273,"completed":170,"skipped":3086,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:39:28.164: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6460
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 18 12:39:39.020: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:39:39.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1218 12:39:39.020211      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6460" for this suite.

• [SLOW TEST:10.879 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":273,"completed":171,"skipped":3102,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:39:39.044: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1919
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-6eab8cbb-bd21-482c-bb77-0feae5e3380e in namespace container-probe-1919
Dec 18 12:39:47.560: INFO: Started pod liveness-6eab8cbb-bd21-482c-bb77-0feae5e3380e in namespace container-probe-1919
STEP: checking the pod's current state and verifying that restartCount is present
Dec 18 12:39:47.567: INFO: Initial restart count of pod liveness-6eab8cbb-bd21-482c-bb77-0feae5e3380e is 0
Dec 18 12:40:11.950: INFO: Restart count of pod container-probe-1919/liveness-6eab8cbb-bd21-482c-bb77-0feae5e3380e is now 1 (24.383180854s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:40:11.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1919" for this suite.

• [SLOW TEST:32.971 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":273,"completed":172,"skipped":3117,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:40:12.018: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1914
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-c913da99-3f83-4cfc-afd8-fd6528910217 in namespace container-probe-1914
Dec 18 12:40:22.293: INFO: Started pod test-webserver-c913da99-3f83-4cfc-afd8-fd6528910217 in namespace container-probe-1914
STEP: checking the pod's current state and verifying that restartCount is present
Dec 18 12:40:22.304: INFO: Initial restart count of pod test-webserver-c913da99-3f83-4cfc-afd8-fd6528910217 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:44:22.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1914" for this suite.

• [SLOW TEST:250.548 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":273,"completed":173,"skipped":3125,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:44:22.567: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-1653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Dec 18 12:44:22.780: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Dec 18 12:44:22.799: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 18 12:44:22.799: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Dec 18 12:44:22.819: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 18 12:44:22.819: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Dec 18 12:44:22.853: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Dec 18 12:44:22.853: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Dec 18 12:44:29.932: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:44:29.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-1653" for this suite.

• [SLOW TEST:7.410 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":273,"completed":174,"skipped":3168,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:44:29.981: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-5887
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9327
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1025
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:44:51.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5887" for this suite.
STEP: Destroying namespace "nsdeletetest-9327" for this suite.
Dec 18 12:44:51.726: INFO: Namespace nsdeletetest-9327 was already deleted
STEP: Destroying namespace "nsdeletetest-1025" for this suite.

• [SLOW TEST:21.765 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":273,"completed":175,"skipped":3193,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:44:51.748: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1133
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-59v8
STEP: Creating a pod to test atomic-volume-subpath
Dec 18 12:44:51.994: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-59v8" in namespace "subpath-1133" to be "Succeeded or Failed"
Dec 18 12:44:52.001: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.794365ms
Dec 18 12:44:54.047: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052715209s
Dec 18 12:44:56.054: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.060103109s
Dec 18 12:44:58.063: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 6.069172851s
Dec 18 12:45:00.071: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 8.077226922s
Dec 18 12:45:02.081: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 10.086624238s
Dec 18 12:45:04.091: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 12.096883507s
Dec 18 12:45:06.099: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 14.105174449s
Dec 18 12:45:08.118: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 16.124487448s
Dec 18 12:45:10.126: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 18.131508449s
Dec 18 12:45:12.134: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 20.139499083s
Dec 18 12:45:14.144: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 22.150474158s
Dec 18 12:45:16.153: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 24.158951791s
Dec 18 12:45:18.165: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 26.171251406s
Dec 18 12:45:20.176: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 28.182485007s
Dec 18 12:45:22.187: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Running", Reason="", readiness=true. Elapsed: 30.193325282s
Dec 18 12:45:24.199: INFO: Pod "pod-subpath-test-downwardapi-59v8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.20538066s
STEP: Saw pod success
Dec 18 12:45:24.199: INFO: Pod "pod-subpath-test-downwardapi-59v8" satisfied condition "Succeeded or Failed"
Dec 18 12:45:24.212: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-subpath-test-downwardapi-59v8 container test-container-subpath-downwardapi-59v8: <nil>
STEP: delete the pod
Dec 18 12:45:24.390: INFO: Waiting for pod pod-subpath-test-downwardapi-59v8 to disappear
Dec 18 12:45:24.404: INFO: Pod pod-subpath-test-downwardapi-59v8 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-59v8
Dec 18 12:45:24.404: INFO: Deleting pod "pod-subpath-test-downwardapi-59v8" in namespace "subpath-1133"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:45:24.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1133" for this suite.

• [SLOW TEST:32.711 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":273,"completed":176,"skipped":3228,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:45:24.459: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 18 12:45:24.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4043'
Dec 18 12:45:24.882: INFO: stderr: ""
Dec 18 12:45:24.882: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Dec 18 12:45:24.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete pods e2e-test-httpd-pod --namespace=kubectl-4043'
Dec 18 12:45:28.756: INFO: stderr: ""
Dec 18 12:45:28.756: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:45:28.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4043" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":273,"completed":177,"skipped":3240,"failed":0}

------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:45:28.785: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1780
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:45:29.035: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:45:30.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1780" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":273,"completed":178,"skipped":3240,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:45:30.124: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-3f657b80-1fca-4b4f-9992-71ae1acedb7c in namespace container-probe-2129
Dec 18 12:45:38.421: INFO: Started pod liveness-3f657b80-1fca-4b4f-9992-71ae1acedb7c in namespace container-probe-2129
STEP: checking the pod's current state and verifying that restartCount is present
Dec 18 12:45:38.429: INFO: Initial restart count of pod liveness-3f657b80-1fca-4b4f-9992-71ae1acedb7c is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:49:39.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2129" for this suite.

• [SLOW TEST:249.797 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":273,"completed":179,"skipped":3241,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:49:39.922: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4650
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Dec 18 12:49:40.178: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:49:50.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4650" for this suite.

• [SLOW TEST:10.634 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":273,"completed":180,"skipped":3262,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:49:50.558: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8770
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-8770
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8770 to expose endpoints map[]
Dec 18 12:49:50.854: INFO: Get endpoints failed (6.102595ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 18 12:49:51.865: INFO: successfully validated that service multi-endpoint-test in namespace services-8770 exposes endpoints map[] (1.016566771s elapsed)
STEP: Creating pod pod1 in namespace services-8770
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8770 to expose endpoints map[pod1:[100]]
Dec 18 12:49:55.991: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.106761617s elapsed, will retry)
Dec 18 12:49:58.022: INFO: successfully validated that service multi-endpoint-test in namespace services-8770 exposes endpoints map[pod1:[100]] (6.13829694s elapsed)
STEP: Creating pod pod2 in namespace services-8770
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8770 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 18 12:50:02.169: INFO: Unexpected endpoints: found map[cee264c5-7d10-4eb7-a23b-69c1bdf967c6:[100]], expected map[pod1:[100] pod2:[101]] (4.126285586s elapsed, will retry)
Dec 18 12:50:03.193: INFO: successfully validated that service multi-endpoint-test in namespace services-8770 exposes endpoints map[pod1:[100] pod2:[101]] (5.150697312s elapsed)
STEP: Deleting pod pod1 in namespace services-8770
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8770 to expose endpoints map[pod2:[101]]
Dec 18 12:50:03.235: INFO: successfully validated that service multi-endpoint-test in namespace services-8770 exposes endpoints map[pod2:[101]] (17.507158ms elapsed)
STEP: Deleting pod pod2 in namespace services-8770
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8770 to expose endpoints map[]
Dec 18 12:50:04.270: INFO: successfully validated that service multi-endpoint-test in namespace services-8770 exposes endpoints map[] (1.018109224s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:50:04.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8770" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:13.770 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":273,"completed":181,"skipped":3273,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:50:04.328: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6824
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6824 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6824;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6824 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6824;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6824.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6824.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6824.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6824.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6824.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6824.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6824.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6824.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6824.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6824.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6824.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6824.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6824.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 119.30.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.30.119_udp@PTR;check="$$(dig +tcp +noall +answer +search 119.30.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.30.119_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6824 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6824;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6824 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6824;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6824.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6824.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6824.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6824.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6824.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6824.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6824.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6824.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6824.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6824.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6824.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6824.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6824.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 119.30.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.30.119_udp@PTR;check="$$(dig +tcp +noall +answer +search 119.30.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.30.119_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 18 12:50:14.623: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:14.635: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:14.679: INFO: Unable to read wheezy_udp@dns-test-service.dns-6824 from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:14.689: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6824 from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:14.701: INFO: Unable to read wheezy_udp@dns-test-service.dns-6824.svc from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:14.713: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6824.svc from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:14.725: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6824.svc from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:14.735: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6824.svc from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:15.019: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:15.031: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:15.045: INFO: Unable to read jessie_udp@dns-test-service.dns-6824 from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:15.058: INFO: Unable to read jessie_tcp@dns-test-service.dns-6824 from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:15.069: INFO: Unable to read jessie_udp@dns-test-service.dns-6824.svc from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:15.083: INFO: Unable to read jessie_tcp@dns-test-service.dns-6824.svc from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:15.094: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6824.svc from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:15.103: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6824.svc from pod dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698: the server could not find the requested resource (get pods dns-test-bd546491-17f1-4531-a7d5-586422bdd698)
Dec 18 12:50:15.338: INFO: Lookups using dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6824 wheezy_tcp@dns-test-service.dns-6824 wheezy_udp@dns-test-service.dns-6824.svc wheezy_tcp@dns-test-service.dns-6824.svc wheezy_udp@_http._tcp.dns-test-service.dns-6824.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6824.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6824 jessie_tcp@dns-test-service.dns-6824 jessie_udp@dns-test-service.dns-6824.svc jessie_tcp@dns-test-service.dns-6824.svc jessie_udp@_http._tcp.dns-test-service.dns-6824.svc jessie_tcp@_http._tcp.dns-test-service.dns-6824.svc]

Dec 18 12:50:21.220: INFO: DNS probes using dns-6824/dns-test-bd546491-17f1-4531-a7d5-586422bdd698 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:50:21.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6824" for this suite.

• [SLOW TEST:17.049 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":273,"completed":182,"skipped":3289,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:50:21.385: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7849
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-82ed6869-638e-4968-afd8-a140578b7c6a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:50:31.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7849" for this suite.

• [SLOW TEST:10.366 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":183,"skipped":3312,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:50:31.753: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5987
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:50:32.356: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 18 12:50:34.386: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892632, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892632, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892632, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892632, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:50:36.395: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892632, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892632, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892632, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892632, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:50:39.424: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:50:39.432: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6147-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:50:40.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5987" for this suite.
STEP: Destroying namespace "webhook-5987-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:9.306 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":273,"completed":184,"skipped":3322,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:50:41.070: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7137
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9171
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:50:47.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9576" for this suite.
STEP: Destroying namespace "nsdeletetest-7137" for this suite.
Dec 18 12:50:47.764: INFO: Namespace nsdeletetest-7137 was already deleted
STEP: Destroying namespace "nsdeletetest-9171" for this suite.

• [SLOW TEST:6.713 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":273,"completed":185,"skipped":3341,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:50:47.786: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9311
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 12:50:47.994: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71638ed3-13ac-49c8-bffd-100ff85dd9be" in namespace "downward-api-9311" to be "Succeeded or Failed"
Dec 18 12:50:48.001: INFO: Pod "downwardapi-volume-71638ed3-13ac-49c8-bffd-100ff85dd9be": Phase="Pending", Reason="", readiness=false. Elapsed: 7.047102ms
Dec 18 12:50:50.011: INFO: Pod "downwardapi-volume-71638ed3-13ac-49c8-bffd-100ff85dd9be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016218802s
Dec 18 12:50:52.023: INFO: Pod "downwardapi-volume-71638ed3-13ac-49c8-bffd-100ff85dd9be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028654072s
Dec 18 12:50:54.031: INFO: Pod "downwardapi-volume-71638ed3-13ac-49c8-bffd-100ff85dd9be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036426724s
STEP: Saw pod success
Dec 18 12:50:54.031: INFO: Pod "downwardapi-volume-71638ed3-13ac-49c8-bffd-100ff85dd9be" satisfied condition "Succeeded or Failed"
Dec 18 12:50:54.039: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-71638ed3-13ac-49c8-bffd-100ff85dd9be container client-container: <nil>
STEP: delete the pod
Dec 18 12:50:54.130: INFO: Waiting for pod downwardapi-volume-71638ed3-13ac-49c8-bffd-100ff85dd9be to disappear
Dec 18 12:50:54.150: INFO: Pod downwardapi-volume-71638ed3-13ac-49c8-bffd-100ff85dd9be no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:50:54.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9311" for this suite.

• [SLOW TEST:6.396 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":273,"completed":186,"skipped":3345,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:50:54.183: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1263
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-ba93cf10-9522-4aa1-a4d1-40b83c40aab2
STEP: Creating a pod to test consume secrets
Dec 18 12:50:54.807: INFO: Waiting up to 5m0s for pod "pod-secrets-27d276c5-1f35-446d-9e93-cf7fbbcc14f8" in namespace "secrets-1263" to be "Succeeded or Failed"
Dec 18 12:50:54.816: INFO: Pod "pod-secrets-27d276c5-1f35-446d-9e93-cf7fbbcc14f8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.623674ms
Dec 18 12:50:56.825: INFO: Pod "pod-secrets-27d276c5-1f35-446d-9e93-cf7fbbcc14f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017699216s
Dec 18 12:50:58.833: INFO: Pod "pod-secrets-27d276c5-1f35-446d-9e93-cf7fbbcc14f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026409787s
Dec 18 12:51:00.845: INFO: Pod "pod-secrets-27d276c5-1f35-446d-9e93-cf7fbbcc14f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038146214s
STEP: Saw pod success
Dec 18 12:51:00.846: INFO: Pod "pod-secrets-27d276c5-1f35-446d-9e93-cf7fbbcc14f8" satisfied condition "Succeeded or Failed"
Dec 18 12:51:00.856: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-secrets-27d276c5-1f35-446d-9e93-cf7fbbcc14f8 container secret-volume-test: <nil>
STEP: delete the pod
Dec 18 12:51:00.914: INFO: Waiting for pod pod-secrets-27d276c5-1f35-446d-9e93-cf7fbbcc14f8 to disappear
Dec 18 12:51:00.921: INFO: Pod pod-secrets-27d276c5-1f35-446d-9e93-cf7fbbcc14f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:51:00.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1263" for this suite.

• [SLOW TEST:6.767 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":187,"skipped":3371,"failed":0}
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:51:00.951: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9519
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Dec 18 12:51:01.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-9519'
Dec 18 12:51:05.139: INFO: stderr: ""
Dec 18 12:51:05.139: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 18 12:51:05.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9519'
Dec 18 12:51:05.274: INFO: stderr: ""
Dec 18 12:51:05.274: INFO: stdout: "update-demo-nautilus-l7jl4 update-demo-nautilus-rf9fn "
Dec 18 12:51:05.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-l7jl4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:08.374: INFO: stderr: ""
Dec 18 12:51:08.374: INFO: stdout: ""
Dec 18 12:51:08.374: INFO: update-demo-nautilus-l7jl4 is created but not running
Dec 18 12:51:13.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9519'
Dec 18 12:51:13.491: INFO: stderr: ""
Dec 18 12:51:13.491: INFO: stdout: "update-demo-nautilus-l7jl4 update-demo-nautilus-rf9fn "
Dec 18 12:51:13.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-l7jl4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:13.609: INFO: stderr: ""
Dec 18 12:51:13.609: INFO: stdout: "true"
Dec 18 12:51:13.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-l7jl4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:13.733: INFO: stderr: ""
Dec 18 12:51:13.733: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 18 12:51:13.733: INFO: validating pod update-demo-nautilus-l7jl4
Dec 18 12:51:13.757: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 18 12:51:13.757: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 18 12:51:13.757: INFO: update-demo-nautilus-l7jl4 is verified up and running
Dec 18 12:51:13.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-rf9fn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:13.861: INFO: stderr: ""
Dec 18 12:51:13.861: INFO: stdout: "true"
Dec 18 12:51:13.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-rf9fn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:13.970: INFO: stderr: ""
Dec 18 12:51:13.970: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 18 12:51:13.970: INFO: validating pod update-demo-nautilus-rf9fn
Dec 18 12:51:14.029: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 18 12:51:14.029: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 18 12:51:14.029: INFO: update-demo-nautilus-rf9fn is verified up and running
STEP: scaling down the replication controller
Dec 18 12:51:14.033: INFO: scanned /root for discovery docs: <nil>
Dec 18 12:51:14.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9519'
Dec 18 12:51:15.207: INFO: stderr: ""
Dec 18 12:51:15.207: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 18 12:51:15.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9519'
Dec 18 12:51:15.338: INFO: stderr: ""
Dec 18 12:51:15.338: INFO: stdout: "update-demo-nautilus-l7jl4 update-demo-nautilus-rf9fn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 18 12:51:20.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9519'
Dec 18 12:51:20.457: INFO: stderr: ""
Dec 18 12:51:20.457: INFO: stdout: "update-demo-nautilus-l7jl4 update-demo-nautilus-rf9fn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 18 12:51:25.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9519'
Dec 18 12:51:25.604: INFO: stderr: ""
Dec 18 12:51:25.604: INFO: stdout: "update-demo-nautilus-l7jl4 update-demo-nautilus-rf9fn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 18 12:51:30.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9519'
Dec 18 12:51:30.730: INFO: stderr: ""
Dec 18 12:51:30.730: INFO: stdout: "update-demo-nautilus-l7jl4 "
Dec 18 12:51:30.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-l7jl4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:30.857: INFO: stderr: ""
Dec 18 12:51:30.857: INFO: stdout: "true"
Dec 18 12:51:30.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-l7jl4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:33.982: INFO: stderr: ""
Dec 18 12:51:33.982: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 18 12:51:33.982: INFO: validating pod update-demo-nautilus-l7jl4
Dec 18 12:51:34.056: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 18 12:51:34.056: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 18 12:51:34.056: INFO: update-demo-nautilus-l7jl4 is verified up and running
STEP: scaling up the replication controller
Dec 18 12:51:34.061: INFO: scanned /root for discovery docs: <nil>
Dec 18 12:51:34.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9519'
Dec 18 12:51:34.533: INFO: stderr: ""
Dec 18 12:51:34.533: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 18 12:51:34.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9519'
Dec 18 12:51:34.640: INFO: stderr: ""
Dec 18 12:51:34.640: INFO: stdout: "update-demo-nautilus-l7jl4 update-demo-nautilus-zxcll "
Dec 18 12:51:34.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-l7jl4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:34.760: INFO: stderr: ""
Dec 18 12:51:34.760: INFO: stdout: "true"
Dec 18 12:51:34.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-l7jl4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:34.871: INFO: stderr: ""
Dec 18 12:51:34.871: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 18 12:51:34.871: INFO: validating pod update-demo-nautilus-l7jl4
Dec 18 12:51:34.884: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 18 12:51:34.884: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 18 12:51:34.884: INFO: update-demo-nautilus-l7jl4 is verified up and running
Dec 18 12:51:34.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-zxcll -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:35.069: INFO: stderr: ""
Dec 18 12:51:35.069: INFO: stdout: ""
Dec 18 12:51:35.069: INFO: update-demo-nautilus-zxcll is created but not running
Dec 18 12:51:40.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9519'
Dec 18 12:51:40.193: INFO: stderr: ""
Dec 18 12:51:40.193: INFO: stdout: "update-demo-nautilus-l7jl4 update-demo-nautilus-zxcll "
Dec 18 12:51:40.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-l7jl4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:40.311: INFO: stderr: ""
Dec 18 12:51:40.311: INFO: stdout: "true"
Dec 18 12:51:40.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-l7jl4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:40.444: INFO: stderr: ""
Dec 18 12:51:40.444: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 18 12:51:40.444: INFO: validating pod update-demo-nautilus-l7jl4
Dec 18 12:51:40.458: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 18 12:51:40.458: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 18 12:51:40.458: INFO: update-demo-nautilus-l7jl4 is verified up and running
Dec 18 12:51:40.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-zxcll -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:40.580: INFO: stderr: ""
Dec 18 12:51:40.580: INFO: stdout: "true"
Dec 18 12:51:40.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods update-demo-nautilus-zxcll -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9519'
Dec 18 12:51:40.702: INFO: stderr: ""
Dec 18 12:51:40.702: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 18 12:51:40.702: INFO: validating pod update-demo-nautilus-zxcll
Dec 18 12:51:40.760: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 18 12:51:40.760: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 18 12:51:40.760: INFO: update-demo-nautilus-zxcll is verified up and running
STEP: using delete to clean up resources
Dec 18 12:51:40.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete --grace-period=0 --force -f - --namespace=kubectl-9519'
Dec 18 12:51:40.906: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 18 12:51:40.906: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 18 12:51:40.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9519'
Dec 18 12:51:41.037: INFO: stderr: "No resources found in kubectl-9519 namespace.\n"
Dec 18 12:51:41.037: INFO: stdout: ""
Dec 18 12:51:41.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -l name=update-demo --namespace=kubectl-9519 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 18 12:51:41.158: INFO: stderr: ""
Dec 18 12:51:41.158: INFO: stdout: "update-demo-nautilus-l7jl4\nupdate-demo-nautilus-zxcll\n"
Dec 18 12:51:41.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9519'
Dec 18 12:51:41.789: INFO: stderr: "No resources found in kubectl-9519 namespace.\n"
Dec 18 12:51:41.789: INFO: stdout: ""
Dec 18 12:51:41.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 get pods -l name=update-demo --namespace=kubectl-9519 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 18 12:51:41.913: INFO: stderr: ""
Dec 18 12:51:41.914: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:51:41.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9519" for this suite.

• [SLOW TEST:40.989 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":273,"completed":188,"skipped":3371,"failed":0}
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:51:41.940: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1083
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-1083
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 18 12:51:42.177: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 18 12:51:42.278: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:51:44.287: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:51:46.445: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 12:51:48.335: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:51:50.291: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:51:52.292: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:51:54.286: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:51:56.287: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:51:58.287: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:52:00.290: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:52:02.286: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:52:04.291: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 12:52:06.290: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 18 12:52:06.307: INFO: The status of Pod netserver-1 is Running (Ready = true)
Dec 18 12:52:06.321: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Dec 18 12:52:16.397: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.2.113 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1083 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:52:16.398: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:52:17.776: INFO: Found all expected endpoints: [netserver-0]
Dec 18 12:52:17.783: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.0.60 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1083 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:52:17.783: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:52:19.171: INFO: Found all expected endpoints: [netserver-1]
Dec 18 12:52:19.178: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.25.1.216 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1083 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 12:52:19.178: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:52:20.463: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:52:20.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1083" for this suite.

• [SLOW TEST:38.569 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":189,"skipped":3373,"failed":0}
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:52:20.510: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 18 12:52:27.859: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:52:27.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7163" for this suite.

• [SLOW TEST:7.424 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":273,"completed":190,"skipped":3376,"failed":0}
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:52:27.938: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9584
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:52:28.179: INFO: Creating deployment "test-recreate-deployment"
Dec 18 12:52:28.191: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 18 12:52:28.207: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec 18 12:52:30.221: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 18 12:52:30.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:52:32.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:52:34.237: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743892748, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:52:36.240: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 18 12:52:36.260: INFO: Updating deployment test-recreate-deployment
Dec 18 12:52:36.260: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 18 12:52:36.449: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9584 /apis/apps/v1/namespaces/deployment-9584/deployments/test-recreate-deployment cad2575d-52f6-472f-8703-770c6343dd04 105896 2 2020-12-18 12:52:28 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-12-18 12:52:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-18 12:52:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004d3cc18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-12-18 12:52:36 +0000 UTC,LastTransitionTime:2020-12-18 12:52:36 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-12-18 12:52:36 +0000 UTC,LastTransitionTime:2020-12-18 12:52:28 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 18 12:52:36.459: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-9584 /apis/apps/v1/namespaces/deployment-9584/replicasets/test-recreate-deployment-d5667d9c7 fe435cdb-bd0e-4f61-81f8-7ff9230dfbd3 105895 1 2020-12-18 12:52:36 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment cad2575d-52f6-472f-8703-770c6343dd04 0xc004d3d150 0xc004d3d151}] []  [{kube-controller-manager Update apps/v1 2020-12-18 12:52:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 97 100 50 53 55 53 100 45 53 50 102 54 45 52 55 50 102 45 56 55 48 51 45 55 55 48 99 54 51 52 51 100 100 48 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004d3d1c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 18 12:52:36.459: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 18 12:52:36.460: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-9584 /apis/apps/v1/namespaces/deployment-9584/replicasets/test-recreate-deployment-74d98b5f7c d514ffd8-7131-48c9-93c6-1aab8036ef4a 105885 2 2020-12-18 12:52:28 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment cad2575d-52f6-472f-8703-770c6343dd04 0xc004d3d057 0xc004d3d058}] []  [{kube-controller-manager Update apps/v1 2020-12-18 12:52:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 97 100 50 53 55 53 100 45 53 50 102 54 45 52 55 50 102 45 56 55 48 51 45 55 55 48 99 54 51 52 51 100 100 48 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004d3d0e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 18 12:52:36.471: INFO: Pod "test-recreate-deployment-d5667d9c7-zpp7s" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-zpp7s test-recreate-deployment-d5667d9c7- deployment-9584 /api/v1/namespaces/deployment-9584/pods/test-recreate-deployment-d5667d9c7-zpp7s e62d867f-dca1-42c7-bada-2a82d1d3c648 105897 0 2020-12-18 12:52:36 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 fe435cdb-bd0e-4f61-81f8-7ff9230dfbd3 0xc004d3d6f0 0xc004d3d6f1}] []  [{kube-controller-manager Update v1 2020-12-18 12:52:36 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 101 52 51 53 99 100 98 45 98 100 48 101 45 52 102 54 49 45 56 49 102 56 45 55 102 102 57 50 51 48 100 102 98 100 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:52:36 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hl5tq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hl5tq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hl5tq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:52:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:52:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:52:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:52:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:,StartTime:2020-12-18 12:52:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:52:36.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9584" for this suite.

• [SLOW TEST:8.557 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":273,"completed":191,"skipped":3379,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:52:36.497: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1218 12:52:37.899525      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 18 12:52:37.899: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:52:37.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7270" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":273,"completed":192,"skipped":3385,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:52:37.921: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-96
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Dec 18 12:52:38.119: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-185975894 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:52:38.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-96" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":273,"completed":193,"skipped":3402,"failed":0}
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:52:38.237: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1476
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:52:38.480: INFO: Creating ReplicaSet my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231
Dec 18 12:52:38.502: INFO: Pod name my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231: Found 0 pods out of 1
Dec 18 12:52:43.518: INFO: Pod name my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231: Found 1 pods out of 1
Dec 18 12:52:43.518: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231" is running
Dec 18 12:52:47.536: INFO: Pod "my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231-wvf4x" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-18 12:52:38 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-18 12:52:38 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-18 12:52:38 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-12-18 12:52:38 +0000 UTC Reason: Message:}])
Dec 18 12:52:47.537: INFO: Trying to dial the pod
Dec 18 12:52:52.607: INFO: Controller my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231: Got expected result from replica 1 [my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231-wvf4x]: "my-hostname-basic-e336768b-9bcb-43b5-8b45-3cf6526b3231-wvf4x", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:52:52.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1476" for this suite.

• [SLOW TEST:14.395 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":273,"completed":194,"skipped":3407,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:52:52.634: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 18 12:52:52.864: INFO: Waiting up to 5m0s for pod "pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2" in namespace "emptydir-5948" to be "Succeeded or Failed"
Dec 18 12:52:52.873: INFO: Pod "pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.232776ms
Dec 18 12:52:54.881: INFO: Pod "pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016254776s
Dec 18 12:52:56.888: INFO: Pod "pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024029882s
Dec 18 12:52:58.897: INFO: Pod "pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032420372s
Dec 18 12:53:00.908: INFO: Pod "pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.043949262s
STEP: Saw pod success
Dec 18 12:53:00.908: INFO: Pod "pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2" satisfied condition "Succeeded or Failed"
Dec 18 12:53:00.924: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2 container test-container: <nil>
STEP: delete the pod
Dec 18 12:53:01.077: INFO: Waiting for pod pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2 to disappear
Dec 18 12:53:01.086: INFO: Pod pod-4cc69a90-f197-4e19-b99d-1faa460bd7f2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:53:01.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5948" for this suite.

• [SLOW TEST:8.487 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":195,"skipped":3411,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:53:01.122: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2313
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Dec 18 12:53:01.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-2313 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 18 12:53:01.922: INFO: stderr: ""
Dec 18 12:53:01.922: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Dec 18 12:53:01.922: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 18 12:53:01.922: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2313" to be "running and ready, or succeeded"
Dec 18 12:53:02.494: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 571.521334ms
Dec 18 12:53:04.502: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.579338402s
Dec 18 12:53:06.510: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.587904543s
Dec 18 12:53:08.519: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 6.596749568s
Dec 18 12:53:08.519: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 18 12:53:08.519: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 18 12:53:08.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 logs logs-generator logs-generator --namespace=kubectl-2313'
Dec 18 12:53:08.667: INFO: stderr: ""
Dec 18 12:53:08.667: INFO: stdout: "I1218 12:53:06.977442       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/txwd 547\nI1218 12:53:07.177653       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/xdm 540\nI1218 12:53:07.377663       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/4fnf 349\nI1218 12:53:07.577698       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/pzw 221\nI1218 12:53:07.777642       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/6nnd 500\nI1218 12:53:07.977616       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/nxjp 479\nI1218 12:53:08.177648       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/rsr 255\nI1218 12:53:08.377642       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/hmk 446\nI1218 12:53:08.577641       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/9k7 386\n"
STEP: limiting log lines
Dec 18 12:53:08.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 logs logs-generator logs-generator --namespace=kubectl-2313 --tail=1'
Dec 18 12:53:08.829: INFO: stderr: ""
Dec 18 12:53:08.829: INFO: stdout: "I1218 12:53:08.777956       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/jz9 485\n"
Dec 18 12:53:08.829: INFO: got output "I1218 12:53:08.777956       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/jz9 485\n"
STEP: limiting log bytes
Dec 18 12:53:08.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 logs logs-generator logs-generator --namespace=kubectl-2313 --limit-bytes=1'
Dec 18 12:53:08.980: INFO: stderr: ""
Dec 18 12:53:08.980: INFO: stdout: "I"
Dec 18 12:53:08.980: INFO: got output "I"
STEP: exposing timestamps
Dec 18 12:53:08.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 logs logs-generator logs-generator --namespace=kubectl-2313 --tail=1 --timestamps'
Dec 18 12:53:09.128: INFO: stderr: ""
Dec 18 12:53:09.128: INFO: stdout: "2020-12-18T12:53:08.980264019Z I1218 12:53:08.980060       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/dcj 589\n"
Dec 18 12:53:09.128: INFO: got output "2020-12-18T12:53:08.980264019Z I1218 12:53:08.980060       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/dcj 589\n"
STEP: restricting to a time range
Dec 18 12:53:11.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 logs logs-generator logs-generator --namespace=kubectl-2313 --since=1s'
Dec 18 12:53:13.035: INFO: stderr: ""
Dec 18 12:53:13.036: INFO: stdout: "I1218 12:53:12.177579       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/default/pods/7jvs 537\nI1218 12:53:12.377593       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/kube-system/pods/2nlx 523\nI1218 12:53:12.577564       1 logs_generator.go:76] 28 GET /api/v1/namespaces/ns/pods/pd8f 313\nI1218 12:53:12.777563       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/kube-system/pods/klv 395\nI1218 12:53:12.977589       1 logs_generator.go:76] 30 GET /api/v1/namespaces/default/pods/9gn 228\n"
Dec 18 12:53:13.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 logs logs-generator logs-generator --namespace=kubectl-2313 --since=24h'
Dec 18 12:53:13.191: INFO: stderr: ""
Dec 18 12:53:13.191: INFO: stdout: "I1218 12:53:06.977442       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/txwd 547\nI1218 12:53:07.177653       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/xdm 540\nI1218 12:53:07.377663       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/4fnf 349\nI1218 12:53:07.577698       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/pzw 221\nI1218 12:53:07.777642       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/6nnd 500\nI1218 12:53:07.977616       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/nxjp 479\nI1218 12:53:08.177648       1 logs_generator.go:76] 6 GET /api/v1/namespaces/ns/pods/rsr 255\nI1218 12:53:08.377642       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/hmk 446\nI1218 12:53:08.577641       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/9k7 386\nI1218 12:53:08.777956       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/jz9 485\nI1218 12:53:08.980060       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/dcj 589\nI1218 12:53:09.177598       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/n6h 398\nI1218 12:53:09.377714       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/w47g 377\nI1218 12:53:09.577617       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/ldt 570\nI1218 12:53:09.778070       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/7cs 294\nI1218 12:53:09.977670       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/8ncr 480\nI1218 12:53:10.177935       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/vrn8 580\nI1218 12:53:10.377618       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/kgtl 535\nI1218 12:53:10.577726       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/pn4 231\nI1218 12:53:10.777606       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/kwzv 314\nI1218 12:53:10.978160       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/gbk 577\nI1218 12:53:11.177995       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/p5wb 488\nI1218 12:53:11.378017       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/pdj 455\nI1218 12:53:11.577664       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/kube-system/pods/wssd 508\nI1218 12:53:11.777585       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/zwqw 338\nI1218 12:53:11.977677       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/vqjz 598\nI1218 12:53:12.177579       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/default/pods/7jvs 537\nI1218 12:53:12.377593       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/kube-system/pods/2nlx 523\nI1218 12:53:12.577564       1 logs_generator.go:76] 28 GET /api/v1/namespaces/ns/pods/pd8f 313\nI1218 12:53:12.777563       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/kube-system/pods/klv 395\nI1218 12:53:12.977589       1 logs_generator.go:76] 30 GET /api/v1/namespaces/default/pods/9gn 228\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Dec 18 12:53:13.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete pod logs-generator --namespace=kubectl-2313'
Dec 18 12:53:16.439: INFO: stderr: ""
Dec 18 12:53:16.439: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:53:16.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2313" for this suite.

• [SLOW TEST:15.349 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1284
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":273,"completed":196,"skipped":3436,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:53:16.471: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8030
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:53:16.725: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:53:23.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8030" for this suite.

• [SLOW TEST:6.896 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":273,"completed":197,"skipped":3441,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:53:23.374: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1931
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1218 12:53:33.768221      21 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 18 12:53:33.768: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:53:33.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1931" for this suite.

• [SLOW TEST:10.420 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":273,"completed":198,"skipped":3458,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:53:33.797: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-170
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-9165b7b6-7a51-47dd-980a-14189cf172b4
STEP: Creating a pod to test consume configMaps
Dec 18 12:53:34.080: INFO: Waiting up to 5m0s for pod "pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c" in namespace "configmap-170" to be "Succeeded or Failed"
Dec 18 12:53:34.089: INFO: Pod "pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.089528ms
Dec 18 12:53:36.164: INFO: Pod "pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083617777s
Dec 18 12:53:38.175: INFO: Pod "pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093833531s
Dec 18 12:53:40.182: INFO: Pod "pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.101431653s
Dec 18 12:53:42.193: INFO: Pod "pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.11227437s
STEP: Saw pod success
Dec 18 12:53:42.193: INFO: Pod "pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c" satisfied condition "Succeeded or Failed"
Dec 18 12:53:42.203: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c container configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 12:53:42.274: INFO: Waiting for pod pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c to disappear
Dec 18 12:53:42.281: INFO: Pod pod-configmaps-f2c41521-870a-409d-8dd1-a95ed917d92c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:53:42.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-170" for this suite.

• [SLOW TEST:8.699 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":273,"completed":199,"skipped":3483,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:53:42.499: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:53:42.755: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 18 12:53:42.774: INFO: Number of nodes with available pods: 0
Dec 18 12:53:42.774: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 18 12:53:42.831: INFO: Number of nodes with available pods: 0
Dec 18 12:53:42.831: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:43.842: INFO: Number of nodes with available pods: 0
Dec 18 12:53:43.842: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:44.839: INFO: Number of nodes with available pods: 0
Dec 18 12:53:44.839: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:45.840: INFO: Number of nodes with available pods: 0
Dec 18 12:53:45.840: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:46.846: INFO: Number of nodes with available pods: 0
Dec 18 12:53:46.846: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:47.838: INFO: Number of nodes with available pods: 1
Dec 18 12:53:47.838: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 18 12:53:47.885: INFO: Number of nodes with available pods: 1
Dec 18 12:53:47.886: INFO: Number of running nodes: 0, number of available pods: 1
Dec 18 12:53:48.898: INFO: Number of nodes with available pods: 0
Dec 18 12:53:48.898: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 18 12:53:48.922: INFO: Number of nodes with available pods: 0
Dec 18 12:53:48.922: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:49.931: INFO: Number of nodes with available pods: 0
Dec 18 12:53:49.931: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:50.930: INFO: Number of nodes with available pods: 0
Dec 18 12:53:50.930: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:51.931: INFO: Number of nodes with available pods: 0
Dec 18 12:53:51.931: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:52.932: INFO: Number of nodes with available pods: 0
Dec 18 12:53:52.932: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:53.931: INFO: Number of nodes with available pods: 0
Dec 18 12:53:53.931: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:54.933: INFO: Number of nodes with available pods: 0
Dec 18 12:53:54.933: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:55.930: INFO: Number of nodes with available pods: 0
Dec 18 12:53:55.930: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:56.934: INFO: Number of nodes with available pods: 0
Dec 18 12:53:56.934: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:53:57.932: INFO: Number of nodes with available pods: 1
Dec 18 12:53:57.932: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3363, will wait for the garbage collector to delete the pods
Dec 18 12:53:58.029: INFO: Deleting DaemonSet.extensions daemon-set took: 24.03141ms
Dec 18 12:53:58.630: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.33862ms
Dec 18 12:54:07.240: INFO: Number of nodes with available pods: 0
Dec 18 12:54:07.240: INFO: Number of running nodes: 0, number of available pods: 0
Dec 18 12:54:07.248: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3363/daemonsets","resourceVersion":"106781"},"items":null}

Dec 18 12:54:07.261: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3363/pods","resourceVersion":"106781"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:54:07.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3363" for this suite.

• [SLOW TEST:24.868 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":273,"completed":200,"skipped":3490,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:54:07.368: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-3dfcd6d8-e636-41fe-8671-dce763f879a6
STEP: Creating a pod to test consume configMaps
Dec 18 12:54:07.594: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a" in namespace "projected-3090" to be "Succeeded or Failed"
Dec 18 12:54:07.608: INFO: Pod "pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.392765ms
Dec 18 12:54:09.617: INFO: Pod "pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02341398s
Dec 18 12:54:11.626: INFO: Pod "pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032507739s
Dec 18 12:54:13.640: INFO: Pod "pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.046589905s
Dec 18 12:54:15.649: INFO: Pod "pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.055160851s
STEP: Saw pod success
Dec 18 12:54:15.649: INFO: Pod "pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a" satisfied condition "Succeeded or Failed"
Dec 18 12:54:15.658: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 12:54:15.709: INFO: Waiting for pod pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a to disappear
Dec 18 12:54:15.716: INFO: Pod pod-projected-configmaps-baaae2d3-9565-4cb1-be84-e78d8b3c1f5a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:54:15.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3090" for this suite.

• [SLOW TEST:8.373 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":201,"skipped":3495,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:54:15.744: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 18 12:54:15.972: INFO: Waiting up to 5m0s for pod "downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3" in namespace "downward-api-7915" to be "Succeeded or Failed"
Dec 18 12:54:15.987: INFO: Pod "downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.0175ms
Dec 18 12:54:18.002: INFO: Pod "downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029073866s
Dec 18 12:54:20.010: INFO: Pod "downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037142547s
Dec 18 12:54:22.018: INFO: Pod "downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.045215548s
Dec 18 12:54:24.032: INFO: Pod "downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.060003825s
Dec 18 12:54:26.046: INFO: Pod "downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.073600789s
Dec 18 12:54:28.054: INFO: Pod "downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.081800089s
STEP: Saw pod success
Dec 18 12:54:28.054: INFO: Pod "downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3" satisfied condition "Succeeded or Failed"
Dec 18 12:54:28.063: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3 container dapi-container: <nil>
STEP: delete the pod
Dec 18 12:54:28.167: INFO: Waiting for pod downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3 to disappear
Dec 18 12:54:28.177: INFO: Pod downward-api-c84ed4ba-6748-41ba-b515-d15f45212bc3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:54:28.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7915" for this suite.

• [SLOW TEST:12.461 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":273,"completed":202,"skipped":3510,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:54:28.213: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8354
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-6904665b-461b-41ac-a6bb-bf737f74d2ce
STEP: Creating a pod to test consume secrets
Dec 18 12:54:28.434: INFO: Waiting up to 5m0s for pod "pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f" in namespace "secrets-8354" to be "Succeeded or Failed"
Dec 18 12:54:28.441: INFO: Pod "pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.920153ms
Dec 18 12:54:30.449: INFO: Pod "pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014865559s
Dec 18 12:54:32.457: INFO: Pod "pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023062912s
Dec 18 12:54:34.465: INFO: Pod "pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031120862s
Dec 18 12:54:36.475: INFO: Pod "pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.041184427s
STEP: Saw pod success
Dec 18 12:54:36.475: INFO: Pod "pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f" satisfied condition "Succeeded or Failed"
Dec 18 12:54:36.482: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f container secret-volume-test: <nil>
STEP: delete the pod
Dec 18 12:54:36.568: INFO: Waiting for pod pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f to disappear
Dec 18 12:54:36.577: INFO: Pod pod-secrets-dfe645f5-98bb-47f5-b5ef-5c4359c9c69f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:54:36.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8354" for this suite.

• [SLOW TEST:8.392 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":273,"completed":203,"skipped":3542,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:54:36.605: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7971
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Dec 18 12:54:36.866: INFO: Waiting up to 5m0s for pod "var-expansion-ec66b1a5-18f7-4b87-b216-9cddd592dde1" in namespace "var-expansion-7971" to be "Succeeded or Failed"
Dec 18 12:54:36.874: INFO: Pod "var-expansion-ec66b1a5-18f7-4b87-b216-9cddd592dde1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.120565ms
Dec 18 12:54:38.888: INFO: Pod "var-expansion-ec66b1a5-18f7-4b87-b216-9cddd592dde1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021505336s
Dec 18 12:54:40.896: INFO: Pod "var-expansion-ec66b1a5-18f7-4b87-b216-9cddd592dde1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029453199s
Dec 18 12:54:42.906: INFO: Pod "var-expansion-ec66b1a5-18f7-4b87-b216-9cddd592dde1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039394506s
STEP: Saw pod success
Dec 18 12:54:42.906: INFO: Pod "var-expansion-ec66b1a5-18f7-4b87-b216-9cddd592dde1" satisfied condition "Succeeded or Failed"
Dec 18 12:54:42.913: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod var-expansion-ec66b1a5-18f7-4b87-b216-9cddd592dde1 container dapi-container: <nil>
STEP: delete the pod
Dec 18 12:54:42.966: INFO: Waiting for pod var-expansion-ec66b1a5-18f7-4b87-b216-9cddd592dde1 to disappear
Dec 18 12:54:42.973: INFO: Pod var-expansion-ec66b1a5-18f7-4b87-b216-9cddd592dde1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:54:42.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7971" for this suite.

• [SLOW TEST:6.392 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":273,"completed":204,"skipped":3557,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:54:42.998: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2332
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-2332
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Dec 18 12:54:43.245: INFO: Found 0 stateful pods, waiting for 3
Dec 18 12:54:53.257: INFO: Found 2 stateful pods, waiting for 3
Dec 18 12:55:03.258: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:55:03.258: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:55:03.258: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 18 12:55:03.341: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 18 12:55:13.518: INFO: Updating stateful set ss2
Dec 18 12:55:13.606: INFO: Waiting for Pod statefulset-2332/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec 18 12:55:23.840: INFO: Found 2 stateful pods, waiting for 3
Dec 18 12:55:33.851: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:55:33.851: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:55:33.851: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Dec 18 12:55:43.854: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:55:43.854: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 12:55:43.854: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 18 12:55:43.904: INFO: Updating stateful set ss2
Dec 18 12:55:43.927: INFO: Waiting for Pod statefulset-2332/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 18 12:55:53.977: INFO: Updating stateful set ss2
Dec 18 12:55:53.999: INFO: Waiting for StatefulSet statefulset-2332/ss2 to complete update
Dec 18 12:55:53.999: INFO: Waiting for Pod statefulset-2332/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 18 12:56:04.053: INFO: Deleting all statefulset in ns statefulset-2332
Dec 18 12:56:04.061: INFO: Scaling statefulset ss2 to 0
Dec 18 12:56:34.100: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 12:56:34.108: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:56:34.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2332" for this suite.

• [SLOW TEST:111.191 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":273,"completed":205,"skipped":3574,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:56:34.191: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3796
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Dec 18 12:56:34.439: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-185975894 proxy --unix-socket=/tmp/kubectl-proxy-unix036790401/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:56:34.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3796" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":273,"completed":206,"skipped":3590,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:56:34.539: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 18 12:56:34.855: INFO: Number of nodes with available pods: 0
Dec 18 12:56:34.855: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:56:35.876: INFO: Number of nodes with available pods: 0
Dec 18 12:56:35.876: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:56:36.877: INFO: Number of nodes with available pods: 0
Dec 18 12:56:36.877: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:56:37.877: INFO: Number of nodes with available pods: 0
Dec 18 12:56:37.877: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:56:38.878: INFO: Number of nodes with available pods: 0
Dec 18 12:56:38.878: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 12:56:39.876: INFO: Number of nodes with available pods: 2
Dec 18 12:56:39.876: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl is running more than one daemon pod
Dec 18 12:56:40.875: INFO: Number of nodes with available pods: 3
Dec 18 12:56:40.875: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 18 12:56:40.934: INFO: Number of nodes with available pods: 2
Dec 18 12:56:40.934: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 12:56:41.957: INFO: Number of nodes with available pods: 2
Dec 18 12:56:41.957: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 12:56:42.961: INFO: Number of nodes with available pods: 2
Dec 18 12:56:42.962: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 12:56:43.951: INFO: Number of nodes with available pods: 2
Dec 18 12:56:43.951: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 12:56:44.955: INFO: Number of nodes with available pods: 2
Dec 18 12:56:44.955: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 12:56:45.955: INFO: Number of nodes with available pods: 2
Dec 18 12:56:45.955: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 12:56:46.954: INFO: Number of nodes with available pods: 2
Dec 18 12:56:46.954: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 12:56:47.958: INFO: Number of nodes with available pods: 2
Dec 18 12:56:47.958: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 12:56:48.952: INFO: Number of nodes with available pods: 3
Dec 18 12:56:48.952: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1960, will wait for the garbage collector to delete the pods
Dec 18 12:56:49.034: INFO: Deleting DaemonSet.extensions daemon-set took: 18.29903ms
Dec 18 12:56:49.134: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.371337ms
Dec 18 12:56:57.141: INFO: Number of nodes with available pods: 0
Dec 18 12:56:57.141: INFO: Number of running nodes: 0, number of available pods: 0
Dec 18 12:56:57.148: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1960/daemonsets","resourceVersion":"108235"},"items":null}

Dec 18 12:56:57.156: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1960/pods","resourceVersion":"108235"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:56:57.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1960" for this suite.

• [SLOW TEST:22.681 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":273,"completed":207,"skipped":3601,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:56:57.224: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:57:08.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2581" for this suite.

• [SLOW TEST:11.000 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":273,"completed":208,"skipped":3617,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:57:08.235: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9154
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:57:09.046: INFO: Creating deployment "webserver-deployment"
Dec 18 12:57:09.143: INFO: Waiting for observed generation 1
Dec 18 12:57:11.161: INFO: Waiting for all required pods to come up
Dec 18 12:57:11.170: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 18 12:57:23.285: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 18 12:57:23.303: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 18 12:57:23.327: INFO: Updating deployment webserver-deployment
Dec 18 12:57:23.327: INFO: Waiting for observed generation 2
Dec 18 12:57:25.412: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 18 12:57:25.423: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 18 12:57:25.430: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 18 12:57:25.450: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 18 12:57:25.450: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 18 12:57:25.457: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 18 12:57:25.471: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 18 12:57:25.471: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 18 12:57:25.490: INFO: Updating deployment webserver-deployment
Dec 18 12:57:25.491: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 18 12:57:25.505: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 18 12:57:25.516: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Dec 18 12:57:27.559: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9154 /apis/apps/v1/namespaces/deployment-9154/deployments/webserver-deployment 2282233d-31a0-4951-ba64-eabd95483525 108721 3 2020-12-18 12:57:09 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00220b7f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-12-18 12:57:25 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-12-18 12:57:25 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 18 12:57:27.569: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-9154 /apis/apps/v1/namespaces/deployment-9154/replicasets/webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 108717 3 2020-12-18 12:57:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 2282233d-31a0-4951-ba64-eabd95483525 0xc00220bfc7 0xc00220bfc8}] []  [{kube-controller-manager Update apps/v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 50 56 50 50 51 51 100 45 51 49 97 48 45 52 57 53 49 45 98 97 54 52 45 101 97 98 100 57 53 52 56 51 53 50 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004d3c048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 18 12:57:27.569: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 18 12:57:27.569: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-9154 /apis/apps/v1/namespaces/deployment-9154/replicasets/webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 108714 3 2020-12-18 12:57:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 2282233d-31a0-4951-ba64-eabd95483525 0xc004d3c0a7 0xc004d3c0a8}] []  [{kube-controller-manager Update apps/v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 50 56 50 50 51 51 100 45 51 49 97 48 45 52 57 53 49 45 98 97 54 52 45 101 97 98 100 57 53 52 56 51 53 50 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004d3c118 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 18 12:57:27.593: INFO: Pod "webserver-deployment-6676bcd6d4-2mmq6" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-2mmq6 webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-2mmq6 6cf725cc-0257-4efc-8743-da921f38cf8b 108631 0 2020-12-18 12:57:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc007187837 0xc007187838}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:,StartTime:2020-12-18 12:57:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.594: INFO: Pod "webserver-deployment-6676bcd6d4-87qv8" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-87qv8 webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-87qv8 b9708b2a-9a53-4007-86dd-a746f6940bf0 108736 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc007187a10 0xc007187a11}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:26 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:,StartTime:2020-12-18 12:57:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.594: INFO: Pod "webserver-deployment-6676bcd6d4-hkzzw" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-hkzzw webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-hkzzw 3c3a4dde-3e1d-4280-8813-7e9ecc803436 108729 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc007187bd0 0xc007187bd1}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.595: INFO: Pod "webserver-deployment-6676bcd6d4-js4bh" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-js4bh webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-js4bh 0907ef6a-df26-42db-b53c-1d8906c91eb4 108751 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc007187d70 0xc007187d71}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:26 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:,StartTime:2020-12-18 12:57:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.595: INFO: Pod "webserver-deployment-6676bcd6d4-l7mnh" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-l7mnh webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-l7mnh 4ce44f7f-b47c-43b7-82b0-3eed194a46fc 108630 0 2020-12-18 12:57:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc007187f00 0xc007187f01}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:,StartTime:2020-12-18 12:57:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.596: INFO: Pod "webserver-deployment-6676bcd6d4-prsvv" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-prsvv webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-prsvv b4516f46-3f0b-4fed-9337-3b5512baab9d 108686 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc00548c0b0 0xc00548c0b1}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.596: INFO: Pod "webserver-deployment-6676bcd6d4-rqgr8" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-rqgr8 webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-rqgr8 bddb277b-4a19-4c49-b9b9-f508fdc1ba8b 108724 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc00548c1e0 0xc00548c1e1}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.597: INFO: Pod "webserver-deployment-6676bcd6d4-sr4lq" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-sr4lq webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-sr4lq cf7e57b6-08d3-4fae-9ebc-05439e6be921 108757 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc00548c370 0xc00548c371}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:27 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:,StartTime:2020-12-18 12:57:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.597: INFO: Pod "webserver-deployment-6676bcd6d4-ttkwb" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-ttkwb webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-ttkwb 2de32175-162d-4914-b368-e6175c12ffc2 108624 0 2020-12-18 12:57:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc00548c500 0xc00548c501}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:,StartTime:2020-12-18 12:57:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.598: INFO: Pod "webserver-deployment-6676bcd6d4-v8r92" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-v8r92 webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-v8r92 db205df5-845e-4582-9f20-1f8af08dbe22 108604 0 2020-12-18 12:57:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc00548c6b0 0xc00548c6b1}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:,StartTime:2020-12-18 12:57:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.598: INFO: Pod "webserver-deployment-6676bcd6d4-vcmhj" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-vcmhj webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-vcmhj 249aa417-2a5c-4dd4-a8ad-d0db6cc0cd2c 108709 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc00548c850 0xc00548c851}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.599: INFO: Pod "webserver-deployment-6676bcd6d4-xn4fd" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-xn4fd webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-xn4fd a823f812-2409-42ba-a8e1-47238cfa5cd9 108723 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc00548c980 0xc00548c981}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.599: INFO: Pod "webserver-deployment-6676bcd6d4-zp8xt" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-zp8xt webserver-deployment-6676bcd6d4- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-6676bcd6d4-zp8xt c42af8dc-033c-4e5f-8e06-007b2c7442f9 108621 0 2020-12-18 12:57:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 5eb704cc-d7cd-49b3-9581-a29f8f4134d4 0xc00548cb10 0xc00548cb11}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 101 98 55 48 52 99 99 45 100 55 99 100 45 52 57 98 51 45 57 53 56 49 45 97 50 57 102 56 102 52 49 51 52 100 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:23 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:,StartTime:2020-12-18 12:57:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.600: INFO: Pod "webserver-deployment-84855cf797-5dz9x" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-5dz9x webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-5dz9x edd33e48-9fcd-4937-80b7-cb4b77242905 108511 0 2020-12-18 12:57:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.2.121/32 cni.projectcalico.org/podIPs:172.25.2.121/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548cce0 0xc00548cce1}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:57:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 50 46 49 50 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:172.25.2.121,StartTime:2020-12-18 12:57:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:57:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://09edc802ef24ebb45628a5fcbb8e6a2175dd74524aeb887595ac7a2e7db8bfbb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.2.121,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.600: INFO: Pod "webserver-deployment-84855cf797-6fzw5" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-6fzw5 webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-6fzw5 0015cb99-5c71-4215-b065-3c85a44b7195 108730 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548ce97 0xc00548ce98}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.601: INFO: Pod "webserver-deployment-84855cf797-9h9hl" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9h9hl webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-9h9hl c2b5ae31-e6b4-4eef-a28e-a77b5189880a 108750 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548d017 0xc00548d018}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:26 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:,StartTime:2020-12-18 12:57:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.602: INFO: Pod "webserver-deployment-84855cf797-9jrq7" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9jrq7 webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-9jrq7 38007894-fdb9-43af-b0aa-e1b356d40318 108759 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548d1a7 0xc00548d1a8}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:27 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:,StartTime:2020-12-18 12:57:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.606: INFO: Pod "webserver-deployment-84855cf797-dvdp5" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-dvdp5 webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-dvdp5 c0c3a0c1-9d95-40a6-86aa-693339b7edda 108733 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548d327 0xc00548d328}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.607: INFO: Pod "webserver-deployment-84855cf797-h2h8v" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-h2h8v webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-h2h8v 8908d1fa-c071-47ab-a477-bd5261cbfcb5 108739 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548d4a7 0xc00548d4a8}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:26 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.607: INFO: Pod "webserver-deployment-84855cf797-hntfh" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-hntfh webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-hntfh a64cf149-5224-418a-803a-f143dbaa0589 108693 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548d627 0xc00548d628}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.608: INFO: Pod "webserver-deployment-84855cf797-jfcfw" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-jfcfw webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-jfcfw 16a7c6e5-5127-4961-845f-c4b210fc6902 108725 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548d740 0xc00548d741}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.608: INFO: Pod "webserver-deployment-84855cf797-kztpw" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-kztpw webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-kztpw c9166cd5-034b-4837-b48f-df9f08396b64 108560 0 2020-12-18 12:57:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.1.237/32 cni.projectcalico.org/podIPs:172.25.1.237/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548d8d7 0xc00548d8d8}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:57:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:21 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 49 46 50 51 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:172.25.1.237,StartTime:2020-12-18 12:57:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:57:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2d3d643497f01d9aadf82bae711233a43868296a70b29799134fbf2597eceabc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.237,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.609: INFO: Pod "webserver-deployment-84855cf797-l4bkv" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-l4bkv webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-l4bkv 88214c94-5569-41f4-806b-8e709f2c2998 108727 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548da87 0xc00548da88}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.609: INFO: Pod "webserver-deployment-84855cf797-lcgcd" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-lcgcd webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-lcgcd afc355e2-6d58-40e9-8e6f-71f10e547b6c 108520 0 2020-12-18 12:57:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.0.67/32 cni.projectcalico.org/podIPs:172.25.0.67/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548dc27 0xc00548dc28}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:10 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:57:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 48 46 54 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:172.25.0.67,StartTime:2020-12-18 12:57:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:57:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://785972bfa19c17921cbf2a1613dcbc31837eddab789c927e1a9c4640f0db0333,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.0.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.610: INFO: Pod "webserver-deployment-84855cf797-lk5nq" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-lk5nq webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-lk5nq 35385399-1fb2-4fa7-aad2-de214a5a8adf 108718 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548ddd7 0xc00548ddd8}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.610: INFO: Pod "webserver-deployment-84855cf797-lrnjp" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-lrnjp webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-lrnjp 05384c4d-b9cc-4551-b1ec-38e2c49c0e8c 108565 0 2020-12-18 12:57:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.1.234/32 cni.projectcalico.org/podIPs:172.25.1.234/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00548df77 0xc00548df78}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:57:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:21 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 49 46 50 51 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:172.25.1.234,StartTime:2020-12-18 12:57:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:57:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://822217e3629e80ca7749c1cf27ac856bafd51200ea8d7d6ea4294f08dc26d49e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.1.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.611: INFO: Pod "webserver-deployment-84855cf797-nz7mx" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-nz7mx webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-nz7mx 81a8c24f-d1c2-45ba-934d-63503510da08 108728 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00696a127 0xc00696a128}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.611: INFO: Pod "webserver-deployment-84855cf797-pshz9" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-pshz9 webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-pshz9 f42a7ba8-b7a9-41f4-871b-de93c335e080 108491 0 2020-12-18 12:57:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.2.120/32 cni.projectcalico.org/podIPs:172.25.2.120/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00696a2c7 0xc00696a2c8}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:57:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 50 46 49 50 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:172.25.2.120,StartTime:2020-12-18 12:57:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:57:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f464a13fdb346db304751a46e19cebd74c7d17d210ec6cb07cad74ef33f05d81,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.2.120,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.612: INFO: Pod "webserver-deployment-84855cf797-rthzh" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rthzh webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-rthzh d93d0aff-e10c-4871-9e5c-d5a1582ede78 108731 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00696a487 0xc00696a488}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.2,PodIP:,StartTime:2020-12-18 12:57:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.612: INFO: Pod "webserver-deployment-84855cf797-tclfx" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-tclfx webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-tclfx 91d320bd-bf92-4569-9324-3ac15bfc9c3e 108513 0 2020-12-18 12:57:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.2.122/32 cni.projectcalico.org/podIPs:172.25.2.122/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00696a627 0xc00696a628}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:57:14 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 50 46 49 50 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-4p69r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.7,PodIP:172.25.2.122,StartTime:2020-12-18 12:57:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:57:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://76f713dc8a6c509e80c9ec048a9adc026f973b14eea2eaa1653a05a16be886ae,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.2.122,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.613: INFO: Pod "webserver-deployment-84855cf797-xjpqw" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-xjpqw webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-xjpqw 3488e2c5-daa3-4e53-a168-2d0184cdb5d8 108526 0 2020-12-18 12:57:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.0.66/32 cni.projectcalico.org/podIPs:172.25.0.66/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00696a7f7 0xc00696a7f8}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:57:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 48 46 54 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:172.25.0.66,StartTime:2020-12-18 12:57:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:57:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a9b4bf506b7f703ccc35c29642db7c856ebed42264a3548dc34569dc718fc995,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.0.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.613: INFO: Pod "webserver-deployment-84855cf797-xp8gv" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-xp8gv webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-xp8gv 7d3a195b-f599-49b7-bbdc-9c394ddd9b03 108694 0 2020-12-18 12:57:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00696a9a7 0xc00696a9a8}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:25 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-t45gl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 12:57:27.613: INFO: Pod "webserver-deployment-84855cf797-z5l25" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-z5l25 webserver-deployment-84855cf797- deployment-9154 /api/v1/namespaces/deployment-9154/pods/webserver-deployment-84855cf797-z5l25 86b36d4b-162b-423b-9cd3-345a5b3b5799 108523 0 2020-12-18 12:57:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[cni.projectcalico.org/podIP:172.25.0.68/32 cni.projectcalico.org/podIPs:172.25.0.68/32] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 0b8d52c0-c6db-4548-ab09-656d2c9414b8 0xc00696aae0 0xc00696aae1}] []  [{kube-controller-manager Update v1 2020-12-18 12:57:09 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 48 98 56 100 53 50 99 48 45 99 54 100 98 45 52 53 52 56 45 97 98 48 57 45 54 53 54 100 50 99 57 52 49 52 98 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {calico Update v1 2020-12-18 12:57:15 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 34 58 123 125 44 34 102 58 99 110 105 46 112 114 111 106 101 99 116 99 97 108 105 99 111 46 111 114 103 47 112 111 100 73 80 115 34 58 123 125 125 125 125],}} {kubelet Update v1 2020-12-18 12:57:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 53 46 48 46 54 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l7czf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l7czf,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l7czf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-12-18 12:57:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.1.9,PodIP:172.25.0.68,StartTime:2020-12-18 12:57:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-12-18 12:57:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://16814d1f3e6e3dbceaee24f7b78ff1166853a38c0ca08451954f139fe6c24f5a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.25.0.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:57:27.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9154" for this suite.

• [SLOW TEST:19.407 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":273,"completed":209,"skipped":3654,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:57:27.643: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3742
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:57:27.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 version'
Dec 18 12:57:28.149: INFO: stderr: ""
Dec 18 12:57:28.149: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.8\", GitCommit:\"9f2892aab98fe339f3bd70e3c470144299398ace\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T16:12:48Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.8\", GitCommit:\"9f2892aab98fe339f3bd70e3c470144299398ace\", GitTreeState:\"clean\", BuildDate:\"2020-08-13T16:04:18Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:57:28.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3742" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":273,"completed":210,"skipped":3667,"failed":0}
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:57:28.173: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 18 12:57:28.456: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 18 12:57:33.465: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:57:34.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6911" for this suite.

• [SLOW TEST:6.366 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":273,"completed":211,"skipped":3669,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:57:34.542: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9752
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-7df61ca7-89b9-461d-ab97-31eee412faef
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:57:34.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9752" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":273,"completed":212,"skipped":3691,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:57:34.810: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9976
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4250
STEP: Creating secret with name secret-test-5fc28796-9085-4bfc-878b-6cf21091eca7
STEP: Creating a pod to test consume secrets
Dec 18 12:57:35.420: INFO: Waiting up to 5m0s for pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32" in namespace "secrets-9976" to be "Succeeded or Failed"
Dec 18 12:57:35.462: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 42.416181ms
Dec 18 12:57:37.472: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052621734s
Dec 18 12:57:39.489: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069235067s
Dec 18 12:57:41.498: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 6.078239425s
Dec 18 12:57:43.506: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 8.086432342s
Dec 18 12:57:45.515: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 10.095615797s
Dec 18 12:57:47.523: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 12.102904407s
Dec 18 12:57:49.541: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 14.121695453s
Dec 18 12:57:51.550: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 16.12991819s
Dec 18 12:57:53.558: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 18.138221612s
Dec 18 12:57:55.566: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Pending", Reason="", readiness=false. Elapsed: 20.14673129s
Dec 18 12:57:57.581: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.161738068s
STEP: Saw pod success
Dec 18 12:57:57.582: INFO: Pod "pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32" satisfied condition "Succeeded or Failed"
Dec 18 12:57:57.589: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32 container secret-volume-test: <nil>
STEP: delete the pod
Dec 18 12:57:57.694: INFO: Waiting for pod pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32 to disappear
Dec 18 12:57:57.699: INFO: Pod pod-secrets-1d0ba79b-03ab-48d1-81a1-27f2beea4b32 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:57:57.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9976" for this suite.
STEP: Destroying namespace "secret-namespace-4250" for this suite.

• [SLOW TEST:22.933 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":273,"completed":213,"skipped":3703,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:57:57.744: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2799
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 18 12:57:58.044: INFO: Waiting up to 5m0s for pod "pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a" in namespace "emptydir-2799" to be "Succeeded or Failed"
Dec 18 12:57:58.084: INFO: Pod "pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 40.132732ms
Dec 18 12:58:00.093: INFO: Pod "pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048762304s
Dec 18 12:58:02.103: INFO: Pod "pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059146027s
Dec 18 12:58:04.119: INFO: Pod "pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.074985477s
Dec 18 12:58:06.133: INFO: Pod "pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.089292382s
Dec 18 12:58:08.143: INFO: Pod "pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.099032871s
STEP: Saw pod success
Dec 18 12:58:08.143: INFO: Pod "pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a" satisfied condition "Succeeded or Failed"
Dec 18 12:58:08.151: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a container test-container: <nil>
STEP: delete the pod
Dec 18 12:58:08.197: INFO: Waiting for pod pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a to disappear
Dec 18 12:58:08.204: INFO: Pod pod-89b6e747-31e0-4694-a954-d0c9ee6ecc7a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:58:08.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2799" for this suite.

• [SLOW TEST:10.480 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":214,"skipped":3721,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:58:08.225: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 18 12:58:08.489: INFO: Waiting up to 5m0s for pod "pod-9931df45-656e-4f31-a51a-28371ab67349" in namespace "emptydir-4257" to be "Succeeded or Failed"
Dec 18 12:58:08.500: INFO: Pod "pod-9931df45-656e-4f31-a51a-28371ab67349": Phase="Pending", Reason="", readiness=false. Elapsed: 10.812262ms
Dec 18 12:58:10.515: INFO: Pod "pod-9931df45-656e-4f31-a51a-28371ab67349": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026694883s
Dec 18 12:58:12.526: INFO: Pod "pod-9931df45-656e-4f31-a51a-28371ab67349": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036931164s
Dec 18 12:58:14.647: INFO: Pod "pod-9931df45-656e-4f31-a51a-28371ab67349": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.158112942s
STEP: Saw pod success
Dec 18 12:58:14.647: INFO: Pod "pod-9931df45-656e-4f31-a51a-28371ab67349" satisfied condition "Succeeded or Failed"
Dec 18 12:58:14.662: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-9931df45-656e-4f31-a51a-28371ab67349 container test-container: <nil>
STEP: delete the pod
Dec 18 12:58:15.031: INFO: Waiting for pod pod-9931df45-656e-4f31-a51a-28371ab67349 to disappear
Dec 18 12:58:15.045: INFO: Pod pod-9931df45-656e-4f31-a51a-28371ab67349 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:58:15.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4257" for this suite.

• [SLOW TEST:7.181 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":215,"skipped":3729,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:58:15.407: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6236
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 12:58:16.729: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893096, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893096, loc:(*time.Location)(0x7b565c0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-779fdc84d9\""}}, CollisionCount:(*int32)(nil)}
Dec 18 12:58:18.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893096, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893096, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893097, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893096, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 12:58:20.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893096, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893096, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893097, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743893096, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 12:58:23.778: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 18 12:58:29.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 attach --namespace=webhook-6236 to-be-attached-pod -i -c=container1'
Dec 18 12:58:30.082: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:58:30.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6236" for this suite.
STEP: Destroying namespace "webhook-6236-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:14.838 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":273,"completed":216,"skipped":3749,"failed":0}
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:58:30.246: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-347
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Dec 18 12:58:39.071: INFO: Successfully updated pod "labelsupdate24878d56-4032-418a-8222-7bb91c6372ff"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:58:41.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-347" for this suite.

• [SLOW TEST:10.903 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":273,"completed":217,"skipped":3749,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:58:41.156: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9722
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 18 12:58:41.385: INFO: Waiting up to 5m0s for pod "pod-58e8a413-6a36-4c47-bee9-f891bf05f480" in namespace "emptydir-9722" to be "Succeeded or Failed"
Dec 18 12:58:41.392: INFO: Pod "pod-58e8a413-6a36-4c47-bee9-f891bf05f480": Phase="Pending", Reason="", readiness=false. Elapsed: 6.78724ms
Dec 18 12:58:43.399: INFO: Pod "pod-58e8a413-6a36-4c47-bee9-f891bf05f480": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01388412s
Dec 18 12:58:45.408: INFO: Pod "pod-58e8a413-6a36-4c47-bee9-f891bf05f480": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023035036s
Dec 18 12:58:47.416: INFO: Pod "pod-58e8a413-6a36-4c47-bee9-f891bf05f480": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031119425s
Dec 18 12:58:49.431: INFO: Pod "pod-58e8a413-6a36-4c47-bee9-f891bf05f480": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.045737306s
STEP: Saw pod success
Dec 18 12:58:49.431: INFO: Pod "pod-58e8a413-6a36-4c47-bee9-f891bf05f480" satisfied condition "Succeeded or Failed"
Dec 18 12:58:49.454: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-58e8a413-6a36-4c47-bee9-f891bf05f480 container test-container: <nil>
STEP: delete the pod
Dec 18 12:58:49.539: INFO: Waiting for pod pod-58e8a413-6a36-4c47-bee9-f891bf05f480 to disappear
Dec 18 12:58:49.556: INFO: Pod pod-58e8a413-6a36-4c47-bee9-f891bf05f480 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:58:49.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9722" for this suite.

• [SLOW TEST:8.465 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":218,"skipped":3786,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:58:49.626: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8524
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 12:58:49.869: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-9bb3d525-1529-4d8d-b8e7-8b4e0c8867db" in namespace "security-context-test-8524" to be "Succeeded or Failed"
Dec 18 12:58:49.874: INFO: Pod "busybox-privileged-false-9bb3d525-1529-4d8d-b8e7-8b4e0c8867db": Phase="Pending", Reason="", readiness=false. Elapsed: 5.476082ms
Dec 18 12:58:51.883: INFO: Pod "busybox-privileged-false-9bb3d525-1529-4d8d-b8e7-8b4e0c8867db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014657407s
Dec 18 12:58:53.895: INFO: Pod "busybox-privileged-false-9bb3d525-1529-4d8d-b8e7-8b4e0c8867db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026592052s
Dec 18 12:58:55.903: INFO: Pod "busybox-privileged-false-9bb3d525-1529-4d8d-b8e7-8b4e0c8867db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033915914s
Dec 18 12:58:57.915: INFO: Pod "busybox-privileged-false-9bb3d525-1529-4d8d-b8e7-8b4e0c8867db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.045821069s
Dec 18 12:58:57.915: INFO: Pod "busybox-privileged-false-9bb3d525-1529-4d8d-b8e7-8b4e0c8867db" satisfied condition "Succeeded or Failed"
Dec 18 12:58:57.938: INFO: Got logs for pod "busybox-privileged-false-9bb3d525-1529-4d8d-b8e7-8b4e0c8867db": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:58:57.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8524" for this suite.

• [SLOW TEST:8.344 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  When creating a pod with privileged
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:227
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":219,"skipped":3838,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:58:57.970: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9179
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 18 12:58:58.204: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 12:59:02.000: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:59:17.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9179" for this suite.

• [SLOW TEST:19.214 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":273,"completed":220,"skipped":3840,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:59:17.185: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 12:59:17.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d" in namespace "projected-9934" to be "Succeeded or Failed"
Dec 18 12:59:17.424: INFO: Pod "downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.738196ms
Dec 18 12:59:19.441: INFO: Pod "downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022674884s
Dec 18 12:59:21.450: INFO: Pod "downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031370646s
Dec 18 12:59:23.458: INFO: Pod "downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03966965s
Dec 18 12:59:25.466: INFO: Pod "downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.047273436s
STEP: Saw pod success
Dec 18 12:59:25.466: INFO: Pod "downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d" satisfied condition "Succeeded or Failed"
Dec 18 12:59:25.474: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d container client-container: <nil>
STEP: delete the pod
Dec 18 12:59:25.558: INFO: Waiting for pod downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d to disappear
Dec 18 12:59:25.568: INFO: Pod downwardapi-volume-1ec62307-9939-492c-b6af-c29c5b72029d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:59:25.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9934" for this suite.

• [SLOW TEST:8.410 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":273,"completed":221,"skipped":3851,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:59:25.597: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7042
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7042.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7042.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7042.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7042.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7042.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7042.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7042.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7042.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7042.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7042.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7042.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 172.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.172_udp@PTR;check="$$(dig +tcp +noall +answer +search 172.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.172_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7042.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7042.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7042.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7042.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7042.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7042.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7042.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7042.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7042.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7042.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7042.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 172.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.172_udp@PTR;check="$$(dig +tcp +noall +answer +search 172.22.240.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.240.22.172_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 18 12:59:41.975: INFO: Unable to read wheezy_udp@dns-test-service.dns-7042.svc.cluster.local from pod dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5: the server could not find the requested resource (get pods dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5)
Dec 18 12:59:42.019: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7042.svc.cluster.local from pod dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5: the server could not find the requested resource (get pods dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5)
Dec 18 12:59:42.045: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local from pod dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5: the server could not find the requested resource (get pods dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5)
Dec 18 12:59:42.066: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local from pod dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5: the server could not find the requested resource (get pods dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5)
Dec 18 12:59:42.343: INFO: Unable to read jessie_udp@dns-test-service.dns-7042.svc.cluster.local from pod dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5: the server could not find the requested resource (get pods dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5)
Dec 18 12:59:42.360: INFO: Unable to read jessie_tcp@dns-test-service.dns-7042.svc.cluster.local from pod dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5: the server could not find the requested resource (get pods dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5)
Dec 18 12:59:42.376: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local from pod dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5: the server could not find the requested resource (get pods dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5)
Dec 18 12:59:42.391: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local from pod dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5: the server could not find the requested resource (get pods dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5)
Dec 18 12:59:42.617: INFO: Lookups using dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5 failed for: [wheezy_udp@dns-test-service.dns-7042.svc.cluster.local wheezy_tcp@dns-test-service.dns-7042.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local jessie_udp@dns-test-service.dns-7042.svc.cluster.local jessie_tcp@dns-test-service.dns-7042.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7042.svc.cluster.local]

Dec 18 12:59:48.306: INFO: DNS probes using dns-7042/dns-test-44e0976f-c98b-4a17-a0eb-3546af13abc5 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:59:48.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7042" for this suite.

• [SLOW TEST:22.940 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":273,"completed":222,"skipped":3873,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:59:48.539: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2468
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 12:59:48.783: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659" in namespace "downward-api-2468" to be "Succeeded or Failed"
Dec 18 12:59:48.794: INFO: Pod "downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659": Phase="Pending", Reason="", readiness=false. Elapsed: 10.839193ms
Dec 18 12:59:50.806: INFO: Pod "downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02290437s
Dec 18 12:59:52.813: INFO: Pod "downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030544279s
Dec 18 12:59:54.824: INFO: Pod "downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040715188s
Dec 18 12:59:56.833: INFO: Pod "downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.049764289s
STEP: Saw pod success
Dec 18 12:59:56.833: INFO: Pod "downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659" satisfied condition "Succeeded or Failed"
Dec 18 12:59:56.843: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659 container client-container: <nil>
STEP: delete the pod
Dec 18 12:59:56.912: INFO: Waiting for pod downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659 to disappear
Dec 18 12:59:56.926: INFO: Pod downwardapi-volume-3a32957a-9010-4f4e-8274-43a2f7034659 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 12:59:56.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2468" for this suite.

• [SLOW TEST:8.412 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":273,"completed":223,"skipped":3878,"failed":0}
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 12:59:56.955: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1153
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1153
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-1153
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1153
Dec 18 12:59:57.210: INFO: Found 0 stateful pods, waiting for 1
Dec 18 13:00:07.223: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 18 13:00:07.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 13:00:09.258: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 13:00:09.258: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 13:00:09.258: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 18 13:00:09.266: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 18 13:00:19.283: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 18 13:00:19.283: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 13:00:19.327: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:19.328: INFO: ss-0  stoic-bose-worker-s2lnv-655cc5dcbf-t45gl  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:09 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:09 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  }]
Dec 18 13:00:19.328: INFO: 
Dec 18 13:00:19.328: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 18 13:00:20.340: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985115393s
Dec 18 13:00:21.349: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.974103129s
Dec 18 13:00:22.363: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.96504376s
Dec 18 13:00:23.374: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.950560541s
Dec 18 13:00:24.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.939954457s
Dec 18 13:00:25.404: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.928170188s
Dec 18 13:00:26.417: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.910046679s
Dec 18 13:00:27.427: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.896641644s
Dec 18 13:00:28.434: INFO: Verifying statefulset ss doesn't scale past 3 for another 887.080084ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1153
Dec 18 13:00:29.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:00:29.976: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 18 13:00:29.976: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 18 13:00:29.976: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 18 13:00:29.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:00:30.605: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 18 13:00:30.605: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 18 13:00:30.605: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 18 13:00:30.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:00:31.097: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 18 13:00:31.097: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 18 13:00:31.097: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 18 13:00:31.110: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 13:00:31.110: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 13:00:31.110: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 18 13:00:31.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 13:00:31.660: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 13:00:31.660: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 13:00:31.660: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 18 13:00:31.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 13:00:32.290: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 13:00:32.290: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 13:00:32.290: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 18 13:00:32.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 13:00:32.835: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 13:00:32.835: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 13:00:32.835: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 18 13:00:32.835: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 13:00:32.863: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec 18 13:00:42.889: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 18 13:00:42.889: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 18 13:00:42.889: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 18 13:00:42.964: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:42.964: INFO: ss-0  stoic-bose-worker-s2lnv-655cc5dcbf-t45gl  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  }]
Dec 18 13:00:42.964: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:42.964: INFO: ss-2  stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:42.964: INFO: 
Dec 18 13:00:42.964: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 18 13:00:44.178: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:44.178: INFO: ss-0  stoic-bose-worker-s2lnv-655cc5dcbf-t45gl  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  }]
Dec 18 13:00:44.178: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:44.178: INFO: ss-2  stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:44.178: INFO: 
Dec 18 13:00:44.178: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 18 13:00:45.191: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:45.191: INFO: ss-0  stoic-bose-worker-s2lnv-655cc5dcbf-t45gl  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  }]
Dec 18 13:00:45.192: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:45.192: INFO: ss-2  stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:45.192: INFO: 
Dec 18 13:00:45.192: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 18 13:00:46.202: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:46.202: INFO: ss-0  stoic-bose-worker-s2lnv-655cc5dcbf-t45gl  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  }]
Dec 18 13:00:46.202: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:46.202: INFO: ss-2  stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:46.202: INFO: 
Dec 18 13:00:46.202: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 18 13:00:47.211: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:47.211: INFO: ss-0  stoic-bose-worker-s2lnv-655cc5dcbf-t45gl  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 12:59:57 +0000 UTC  }]
Dec 18 13:00:47.211: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:47.211: INFO: 
Dec 18 13:00:47.211: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 18 13:00:48.226: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:48.226: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:48.226: INFO: 
Dec 18 13:00:48.226: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 18 13:00:49.249: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:49.249: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:49.249: INFO: 
Dec 18 13:00:49.249: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 18 13:00:50.256: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:50.256: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:50.257: INFO: 
Dec 18 13:00:50.257: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 18 13:00:51.273: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:51.273: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:51.273: INFO: 
Dec 18 13:00:51.273: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 18 13:00:52.283: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 18 13:00:52.283: INFO: ss-1  stoic-bose-worker-s2lnv-655cc5dcbf-4p69r  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-12-18 13:00:19 +0000 UTC  }]
Dec 18 13:00:52.283: INFO: 
Dec 18 13:00:52.283: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1153
Dec 18 13:00:53.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:00:53.522: INFO: rc: 1
Dec 18 13:00:53.522: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Dec 18 13:01:03.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:01:08.106: INFO: rc: 1
Dec 18 13:01:08.106: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:01:18.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:01:18.372: INFO: rc: 1
Dec 18 13:01:18.372: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:01:28.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:01:28.480: INFO: rc: 1
Dec 18 13:01:28.480: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:01:38.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:01:38.602: INFO: rc: 1
Dec 18 13:01:38.603: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:01:48.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:01:48.720: INFO: rc: 1
Dec 18 13:01:48.720: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:01:58.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:01:58.847: INFO: rc: 1
Dec 18 13:01:58.847: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:02:08.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:02:08.968: INFO: rc: 1
Dec 18 13:02:08.968: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:02:18.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:02:19.087: INFO: rc: 1
Dec 18 13:02:19.087: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:02:29.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:02:29.215: INFO: rc: 1
Dec 18 13:02:29.215: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:02:39.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:02:39.332: INFO: rc: 1
Dec 18 13:02:39.332: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:02:49.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:02:49.461: INFO: rc: 1
Dec 18 13:02:49.461: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:02:59.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:02:59.575: INFO: rc: 1
Dec 18 13:02:59.575: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:03:09.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:03:09.705: INFO: rc: 1
Dec 18 13:03:09.705: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:03:19.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:03:19.841: INFO: rc: 1
Dec 18 13:03:19.841: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:03:29.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:03:29.966: INFO: rc: 1
Dec 18 13:03:29.966: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:03:39.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:03:40.091: INFO: rc: 1
Dec 18 13:03:40.091: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:03:50.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:03:50.214: INFO: rc: 1
Dec 18 13:03:50.215: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:04:00.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:04:00.338: INFO: rc: 1
Dec 18 13:04:00.338: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:04:10.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:04:10.480: INFO: rc: 1
Dec 18 13:04:10.480: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:04:20.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:04:20.622: INFO: rc: 1
Dec 18 13:04:20.622: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:04:30.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:04:30.749: INFO: rc: 1
Dec 18 13:04:30.749: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:04:40.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:04:40.882: INFO: rc: 1
Dec 18 13:04:40.882: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:04:50.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:04:51.021: INFO: rc: 1
Dec 18 13:04:51.021: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:05:01.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:05:01.151: INFO: rc: 1
Dec 18 13:05:01.151: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:05:11.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:05:11.280: INFO: rc: 1
Dec 18 13:05:11.280: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:05:21.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:05:21.420: INFO: rc: 1
Dec 18 13:05:21.420: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:05:31.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:05:31.539: INFO: rc: 1
Dec 18 13:05:31.539: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:05:41.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:05:41.661: INFO: rc: 1
Dec 18 13:05:41.661: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:05:51.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:05:51.787: INFO: rc: 1
Dec 18 13:05:51.787: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 18 13:06:01.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-1153 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:06:01.910: INFO: rc: 1
Dec 18 13:06:01.910: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: 
Dec 18 13:06:01.910: INFO: Scaling statefulset ss to 0
Dec 18 13:06:01.946: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 18 13:06:01.955: INFO: Deleting all statefulset in ns statefulset-1153
Dec 18 13:06:01.963: INFO: Scaling statefulset ss to 0
Dec 18 13:06:01.997: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 13:06:02.009: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:06:02.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1153" for this suite.

• [SLOW TEST:365.135 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":273,"completed":224,"skipped":3879,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:06:02.092: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1056
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1056
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1056
STEP: Creating statefulset with conflicting port in namespace statefulset-1056
STEP: Waiting until pod test-pod will start running in namespace statefulset-1056
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1056
Dec 18 13:06:12.396: INFO: Observed stateful pod in namespace: statefulset-1056, name: ss-0, uid: 162fed5f-d294-40a5-9dfb-a8d4ea645af5, status phase: Failed. Waiting for statefulset controller to delete.
Dec 18 13:06:12.422: INFO: Observed stateful pod in namespace: statefulset-1056, name: ss-0, uid: 162fed5f-d294-40a5-9dfb-a8d4ea645af5, status phase: Failed. Waiting for statefulset controller to delete.
Dec 18 13:06:12.431: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1056
STEP: Removing pod with conflicting port in namespace statefulset-1056
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1056 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 18 13:06:18.519: INFO: Deleting all statefulset in ns statefulset-1056
Dec 18 13:06:18.526: INFO: Scaling statefulset ss to 0
Dec 18 13:06:28.572: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 13:06:28.585: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:06:28.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1056" for this suite.

• [SLOW TEST:26.559 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":273,"completed":225,"skipped":3893,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:06:28.651: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8717
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:06:39.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8717" for this suite.

• [SLOW TEST:11.337 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":273,"completed":226,"skipped":3900,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:06:39.990: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-55f9a6d3-c7b2-44fb-bada-63e2a6716732
STEP: Creating a pod to test consume configMaps
Dec 18 13:06:40.227: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85" in namespace "projected-6443" to be "Succeeded or Failed"
Dec 18 13:06:40.236: INFO: Pod "pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85": Phase="Pending", Reason="", readiness=false. Elapsed: 8.66057ms
Dec 18 13:06:42.245: INFO: Pod "pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018074462s
Dec 18 13:06:44.253: INFO: Pod "pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025783698s
Dec 18 13:06:46.269: INFO: Pod "pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041815962s
Dec 18 13:06:48.278: INFO: Pod "pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.050759786s
STEP: Saw pod success
Dec 18 13:06:48.278: INFO: Pod "pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85" satisfied condition "Succeeded or Failed"
Dec 18 13:06:48.286: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 13:06:48.358: INFO: Waiting for pod pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85 to disappear
Dec 18 13:06:48.365: INFO: Pod pod-projected-configmaps-77532e1e-b5c4-4fdd-bbec-35eb4b673e85 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:06:48.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6443" for this suite.

• [SLOW TEST:8.396 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":273,"completed":227,"skipped":3917,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:06:48.388: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 18 13:06:48.578: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 18 13:06:48.633: INFO: Waiting for terminating namespaces to be deleted...
Dec 18 13:06:48.645: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r before test
Dec 18 13:06:48.709: INFO: node-exporter-9db9x from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.709: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 13:06:48.709: INFO: sonobuoy-e2e-job-e8b5ba8e22894e5b from sonobuoy started at 2020-12-18 11:49:39 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.709: INFO: 	Container e2e ready: true, restart count 0
Dec 18 13:06:48.709: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 13:06:48.709: INFO: user-ssh-keys-agent-c7l5b from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.710: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 13:06:48.710: INFO: kube-proxy-lhksn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.710: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 13:06:48.710: INFO: canal-hrvbb from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.710: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 13:06:48.710: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 13:06:48.710: INFO: syseleven-node-problem-detector-njhnw from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.710: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 13:06:48.710: INFO: node-local-dns-b8hqm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.710: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 13:06:48.710: INFO: csi-cinder-nodeplugin-ubuntu-xgvkm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.710: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 13:06:48.710: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 13:06:48.710: INFO: sonobuoy from sonobuoy started at 2020-12-18 11:49:35 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.710: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 18 13:06:48.710: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-f897c from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.710: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 18 13:06:48.710: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 13:06:48.710: INFO: coredns-854998958f-grdws from kube-system started at 2020-12-18 08:54:22 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.710: INFO: 	Container coredns ready: true, restart count 0
Dec 18 13:06:48.710: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 before test
Dec 18 13:06:48.820: INFO: csi-cinder-nodeplugin-ubuntu-mgs7f from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 13:06:48.820: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 13:06:48.820: INFO: dns-autoscaler-596856b68b-sdb66 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container autoscaler ready: true, restart count 0
Dec 18 13:06:48.820: INFO: node-local-dns-hd82q from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 13:06:48.820: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-26dcz from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 18 13:06:48.820: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 13:06:48.820: INFO: user-ssh-keys-agent-9dgcw from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 13:06:48.820: INFO: coredns-854998958f-xqqnb from kube-system started at 2020-12-18 08:52:04 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container coredns ready: true, restart count 0
Dec 18 13:06:48.820: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (5 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 13:06:48.820: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 18 13:06:48.820: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 18 13:06:48.820: INFO: 	Container csi-resizer ready: true, restart count 0
Dec 18 13:06:48.820: INFO: 	Container csi-snapshotter ready: true, restart count 0
Dec 18 13:06:48.820: INFO: syseleven-node-problem-detector-scggf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 13:06:48.820: INFO: kube-proxy-xljhw from kube-system started at 2020-12-18 08:51:26 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 13:06:48.820: INFO: canal-x2srj from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 13:06:48.820: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 13:06:48.820: INFO: node-exporter-sxvt4 from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.820: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 13:06:48.820: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl before test
Dec 18 13:06:48.894: INFO: user-ssh-keys-agent-s8rkn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 13:06:48.894: INFO: syseleven-node-problem-detector-t5b9t from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 13:06:48.894: INFO: node-local-dns-2xjfh from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 13:06:48.894: INFO: openvpn-client-56dc45fdbd-hlz4z from kube-system started at 2020-12-18 08:54:10 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 18 13:06:48.894: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 18 13:06:48.894: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-t59nh from sonobuoy started at 2020-12-18 11:49:41 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 18 13:06:48.894: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 13:06:48.894: INFO: canal-fwhcf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 13:06:48.894: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 13:06:48.894: INFO: csi-cinder-nodeplugin-ubuntu-crqmv from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 13:06:48.894: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 13:06:48.894: INFO: cluster-autoscaler-5c8c86777b-zbqbq from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 18 13:06:48.894: INFO: tiller-deploy-5648ccb4b6-28wjd from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container tiller ready: true, restart count 0
Dec 18 13:06:48.894: INFO: kube-proxy-sgz6s from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 13:06:48.894: INFO: node-exporter-7rrpc from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:48.894: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
STEP: verifying the node has the label node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
STEP: verifying the node has the label node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.053: INFO: Pod canal-fwhcf requesting resource cpu=350m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.053: INFO: Pod canal-hrvbb requesting resource cpu=350m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.053: INFO: Pod canal-x2srj requesting resource cpu=350m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.053: INFO: Pod cluster-autoscaler-5c8c86777b-zbqbq requesting resource cpu=10m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.053: INFO: Pod coredns-854998958f-grdws requesting resource cpu=100m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.053: INFO: Pod coredns-854998958f-xqqnb requesting resource cpu=100m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.053: INFO: Pod csi-cinder-controllerplugin-0 requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.053: INFO: Pod csi-cinder-nodeplugin-ubuntu-crqmv requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.053: INFO: Pod csi-cinder-nodeplugin-ubuntu-mgs7f requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.053: INFO: Pod csi-cinder-nodeplugin-ubuntu-xgvkm requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.053: INFO: Pod dns-autoscaler-596856b68b-sdb66 requesting resource cpu=20m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.053: INFO: Pod kube-proxy-lhksn requesting resource cpu=75m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.054: INFO: Pod kube-proxy-sgz6s requesting resource cpu=75m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.054: INFO: Pod kube-proxy-xljhw requesting resource cpu=75m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.054: INFO: Pod node-exporter-7rrpc requesting resource cpu=3m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.054: INFO: Pod node-exporter-9db9x requesting resource cpu=3m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.054: INFO: Pod node-exporter-sxvt4 requesting resource cpu=3m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.054: INFO: Pod node-local-dns-2xjfh requesting resource cpu=50m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.054: INFO: Pod node-local-dns-b8hqm requesting resource cpu=50m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.054: INFO: Pod node-local-dns-hd82q requesting resource cpu=50m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.054: INFO: Pod openvpn-client-56dc45fdbd-hlz4z requesting resource cpu=30m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.054: INFO: Pod syseleven-node-problem-detector-njhnw requesting resource cpu=10m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.054: INFO: Pod syseleven-node-problem-detector-scggf requesting resource cpu=10m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.054: INFO: Pod syseleven-node-problem-detector-t5b9t requesting resource cpu=10m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.055: INFO: Pod tiller-deploy-5648ccb4b6-28wjd requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.055: INFO: Pod user-ssh-keys-agent-9dgcw requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.055: INFO: Pod user-ssh-keys-agent-c7l5b requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.055: INFO: Pod user-ssh-keys-agent-s8rkn requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.055: INFO: Pod sonobuoy requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.055: INFO: Pod sonobuoy-e2e-job-e8b5ba8e22894e5b requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.055: INFO: Pod sonobuoy-systemd-logs-daemon-set-a793f22683684929-26dcz requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
Dec 18 13:06:49.055: INFO: Pod sonobuoy-systemd-logs-daemon-set-a793f22683684929-f897c requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.055: INFO: Pod sonobuoy-systemd-logs-daemon-set-a793f22683684929-t59nh requesting resource cpu=0m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
STEP: Starting Pods to consume most of the cluster CPU.
Dec 18 13:06:49.055: INFO: Creating a pod which consumes cpu=2290m on Node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
Dec 18 13:06:49.077: INFO: Creating a pod which consumes cpu=2248m on Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
Dec 18 13:06:49.086: INFO: Creating a pod which consumes cpu=2234m on Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0ead8d38-eef6-40f6-9554-45b8fa19a0e4.1651d16d410ce285], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9832/filler-pod-0ead8d38-eef6-40f6-9554-45b8fa19a0e4 to stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0ead8d38-eef6-40f6-9554-45b8fa19a0e4.1651d16e02c19fa7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0ead8d38-eef6-40f6-9554-45b8fa19a0e4.1651d16e49d3907d], Reason = [Created], Message = [Created container filler-pod-0ead8d38-eef6-40f6-9554-45b8fa19a0e4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0ead8d38-eef6-40f6-9554-45b8fa19a0e4.1651d16e667a089f], Reason = [Started], Message = [Started container filler-pod-0ead8d38-eef6-40f6-9554-45b8fa19a0e4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4be7d7d3-dfa5-4d2e-b811-0ea69cd8aec9.1651d16d3f28a2af], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9832/filler-pod-4be7d7d3-dfa5-4d2e-b811-0ea69cd8aec9 to stoic-bose-worker-s2lnv-655cc5dcbf-t45gl]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4be7d7d3-dfa5-4d2e-b811-0ea69cd8aec9.1651d16df01d753e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4be7d7d3-dfa5-4d2e-b811-0ea69cd8aec9.1651d16e33828bf0], Reason = [Created], Message = [Created container filler-pod-4be7d7d3-dfa5-4d2e-b811-0ea69cd8aec9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4be7d7d3-dfa5-4d2e-b811-0ea69cd8aec9.1651d16e61fbec04], Reason = [Started], Message = [Started container filler-pod-4be7d7d3-dfa5-4d2e-b811-0ea69cd8aec9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-857e7640-6467-40b3-91a7-a450a40211dd.1651d16d40a03298], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9832/filler-pod-857e7640-6467-40b3-91a7-a450a40211dd to stoic-bose-worker-s2lnv-655cc5dcbf-4p69r]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-857e7640-6467-40b3-91a7-a450a40211dd.1651d16ddf7366cc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-857e7640-6467-40b3-91a7-a450a40211dd.1651d16e19c5b468], Reason = [Created], Message = [Created container filler-pod-857e7640-6467-40b3-91a7-a450a40211dd]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-857e7640-6467-40b3-91a7-a450a40211dd.1651d16e33be834b], Reason = [Started], Message = [Started container filler-pod-857e7640-6467-40b3-91a7-a450a40211dd]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1651d16ea9b7d2c7], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1651d16eab50d733], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:06:56.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9832" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:7.938 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":273,"completed":228,"skipped":3937,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:06:56.328: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2984
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Dec 18 13:06:56.533: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 18 13:06:56.563: INFO: Waiting for terminating namespaces to be deleted...
Dec 18 13:06:56.569: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r before test
Dec 18 13:06:56.729: INFO: csi-cinder-nodeplugin-ubuntu-xgvkm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.730: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 13:06:56.730: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 13:06:56.730: INFO: sonobuoy from sonobuoy started at 2020-12-18 11:49:35 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.730: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 18 13:06:56.730: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-f897c from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.730: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 18 13:06:56.730: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 13:06:56.730: INFO: filler-pod-857e7640-6467-40b3-91a7-a450a40211dd from sched-pred-9832 started at 2020-12-18 13:06:49 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.730: INFO: 	Container filler-pod-857e7640-6467-40b3-91a7-a450a40211dd ready: true, restart count 0
Dec 18 13:06:56.730: INFO: syseleven-node-problem-detector-njhnw from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.730: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 13:06:56.730: INFO: node-local-dns-b8hqm from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.731: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 13:06:56.731: INFO: coredns-854998958f-grdws from kube-system started at 2020-12-18 08:54:22 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.731: INFO: 	Container coredns ready: true, restart count 0
Dec 18 13:06:56.731: INFO: node-exporter-9db9x from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.731: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 13:06:56.731: INFO: sonobuoy-e2e-job-e8b5ba8e22894e5b from sonobuoy started at 2020-12-18 11:49:39 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.731: INFO: 	Container e2e ready: true, restart count 0
Dec 18 13:06:56.731: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 18 13:06:56.731: INFO: canal-hrvbb from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.731: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 13:06:56.731: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 13:06:56.731: INFO: user-ssh-keys-agent-c7l5b from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.731: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 13:06:56.731: INFO: kube-proxy-lhksn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.731: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 13:06:56.732: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 before test
Dec 18 13:06:56.792: INFO: csi-cinder-controllerplugin-0 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (5 container statuses recorded)
Dec 18 13:06:56.792: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 13:06:56.792: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 18 13:06:56.792: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 18 13:06:56.792: INFO: 	Container csi-resizer ready: true, restart count 0
Dec 18 13:06:56.792: INFO: 	Container csi-snapshotter ready: true, restart count 0
Dec 18 13:06:56.792: INFO: syseleven-node-problem-detector-scggf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.793: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 13:06:56.793: INFO: kube-proxy-xljhw from kube-system started at 2020-12-18 08:51:26 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.793: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 13:06:56.793: INFO: canal-x2srj from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.793: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 13:06:56.793: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 13:06:56.793: INFO: user-ssh-keys-agent-9dgcw from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.793: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 13:06:56.793: INFO: coredns-854998958f-xqqnb from kube-system started at 2020-12-18 08:52:04 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.793: INFO: 	Container coredns ready: true, restart count 0
Dec 18 13:06:56.793: INFO: node-exporter-sxvt4 from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.793: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 13:06:56.793: INFO: filler-pod-0ead8d38-eef6-40f6-9554-45b8fa19a0e4 from sched-pred-9832 started at 2020-12-18 13:06:49 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.793: INFO: 	Container filler-pod-0ead8d38-eef6-40f6-9554-45b8fa19a0e4 ready: true, restart count 0
Dec 18 13:06:56.793: INFO: csi-cinder-nodeplugin-ubuntu-mgs7f from kube-system started at 2020-12-18 08:51:27 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.793: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 13:06:56.793: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 13:06:56.793: INFO: dns-autoscaler-596856b68b-sdb66 from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.794: INFO: 	Container autoscaler ready: true, restart count 0
Dec 18 13:06:56.794: INFO: node-local-dns-hd82q from kube-system started at 2020-12-18 08:51:27 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.794: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 13:06:56.794: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-26dcz from sonobuoy started at 2020-12-18 11:49:40 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.794: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 18 13:06:56.794: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 13:06:56.794: INFO: 
Logging pods the kubelet thinks is on node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl before test
Dec 18 13:06:56.894: INFO: node-exporter-7rrpc from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.894: INFO: 	Container node-exporter ready: true, restart count 0
Dec 18 13:06:56.894: INFO: syseleven-node-problem-detector-t5b9t from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.894: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 18 13:06:56.894: INFO: user-ssh-keys-agent-s8rkn from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.894: INFO: 	Container user-ssh-keys-agent ready: true, restart count 0
Dec 18 13:06:56.895: INFO: filler-pod-4be7d7d3-dfa5-4d2e-b811-0ea69cd8aec9 from sched-pred-9832 started at 2020-12-18 13:06:49 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.895: INFO: 	Container filler-pod-4be7d7d3-dfa5-4d2e-b811-0ea69cd8aec9 ready: true, restart count 0
Dec 18 13:06:56.895: INFO: canal-fwhcf from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.895: INFO: 	Container calico-node ready: true, restart count 0
Dec 18 13:06:56.895: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 18 13:06:56.895: INFO: node-local-dns-2xjfh from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.895: INFO: 	Container node-cache ready: true, restart count 0
Dec 18 13:06:56.895: INFO: openvpn-client-56dc45fdbd-hlz4z from kube-system started at 2020-12-18 08:54:10 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.895: INFO: 	Container dnat-controller ready: true, restart count 0
Dec 18 13:06:56.895: INFO: 	Container openvpn-client ready: true, restart count 0
Dec 18 13:06:56.895: INFO: sonobuoy-systemd-logs-daemon-set-a793f22683684929-t59nh from sonobuoy started at 2020-12-18 11:49:41 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.895: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 18 13:06:56.895: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 18 13:06:56.895: INFO: kube-proxy-sgz6s from kube-system started at 2020-12-18 08:51:25 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.896: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 18 13:06:56.896: INFO: csi-cinder-nodeplugin-ubuntu-crqmv from kube-system started at 2020-12-18 08:51:25 +0000 UTC (2 container statuses recorded)
Dec 18 13:06:56.896: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Dec 18 13:06:56.896: INFO: 	Container node-driver-registrar ready: true, restart count 0
Dec 18 13:06:56.896: INFO: cluster-autoscaler-5c8c86777b-zbqbq from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.896: INFO: 	Container cluster-autoscaler ready: true, restart count 0
Dec 18 13:06:56.896: INFO: tiller-deploy-5648ccb4b6-28wjd from kube-system started at 2020-12-18 08:54:10 +0000 UTC (1 container statuses recorded)
Dec 18 13:06:56.896: INFO: 	Container tiller ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1651d170808c7d23], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1651d1708272d8e0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:07:04.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2984" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:7.789 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":273,"completed":229,"skipped":3957,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:07:04.118: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7241
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Dec 18 13:07:04.365: INFO: Created pod &Pod{ObjectMeta:{dns-7241  dns-7241 /api/v1/namespaces/dns-7241/pods/dns-7241 72248857-b97c-4730-8ac9-d7c02f859801 113027 0 2020-12-18 13:07:04 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2020-12-18 13:07:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6dxbk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6dxbk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6dxbk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 18 13:07:04.372: INFO: The status of Pod dns-7241 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:07:06.384: INFO: The status of Pod dns-7241 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:07:08.387: INFO: The status of Pod dns-7241 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:07:10.381: INFO: The status of Pod dns-7241 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:07:12.382: INFO: The status of Pod dns-7241 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:07:14.388: INFO: The status of Pod dns-7241 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:07:16.381: INFO: The status of Pod dns-7241 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:07:18.380: INFO: The status of Pod dns-7241 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:07:20.383: INFO: The status of Pod dns-7241 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:07:22.386: INFO: The status of Pod dns-7241 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Dec 18 13:07:22.386: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7241 PodName:dns-7241 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 13:07:22.386: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Verifying customized DNS server is configured on pod...
Dec 18 13:07:22.654: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7241 PodName:dns-7241 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 13:07:22.654: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 13:07:22.997: INFO: Deleting pod dns-7241...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:07:23.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7241" for this suite.

• [SLOW TEST:18.947 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":273,"completed":230,"skipped":3975,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:07:23.066: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-0
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Dec 18 13:07:23.826: INFO: created pod pod-service-account-defaultsa
Dec 18 13:07:23.826: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 18 13:07:23.851: INFO: created pod pod-service-account-mountsa
Dec 18 13:07:23.851: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 18 13:07:23.862: INFO: created pod pod-service-account-nomountsa
Dec 18 13:07:23.862: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 18 13:07:23.879: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 18 13:07:23.879: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 18 13:07:23.892: INFO: created pod pod-service-account-mountsa-mountspec
Dec 18 13:07:23.893: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 18 13:07:23.905: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 18 13:07:23.905: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 18 13:07:23.927: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 18 13:07:23.927: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 18 13:07:23.945: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 18 13:07:23.945: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 18 13:07:23.955: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 18 13:07:23.955: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:07:23.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-0" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":273,"completed":231,"skipped":3988,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:07:23.989: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4340
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 13:07:24.230: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 18 13:07:28.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-4340 create -f -'
Dec 18 13:07:37.628: INFO: stderr: ""
Dec 18 13:07:37.628: INFO: stdout: "e2e-test-crd-publish-openapi-5566-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 18 13:07:37.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-4340 delete e2e-test-crd-publish-openapi-5566-crds test-cr'
Dec 18 13:07:37.822: INFO: stderr: ""
Dec 18 13:07:37.822: INFO: stdout: "e2e-test-crd-publish-openapi-5566-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 18 13:07:37.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-4340 apply -f -'
Dec 18 13:07:38.270: INFO: stderr: ""
Dec 18 13:07:38.270: INFO: stdout: "e2e-test-crd-publish-openapi-5566-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 18 13:07:38.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 --namespace=crd-publish-openapi-4340 delete e2e-test-crd-publish-openapi-5566-crds test-cr'
Dec 18 13:07:38.477: INFO: stderr: ""
Dec 18 13:07:38.477: INFO: stdout: "e2e-test-crd-publish-openapi-5566-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 18 13:07:38.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 explain e2e-test-crd-publish-openapi-5566-crds'
Dec 18 13:07:39.431: INFO: stderr: ""
Dec 18 13:07:39.431: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5566-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:07:43.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4340" for this suite.

• [SLOW TEST:19.916 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":273,"completed":232,"skipped":4003,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:07:43.906: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9099
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-8aa26ab5-6461-43cc-b9be-d2cd3b9819d5
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-8aa26ab5-6461-43cc-b9be-d2cd3b9819d5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:07:54.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9099" for this suite.

• [SLOW TEST:10.556 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":233,"skipped":4039,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:07:54.463: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7491
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:08:07.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7491" for this suite.

• [SLOW TEST:13.550 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":273,"completed":234,"skipped":4066,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:08:08.013: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5145
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:08:08.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5145" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":273,"completed":235,"skipped":4077,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:08:08.330: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9247
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-e0c2b010-35b1-4595-bb17-2c5fe442988a
STEP: Creating configMap with name cm-test-opt-upd-240f05d5-ab7c-4513-849e-2090cea37019
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e0c2b010-35b1-4595-bb17-2c5fe442988a
STEP: Updating configmap cm-test-opt-upd-240f05d5-ab7c-4513-849e-2090cea37019
STEP: Creating configMap with name cm-test-opt-create-d5871761-6cc3-409c-acd7-52cae6b5b403
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:08:20.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9247" for this suite.

• [SLOW TEST:12.640 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":236,"skipped":4081,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:08:20.971: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3874
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 18 13:08:27.818: INFO: Successfully updated pod "pod-update-5169b68c-12a4-4ffa-a611-5cc6ae52a9db"
STEP: verifying the updated pod is in kubernetes
Dec 18 13:08:27.833: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:08:27.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3874" for this suite.

• [SLOW TEST:6.886 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":273,"completed":237,"skipped":4103,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:08:27.866: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2071
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 13:08:28.086: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8" in namespace "projected-2071" to be "Succeeded or Failed"
Dec 18 13:08:28.094: INFO: Pod "downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.74449ms
Dec 18 13:08:30.104: INFO: Pod "downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01728714s
Dec 18 13:08:32.237: INFO: Pod "downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.150525307s
Dec 18 13:08:34.250: INFO: Pod "downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.164002236s
Dec 18 13:08:36.259: INFO: Pod "downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.17317235s
STEP: Saw pod success
Dec 18 13:08:36.260: INFO: Pod "downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8" satisfied condition "Succeeded or Failed"
Dec 18 13:08:36.395: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r pod downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8 container client-container: <nil>
STEP: delete the pod
Dec 18 13:08:36.733: INFO: Waiting for pod downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8 to disappear
Dec 18 13:08:36.920: INFO: Pod downwardapi-volume-2b70e53b-296b-48b2-9233-174e767295b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:08:36.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2071" for this suite.

• [SLOW TEST:9.180 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":273,"completed":238,"skipped":4120,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:08:37.045: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9977
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:08:49.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9977" for this suite.

• [SLOW TEST:12.570 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:79
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":273,"completed":239,"skipped":4136,"failed":0}
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:08:49.615: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2224
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-54e3acd8-2fe7-40f9-9800-0bf5b24830eb
STEP: Creating secret with name s-test-opt-upd-d346cab2-a6cc-47b1-9f9e-093458977d63
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-54e3acd8-2fe7-40f9-9800-0bf5b24830eb
STEP: Updating secret s-test-opt-upd-d346cab2-a6cc-47b1-9f9e-093458977d63
STEP: Creating secret with name s-test-opt-create-e31a26a1-8564-42e8-b1c2-8edcb2d6031e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:09:03.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2224" for this suite.

• [SLOW TEST:13.487 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":273,"completed":240,"skipped":4136,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:09:03.108: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3476
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 18 13:09:09.403: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:09:09.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3476" for this suite.

• [SLOW TEST:6.360 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":273,"completed":241,"skipped":4192,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:09:09.471: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2661
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 13:09:09.705: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:09:15.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2661" for this suite.

• [SLOW TEST:6.488 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":273,"completed":242,"skipped":4209,"failed":0}
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:09:15.959: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:09:22.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2988" for this suite.

• [SLOW TEST:6.306 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a read only busybox container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:188
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":243,"skipped":4212,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:09:22.274: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1333.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1333.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1333.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1333.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1333.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1333.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 18 13:09:32.775: INFO: DNS probes using dns-1333/dns-test-33c27ffa-51ba-4efb-b13e-96a40096fa79 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:09:32.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1333" for this suite.

• [SLOW TEST:10.565 seconds]
[sig-network] DNS
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":273,"completed":244,"skipped":4243,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:09:32.839: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1501
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-9ecea8ad-7f29-4aaa-a3c1-6e02c4c44519 in namespace container-probe-1501
Dec 18 13:09:41.111: INFO: Started pod busybox-9ecea8ad-7f29-4aaa-a3c1-6e02c4c44519 in namespace container-probe-1501
STEP: checking the pod's current state and verifying that restartCount is present
Dec 18 13:09:41.118: INFO: Initial restart count of pod busybox-9ecea8ad-7f29-4aaa-a3c1-6e02c4c44519 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:13:42.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1501" for this suite.

• [SLOW TEST:249.791 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":273,"completed":245,"skipped":4251,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:13:42.632: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-1994
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 18 13:13:43.410: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Dec 18 13:13:45.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 13:13:47.460: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 13:13:49.455: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894023, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 13:13:52.484: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 13:13:52.496: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:13:53.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1994" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:11.514 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":273,"completed":246,"skipped":4256,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:13:54.149: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 13:13:54.392: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849" in namespace "projected-8862" to be "Succeeded or Failed"
Dec 18 13:13:54.403: INFO: Pod "downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849": Phase="Pending", Reason="", readiness=false. Elapsed: 10.573977ms
Dec 18 13:13:56.411: INFO: Pod "downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019316631s
Dec 18 13:13:58.425: INFO: Pod "downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032366683s
Dec 18 13:14:00.432: INFO: Pod "downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040203001s
Dec 18 13:14:02.440: INFO: Pod "downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04820077s
STEP: Saw pod success
Dec 18 13:14:02.440: INFO: Pod "downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849" satisfied condition "Succeeded or Failed"
Dec 18 13:14:02.454: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849 container client-container: <nil>
STEP: delete the pod
Dec 18 13:14:02.514: INFO: Waiting for pod downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849 to disappear
Dec 18 13:14:02.523: INFO: Pod downwardapi-volume-5f0ba2e4-066a-4a11-a62c-4cc91dc7d849 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:14:02.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8862" for this suite.

• [SLOW TEST:8.413 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":247,"skipped":4269,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:14:02.563: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 18 13:14:03.453: INFO: Pod name wrapped-volume-race-a58abf25-0747-4c6d-ac09-bc0c8a18e59c: Found 0 pods out of 5
Dec 18 13:14:08.468: INFO: Pod name wrapped-volume-race-a58abf25-0747-4c6d-ac09-bc0c8a18e59c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a58abf25-0747-4c6d-ac09-bc0c8a18e59c in namespace emptydir-wrapper-4956, will wait for the garbage collector to delete the pods
Dec 18 13:14:24.650: INFO: Deleting ReplicationController wrapped-volume-race-a58abf25-0747-4c6d-ac09-bc0c8a18e59c took: 22.361394ms
Dec 18 13:14:25.250: INFO: Terminating ReplicationController wrapped-volume-race-a58abf25-0747-4c6d-ac09-bc0c8a18e59c pods took: 600.464641ms
STEP: Creating RC which spawns configmap-volume pods
Dec 18 13:14:37.404: INFO: Pod name wrapped-volume-race-ed8d1ae4-139b-4ea9-b52f-8d047c940cbf: Found 0 pods out of 5
Dec 18 13:14:42.419: INFO: Pod name wrapped-volume-race-ed8d1ae4-139b-4ea9-b52f-8d047c940cbf: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ed8d1ae4-139b-4ea9-b52f-8d047c940cbf in namespace emptydir-wrapper-4956, will wait for the garbage collector to delete the pods
Dec 18 13:14:58.570: INFO: Deleting ReplicationController wrapped-volume-race-ed8d1ae4-139b-4ea9-b52f-8d047c940cbf took: 20.552654ms
Dec 18 13:14:59.170: INFO: Terminating ReplicationController wrapped-volume-race-ed8d1ae4-139b-4ea9-b52f-8d047c940cbf pods took: 600.469439ms
STEP: Creating RC which spawns configmap-volume pods
Dec 18 13:15:18.232: INFO: Pod name wrapped-volume-race-aad7d5d9-b00f-481d-976e-f87ad4dc2a37: Found 0 pods out of 5
Dec 18 13:15:23.345: INFO: Pod name wrapped-volume-race-aad7d5d9-b00f-481d-976e-f87ad4dc2a37: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-aad7d5d9-b00f-481d-976e-f87ad4dc2a37 in namespace emptydir-wrapper-4956, will wait for the garbage collector to delete the pods
Dec 18 13:15:40.003: INFO: Deleting ReplicationController wrapped-volume-race-aad7d5d9-b00f-481d-976e-f87ad4dc2a37 took: 145.406917ms
Dec 18 13:15:40.803: INFO: Terminating ReplicationController wrapped-volume-race-aad7d5d9-b00f-481d-976e-f87ad4dc2a37 pods took: 800.333774ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:15:58.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4956" for this suite.

• [SLOW TEST:115.965 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":273,"completed":248,"skipped":4284,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:15:58.541: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 18 13:15:58.811: INFO: Waiting up to 5m0s for pod "downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba" in namespace "downward-api-3417" to be "Succeeded or Failed"
Dec 18 13:15:58.818: INFO: Pod "downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba": Phase="Pending", Reason="", readiness=false. Elapsed: 6.584993ms
Dec 18 13:16:00.832: INFO: Pod "downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020849282s
Dec 18 13:16:02.840: INFO: Pod "downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028210671s
Dec 18 13:16:04.855: INFO: Pod "downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043602839s
Dec 18 13:16:06.864: INFO: Pod "downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.052662557s
STEP: Saw pod success
Dec 18 13:16:06.864: INFO: Pod "downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba" satisfied condition "Succeeded or Failed"
Dec 18 13:16:06.871: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba container dapi-container: <nil>
STEP: delete the pod
Dec 18 13:16:06.998: INFO: Waiting for pod downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba to disappear
Dec 18 13:16:07.008: INFO: Pod downward-api-1624a9ca-5648-473e-ae0a-aeee50b0aeba no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:16:07.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3417" for this suite.

• [SLOW TEST:8.501 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":273,"completed":249,"skipped":4319,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:16:07.046: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8906
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-8906
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Dec 18 13:16:07.276: INFO: Found 0 stateful pods, waiting for 3
Dec 18 13:16:17.290: INFO: Found 2 stateful pods, waiting for 3
Dec 18 13:16:27.290: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 13:16:27.290: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 13:16:27.290: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 18 13:16:27.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-8906 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 13:16:27.801: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 13:16:27.801: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 13:16:27.801: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 18 13:16:37.873: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 18 13:16:47.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-8906 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:16:51.366: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 18 13:16:51.366: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 18 13:16:51.366: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 18 13:17:01.439: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
Dec 18 13:17:01.439: INFO: Waiting for Pod statefulset-8906/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 18 13:17:01.439: INFO: Waiting for Pod statefulset-8906/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 18 13:17:01.439: INFO: Waiting for Pod statefulset-8906/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 18 13:17:11.459: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
Dec 18 13:17:11.459: INFO: Waiting for Pod statefulset-8906/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 18 13:17:11.459: INFO: Waiting for Pod statefulset-8906/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 18 13:17:21.458: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
Dec 18 13:17:21.459: INFO: Waiting for Pod statefulset-8906/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 18 13:17:21.459: INFO: Waiting for Pod statefulset-8906/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 18 13:17:31.468: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
Dec 18 13:17:31.468: INFO: Waiting for Pod statefulset-8906/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 18 13:17:41.462: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
STEP: Rolling back to a previous revision
Dec 18 13:17:51.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-8906 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 18 13:17:54.196: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 18 13:17:54.196: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 18 13:17:54.196: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 18 13:18:04.265: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 18 13:18:14.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=statefulset-8906 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 18 13:18:14.794: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 18 13:18:14.794: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 18 13:18:14.794: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 18 13:18:24.853: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
Dec 18 13:18:24.853: INFO: Waiting for Pod statefulset-8906/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 18 13:18:24.853: INFO: Waiting for Pod statefulset-8906/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 18 13:18:24.853: INFO: Waiting for Pod statefulset-8906/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 18 13:18:34.871: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
Dec 18 13:18:34.871: INFO: Waiting for Pod statefulset-8906/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 18 13:18:34.871: INFO: Waiting for Pod statefulset-8906/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 18 13:18:44.873: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
Dec 18 13:18:44.873: INFO: Waiting for Pod statefulset-8906/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 18 13:18:54.897: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
Dec 18 13:18:54.897: INFO: Waiting for Pod statefulset-8906/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 18 13:19:04.872: INFO: Waiting for StatefulSet statefulset-8906/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Dec 18 13:19:14.876: INFO: Deleting all statefulset in ns statefulset-8906
Dec 18 13:19:14.882: INFO: Scaling statefulset ss2 to 0
Dec 18 13:19:44.933: INFO: Waiting for statefulset status.replicas updated to 0
Dec 18 13:19:44.941: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:19:44.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8906" for this suite.

• [SLOW TEST:217.969 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":273,"completed":250,"skipped":4345,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:19:45.020: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2919
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2919
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2919
STEP: creating replication controller externalsvc in namespace services-2919
I1218 13:19:45.344763      21 runners.go:190] Created replication controller with name: externalsvc, namespace: services-2919, replica count: 2
I1218 13:19:48.395541      21 runners.go:190] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1218 13:19:51.395984      21 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 18 13:19:51.444: INFO: Creating new exec pod
Dec 18 13:19:57.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 exec --namespace=services-2919 execpodjztmj -- /bin/sh -x -c nslookup nodeport-service'
Dec 18 13:19:57.977: INFO: stderr: "+ nslookup nodeport-service\n"
Dec 18 13:19:57.977: INFO: stdout: "Server:\t\t169.254.20.10\nAddress:\t169.254.20.10#53\n\nnodeport-service.services-2919.svc.cluster.local\tcanonical name = externalsvc.services-2919.svc.cluster.local.\nName:\texternalsvc.services-2919.svc.cluster.local\nAddress: 10.240.23.98\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2919, will wait for the garbage collector to delete the pods
Dec 18 13:19:58.059: INFO: Deleting ReplicationController externalsvc took: 23.615558ms
Dec 18 13:19:58.660: INFO: Terminating ReplicationController externalsvc pods took: 600.302308ms
Dec 18 13:20:09.738: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:20:09.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2919" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:24.851 seconds]
[sig-network] Services
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":273,"completed":251,"skipped":4363,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:20:09.875: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1364
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 13:20:10.122: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:20:11.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1364" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":273,"completed":252,"skipped":4394,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:20:11.593: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-3248
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Dec 18 13:20:11.835: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3248" to be "Succeeded or Failed"
Dec 18 13:20:11.841: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.421809ms
Dec 18 13:20:13.854: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019185881s
Dec 18 13:20:15.863: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027554705s
Dec 18 13:20:17.874: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039065599s
Dec 18 13:20:19.884: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.04854651s
Dec 18 13:20:21.890: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.055106314s
Dec 18 13:20:23.898: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.063312676s
STEP: Saw pod success
Dec 18 13:20:23.899: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Dec 18 13:20:23.905: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 18 13:20:24.045: INFO: Waiting for pod pod-host-path-test to disappear
Dec 18 13:20:24.051: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:20:24.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3248" for this suite.

• [SLOW TEST:12.484 seconds]
[sig-storage] HostPath
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":253,"skipped":4452,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:20:24.077: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-845
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 18 13:20:24.297: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-845 /api/v1/namespaces/watch-845/configmaps/e2e-watch-test-watch-closed 5f919bdc-04fe-4187-8b55-b8cf57b56d8a 119396 0 2020-12-18 13:20:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-12-18 13:20:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 13:20:24.298: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-845 /api/v1/namespaces/watch-845/configmaps/e2e-watch-test-watch-closed 5f919bdc-04fe-4187-8b55-b8cf57b56d8a 119397 0 2020-12-18 13:20:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-12-18 13:20:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 18 13:20:24.346: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-845 /api/v1/namespaces/watch-845/configmaps/e2e-watch-test-watch-closed 5f919bdc-04fe-4187-8b55-b8cf57b56d8a 119398 0 2020-12-18 13:20:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-12-18 13:20:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 13:20:24.347: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-845 /api/v1/namespaces/watch-845/configmaps/e2e-watch-test-watch-closed 5f919bdc-04fe-4187-8b55-b8cf57b56d8a 119399 0 2020-12-18 13:20:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-12-18 13:20:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:20:24.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-845" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":273,"completed":254,"skipped":4470,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:20:24.370: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6777
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 13:20:24.581: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60" in namespace "downward-api-6777" to be "Succeeded or Failed"
Dec 18 13:20:24.591: INFO: Pod "downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60": Phase="Pending", Reason="", readiness=false. Elapsed: 9.531828ms
Dec 18 13:20:26.602: INFO: Pod "downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021277383s
Dec 18 13:20:28.614: INFO: Pod "downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032795758s
Dec 18 13:20:30.622: INFO: Pod "downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04113914s
Dec 18 13:20:32.632: INFO: Pod "downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.050824632s
STEP: Saw pod success
Dec 18 13:20:32.632: INFO: Pod "downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60" satisfied condition "Succeeded or Failed"
Dec 18 13:20:32.639: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60 container client-container: <nil>
STEP: delete the pod
Dec 18 13:20:32.705: INFO: Waiting for pod downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60 to disappear
Dec 18 13:20:32.713: INFO: Pod downwardapi-volume-b7c13c35-0991-4dc0-a6e5-cf8f82182b60 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:20:32.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6777" for this suite.

• [SLOW TEST:8.370 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":273,"completed":255,"skipped":4482,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:20:32.741: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7783
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Dec 18 13:20:39.573: INFO: Successfully updated pod "labelsupdatead3ffb68-6925-4bbd-bdd6-7adc14141405"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:20:41.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7783" for this suite.

• [SLOW TEST:8.926 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":273,"completed":256,"skipped":4491,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:20:41.673: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5436
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 13:20:41.894: INFO: Waiting up to 5m0s for pod "downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007" in namespace "projected-5436" to be "Succeeded or Failed"
Dec 18 13:20:41.904: INFO: Pod "downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007": Phase="Pending", Reason="", readiness=false. Elapsed: 9.532105ms
Dec 18 13:20:43.915: INFO: Pod "downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021102366s
Dec 18 13:20:45.924: INFO: Pod "downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029666743s
Dec 18 13:20:47.937: INFO: Pod "downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04308206s
Dec 18 13:20:49.948: INFO: Pod "downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.053535675s
STEP: Saw pod success
Dec 18 13:20:49.948: INFO: Pod "downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007" satisfied condition "Succeeded or Failed"
Dec 18 13:20:49.956: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007 container client-container: <nil>
STEP: delete the pod
Dec 18 13:20:50.008: INFO: Waiting for pod downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007 to disappear
Dec 18 13:20:50.025: INFO: Pod downwardapi-volume-496b01dc-9cf9-450b-8be9-895afcb58007 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:20:50.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5436" for this suite.

• [SLOW TEST:8.382 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":257,"skipped":4527,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:20:50.061: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4533
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Dec 18 13:20:50.314: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Dec 18 13:20:50.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-4533'
Dec 18 13:20:50.816: INFO: stderr: ""
Dec 18 13:20:50.816: INFO: stdout: "service/agnhost-slave created\n"
Dec 18 13:20:50.817: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Dec 18 13:20:50.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-4533'
Dec 18 13:20:51.311: INFO: stderr: ""
Dec 18 13:20:51.311: INFO: stdout: "service/agnhost-master created\n"
Dec 18 13:20:51.311: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 18 13:20:51.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-4533'
Dec 18 13:20:51.824: INFO: stderr: ""
Dec 18 13:20:51.824: INFO: stdout: "service/frontend created\n"
Dec 18 13:20:51.825: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Dec 18 13:20:51.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-4533'
Dec 18 13:20:52.289: INFO: stderr: ""
Dec 18 13:20:52.289: INFO: stdout: "deployment.apps/frontend created\n"
Dec 18 13:20:52.289: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 18 13:20:52.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-4533'
Dec 18 13:20:52.775: INFO: stderr: ""
Dec 18 13:20:52.775: INFO: stdout: "deployment.apps/agnhost-master created\n"
Dec 18 13:20:52.776: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 18 13:20:52.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-4533'
Dec 18 13:20:53.301: INFO: stderr: ""
Dec 18 13:20:53.301: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Dec 18 13:20:53.301: INFO: Waiting for all frontend pods to be Running.
Dec 18 13:21:08.352: INFO: Waiting for frontend to serve content.
Dec 18 13:21:08.411: INFO: Trying to add a new entry to the guestbook.
Dec 18 13:21:08.485: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 18 13:21:08.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete --grace-period=0 --force -f - --namespace=kubectl-4533'
Dec 18 13:21:08.659: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 18 13:21:08.659: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 18 13:21:08.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete --grace-period=0 --force -f - --namespace=kubectl-4533'
Dec 18 13:21:08.893: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 18 13:21:08.893: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 18 13:21:08.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete --grace-period=0 --force -f - --namespace=kubectl-4533'
Dec 18 13:21:09.027: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 18 13:21:09.027: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 18 13:21:09.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete --grace-period=0 --force -f - --namespace=kubectl-4533'
Dec 18 13:21:09.161: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 18 13:21:09.161: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 18 13:21:09.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete --grace-period=0 --force -f - --namespace=kubectl-4533'
Dec 18 13:21:09.306: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 18 13:21:09.306: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 18 13:21:09.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 delete --grace-period=0 --force -f - --namespace=kubectl-4533'
Dec 18 13:21:09.470: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 18 13:21:09.470: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:21:09.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4533" for this suite.

• [SLOW TEST:19.441 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:310
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":273,"completed":258,"skipped":4558,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:21:09.503: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 13:21:09.751: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c" in namespace "projected-8113" to be "Succeeded or Failed"
Dec 18 13:21:09.766: INFO: Pod "downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.918739ms
Dec 18 13:21:11.780: INFO: Pod "downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028896311s
Dec 18 13:21:13.790: INFO: Pod "downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039436808s
Dec 18 13:21:15.798: INFO: Pod "downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.047117958s
Dec 18 13:21:17.807: INFO: Pod "downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.055815708s
Dec 18 13:21:19.823: INFO: Pod "downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.071566303s
Dec 18 13:21:21.839: INFO: Pod "downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.087835261s
STEP: Saw pod success
Dec 18 13:21:21.839: INFO: Pod "downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c" satisfied condition "Succeeded or Failed"
Dec 18 13:21:21.847: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c container client-container: <nil>
STEP: delete the pod
Dec 18 13:21:21.903: INFO: Waiting for pod downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c to disappear
Dec 18 13:21:21.910: INFO: Pod downwardapi-volume-bfb10229-62b1-4c43-a785-524bb42e703c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:21:21.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8113" for this suite.

• [SLOW TEST:12.436 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":273,"completed":259,"skipped":4567,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:21:21.940: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4222
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-d026ff98-d5d2-4d18-ae2f-61635af6791d
STEP: Creating a pod to test consume configMaps
Dec 18 13:21:22.205: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c" in namespace "projected-4222" to be "Succeeded or Failed"
Dec 18 13:21:22.218: INFO: Pod "pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.884759ms
Dec 18 13:21:24.225: INFO: Pod "pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019777341s
Dec 18 13:21:26.234: INFO: Pod "pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029174231s
Dec 18 13:21:28.245: INFO: Pod "pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039203887s
Dec 18 13:21:30.255: INFO: Pod "pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.049238243s
Dec 18 13:21:32.262: INFO: Pod "pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.056902528s
STEP: Saw pod success
Dec 18 13:21:32.262: INFO: Pod "pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c" satisfied condition "Succeeded or Failed"
Dec 18 13:21:32.269: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r pod pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 18 13:21:32.334: INFO: Waiting for pod pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c to disappear
Dec 18 13:21:32.339: INFO: Pod pod-projected-configmaps-5d1f4cd8-d02f-40f7-8e50-094eee9db30c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:21:32.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4222" for this suite.

• [SLOW TEST:10.423 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":273,"completed":260,"skipped":4579,"failed":0}
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:21:32.363: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5527
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-5527
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 18 13:21:32.562: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 18 13:21:32.657: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:21:34.665: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:21:36.665: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 18 13:21:38.666: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 13:21:40.668: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 13:21:42.666: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 13:21:44.664: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 13:21:46.730: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 13:21:48.722: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 13:21:50.666: INFO: The status of Pod netserver-0 is Running (Ready = false)
Dec 18 13:21:52.666: INFO: The status of Pod netserver-0 is Running (Ready = true)
Dec 18 13:21:52.684: INFO: The status of Pod netserver-1 is Running (Ready = true)
Dec 18 13:21:52.700: INFO: The status of Pod netserver-2 is Running (Ready = false)
Dec 18 13:21:54.708: INFO: The status of Pod netserver-2 is Running (Ready = false)
Dec 18 13:21:56.713: INFO: The status of Pod netserver-2 is Running (Ready = false)
Dec 18 13:21:58.715: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Dec 18 13:22:06.870: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.2.158:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5527 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 13:22:06.871: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 13:22:07.277: INFO: Found all expected endpoints: [netserver-0]
Dec 18 13:22:07.285: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.0.90:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5527 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 13:22:07.285: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 13:22:07.685: INFO: Found all expected endpoints: [netserver-1]
Dec 18 13:22:07.768: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.1.35:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5527 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 18 13:22:07.768: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
Dec 18 13:22:11.074: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:22:11.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5527" for this suite.

• [SLOW TEST:38.747 seconds]
[sig-network] Networking
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":261,"skipped":4585,"failed":0}
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:22:11.113: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8940
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Dec 18 13:22:11.351: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-8455a285-184b-4cf0-9122-bf61419a7073" in namespace "security-context-test-8940" to be "Succeeded or Failed"
Dec 18 13:22:11.359: INFO: Pod "alpine-nnp-false-8455a285-184b-4cf0-9122-bf61419a7073": Phase="Pending", Reason="", readiness=false. Elapsed: 7.73218ms
Dec 18 13:22:13.367: INFO: Pod "alpine-nnp-false-8455a285-184b-4cf0-9122-bf61419a7073": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015755295s
Dec 18 13:22:15.377: INFO: Pod "alpine-nnp-false-8455a285-184b-4cf0-9122-bf61419a7073": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026332192s
Dec 18 13:22:17.387: INFO: Pod "alpine-nnp-false-8455a285-184b-4cf0-9122-bf61419a7073": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03605506s
Dec 18 13:22:19.491: INFO: Pod "alpine-nnp-false-8455a285-184b-4cf0-9122-bf61419a7073": Phase="Pending", Reason="", readiness=false. Elapsed: 8.139636585s
Dec 18 13:22:21.501: INFO: Pod "alpine-nnp-false-8455a285-184b-4cf0-9122-bf61419a7073": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.149471975s
Dec 18 13:22:21.501: INFO: Pod "alpine-nnp-false-8455a285-184b-4cf0-9122-bf61419a7073" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:22:21.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8940" for this suite.

• [SLOW TEST:10.489 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:291
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":273,"completed":262,"skipped":4585,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:22:21.603: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Dec 18 13:22:22.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3" in namespace "downward-api-6613" to be "Succeeded or Failed"
Dec 18 13:22:22.345: INFO: Pod "downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.163757ms
Dec 18 13:22:24.354: INFO: Pod "downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015152502s
Dec 18 13:22:26.472: INFO: Pod "downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.133041146s
Dec 18 13:22:28.479: INFO: Pod "downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.140141046s
Dec 18 13:22:30.491: INFO: Pod "downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.151505096s
STEP: Saw pod success
Dec 18 13:22:30.491: INFO: Pod "downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3" satisfied condition "Succeeded or Failed"
Dec 18 13:22:30.497: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3 container client-container: <nil>
STEP: delete the pod
Dec 18 13:22:30.547: INFO: Waiting for pod downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3 to disappear
Dec 18 13:22:30.552: INFO: Pod downwardapi-volume-d1a8f05e-54dd-426a-b53b-a5de9c5b4bc3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:22:30.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6613" for this suite.

• [SLOW TEST:8.975 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":273,"completed":263,"skipped":4610,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:22:30.579: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8545
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 18 13:22:30.935: INFO: Number of nodes with available pods: 0
Dec 18 13:22:30.935: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:31.954: INFO: Number of nodes with available pods: 0
Dec 18 13:22:31.954: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:32.967: INFO: Number of nodes with available pods: 0
Dec 18 13:22:32.967: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:33.953: INFO: Number of nodes with available pods: 0
Dec 18 13:22:33.953: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:34.956: INFO: Number of nodes with available pods: 0
Dec 18 13:22:34.956: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:35.955: INFO: Number of nodes with available pods: 2
Dec 18 13:22:35.955: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-sdzg6 is running more than one daemon pod
Dec 18 13:22:36.962: INFO: Number of nodes with available pods: 3
Dec 18 13:22:36.962: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 18 13:22:37.025: INFO: Number of nodes with available pods: 2
Dec 18 13:22:37.026: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:38.046: INFO: Number of nodes with available pods: 2
Dec 18 13:22:38.046: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:39.071: INFO: Number of nodes with available pods: 2
Dec 18 13:22:39.071: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:40.053: INFO: Number of nodes with available pods: 2
Dec 18 13:22:40.053: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:41.057: INFO: Number of nodes with available pods: 2
Dec 18 13:22:41.058: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:42.058: INFO: Number of nodes with available pods: 2
Dec 18 13:22:42.058: INFO: Node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r is running more than one daemon pod
Dec 18 13:22:43.058: INFO: Number of nodes with available pods: 3
Dec 18 13:22:43.058: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8545, will wait for the garbage collector to delete the pods
Dec 18 13:22:43.154: INFO: Deleting DaemonSet.extensions daemon-set took: 22.00539ms
Dec 18 13:22:43.755: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.810817ms
Dec 18 13:22:48.462: INFO: Number of nodes with available pods: 0
Dec 18 13:22:48.463: INFO: Number of running nodes: 0, number of available pods: 0
Dec 18 13:22:48.470: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8545/daemonsets","resourceVersion":"120794"},"items":null}

Dec 18 13:22:48.477: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8545/pods","resourceVersion":"120794"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:22:48.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8545" for this suite.

• [SLOW TEST:17.974 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":273,"completed":264,"skipped":4613,"failed":0}
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:22:48.553: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3533
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 18 13:22:55.351: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3533 pod-service-account-48c11774-1521-4e7d-bb48-30101761897f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 18 13:22:55.822: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3533 pod-service-account-48c11774-1521-4e7d-bb48-30101761897f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 18 13:22:56.317: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3533 pod-service-account-48c11774-1521-4e7d-bb48-30101761897f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:22:56.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3533" for this suite.

• [SLOW TEST:8.222 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":273,"completed":265,"skipped":4618,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:22:56.776: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:22:56.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9306" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":273,"completed":266,"skipped":4628,"failed":0}
S
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:22:57.020: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-466
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 18 13:23:03.806: INFO: Successfully updated pod "adopt-release-nflqf"
STEP: Checking that the Job readopts the Pod
Dec 18 13:23:03.806: INFO: Waiting up to 15m0s for pod "adopt-release-nflqf" in namespace "job-466" to be "adopted"
Dec 18 13:23:03.827: INFO: Pod "adopt-release-nflqf": Phase="Running", Reason="", readiness=true. Elapsed: 20.318527ms
Dec 18 13:23:05.836: INFO: Pod "adopt-release-nflqf": Phase="Running", Reason="", readiness=true. Elapsed: 2.030109689s
Dec 18 13:23:05.837: INFO: Pod "adopt-release-nflqf" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 18 13:23:06.358: INFO: Successfully updated pod "adopt-release-nflqf"
STEP: Checking that the Job releases the Pod
Dec 18 13:23:06.358: INFO: Waiting up to 15m0s for pod "adopt-release-nflqf" in namespace "job-466" to be "released"
Dec 18 13:23:06.366: INFO: Pod "adopt-release-nflqf": Phase="Running", Reason="", readiness=true. Elapsed: 7.897702ms
Dec 18 13:23:08.447: INFO: Pod "adopt-release-nflqf": Phase="Running", Reason="", readiness=true. Elapsed: 2.089192636s
Dec 18 13:23:08.447: INFO: Pod "adopt-release-nflqf" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:23:08.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-466" for this suite.

• [SLOW TEST:11.452 seconds]
[sig-apps] Job
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":273,"completed":267,"skipped":4629,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:23:08.478: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Dec 18 13:23:08.707: INFO: namespace kubectl-1736
Dec 18 13:23:08.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 create -f - --namespace=kubectl-1736'
Dec 18 13:23:09.135: INFO: stderr: ""
Dec 18 13:23:09.135: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Dec 18 13:23:10.220: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 13:23:10.220: INFO: Found 0 / 1
Dec 18 13:23:11.146: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 13:23:11.146: INFO: Found 0 / 1
Dec 18 13:23:12.142: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 13:23:12.142: INFO: Found 0 / 1
Dec 18 13:23:13.143: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 13:23:13.143: INFO: Found 0 / 1
Dec 18 13:23:14.149: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 13:23:14.149: INFO: Found 0 / 1
Dec 18 13:23:15.141: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 13:23:15.141: INFO: Found 0 / 1
Dec 18 13:23:16.144: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 13:23:16.144: INFO: Found 0 / 1
Dec 18 13:23:17.143: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 13:23:17.143: INFO: Found 1 / 1
Dec 18 13:23:17.143: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 18 13:23:17.152: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 18 13:23:17.152: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 18 13:23:17.152: INFO: wait on agnhost-master startup in kubectl-1736 
Dec 18 13:23:17.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 logs agnhost-master-nkgsb agnhost-master --namespace=kubectl-1736'
Dec 18 13:23:17.286: INFO: stderr: ""
Dec 18 13:23:17.286: INFO: stdout: "Paused\n"
STEP: exposing RC
Dec 18 13:23:17.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1736'
Dec 18 13:23:17.435: INFO: stderr: ""
Dec 18 13:23:17.435: INFO: stdout: "service/rm2 exposed\n"
Dec 18 13:23:17.446: INFO: Service rm2 in namespace kubectl-1736 found.
STEP: exposing service
Dec 18 13:23:19.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-185975894 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1736'
Dec 18 13:23:19.609: INFO: stderr: ""
Dec 18 13:23:19.609: INFO: stdout: "service/rm3 exposed\n"
Dec 18 13:23:19.622: INFO: Service rm3 in namespace kubectl-1736 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:23:21.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1736" for this suite.

• [SLOW TEST:13.190 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1119
    should create services for rc  [Conformance]
    /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":273,"completed":268,"skipped":4635,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:23:21.669: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3781
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Dec 18 13:23:21.915: INFO: Waiting up to 5m0s for pod "downward-api-b7b90e89-148b-452f-9263-dea0c344207f" in namespace "downward-api-3781" to be "Succeeded or Failed"
Dec 18 13:23:21.923: INFO: Pod "downward-api-b7b90e89-148b-452f-9263-dea0c344207f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.667682ms
Dec 18 13:23:23.931: INFO: Pod "downward-api-b7b90e89-148b-452f-9263-dea0c344207f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016482575s
Dec 18 13:23:25.939: INFO: Pod "downward-api-b7b90e89-148b-452f-9263-dea0c344207f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024768555s
Dec 18 13:23:27.951: INFO: Pod "downward-api-b7b90e89-148b-452f-9263-dea0c344207f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036022192s
STEP: Saw pod success
Dec 18 13:23:27.951: INFO: Pod "downward-api-b7b90e89-148b-452f-9263-dea0c344207f" satisfied condition "Succeeded or Failed"
Dec 18 13:23:27.960: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-4p69r pod downward-api-b7b90e89-148b-452f-9263-dea0c344207f container dapi-container: <nil>
STEP: delete the pod
Dec 18 13:23:28.082: INFO: Waiting for pod downward-api-b7b90e89-148b-452f-9263-dea0c344207f to disappear
Dec 18 13:23:28.088: INFO: Pod downward-api-b7b90e89-148b-452f-9263-dea0c344207f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:23:28.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3781" for this suite.

• [SLOW TEST:6.446 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":273,"completed":269,"skipped":4649,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:23:28.119: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 18 13:23:28.949: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 18 13:23:31.003: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894608, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894608, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894608, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894608, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 18 13:23:33.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894608, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894608, loc:(*time.Location)(0x7b565c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894608, loc:(*time.Location)(0x7b565c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63743894608, loc:(*time.Location)(0x7b565c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 18 13:23:36.038: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:23:36.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3636" for this suite.
STEP: Destroying namespace "webhook-3636-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.392 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":273,"completed":270,"skipped":4673,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:23:36.513: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:23:52.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5120" for this suite.

• [SLOW TEST:16.513 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":273,"completed":271,"skipped":4686,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:23:53.028: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5978
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-3f658a3c-c2d9-4b04-b28f-014c9cb3df8f
STEP: Creating a pod to test consume secrets
Dec 18 13:23:53.290: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136" in namespace "projected-5978" to be "Succeeded or Failed"
Dec 18 13:23:53.300: INFO: Pod "pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136": Phase="Pending", Reason="", readiness=false. Elapsed: 9.202256ms
Dec 18 13:23:55.308: INFO: Pod "pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017618405s
Dec 18 13:23:57.317: INFO: Pod "pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026188316s
Dec 18 13:23:59.323: INFO: Pod "pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033045192s
Dec 18 13:24:01.333: INFO: Pod "pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042539532s
STEP: Saw pod success
Dec 18 13:24:01.333: INFO: Pod "pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136" satisfied condition "Succeeded or Failed"
Dec 18 13:24:01.343: INFO: Trying to get logs from node stoic-bose-worker-s2lnv-655cc5dcbf-t45gl pod pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136 container secret-volume-test: <nil>
STEP: delete the pod
Dec 18 13:24:01.447: INFO: Waiting for pod pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136 to disappear
Dec 18 13:24:01.458: INFO: Pod pod-projected-secrets-7ae2eeb5-1ec1-4219-bc9a-42408dea6136 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:24:01.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5978" for this suite.

• [SLOW TEST:8.472 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":273,"completed":272,"skipped":4694,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Dec 18 13:24:01.500: INFO: >>> kubeConfig: /tmp/kubeconfig-185975894
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1624
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 18 13:24:01.771: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-a 8ded498f-b4b4-4c9f-afc8-fc3c55129fef 121595 0 2020-12-18 13:24:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 13:24:01.771: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-a 8ded498f-b4b4-4c9f-afc8-fc3c55129fef 121595 0 2020-12-18 13:24:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 18 13:24:11.799: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-a 8ded498f-b4b4-4c9f-afc8-fc3c55129fef 121662 0 2020-12-18 13:24:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 13:24:11.800: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-a 8ded498f-b4b4-4c9f-afc8-fc3c55129fef 121662 0 2020-12-18 13:24:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:11 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 18 13:24:21.991: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-a 8ded498f-b4b4-4c9f-afc8-fc3c55129fef 121714 0 2020-12-18 13:24:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:21 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 13:24:21.991: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-a 8ded498f-b4b4-4c9f-afc8-fc3c55129fef 121714 0 2020-12-18 13:24:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:21 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 18 13:24:32.009: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-a 8ded498f-b4b4-4c9f-afc8-fc3c55129fef 121764 0 2020-12-18 13:24:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:21 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 13:24:32.009: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-a 8ded498f-b4b4-4c9f-afc8-fc3c55129fef 121764 0 2020-12-18 13:24:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:21 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 18 13:24:42.030: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-b 4b7cd12e-9fdf-4140-8523-602c19f677da 121816 0 2020-12-18 13:24:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 13:24:42.030: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-b 4b7cd12e-9fdf-4140-8523-602c19f677da 121816 0 2020-12-18 13:24:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 18 13:24:52.063: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-b 4b7cd12e-9fdf-4140-8523-602c19f677da 121869 0 2020-12-18 13:24:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 18 13:24:52.063: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1624 /api/v1/namespaces/watch-1624/configmaps/e2e-watch-test-configmap-b 4b7cd12e-9fdf-4140-8523-602c19f677da 121869 0 2020-12-18 13:24:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-12-18 13:24:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Dec 18 13:25:02.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1624" for this suite.

• [SLOW TEST:60.590 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.8-rc.1-3+e2dc4848ea15e7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":273,"completed":273,"skipped":4704,"failed":0}
SSSSSSSSSSSSSSSDec 18 13:25:02.092: INFO: Running AfterSuite actions on all nodes
Dec 18 13:25:02.092: INFO: Running AfterSuite actions on node 1
Dec 18 13:25:02.092: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":273,"completed":273,"skipped":4719,"failed":0}

Ran 273 of 4992 Specs in 5716.363 seconds
SUCCESS! -- 273 Passed | 0 Failed | 0 Pending | 4719 Skipped
PASS

Ginkgo ran 1 suite in 1h35m18.235179197s
Test Suite Passed

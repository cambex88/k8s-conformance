I0403 09:29:06.841338      17 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-398250616
I0403 09:29:06.841462      17 e2e.go:240] Starting e2e run "ed286ea1-55f2-11e9-a6c1-a20d030b39ea" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1554283746 - Will randomize all specs
Will run 204 of 3584 specs

Apr  3 09:29:06.955: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 09:29:06.957: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr  3 09:29:06.967: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr  3 09:29:06.984: INFO: 7 / 7 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr  3 09:29:06.984: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Apr  3 09:29:06.984: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr  3 09:29:06.990: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr  3 09:29:06.990: INFO: e2e test version: v1.14.0
Apr  3 09:29:06.991: INFO: kube-apiserver version: v1.14.0
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:29:06.991: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
Apr  3 09:29:07.028: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  3 09:29:07.039: INFO: Waiting up to 5m0s for pod "downward-api-edb96068-55f2-11e9-a6c1-a20d030b39ea" in namespace "downward-api-9222" to be "success or failure"
Apr  3 09:29:07.045: INFO: Pod "downward-api-edb96068-55f2-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.537013ms
Apr  3 09:29:09.047: INFO: Pod "downward-api-edb96068-55f2-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008116297s
Apr  3 09:29:11.051: INFO: Pod "downward-api-edb96068-55f2-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01219446s
Apr  3 09:29:13.055: INFO: Pod "downward-api-edb96068-55f2-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015563016s
STEP: Saw pod success
Apr  3 09:29:13.055: INFO: Pod "downward-api-edb96068-55f2-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:29:13.057: INFO: Trying to get logs from node docker-desktop pod downward-api-edb96068-55f2-11e9-a6c1-a20d030b39ea container dapi-container: <nil>
STEP: delete the pod
Apr  3 09:29:13.072: INFO: Waiting for pod downward-api-edb96068-55f2-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:29:13.074: INFO: Pod downward-api-edb96068-55f2-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:29:13.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9222" for this suite.
Apr  3 09:29:19.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:29:19.164: INFO: namespace downward-api-9222 deletion completed in 6.086747502s

• [SLOW TEST:12.173 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:29:19.164: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-f4f8732f-55f2-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 09:29:19.194: INFO: Waiting up to 5m0s for pod "pod-secrets-f4f8d551-55f2-11e9-a6c1-a20d030b39ea" in namespace "secrets-8336" to be "success or failure"
Apr  3 09:29:19.196: INFO: Pod "pod-secrets-f4f8d551-55f2-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.161014ms
Apr  3 09:29:21.200: INFO: Pod "pod-secrets-f4f8d551-55f2-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006001394s
Apr  3 09:29:23.204: INFO: Pod "pod-secrets-f4f8d551-55f2-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009541536s
STEP: Saw pod success
Apr  3 09:29:23.204: INFO: Pod "pod-secrets-f4f8d551-55f2-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:29:23.206: INFO: Trying to get logs from node docker-desktop pod pod-secrets-f4f8d551-55f2-11e9-a6c1-a20d030b39ea container secret-volume-test: <nil>
STEP: delete the pod
Apr  3 09:29:23.222: INFO: Waiting for pod pod-secrets-f4f8d551-55f2-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:29:23.224: INFO: Pod pod-secrets-f4f8d551-55f2-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:29:23.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8336" for this suite.
Apr  3 09:29:29.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:29:29.316: INFO: namespace secrets-8336 deletion completed in 6.085074619s

• [SLOW TEST:10.148 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:29:29.316: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 09:29:29.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 version'
Apr  3 09:29:29.398: INFO: stderr: ""
Apr  3 09:29:29.398: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:53:57Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:45:25Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:29:29.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8086" for this suite.
Apr  3 09:29:35.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:29:35.485: INFO: namespace kubectl-8086 deletion completed in 6.084615812s

• [SLOW TEST:6.168 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:29:35.485: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr  3 09:29:36.049: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Apr  3 09:29:38.090: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:29:40.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:29:42.093: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:29:44.094: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880576, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:29:46.712: INFO: Waited 614.713242ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:29:47.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8066" for this suite.
Apr  3 09:29:53.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:29:53.477: INFO: namespace aggregator-8066 deletion completed in 6.167267083s

• [SLOW TEST:17.992 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:29:53.478: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:29:53.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4579" for this suite.
Apr  3 09:30:15.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:30:15.612: INFO: namespace pods-4579 deletion completed in 22.099612588s

• [SLOW TEST:22.134 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:30:15.624: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-9781
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  3 09:30:15.655: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  3 09:30:41.714: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.0.11 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9781 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 09:30:41.714: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 09:30:42.824: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:30:42.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9781" for this suite.
Apr  3 09:31:04.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:31:04.910: INFO: namespace pod-network-test-9781 deletion completed in 22.080970786s

• [SLOW TEST:49.285 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:31:04.910: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr  3 09:31:04.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 --namespace=kubectl-7981 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr  3 09:31:07.092: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr  3 09:31:07.092: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:31:09.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7981" for this suite.
Apr  3 09:31:15.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:31:15.195: INFO: namespace kubectl-7981 deletion completed in 6.092780087s

• [SLOW TEST:10.285 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:31:15.196: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 09:31:15.232: INFO: Creating deployment "nginx-deployment"
Apr  3 09:31:15.244: INFO: Waiting for observed generation 1
Apr  3 09:31:17.255: INFO: Waiting for all required pods to come up
Apr  3 09:31:17.275: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr  3 09:31:23.295: INFO: Waiting for deployment "nginx-deployment" to complete
Apr  3 09:31:23.301: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr  3 09:31:23.310: INFO: Updating deployment nginx-deployment
Apr  3 09:31:23.310: INFO: Waiting for observed generation 2
Apr  3 09:31:25.321: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr  3 09:31:25.327: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr  3 09:31:25.333: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  3 09:31:25.349: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr  3 09:31:25.349: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr  3 09:31:25.353: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  3 09:31:25.368: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr  3 09:31:25.368: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr  3 09:31:25.384: INFO: Updating deployment nginx-deployment
Apr  3 09:31:25.384: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr  3 09:31:25.407: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr  3 09:31:27.452: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  3 09:31:27.489: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-35,SelfLink:/apis/apps/v1/namespaces/deployment-35/deployments/nginx-deployment,UID:3a24090d-55f3-11e9-ad16-025000000001,ResourceVersion:1919,Generation:3,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-04-03 09:31:25 +0000 UTC 2019-04-03 09:31:25 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-03 09:31:25 +0000 UTC 2019-04-03 09:31:15 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr  3 09:31:27.516: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-35,SelfLink:/apis/apps/v1/namespaces/deployment-35/replicasets/nginx-deployment-5f9595f595,UID:3ef3f2bb-55f3-11e9-ad16-025000000001,ResourceVersion:1906,Generation:3,CreationTimestamp:2019-04-03 09:31:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3a24090d-55f3-11e9-ad16-025000000001 0xc002d627c7 0xc002d627c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  3 09:31:27.517: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr  3 09:31:27.517: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-35,SelfLink:/apis/apps/v1/namespaces/deployment-35/replicasets/nginx-deployment-6f478d8d8,UID:3a257664-55f3-11e9-ad16-025000000001,ResourceVersion:1916,Generation:3,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3a24090d-55f3-11e9-ad16-025000000001 0xc002d62897 0xc002d62898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr  3 09:31:27.542: INFO: Pod "nginx-deployment-5f9595f595-5ms95" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5ms95,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-5ms95,UID:4041e0cd-55f3-11e9-ad16-025000000001,ResourceVersion:1902,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d63180 0xc002d63181}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d63200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d63220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.542: INFO: Pod "nginx-deployment-5f9595f595-6dp5q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6dp5q,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-6dp5q,UID:403c1374-55f3-11e9-ad16-025000000001,ResourceVersion:1897,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d632a0 0xc002d632a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d63320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d63340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.543: INFO: Pod "nginx-deployment-5f9595f595-6pwm9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6pwm9,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-6pwm9,UID:3ef5d020-55f3-11e9-ad16-025000000001,ResourceVersion:1833,Generation:0,CreationTimestamp:2019-04-03 09:31:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d633c0 0xc002d633c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d63440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d63460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.543: INFO: Pod "nginx-deployment-5f9595f595-6vvbd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6vvbd,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-6vvbd,UID:403c045e-55f3-11e9-ad16-025000000001,ResourceVersion:1895,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d63530 0xc002d63531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d635b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d635d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.543: INFO: Pod "nginx-deployment-5f9595f595-6x6gt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-6x6gt,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-6x6gt,UID:4034bb9f-55f3-11e9-ad16-025000000001,ResourceVersion:1914,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d63650 0xc002d63651}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d636d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d636f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.543: INFO: Pod "nginx-deployment-5f9595f595-8ckw5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8ckw5,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-8ckw5,UID:3ef5cbd9-55f3-11e9-ad16-025000000001,ResourceVersion:1842,Generation:0,CreationTimestamp:2019-04-03 09:31:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d637c0 0xc002d637c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d63840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d63860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.543: INFO: Pod "nginx-deployment-5f9595f595-d52ks" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-d52ks,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-d52ks,UID:403c0480-55f3-11e9-ad16-025000000001,ResourceVersion:1960,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d63930 0xc002d63931}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d639b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d639d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.543: INFO: Pod "nginx-deployment-5f9595f595-j5gb8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-j5gb8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-j5gb8,UID:40369d27-55f3-11e9-ad16-025000000001,ResourceVersion:1955,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d63aa0 0xc002d63aa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d63b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d63b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.544: INFO: Pod "nginx-deployment-5f9595f595-vw4tt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-vw4tt,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-vw4tt,UID:403bd631-55f3-11e9-ad16-025000000001,ResourceVersion:1959,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d63c10 0xc002d63c11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d63c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d63cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.544: INFO: Pod "nginx-deployment-5f9595f595-wgwgf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-wgwgf,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-wgwgf,UID:3efdcdb1-55f3-11e9-ad16-025000000001,ResourceVersion:1846,Generation:0,CreationTimestamp:2019-04-03 09:31:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d63d80 0xc002d63d81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d63e00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d63e20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.544: INFO: Pod "nginx-deployment-5f9595f595-wssgx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-wssgx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-wssgx,UID:3ef4bd97-55f3-11e9-ad16-025000000001,ResourceVersion:1819,Generation:0,CreationTimestamp:2019-04-03 09:31:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002d63ef0 0xc002d63ef1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d63f70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d63f90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.544: INFO: Pod "nginx-deployment-5f9595f595-z74jf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-z74jf,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-z74jf,UID:3f010da1-55f3-11e9-ad16-025000000001,ResourceVersion:1848,Generation:0,CreationTimestamp:2019-04-03 09:31:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002f16060 0xc002f16061}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f160e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.544: INFO: Pod "nginx-deployment-5f9595f595-zdzgq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-zdzgq,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-5f9595f595-zdzgq,UID:4036c7e6-55f3-11e9-ad16-025000000001,ResourceVersion:1925,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 3ef3f2bb-55f3-11e9-ad16-025000000001 0xc002f161d0 0xc002f161d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.547: INFO: Pod "nginx-deployment-6f478d8d8-2n2bf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2n2bf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-2n2bf,UID:403c2373-55f3-11e9-ad16-025000000001,ResourceVersion:1899,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f16340 0xc002f16341}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f163b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f163d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.547: INFO: Pod "nginx-deployment-6f478d8d8-46cc9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-46cc9,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-46cc9,UID:403633f2-55f3-11e9-ad16-025000000001,ResourceVersion:1946,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f16450 0xc002f16451}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f164c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f164e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.547: INFO: Pod "nginx-deployment-6f478d8d8-4f6bd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-4f6bd,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-4f6bd,UID:404226ec-55f3-11e9-ad16-025000000001,ResourceVersion:1908,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f165a0 0xc002f165a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.547: INFO: Pod "nginx-deployment-6f478d8d8-8cxnm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8cxnm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-8cxnm,UID:3a29fc7d-55f3-11e9-ad16-025000000001,ResourceVersion:1750,Generation:0,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f166b0 0xc002f166b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.21,StartTime:2019-04-03 09:31:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-03 09:31:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://4ac6350e924d8d007a77bc025c74a31ada664212453cf10058f804d29c340e4c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.552: INFO: Pod "nginx-deployment-6f478d8d8-bdqxd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-bdqxd,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-bdqxd,UID:40362d27-55f3-11e9-ad16-025000000001,ResourceVersion:1929,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f16810 0xc002f16811}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f168a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.553: INFO: Pod "nginx-deployment-6f478d8d8-dgtcz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-dgtcz,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-dgtcz,UID:403c1b8f-55f3-11e9-ad16-025000000001,ResourceVersion:1900,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f16960 0xc002f16961}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f169d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f169f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.553: INFO: Pod "nginx-deployment-6f478d8d8-hqtck" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-hqtck,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-hqtck,UID:4032efed-55f3-11e9-ad16-025000000001,ResourceVersion:1881,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f16a70 0xc002f16a71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.553: INFO: Pod "nginx-deployment-6f478d8d8-kj2k2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kj2k2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-kj2k2,UID:3a2e17bf-55f3-11e9-ad16-025000000001,ResourceVersion:1777,Generation:0,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f16bc0 0xc002f16bc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.20,StartTime:2019-04-03 09:31:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-03 09:31:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://730e3a0feca2c3e00cd19a46739dc52b78a4f0a6ffa9d67a6d259a394e14c5e4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.553: INFO: Pod "nginx-deployment-6f478d8d8-kq27l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kq27l,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-kq27l,UID:403c0325-55f3-11e9-ad16-025000000001,ResourceVersion:1898,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f16d20 0xc002f16d21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.554: INFO: Pod "nginx-deployment-6f478d8d8-m2d6d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-m2d6d,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-m2d6d,UID:4041ff33-55f3-11e9-ad16-025000000001,ResourceVersion:1911,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f16e30 0xc002f16e31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.554: INFO: Pod "nginx-deployment-6f478d8d8-mwmg6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-mwmg6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-mwmg6,UID:404220e8-55f3-11e9-ad16-025000000001,ResourceVersion:1910,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f16f40 0xc002f16f41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f16fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f16fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.554: INFO: Pod "nginx-deployment-6f478d8d8-nm9dv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-nm9dv,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-nm9dv,UID:40420baf-55f3-11e9-ad16-025000000001,ResourceVersion:1907,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f17050 0xc002f17051}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f170c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f170e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.554: INFO: Pod "nginx-deployment-6f478d8d8-pvr46" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pvr46,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-pvr46,UID:3a29cd1e-55f3-11e9-ad16-025000000001,ResourceVersion:1744,Generation:0,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f17160 0xc002f17161}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f171d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f171f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.17,StartTime:2019-04-03 09:31:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-03 09:31:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://944caa89c90d956f7e5a49a6f3131d844944b187a1984dc9e810ffa6ec112928}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.554: INFO: Pod "nginx-deployment-6f478d8d8-pw9xv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-pw9xv,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-pw9xv,UID:3a2a23e5-55f3-11e9-ad16-025000000001,ResourceVersion:1755,Generation:0,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f172c0 0xc002f172c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f17330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f17350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.19,StartTime:2019-04-03 09:31:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-03 09:31:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://9c79c8b2dc8bd5b1df356190dd5d29d3ad1df2f572f0982eb03d482fc0fc199b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.558: INFO: Pod "nginx-deployment-6f478d8d8-q2x27" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-q2x27,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-q2x27,UID:3a276e80-55f3-11e9-ad16-025000000001,ResourceVersion:1785,Generation:0,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f17420 0xc002f17421}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f17490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f174b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.14,StartTime:2019-04-03 09:31:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-03 09:31:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://3619cce731a2887631be2f63faf679dd7726ee87761f0b026e54151ca04c8bce}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.558: INFO: Pod "nginx-deployment-6f478d8d8-q86np" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-q86np,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-q86np,UID:3a2825a9-55f3-11e9-ad16-025000000001,ResourceVersion:1760,Generation:0,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f17580 0xc002f17581}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f175f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f17610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.16,StartTime:2019-04-03 09:31:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-03 09:31:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://c0fd77e4baeae2f2535ee9e68c134a14d4c9aff652da62f5c074aa40d0ddf875}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.559: INFO: Pod "nginx-deployment-6f478d8d8-rc27n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-rc27n,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-rc27n,UID:40422b05-55f3-11e9-ad16-025000000001,ResourceVersion:1909,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f176e0 0xc002f176e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f17750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f17770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.595: INFO: Pod "nginx-deployment-6f478d8d8-tx4w5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tx4w5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-tx4w5,UID:403c0cd6-55f3-11e9-ad16-025000000001,ResourceVersion:1958,Generation:0,CreationTimestamp:2019-04-03 09:31:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f177f0 0xc002f177f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f17860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f17880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 09:31:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.595: INFO: Pod "nginx-deployment-6f478d8d8-v5gsv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-v5gsv,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-v5gsv,UID:3a2e0626-55f3-11e9-ad16-025000000001,ResourceVersion:1765,Generation:0,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f17940 0xc002f17941}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f179b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f179d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.22,StartTime:2019-04-03 09:31:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-03 09:31:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://61c4921527692dbf6902f71620b8a5ca5a64cfe60f14b0c7aa1d96e82c9615c6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  3 09:31:27.596: INFO: Pod "nginx-deployment-6f478d8d8-wkjm8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wkjm8,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-35,SelfLink:/api/v1/namespaces/deployment-35/pods/nginx-deployment-6f478d8d8-wkjm8,UID:3a285160-55f3-11e9-ad16-025000000001,ResourceVersion:1771,Generation:0,CreationTimestamp:2019-04-03 09:31:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 3a257664-55f3-11e9-ad16-025000000001 0xc002f17aa0 0xc002f17aa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-72qvf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-72qvf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-72qvf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f17b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f17b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:31:15 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.15,StartTime:2019-04-03 09:31:15 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-03 09:31:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://b28e371f086b097a2b552733a0998509894b9b1dd5e3c5c417937933247cbe4d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:31:27.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-35" for this suite.
Apr  3 09:31:35.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:31:36.401: INFO: namespace deployment-35 deletion completed in 8.710163418s

• [SLOW TEST:21.205 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:31:36.407: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  3 09:31:36.509: INFO: PodSpec: initContainers in spec.initContainers
Apr  3 09:32:26.010: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-46d20b4f-55f3-11e9-a6c1-a20d030b39ea", GenerateName:"", Namespace:"init-container-7050", SelfLink:"/api/v1/namespaces/init-container-7050/pods/pod-init-46d20b4f-55f3-11e9-a6c1-a20d030b39ea", UID:"46d2d1f6-55f3-11e9-ad16-025000000001", ResourceVersion:"2262", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63689880696, loc:(*time.Location)(0x89f10e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"509530666"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5qxb2", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00246b580), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5qxb2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5qxb2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5qxb2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0023e8b68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"docker-desktop", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00242c540), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023e8bf0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0023e8c10)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0023e8c18), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0023e8c1c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880696, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880696, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880696, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689880696, loc:(*time.Location)(0x89f10e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.65.3", PodIP:"10.1.0.49", StartTime:(*v1.Time)(0xc000d60c20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001716460)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0017164d0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://7470737c174b324ea8cc44a9171a0eb350b717ab093c95fc74b34543f893cc0b"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000d60c60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000d60c40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:32:26.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7050" for this suite.
Apr  3 09:32:48.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:32:48.143: INFO: namespace init-container-7050 deletion completed in 22.124267335s

• [SLOW TEST:71.736 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:32:48.143: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-9277
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9277
STEP: Deleting pre-stop pod
Apr  3 09:33:01.239: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:33:01.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9277" for this suite.
Apr  3 09:33:39.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:33:39.344: INFO: namespace prestop-9277 deletion completed in 38.087463962s

• [SLOW TEST:51.199 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:33:39.351: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 09:33:39.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 version --client'
Apr  3 09:33:39.442: INFO: stderr: ""
Apr  3 09:33:39.442: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:53:57Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr  3 09:33:39.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-522'
Apr  3 09:33:39.642: INFO: stderr: ""
Apr  3 09:33:39.643: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr  3 09:33:39.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-522'
Apr  3 09:33:39.876: INFO: stderr: ""
Apr  3 09:33:39.876: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  3 09:33:40.880: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:33:40.880: INFO: Found 0 / 1
Apr  3 09:33:41.879: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:33:41.879: INFO: Found 0 / 1
Apr  3 09:33:42.880: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:33:42.880: INFO: Found 1 / 1
Apr  3 09:33:42.880: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  3 09:33:42.884: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:33:42.884: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  3 09:33:42.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 describe pod redis-master-qx7mk --namespace=kubectl-522'
Apr  3 09:33:42.979: INFO: stderr: ""
Apr  3 09:33:42.979: INFO: stdout: "Name:               redis-master-qx7mk\nNamespace:          kubectl-522\nPriority:           0\nPriorityClassName:  <none>\nNode:               docker-desktop/192.168.65.3\nStart Time:         Wed, 03 Apr 2019 09:33:39 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.1.0.52\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://b00a9e25bedab5b6ad56cfb20a6ea398594acdbe27d2417081d2adf563d2045a\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 03 Apr 2019 09:33:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jgb5x (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-jgb5x:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-jgb5x\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  3s    default-scheduler        Successfully assigned kubectl-522/redis-master-qx7mk to docker-desktop\n  Normal  Pulling    2s    kubelet, docker-desktop  Pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     0s    kubelet, docker-desktop  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    0s    kubelet, docker-desktop  Created container redis-master\n  Normal  Started    0s    kubelet, docker-desktop  Started container redis-master\n"
Apr  3 09:33:42.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 describe rc redis-master --namespace=kubectl-522'
Apr  3 09:33:43.070: INFO: stderr: ""
Apr  3 09:33:43.070: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-522\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-qx7mk\n"
Apr  3 09:33:43.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 describe service redis-master --namespace=kubectl-522'
Apr  3 09:33:43.156: INFO: stderr: ""
Apr  3 09:33:43.156: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-522\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.110.131.37\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.1.0.52:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr  3 09:33:43.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 describe node docker-desktop'
Apr  3 09:33:43.269: INFO: stderr: ""
Apr  3 09:33:43.269: INFO: stdout: "Name:               docker-desktop\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=docker-desktop\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 03 Apr 2019 09:19:28 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 03 Apr 2019 09:33:02 +0000   Wed, 03 Apr 2019 09:19:26 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 03 Apr 2019 09:33:02 +0000   Wed, 03 Apr 2019 09:19:26 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 03 Apr 2019 09:33:02 +0000   Wed, 03 Apr 2019 09:19:26 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 03 Apr 2019 09:33:02 +0000   Wed, 03 Apr 2019 09:19:26 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.65.3\n  Hostname:    docker-desktop\nCapacity:\n cpu:                6\n ephemeral-storage:  61255492Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2046460Ki\n pods:               110\nAllocatable:\n cpu:                6\n ephemeral-storage:  56453061334\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1944060Ki\n pods:               110\nSystem Info:\n Machine ID:                 \n System UUID:                4E4D4EDE-0000-0000-89AD-35B547AE8B1F\n Boot ID:                    cada87c0-14fd-4de9-93bf-949d6e54c102\n Kernel Version:             4.9.125-linuxkit\n OS Image:                   Docker Desktop\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://0.0.0-20190308210551-485aab6\n Kubelet Version:            v1.14.0\n Kube-Proxy Version:         v1.14.0\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  docker                     compose-749b4b56db-j7lz7                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m\n  docker                     compose-api-6fbb7b5685-6tssl                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m7s\n  heptio-sonobuoy            sonobuoy-e2e-job-4831e90eb5a940fb                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m1s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-0adeda72764b486f-sj4sz    0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m1s\n  kube-system                coredns-fb8b8dccf-tnbsj                                    100m (1%)     0 (0%)      70Mi (3%)        170Mi (8%)     14m\n  kube-system                coredns-fb8b8dccf-zwcdc                                    100m (1%)     0 (0%)      70Mi (3%)        170Mi (8%)     14m\n  kube-system                etcd-docker-desktop                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         13m\n  kube-system                kube-apiserver-docker-desktop                              250m (4%)     0 (0%)      0 (0%)           0 (0%)         12m\n  kube-system                kube-controller-manager-docker-desktop                     200m (3%)     0 (0%)      0 (0%)           0 (0%)         12m\n  kube-system                kube-proxy-p6h6h                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         14m\n  kube-system                kube-scheduler-docker-desktop                              100m (1%)     0 (0%)      0 (0%)           0 (0%)         12m\n  kubectl-522                redis-master-qx7mk                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                750m (12%)  0 (0%)\n  memory             140Mi (7%)  340Mi (17%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                        Message\n  ----    ------                   ----               ----                        -------\n  Normal  Starting                 14m                kubelet, docker-desktop     Starting kubelet.\n  Normal  NodeHasSufficientMemory  14m (x8 over 14m)  kubelet, docker-desktop     Node docker-desktop status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    14m (x8 over 14m)  kubelet, docker-desktop     Node docker-desktop status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     14m (x7 over 14m)  kubelet, docker-desktop     Node docker-desktop status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  14m                kubelet, docker-desktop     Updated Node Allocatable limit across pods\n  Normal  Starting                 14m                kube-proxy, docker-desktop  Starting kube-proxy.\n"
Apr  3 09:33:43.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 describe namespace kubectl-522'
Apr  3 09:33:43.355: INFO: stderr: ""
Apr  3 09:33:43.355: INFO: stdout: "Name:         kubectl-522\nLabels:       e2e-framework=kubectl\n              e2e-run=ed286ea1-55f2-11e9-a6c1-a20d030b39ea\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:33:43.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-522" for this suite.
Apr  3 09:34:05.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:34:05.431: INFO: namespace kubectl-522 deletion completed in 22.071752601s

• [SLOW TEST:26.079 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:34:05.431: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0403 09:34:15.494550      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  3 09:34:15.494: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:34:15.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7417" for this suite.
Apr  3 09:34:21.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:34:21.576: INFO: namespace gc-7417 deletion completed in 6.077533561s

• [SLOW TEST:16.145 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:34:21.576: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  3 09:34:21.605: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:34:25.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4689" for this suite.
Apr  3 09:34:45.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:34:45.696: INFO: namespace init-container-4689 deletion completed in 20.075997208s

• [SLOW TEST:24.120 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:34:45.707: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 09:34:45.745: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b79be2b5-55f3-11e9-a6c1-a20d030b39ea" in namespace "projected-150" to be "success or failure"
Apr  3 09:34:45.747: INFO: Pod "downwardapi-volume-b79be2b5-55f3-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.566854ms
Apr  3 09:34:47.751: INFO: Pod "downwardapi-volume-b79be2b5-55f3-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005812995s
Apr  3 09:34:49.754: INFO: Pod "downwardapi-volume-b79be2b5-55f3-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009306028s
STEP: Saw pod success
Apr  3 09:34:49.754: INFO: Pod "downwardapi-volume-b79be2b5-55f3-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:34:49.757: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-b79be2b5-55f3-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 09:34:49.781: INFO: Waiting for pod downwardapi-volume-b79be2b5-55f3-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:34:49.784: INFO: Pod downwardapi-volume-b79be2b5-55f3-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:34:49.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-150" for this suite.
Apr  3 09:34:55.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:34:55.896: INFO: namespace projected-150 deletion completed in 6.105342934s

• [SLOW TEST:10.189 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:34:55.898: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  3 09:34:55.949: INFO: Waiting up to 5m0s for pod "pod-bdaffd78-55f3-11e9-a6c1-a20d030b39ea" in namespace "emptydir-3161" to be "success or failure"
Apr  3 09:34:55.955: INFO: Pod "pod-bdaffd78-55f3-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.900951ms
Apr  3 09:34:57.959: INFO: Pod "pod-bdaffd78-55f3-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009635083s
Apr  3 09:34:59.962: INFO: Pod "pod-bdaffd78-55f3-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012739759s
STEP: Saw pod success
Apr  3 09:34:59.962: INFO: Pod "pod-bdaffd78-55f3-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:34:59.966: INFO: Trying to get logs from node docker-desktop pod pod-bdaffd78-55f3-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 09:34:59.990: INFO: Waiting for pod pod-bdaffd78-55f3-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:34:59.993: INFO: Pod pod-bdaffd78-55f3-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:34:59.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3161" for this suite.
Apr  3 09:35:06.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:35:06.107: INFO: namespace emptydir-3161 deletion completed in 6.110067659s

• [SLOW TEST:10.209 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:35:06.108: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr  3 09:35:06.140: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-398250616 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:35:06.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2170" for this suite.
Apr  3 09:35:12.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:35:12.341: INFO: namespace kubectl-2170 deletion completed in 6.102212769s

• [SLOW TEST:6.234 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:35:12.345: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:35:18.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4203" for this suite.
Apr  3 09:35:24.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:35:24.530: INFO: namespace emptydir-wrapper-4203 deletion completed in 6.100985699s

• [SLOW TEST:12.186 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:35:24.532: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-7725/configmap-test-cec07458-55f3-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 09:35:24.580: INFO: Waiting up to 5m0s for pod "pod-configmaps-cec1b05b-55f3-11e9-a6c1-a20d030b39ea" in namespace "configmap-7725" to be "success or failure"
Apr  3 09:35:24.589: INFO: Pod "pod-configmaps-cec1b05b-55f3-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.118744ms
Apr  3 09:35:26.593: INFO: Pod "pod-configmaps-cec1b05b-55f3-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010535318s
STEP: Saw pod success
Apr  3 09:35:26.593: INFO: Pod "pod-configmaps-cec1b05b-55f3-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:35:26.596: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-cec1b05b-55f3-11e9-a6c1-a20d030b39ea container env-test: <nil>
STEP: delete the pod
Apr  3 09:35:26.623: INFO: Waiting for pod pod-configmaps-cec1b05b-55f3-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:35:26.633: INFO: Pod pod-configmaps-cec1b05b-55f3-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:35:26.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7725" for this suite.
Apr  3 09:35:32.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:35:32.724: INFO: namespace configmap-7725 deletion completed in 6.080471131s

• [SLOW TEST:8.193 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:35:32.724: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr  3 09:35:32.767: INFO: Waiting up to 5m0s for pod "pod-d3a22d55-55f3-11e9-a6c1-a20d030b39ea" in namespace "emptydir-7257" to be "success or failure"
Apr  3 09:35:32.774: INFO: Pod "pod-d3a22d55-55f3-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.070357ms
Apr  3 09:35:34.779: INFO: Pod "pod-d3a22d55-55f3-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01130244s
STEP: Saw pod success
Apr  3 09:35:34.779: INFO: Pod "pod-d3a22d55-55f3-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:35:34.782: INFO: Trying to get logs from node docker-desktop pod pod-d3a22d55-55f3-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 09:35:34.807: INFO: Waiting for pod pod-d3a22d55-55f3-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:35:34.813: INFO: Pod pod-d3a22d55-55f3-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:35:34.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7257" for this suite.
Apr  3 09:35:40.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:35:40.905: INFO: namespace emptydir-7257 deletion completed in 6.086047424s

• [SLOW TEST:8.180 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:35:40.906: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4660.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4660.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4660.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4660.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4660.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4660.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4660.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4660.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4660.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4660.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4660.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 133.252.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.252.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.252.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.252.133_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4660.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4660.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4660.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4660.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4660.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4660.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4660.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4660.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4660.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4660.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4660.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 133.252.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.252.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.252.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.252.133_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  3 09:35:52.989: INFO: Unable to read wheezy_udp@dns-test-service.dns-4660.svc.cluster.local from pod dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea: the server could not find the requested resource (get pods dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea)
Apr  3 09:35:52.992: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4660.svc.cluster.local from pod dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea: the server could not find the requested resource (get pods dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea)
Apr  3 09:35:52.995: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local from pod dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea: the server could not find the requested resource (get pods dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea)
Apr  3 09:35:53.000: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local from pod dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea: the server could not find the requested resource (get pods dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea)
Apr  3 09:35:53.018: INFO: Unable to read jessie_udp@dns-test-service.dns-4660.svc.cluster.local from pod dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea: the server could not find the requested resource (get pods dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea)
Apr  3 09:35:53.021: INFO: Unable to read jessie_tcp@dns-test-service.dns-4660.svc.cluster.local from pod dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea: the server could not find the requested resource (get pods dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea)
Apr  3 09:35:53.025: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local from pod dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea: the server could not find the requested resource (get pods dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea)
Apr  3 09:35:53.030: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local from pod dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea: the server could not find the requested resource (get pods dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea)
Apr  3 09:35:53.044: INFO: Lookups using dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea failed for: [wheezy_udp@dns-test-service.dns-4660.svc.cluster.local wheezy_tcp@dns-test-service.dns-4660.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local jessie_udp@dns-test-service.dns-4660.svc.cluster.local jessie_tcp@dns-test-service.dns-4660.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4660.svc.cluster.local]

Apr  3 09:35:58.098: INFO: DNS probes using dns-4660/dns-test-d885d598-55f3-11e9-a6c1-a20d030b39ea succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:35:58.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4660" for this suite.
Apr  3 09:36:04.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:36:04.304: INFO: namespace dns-4660 deletion completed in 6.10034051s

• [SLOW TEST:23.397 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:36:04.304: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  3 09:36:04.349: INFO: Waiting up to 5m0s for pod "pod-e67521e9-55f3-11e9-a6c1-a20d030b39ea" in namespace "emptydir-7397" to be "success or failure"
Apr  3 09:36:04.365: INFO: Pod "pod-e67521e9-55f3-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 15.943111ms
Apr  3 09:36:06.368: INFO: Pod "pod-e67521e9-55f3-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018868373s
STEP: Saw pod success
Apr  3 09:36:06.368: INFO: Pod "pod-e67521e9-55f3-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:36:06.372: INFO: Trying to get logs from node docker-desktop pod pod-e67521e9-55f3-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 09:36:06.387: INFO: Waiting for pod pod-e67521e9-55f3-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:36:06.391: INFO: Pod pod-e67521e9-55f3-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:36:06.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7397" for this suite.
Apr  3 09:36:12.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:36:12.488: INFO: namespace emptydir-7397 deletion completed in 6.09155328s

• [SLOW TEST:8.184 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:36:12.488: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-4775
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4775 to expose endpoints map[]
Apr  3 09:36:12.546: INFO: successfully validated that service multi-endpoint-test in namespace services-4775 exposes endpoints map[] (10.026788ms elapsed)
STEP: Creating pod pod1 in namespace services-4775
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4775 to expose endpoints map[pod1:[100]]
Apr  3 09:36:14.581: INFO: successfully validated that service multi-endpoint-test in namespace services-4775 exposes endpoints map[pod1:[100]] (2.027292677s elapsed)
STEP: Creating pod pod2 in namespace services-4775
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4775 to expose endpoints map[pod1:[100] pod2:[101]]
Apr  3 09:36:16.619: INFO: successfully validated that service multi-endpoint-test in namespace services-4775 exposes endpoints map[pod1:[100] pod2:[101]] (2.031200626s elapsed)
STEP: Deleting pod pod1 in namespace services-4775
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4775 to expose endpoints map[pod2:[101]]
Apr  3 09:36:17.643: INFO: successfully validated that service multi-endpoint-test in namespace services-4775 exposes endpoints map[pod2:[101]] (1.019702915s elapsed)
STEP: Deleting pod pod2 in namespace services-4775
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4775 to expose endpoints map[]
Apr  3 09:36:18.658: INFO: successfully validated that service multi-endpoint-test in namespace services-4775 exposes endpoints map[] (1.010398456s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:36:18.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4775" for this suite.
Apr  3 09:36:24.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:36:24.767: INFO: namespace services-4775 deletion completed in 6.087025668s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:12.279 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:36:24.769: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  3 09:36:24.808: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  3 09:36:24.817: INFO: Waiting for terminating namespaces to be deleted...
Apr  3 09:36:24.822: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Apr  3 09:36:24.829: INFO: kube-apiserver-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 09:36:24.829: INFO: kube-proxy-p6h6h from kube-system started at 2019-04-03 09:19:39 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:24.829: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  3 09:36:24.829: INFO: kube-controller-manager-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 09:36:24.829: INFO: sonobuoy-e2e-job-4831e90eb5a940fb from heptio-sonobuoy started at 2019-04-03 09:28:42 +0000 UTC (2 container statuses recorded)
Apr  3 09:36:24.829: INFO: 	Container e2e ready: true, restart count 0
Apr  3 09:36:24.829: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  3 09:36:24.829: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-03 09:28:36 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:24.829: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  3 09:36:24.829: INFO: kube-scheduler-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 09:36:24.829: INFO: etcd-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 09:36:24.829: INFO: coredns-fb8b8dccf-zwcdc from kube-system started at 2019-04-03 09:19:39 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:24.829: INFO: 	Container coredns ready: true, restart count 1
Apr  3 09:36:24.829: INFO: compose-749b4b56db-j7lz7 from docker started at 2019-04-03 09:20:52 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:24.829: INFO: 	Container compose ready: true, restart count 0
Apr  3 09:36:24.829: INFO: coredns-fb8b8dccf-tnbsj from kube-system started at 2019-04-03 09:19:39 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:24.829: INFO: 	Container coredns ready: true, restart count 1
Apr  3 09:36:24.829: INFO: compose-api-6fbb7b5685-6tssl from docker started at 2019-04-03 09:20:52 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:24.829: INFO: 	Container compose ready: true, restart count 0
Apr  3 09:36:24.829: INFO: sonobuoy-systemd-logs-daemon-set-0adeda72764b486f-sj4sz from heptio-sonobuoy started at 2019-04-03 09:28:42 +0000 UTC (2 container statuses recorded)
Apr  3 09:36:24.829: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 6
Apr  3 09:36:24.829: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f3e1a928-55f3-11e9-a6c1-a20d030b39ea 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f3e1a928-55f3-11e9-a6c1-a20d030b39ea off the node docker-desktop
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f3e1a928-55f3-11e9-a6c1-a20d030b39ea
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:36:28.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6964" for this suite.
Apr  3 09:36:36.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:36:37.010: INFO: namespace sched-pred-6964 deletion completed in 8.094720703s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.241 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:36:37.011: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 09:36:37.041: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:36:37.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4940" for this suite.
Apr  3 09:36:43.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:36:43.691: INFO: namespace custom-resource-definition-4940 deletion completed in 6.079877736s

• [SLOW TEST:6.680 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:36:43.699: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  3 09:36:43.730: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  3 09:36:43.737: INFO: Waiting for terminating namespaces to be deleted...
Apr  3 09:36:43.741: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Apr  3 09:36:43.746: INFO: kube-scheduler-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 09:36:43.746: INFO: etcd-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 09:36:43.746: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-03 09:28:36 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:43.746: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  3 09:36:43.746: INFO: coredns-fb8b8dccf-zwcdc from kube-system started at 2019-04-03 09:19:39 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:43.747: INFO: 	Container coredns ready: true, restart count 1
Apr  3 09:36:43.747: INFO: compose-749b4b56db-j7lz7 from docker started at 2019-04-03 09:20:52 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:43.747: INFO: 	Container compose ready: true, restart count 0
Apr  3 09:36:43.747: INFO: coredns-fb8b8dccf-tnbsj from kube-system started at 2019-04-03 09:19:39 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:43.747: INFO: 	Container coredns ready: true, restart count 1
Apr  3 09:36:43.748: INFO: compose-api-6fbb7b5685-6tssl from docker started at 2019-04-03 09:20:52 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:43.748: INFO: 	Container compose ready: true, restart count 0
Apr  3 09:36:43.748: INFO: sonobuoy-systemd-logs-daemon-set-0adeda72764b486f-sj4sz from heptio-sonobuoy started at 2019-04-03 09:28:42 +0000 UTC (2 container statuses recorded)
Apr  3 09:36:43.748: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 6
Apr  3 09:36:43.748: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  3 09:36:43.749: INFO: kube-apiserver-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 09:36:43.749: INFO: kube-proxy-p6h6h from kube-system started at 2019-04-03 09:19:39 +0000 UTC (1 container statuses recorded)
Apr  3 09:36:43.749: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  3 09:36:43.749: INFO: kube-controller-manager-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 09:36:43.749: INFO: sonobuoy-e2e-job-4831e90eb5a940fb from heptio-sonobuoy started at 2019-04-03 09:28:42 +0000 UTC (2 container statuses recorded)
Apr  3 09:36:43.750: INFO: 	Container e2e ready: true, restart count 0
Apr  3 09:36:43.751: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1591ed3f95880174], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:36:44.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-787" for this suite.
Apr  3 09:36:50.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:36:50.850: INFO: namespace sched-pred-787 deletion completed in 6.07687135s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.151 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:36:50.850: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 09:36:50.879: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:36:54.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3198" for this suite.
Apr  3 09:37:45.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:37:45.069: INFO: namespace pods-3198 deletion completed in 50.072547565s

• [SLOW TEST:54.218 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:37:45.069: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  3 09:37:45.111: INFO: Waiting up to 5m0s for pod "pod-2284c413-55f4-11e9-a6c1-a20d030b39ea" in namespace "emptydir-4489" to be "success or failure"
Apr  3 09:37:45.121: INFO: Pod "pod-2284c413-55f4-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 10.336803ms
Apr  3 09:37:47.126: INFO: Pod "pod-2284c413-55f4-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015048485s
STEP: Saw pod success
Apr  3 09:37:47.126: INFO: Pod "pod-2284c413-55f4-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:37:47.129: INFO: Trying to get logs from node docker-desktop pod pod-2284c413-55f4-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 09:37:47.154: INFO: Waiting for pod pod-2284c413-55f4-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:37:47.159: INFO: Pod pod-2284c413-55f4-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:37:47.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4489" for this suite.
Apr  3 09:37:53.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:37:53.256: INFO: namespace emptydir-4489 deletion completed in 6.090757013s

• [SLOW TEST:8.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:37:53.256: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-27668280-55f4-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 09:37:53.309: INFO: Waiting up to 5m0s for pod "pod-secrets-27673490-55f4-11e9-a6c1-a20d030b39ea" in namespace "secrets-7739" to be "success or failure"
Apr  3 09:37:53.324: INFO: Pod "pod-secrets-27673490-55f4-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 14.938067ms
Apr  3 09:37:55.327: INFO: Pod "pod-secrets-27673490-55f4-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017744762s
STEP: Saw pod success
Apr  3 09:37:55.327: INFO: Pod "pod-secrets-27673490-55f4-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:37:55.333: INFO: Trying to get logs from node docker-desktop pod pod-secrets-27673490-55f4-11e9-a6c1-a20d030b39ea container secret-volume-test: <nil>
STEP: delete the pod
Apr  3 09:37:55.358: INFO: Waiting for pod pod-secrets-27673490-55f4-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:37:55.361: INFO: Pod pod-secrets-27673490-55f4-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:37:55.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7739" for this suite.
Apr  3 09:38:01.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:38:01.460: INFO: namespace secrets-7739 deletion completed in 6.090117278s

• [SLOW TEST:8.204 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:38:01.461: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:39:01.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9001" for this suite.
Apr  3 09:39:23.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:39:23.614: INFO: namespace container-probe-9001 deletion completed in 22.10086351s

• [SLOW TEST:82.153 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:39:23.616: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-3764
Apr  3 09:39:27.676: INFO: Started pod liveness-exec in namespace container-probe-3764
STEP: checking the pod's current state and verifying that restartCount is present
Apr  3 09:39:27.679: INFO: Initial restart count of pod liveness-exec is 0
Apr  3 09:40:13.763: INFO: Restart count of pod container-probe-3764/liveness-exec is now 1 (46.082694861s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:40:13.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3764" for this suite.
Apr  3 09:40:19.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:40:19.888: INFO: namespace container-probe-3764 deletion completed in 6.108246612s

• [SLOW TEST:56.271 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:40:19.889: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1934
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  3 09:40:19.958: INFO: Found 0 stateful pods, waiting for 3
Apr  3 09:40:29.962: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 09:40:29.962: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 09:40:29.962: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  3 09:40:29.989: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr  3 09:40:40.023: INFO: Updating stateful set ss2
Apr  3 09:40:40.030: INFO: Waiting for Pod statefulset-1934/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  3 09:40:50.035: INFO: Waiting for Pod statefulset-1934/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr  3 09:41:00.114: INFO: Found 2 stateful pods, waiting for 3
Apr  3 09:41:10.118: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 09:41:10.118: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 09:41:10.118: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr  3 09:41:10.139: INFO: Updating stateful set ss2
Apr  3 09:41:10.148: INFO: Waiting for Pod statefulset-1934/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  3 09:41:20.155: INFO: Waiting for Pod statefulset-1934/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  3 09:41:30.174: INFO: Updating stateful set ss2
Apr  3 09:41:30.182: INFO: Waiting for StatefulSet statefulset-1934/ss2 to complete update
Apr  3 09:41:30.182: INFO: Waiting for Pod statefulset-1934/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  3 09:41:40.189: INFO: Deleting all statefulset in ns statefulset-1934
Apr  3 09:41:40.194: INFO: Scaling statefulset ss2 to 0
Apr  3 09:41:50.213: INFO: Waiting for statefulset status.replicas updated to 0
Apr  3 09:41:50.218: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:41:50.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1934" for this suite.
Apr  3 09:41:56.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:41:56.343: INFO: namespace statefulset-1934 deletion completed in 6.106292969s

• [SLOW TEST:96.453 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:41:56.344: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-b84b5c31-55f4-11e9-a6c1-a20d030b39ea
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:41:56.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7119" for this suite.
Apr  3 09:42:02.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:42:02.487: INFO: namespace configmap-7119 deletion completed in 6.093575503s

• [SLOW TEST:6.143 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:42:02.487: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr  3 09:42:02.534: INFO: Waiting up to 5m0s for pod "client-containers-bbf347c3-55f4-11e9-a6c1-a20d030b39ea" in namespace "containers-5635" to be "success or failure"
Apr  3 09:42:02.552: INFO: Pod "client-containers-bbf347c3-55f4-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 17.571124ms
Apr  3 09:42:04.555: INFO: Pod "client-containers-bbf347c3-55f4-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021327087s
Apr  3 09:42:06.558: INFO: Pod "client-containers-bbf347c3-55f4-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024287926s
STEP: Saw pod success
Apr  3 09:42:06.558: INFO: Pod "client-containers-bbf347c3-55f4-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:42:06.561: INFO: Trying to get logs from node docker-desktop pod client-containers-bbf347c3-55f4-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 09:42:06.587: INFO: Waiting for pod client-containers-bbf347c3-55f4-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:42:06.590: INFO: Pod client-containers-bbf347c3-55f4-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:42:06.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5635" for this suite.
Apr  3 09:42:12.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:42:12.679: INFO: namespace containers-5635 deletion completed in 6.084224682s

• [SLOW TEST:10.192 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:42:12.679: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-4310
Apr  3 09:42:16.731: INFO: Started pod liveness-http in namespace container-probe-4310
STEP: checking the pod's current state and verifying that restartCount is present
Apr  3 09:42:16.735: INFO: Initial restart count of pod liveness-http is 0
Apr  3 09:42:34.767: INFO: Restart count of pod container-probe-4310/liveness-http is now 1 (18.030978287s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:42:34.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4310" for this suite.
Apr  3 09:42:40.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:42:40.878: INFO: namespace container-probe-4310 deletion completed in 6.089525008s

• [SLOW TEST:28.198 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:42:40.879: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  3 09:42:48.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:42:48.963: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  3 09:42:50.964: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:42:50.966: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  3 09:42:52.964: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:42:52.968: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  3 09:42:54.964: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:42:54.967: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  3 09:42:56.965: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:42:56.969: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  3 09:42:58.965: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:42:58.970: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  3 09:43:00.964: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:43:00.968: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  3 09:43:02.964: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:43:02.967: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  3 09:43:04.965: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:43:04.967: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  3 09:43:06.965: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  3 09:43:06.968: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:43:06.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7303" for this suite.
Apr  3 09:43:28.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:43:29.073: INFO: namespace container-lifecycle-hook-7303 deletion completed in 22.092056944s

• [SLOW TEST:48.194 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:43:29.075: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-ef91bba7-55f4-11e9-a6c1-a20d030b39ea
STEP: Creating secret with name s-test-opt-upd-ef91bbe8-55f4-11e9-a6c1-a20d030b39ea
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ef91bba7-55f4-11e9-a6c1-a20d030b39ea
STEP: Updating secret s-test-opt-upd-ef91bbe8-55f4-11e9-a6c1-a20d030b39ea
STEP: Creating secret with name s-test-opt-create-ef91bbf7-55f4-11e9-a6c1-a20d030b39ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:44:49.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5087" for this suite.
Apr  3 09:45:11.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:45:11.642: INFO: namespace projected-5087 deletion completed in 22.084585567s

• [SLOW TEST:102.565 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:45:11.643: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:45:33.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8863" for this suite.
Apr  3 09:45:39.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:45:40.010: INFO: namespace container-runtime-8863 deletion completed in 6.091874457s

• [SLOW TEST:28.367 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:45:40.017: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr  3 09:45:40.053: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr  3 09:45:40.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-9602'
Apr  3 09:45:40.320: INFO: stderr: ""
Apr  3 09:45:40.321: INFO: stdout: "service/redis-slave created\n"
Apr  3 09:45:40.321: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr  3 09:45:40.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-9602'
Apr  3 09:45:40.496: INFO: stderr: ""
Apr  3 09:45:40.496: INFO: stdout: "service/redis-master created\n"
Apr  3 09:45:40.496: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr  3 09:45:40.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-9602'
Apr  3 09:45:40.668: INFO: stderr: ""
Apr  3 09:45:40.668: INFO: stdout: "service/frontend created\n"
Apr  3 09:45:40.668: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr  3 09:45:40.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-9602'
Apr  3 09:45:40.845: INFO: stderr: ""
Apr  3 09:45:40.845: INFO: stdout: "deployment.apps/frontend created\n"
Apr  3 09:45:40.845: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr  3 09:45:40.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-9602'
Apr  3 09:45:41.069: INFO: stderr: ""
Apr  3 09:45:41.069: INFO: stdout: "deployment.apps/redis-master created\n"
Apr  3 09:45:41.069: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr  3 09:45:41.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-9602'
Apr  3 09:45:41.250: INFO: stderr: ""
Apr  3 09:45:41.250: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr  3 09:45:41.251: INFO: Waiting for all frontend pods to be Running.
Apr  3 09:46:01.308: INFO: Waiting for frontend to serve content.
Apr  3 09:46:02.393: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Apr  3 09:46:07.405: INFO: Trying to add a new entry to the guestbook.
Apr  3 09:46:07.417: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr  3 09:46:07.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-9602'
Apr  3 09:46:07.528: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 09:46:07.528: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr  3 09:46:07.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-9602'
Apr  3 09:46:07.633: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 09:46:07.633: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  3 09:46:07.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-9602'
Apr  3 09:46:07.741: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 09:46:07.742: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  3 09:46:07.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-9602'
Apr  3 09:46:07.839: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 09:46:07.840: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  3 09:46:07.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-9602'
Apr  3 09:46:07.934: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 09:46:07.934: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  3 09:46:07.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-9602'
Apr  3 09:46:08.024: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 09:46:08.024: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:46:08.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9602" for this suite.
Apr  3 09:46:46.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:46:46.120: INFO: namespace kubectl-9602 deletion completed in 38.086359348s

• [SLOW TEST:66.101 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:46:46.127: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-65037d54-55f5-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 09:46:46.180: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-65050b2e-55f5-11e9-a6c1-a20d030b39ea" in namespace "projected-1573" to be "success or failure"
Apr  3 09:46:46.185: INFO: Pod "pod-projected-configmaps-65050b2e-55f5-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.556786ms
Apr  3 09:46:48.189: INFO: Pod "pod-projected-configmaps-65050b2e-55f5-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008415207s
Apr  3 09:46:50.193: INFO: Pod "pod-projected-configmaps-65050b2e-55f5-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012523013s
STEP: Saw pod success
Apr  3 09:46:50.193: INFO: Pod "pod-projected-configmaps-65050b2e-55f5-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:46:50.196: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-65050b2e-55f5-11e9-a6c1-a20d030b39ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 09:46:50.215: INFO: Waiting for pod pod-projected-configmaps-65050b2e-55f5-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:46:50.218: INFO: Pod pod-projected-configmaps-65050b2e-55f5-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:46:50.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1573" for this suite.
Apr  3 09:46:56.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:46:56.311: INFO: namespace projected-1573 deletion completed in 6.089513217s

• [SLOW TEST:10.183 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:46:56.312: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:46:58.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2220" for this suite.
Apr  3 09:47:48.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:47:48.468: INFO: namespace kubelet-test-2220 deletion completed in 50.085752478s

• [SLOW TEST:52.155 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:47:48.468: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0403 09:47:54.535341      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  3 09:47:54.535: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:47:54.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6582" for this suite.
Apr  3 09:48:00.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:48:00.641: INFO: namespace gc-6582 deletion completed in 6.102145036s

• [SLOW TEST:12.173 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:48:00.641: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  3 09:48:00.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-7660'
Apr  3 09:48:00.848: INFO: stderr: ""
Apr  3 09:48:00.849: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  3 09:48:00.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7660'
Apr  3 09:48:00.936: INFO: stderr: ""
Apr  3 09:48:00.936: INFO: stdout: "update-demo-nautilus-tgpv5 update-demo-nautilus-zprg5 "
Apr  3 09:48:00.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-tgpv5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:01.023: INFO: stderr: ""
Apr  3 09:48:01.023: INFO: stdout: ""
Apr  3 09:48:01.023: INFO: update-demo-nautilus-tgpv5 is created but not running
Apr  3 09:48:06.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7660'
Apr  3 09:48:06.106: INFO: stderr: ""
Apr  3 09:48:06.106: INFO: stdout: "update-demo-nautilus-tgpv5 update-demo-nautilus-zprg5 "
Apr  3 09:48:06.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-tgpv5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:06.188: INFO: stderr: ""
Apr  3 09:48:06.188: INFO: stdout: "true"
Apr  3 09:48:06.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-tgpv5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:06.267: INFO: stderr: ""
Apr  3 09:48:06.267: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  3 09:48:06.267: INFO: validating pod update-demo-nautilus-tgpv5
Apr  3 09:48:06.275: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  3 09:48:06.276: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  3 09:48:06.276: INFO: update-demo-nautilus-tgpv5 is verified up and running
Apr  3 09:48:06.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-zprg5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:06.360: INFO: stderr: ""
Apr  3 09:48:06.360: INFO: stdout: "true"
Apr  3 09:48:06.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-zprg5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:06.439: INFO: stderr: ""
Apr  3 09:48:06.439: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  3 09:48:06.439: INFO: validating pod update-demo-nautilus-zprg5
Apr  3 09:48:06.444: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  3 09:48:06.444: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  3 09:48:06.444: INFO: update-demo-nautilus-zprg5 is verified up and running
STEP: scaling down the replication controller
Apr  3 09:48:06.449: INFO: scanned /root for discovery docs: <nil>
Apr  3 09:48:06.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7660'
Apr  3 09:48:07.560: INFO: stderr: ""
Apr  3 09:48:07.560: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  3 09:48:07.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7660'
Apr  3 09:48:07.640: INFO: stderr: ""
Apr  3 09:48:07.640: INFO: stdout: "update-demo-nautilus-tgpv5 update-demo-nautilus-zprg5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  3 09:48:12.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7660'
Apr  3 09:48:12.725: INFO: stderr: ""
Apr  3 09:48:12.725: INFO: stdout: "update-demo-nautilus-tgpv5 update-demo-nautilus-zprg5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  3 09:48:17.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7660'
Apr  3 09:48:17.806: INFO: stderr: ""
Apr  3 09:48:17.806: INFO: stdout: "update-demo-nautilus-zprg5 "
Apr  3 09:48:17.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-zprg5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:17.889: INFO: stderr: ""
Apr  3 09:48:17.890: INFO: stdout: "true"
Apr  3 09:48:17.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-zprg5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:17.971: INFO: stderr: ""
Apr  3 09:48:17.971: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  3 09:48:17.971: INFO: validating pod update-demo-nautilus-zprg5
Apr  3 09:48:17.976: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  3 09:48:17.976: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  3 09:48:17.976: INFO: update-demo-nautilus-zprg5 is verified up and running
STEP: scaling up the replication controller
Apr  3 09:48:17.979: INFO: scanned /root for discovery docs: <nil>
Apr  3 09:48:17.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7660'
Apr  3 09:48:19.090: INFO: stderr: ""
Apr  3 09:48:19.090: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  3 09:48:19.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7660'
Apr  3 09:48:19.201: INFO: stderr: ""
Apr  3 09:48:19.201: INFO: stdout: "update-demo-nautilus-x5dr9 update-demo-nautilus-zprg5 "
Apr  3 09:48:19.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-x5dr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:19.278: INFO: stderr: ""
Apr  3 09:48:19.278: INFO: stdout: ""
Apr  3 09:48:19.278: INFO: update-demo-nautilus-x5dr9 is created but not running
Apr  3 09:48:24.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7660'
Apr  3 09:48:24.369: INFO: stderr: ""
Apr  3 09:48:24.369: INFO: stdout: "update-demo-nautilus-x5dr9 update-demo-nautilus-zprg5 "
Apr  3 09:48:24.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-x5dr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:24.450: INFO: stderr: ""
Apr  3 09:48:24.450: INFO: stdout: "true"
Apr  3 09:48:24.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-x5dr9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:24.536: INFO: stderr: ""
Apr  3 09:48:24.536: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  3 09:48:24.536: INFO: validating pod update-demo-nautilus-x5dr9
Apr  3 09:48:24.542: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  3 09:48:24.542: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  3 09:48:24.542: INFO: update-demo-nautilus-x5dr9 is verified up and running
Apr  3 09:48:24.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-zprg5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:24.627: INFO: stderr: ""
Apr  3 09:48:24.627: INFO: stdout: "true"
Apr  3 09:48:24.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-zprg5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7660'
Apr  3 09:48:24.705: INFO: stderr: ""
Apr  3 09:48:24.705: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  3 09:48:24.705: INFO: validating pod update-demo-nautilus-zprg5
Apr  3 09:48:24.708: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  3 09:48:24.708: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  3 09:48:24.708: INFO: update-demo-nautilus-zprg5 is verified up and running
STEP: using delete to clean up resources
Apr  3 09:48:24.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-7660'
Apr  3 09:48:24.796: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 09:48:24.796: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  3 09:48:24.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7660'
Apr  3 09:48:24.901: INFO: stderr: "No resources found.\n"
Apr  3 09:48:24.901: INFO: stdout: ""
Apr  3 09:48:24.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -l name=update-demo --namespace=kubectl-7660 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  3 09:48:24.982: INFO: stderr: ""
Apr  3 09:48:24.982: INFO: stdout: "update-demo-nautilus-x5dr9\nupdate-demo-nautilus-zprg5\n"
Apr  3 09:48:25.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7660'
Apr  3 09:48:25.586: INFO: stderr: "No resources found.\n"
Apr  3 09:48:25.586: INFO: stdout: ""
Apr  3 09:48:25.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -l name=update-demo --namespace=kubectl-7660 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  3 09:48:25.686: INFO: stderr: ""
Apr  3 09:48:25.686: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:48:25.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7660" for this suite.
Apr  3 09:48:47.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:48:47.796: INFO: namespace kubectl-7660 deletion completed in 22.105382935s

• [SLOW TEST:47.155 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:48:47.797: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  3 09:48:47.838: INFO: namespace kubectl-9642
Apr  3 09:48:47.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-9642'
Apr  3 09:48:48.004: INFO: stderr: ""
Apr  3 09:48:48.004: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  3 09:48:49.008: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:48:49.008: INFO: Found 0 / 1
Apr  3 09:48:50.008: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:48:50.008: INFO: Found 1 / 1
Apr  3 09:48:50.008: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  3 09:48:50.010: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:48:50.010: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  3 09:48:50.010: INFO: wait on redis-master startup in kubectl-9642 
Apr  3 09:48:50.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 logs redis-master-74rj4 redis-master --namespace=kubectl-9642'
Apr  3 09:48:50.103: INFO: stderr: ""
Apr  3 09:48:50.103: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Apr 09:48:49.344 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Apr 09:48:49.345 # Server started, Redis version 3.2.12\n1:M 03 Apr 09:48:49.345 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Apr 09:48:49.345 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr  3 09:48:50.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9642'
Apr  3 09:48:50.208: INFO: stderr: ""
Apr  3 09:48:50.208: INFO: stdout: "service/rm2 exposed\n"
Apr  3 09:48:50.213: INFO: Service rm2 in namespace kubectl-9642 found.
STEP: exposing service
Apr  3 09:48:52.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9642'
Apr  3 09:48:52.311: INFO: stderr: ""
Apr  3 09:48:52.311: INFO: stdout: "service/rm3 exposed\n"
Apr  3 09:48:52.314: INFO: Service rm3 in namespace kubectl-9642 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:48:54.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9642" for this suite.
Apr  3 09:49:16.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:49:16.447: INFO: namespace kubectl-9642 deletion completed in 22.121604103s

• [SLOW TEST:28.649 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:49:16.455: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0403 09:49:26.570863      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  3 09:49:26.570: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:49:26.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8991" for this suite.
Apr  3 09:49:32.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:49:32.703: INFO: namespace gc-8991 deletion completed in 6.125285992s

• [SLOW TEST:16.248 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:49:32.704: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-c84d7849-55f5-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 09:49:32.762: INFO: Waiting up to 5m0s for pod "pod-configmaps-c84ef9ec-55f5-11e9-a6c1-a20d030b39ea" in namespace "configmap-4397" to be "success or failure"
Apr  3 09:49:32.771: INFO: Pod "pod-configmaps-c84ef9ec-55f5-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 9.001485ms
Apr  3 09:49:34.775: INFO: Pod "pod-configmaps-c84ef9ec-55f5-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012623665s
Apr  3 09:49:36.779: INFO: Pod "pod-configmaps-c84ef9ec-55f5-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01626374s
STEP: Saw pod success
Apr  3 09:49:36.779: INFO: Pod "pod-configmaps-c84ef9ec-55f5-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:49:36.781: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-c84ef9ec-55f5-11e9-a6c1-a20d030b39ea container configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 09:49:36.802: INFO: Waiting for pod pod-configmaps-c84ef9ec-55f5-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:49:36.806: INFO: Pod pod-configmaps-c84ef9ec-55f5-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:49:36.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4397" for this suite.
Apr  3 09:49:42.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:49:42.945: INFO: namespace configmap-4397 deletion completed in 6.132706436s

• [SLOW TEST:10.242 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:49:42.945: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  3 09:49:42.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-5155'
Apr  3 09:49:43.086: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  3 09:49:43.086: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr  3 09:49:45.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete deployment e2e-test-nginx-deployment --namespace=kubectl-5155'
Apr  3 09:49:45.201: INFO: stderr: ""
Apr  3 09:49:45.201: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:49:45.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5155" for this suite.
Apr  3 09:50:07.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:50:07.283: INFO: namespace kubectl-5155 deletion completed in 22.073570144s

• [SLOW TEST:24.337 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:50:07.283: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  3 09:50:07.348: INFO: Waiting up to 5m0s for pod "pod-dced1c31-55f5-11e9-a6c1-a20d030b39ea" in namespace "emptydir-4639" to be "success or failure"
Apr  3 09:50:07.355: INFO: Pod "pod-dced1c31-55f5-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.518283ms
Apr  3 09:50:09.358: INFO: Pod "pod-dced1c31-55f5-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009309374s
Apr  3 09:50:11.361: INFO: Pod "pod-dced1c31-55f5-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012083711s
STEP: Saw pod success
Apr  3 09:50:11.361: INFO: Pod "pod-dced1c31-55f5-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:50:11.366: INFO: Trying to get logs from node docker-desktop pod pod-dced1c31-55f5-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 09:50:11.389: INFO: Waiting for pod pod-dced1c31-55f5-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:50:11.394: INFO: Pod pod-dced1c31-55f5-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:50:11.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4639" for this suite.
Apr  3 09:50:17.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:50:17.518: INFO: namespace emptydir-4639 deletion completed in 6.120593633s

• [SLOW TEST:10.236 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:50:17.521: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-e3046e66-55f5-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 09:50:17.576: INFO: Waiting up to 5m0s for pod "pod-secrets-e304ffe8-55f5-11e9-a6c1-a20d030b39ea" in namespace "secrets-9533" to be "success or failure"
Apr  3 09:50:17.588: INFO: Pod "pod-secrets-e304ffe8-55f5-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 11.80141ms
Apr  3 09:50:19.591: INFO: Pod "pod-secrets-e304ffe8-55f5-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01572343s
STEP: Saw pod success
Apr  3 09:50:19.592: INFO: Pod "pod-secrets-e304ffe8-55f5-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:50:19.595: INFO: Trying to get logs from node docker-desktop pod pod-secrets-e304ffe8-55f5-11e9-a6c1-a20d030b39ea container secret-volume-test: <nil>
STEP: delete the pod
Apr  3 09:50:19.619: INFO: Waiting for pod pod-secrets-e304ffe8-55f5-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:50:19.624: INFO: Pod pod-secrets-e304ffe8-55f5-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:50:19.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9533" for this suite.
Apr  3 09:50:25.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:50:25.706: INFO: namespace secrets-9533 deletion completed in 6.078385801s

• [SLOW TEST:8.185 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:50:25.708: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-e7e49d41-55f5-11e9-a6c1-a20d030b39ea
Apr  3 09:50:25.749: INFO: Pod name my-hostname-basic-e7e49d41-55f5-11e9-a6c1-a20d030b39ea: Found 0 pods out of 1
Apr  3 09:50:30.752: INFO: Pod name my-hostname-basic-e7e49d41-55f5-11e9-a6c1-a20d030b39ea: Found 1 pods out of 1
Apr  3 09:50:30.752: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e7e49d41-55f5-11e9-a6c1-a20d030b39ea" are running
Apr  3 09:50:30.756: INFO: Pod "my-hostname-basic-e7e49d41-55f5-11e9-a6c1-a20d030b39ea-m9mgc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-03 09:50:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-03 09:50:29 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-03 09:50:29 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-03 09:50:25 +0000 UTC Reason: Message:}])
Apr  3 09:50:30.757: INFO: Trying to dial the pod
Apr  3 09:50:35.767: INFO: Controller my-hostname-basic-e7e49d41-55f5-11e9-a6c1-a20d030b39ea: Got expected result from replica 1 [my-hostname-basic-e7e49d41-55f5-11e9-a6c1-a20d030b39ea-m9mgc]: "my-hostname-basic-e7e49d41-55f5-11e9-a6c1-a20d030b39ea-m9mgc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:50:35.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2158" for this suite.
Apr  3 09:50:41.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:50:41.853: INFO: namespace replication-controller-2158 deletion completed in 6.082543004s

• [SLOW TEST:16.145 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:50:41.853: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr  3 09:50:44.411: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1255 pod-service-account-f1d2f75b-55f5-11e9-a6c1-a20d030b39ea -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr  3 09:50:44.575: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1255 pod-service-account-f1d2f75b-55f5-11e9-a6c1-a20d030b39ea -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr  3 09:50:44.748: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1255 pod-service-account-f1d2f75b-55f5-11e9-a6c1-a20d030b39ea -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:50:44.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1255" for this suite.
Apr  3 09:50:50.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:50:51.028: INFO: namespace svcaccounts-1255 deletion completed in 6.103847725s

• [SLOW TEST:9.176 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:50:51.028: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr  3 09:50:51.072: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-398250616 proxy --unix-socket=/tmp/kubectl-proxy-unix657738395/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:50:51.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5760" for this suite.
Apr  3 09:50:57.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:50:57.228: INFO: namespace kubectl-5760 deletion completed in 6.078428339s

• [SLOW TEST:6.199 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:50:57.229: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:51:21.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8641" for this suite.
Apr  3 09:51:27.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:51:27.422: INFO: namespace namespaces-8641 deletion completed in 6.078824964s
STEP: Destroying namespace "nsdeletetest-7831" for this suite.
Apr  3 09:51:27.426: INFO: Namespace nsdeletetest-7831 was already deleted
STEP: Destroying namespace "nsdeletetest-2204" for this suite.
Apr  3 09:51:33.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:51:33.538: INFO: namespace nsdeletetest-2204 deletion completed in 6.112032315s

• [SLOW TEST:36.309 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:51:33.538: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4087.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4087.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4087.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4087.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4087.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4087.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  3 09:51:37.670: INFO: DNS probes using dns-4087/dns-test-105b7910-55f6-11e9-a6c1-a20d030b39ea succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:51:37.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4087" for this suite.
Apr  3 09:51:43.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:51:43.781: INFO: namespace dns-4087 deletion completed in 6.091403531s

• [SLOW TEST:10.244 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:51:43.782: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  3 09:51:46.338: INFO: Successfully updated pod "pod-update-activedeadlineseconds-166e02a8-55f6-11e9-a6c1-a20d030b39ea"
Apr  3 09:51:46.339: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-166e02a8-55f6-11e9-a6c1-a20d030b39ea" in namespace "pods-4813" to be "terminated due to deadline exceeded"
Apr  3 09:51:46.343: INFO: Pod "pod-update-activedeadlineseconds-166e02a8-55f6-11e9-a6c1-a20d030b39ea": Phase="Running", Reason="", readiness=true. Elapsed: 3.948017ms
Apr  3 09:51:48.347: INFO: Pod "pod-update-activedeadlineseconds-166e02a8-55f6-11e9-a6c1-a20d030b39ea": Phase="Running", Reason="", readiness=true. Elapsed: 2.008169286s
Apr  3 09:51:50.351: INFO: Pod "pod-update-activedeadlineseconds-166e02a8-55f6-11e9-a6c1-a20d030b39ea": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.01194775s
Apr  3 09:51:50.351: INFO: Pod "pod-update-activedeadlineseconds-166e02a8-55f6-11e9-a6c1-a20d030b39ea" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:51:50.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4813" for this suite.
Apr  3 09:51:56.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:51:56.439: INFO: namespace pods-4813 deletion completed in 6.083703863s

• [SLOW TEST:12.656 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:51:56.439: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 09:51:56.482: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr  3 09:52:01.493: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  3 09:52:01.493: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr  3 09:52:03.496: INFO: Creating deployment "test-rollover-deployment"
Apr  3 09:52:03.505: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr  3 09:52:05.515: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr  3 09:52:05.522: INFO: Ensure that both replica sets have 1 created replica
Apr  3 09:52:05.527: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr  3 09:52:05.534: INFO: Updating deployment test-rollover-deployment
Apr  3 09:52:05.534: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr  3 09:52:07.543: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr  3 09:52:07.551: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr  3 09:52:07.558: INFO: all replica sets need to contain the pod-template-hash label
Apr  3 09:52:07.558: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881925, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:52:09.563: INFO: all replica sets need to contain the pod-template-hash label
Apr  3 09:52:09.563: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881928, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:52:11.564: INFO: all replica sets need to contain the pod-template-hash label
Apr  3 09:52:11.564: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881928, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:52:13.562: INFO: all replica sets need to contain the pod-template-hash label
Apr  3 09:52:13.563: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881928, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:52:15.563: INFO: all replica sets need to contain the pod-template-hash label
Apr  3 09:52:15.563: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881928, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:52:17.563: INFO: all replica sets need to contain the pod-template-hash label
Apr  3 09:52:17.563: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881928, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63689881923, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  3 09:52:19.563: INFO: 
Apr  3 09:52:19.563: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  3 09:52:19.572: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-2235,SelfLink:/apis/apps/v1/namespaces/deployment-2235/deployments/test-rollover-deployment,UID:2229728a-55f6-11e9-ad16-025000000001,ResourceVersion:6096,Generation:2,CreationTimestamp:2019-04-03 09:52:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-03 09:52:03 +0000 UTC 2019-04-03 09:52:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-03 09:52:18 +0000 UTC 2019-04-03 09:52:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  3 09:52:19.579: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-2235,SelfLink:/apis/apps/v1/namespaces/deployment-2235/replicasets/test-rollover-deployment-766b4d6c9d,UID:2360ab3c-55f6-11e9-ad16-025000000001,ResourceVersion:6085,Generation:2,CreationTimestamp:2019-04-03 09:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2229728a-55f6-11e9-ad16-025000000001 0xc000f05557 0xc000f05558}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  3 09:52:19.579: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr  3 09:52:19.580: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-2235,SelfLink:/apis/apps/v1/namespaces/deployment-2235/replicasets/test-rollover-controller,UID:1df97cd7-55f6-11e9-ad16-025000000001,ResourceVersion:6094,Generation:2,CreationTimestamp:2019-04-03 09:51:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2229728a-55f6-11e9-ad16-025000000001 0xc000f053af 0xc000f053c0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  3 09:52:19.581: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-2235,SelfLink:/apis/apps/v1/namespaces/deployment-2235/replicasets/test-rollover-deployment-6455657675,UID:222d2c6c-55f6-11e9-ad16-025000000001,ResourceVersion:6059,Generation:2,CreationTimestamp:2019-04-03 09:52:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2229728a-55f6-11e9-ad16-025000000001 0xc000f05487 0xc000f05488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  3 09:52:19.586: INFO: Pod "test-rollover-deployment-766b4d6c9d-wtj7x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-wtj7x,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-2235,SelfLink:/api/v1/namespaces/deployment-2235/pods/test-rollover-deployment-766b4d6c9d-wtj7x,UID:23645f3f-55f6-11e9-ad16-025000000001,ResourceVersion:6070,Generation:0,CreationTimestamp:2019-04-03 09:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 2360ab3c-55f6-11e9-ad16-025000000001 0xc0015b0107 0xc0015b0108}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5zxts {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5zxts,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5zxts true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b01b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b01d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:52:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:52:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:52:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:52:05 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.132,StartTime:2019-04-03 09:52:05 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-03 09:52:07 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e1a15fb9364a39b7884b139ac973df74a132e19db49cbd901954025cabc35f66}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:52:19.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2235" for this suite.
Apr  3 09:52:25.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:52:25.672: INFO: namespace deployment-2235 deletion completed in 6.080351361s

• [SLOW TEST:29.232 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:52:25.672: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:52:27.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6641" for this suite.
Apr  3 09:53:17.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:53:17.827: INFO: namespace kubelet-test-6641 deletion completed in 50.089312453s

• [SLOW TEST:52.155 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:53:17.827: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-4e7d6888-55f6-11e9-a6c1-a20d030b39ea
STEP: Creating secret with name s-test-opt-upd-4e7d68c7-55f6-11e9-a6c1-a20d030b39ea
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-4e7d6888-55f6-11e9-a6c1-a20d030b39ea
STEP: Updating secret s-test-opt-upd-4e7d68c7-55f6-11e9-a6c1-a20d030b39ea
STEP: Creating secret with name s-test-opt-create-4e7d68d6-55f6-11e9-a6c1-a20d030b39ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:53:25.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8749" for this suite.
Apr  3 09:53:48.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:53:48.082: INFO: namespace secrets-8749 deletion completed in 22.083777988s

• [SLOW TEST:30.255 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:53:48.084: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr  3 09:53:48.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-397'
Apr  3 09:53:48.266: INFO: stderr: ""
Apr  3 09:53:48.266: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr  3 09:53:49.270: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:53:49.270: INFO: Found 0 / 1
Apr  3 09:53:50.270: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:53:50.270: INFO: Found 0 / 1
Apr  3 09:53:51.271: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:53:51.271: INFO: Found 1 / 1
Apr  3 09:53:51.271: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  3 09:53:51.275: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 09:53:51.276: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr  3 09:53:51.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 logs redis-master-dzf57 redis-master --namespace=kubectl-397'
Apr  3 09:53:51.365: INFO: stderr: ""
Apr  3 09:53:51.365: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Apr 09:53:49.514 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Apr 09:53:49.514 # Server started, Redis version 3.2.12\n1:M 03 Apr 09:53:49.514 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Apr 09:53:49.514 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr  3 09:53:51.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 log redis-master-dzf57 redis-master --namespace=kubectl-397 --tail=1'
Apr  3 09:53:51.458: INFO: stderr: ""
Apr  3 09:53:51.458: INFO: stdout: "1:M 03 Apr 09:53:49.514 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr  3 09:53:51.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 log redis-master-dzf57 redis-master --namespace=kubectl-397 --limit-bytes=1'
Apr  3 09:53:51.557: INFO: stderr: ""
Apr  3 09:53:51.557: INFO: stdout: " "
STEP: exposing timestamps
Apr  3 09:53:51.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 log redis-master-dzf57 redis-master --namespace=kubectl-397 --tail=1 --timestamps'
Apr  3 09:53:51.647: INFO: stderr: ""
Apr  3 09:53:51.647: INFO: stdout: "2019-04-03T09:53:49.514950529Z 1:M 03 Apr 09:53:49.514 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr  3 09:53:54.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 log redis-master-dzf57 redis-master --namespace=kubectl-397 --since=1s'
Apr  3 09:53:54.243: INFO: stderr: ""
Apr  3 09:53:54.243: INFO: stdout: ""
Apr  3 09:53:54.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 log redis-master-dzf57 redis-master --namespace=kubectl-397 --since=24h'
Apr  3 09:53:54.337: INFO: stderr: ""
Apr  3 09:53:54.337: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Apr 09:53:49.514 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Apr 09:53:49.514 # Server started, Redis version 3.2.12\n1:M 03 Apr 09:53:49.514 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Apr 09:53:49.514 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr  3 09:53:54.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-397'
Apr  3 09:53:54.425: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 09:53:54.425: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr  3 09:53:54.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get rc,svc -l name=nginx --no-headers --namespace=kubectl-397'
Apr  3 09:53:54.510: INFO: stderr: "No resources found.\n"
Apr  3 09:53:54.510: INFO: stdout: ""
Apr  3 09:53:54.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -l name=nginx --namespace=kubectl-397 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  3 09:53:54.598: INFO: stderr: ""
Apr  3 09:53:54.598: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:53:54.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-397" for this suite.
Apr  3 09:54:16.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:54:16.689: INFO: namespace kubectl-397 deletion completed in 22.08572275s

• [SLOW TEST:28.605 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:54:16.689: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-7190f111-55f6-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 09:54:16.728: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7191dd4b-55f6-11e9-a6c1-a20d030b39ea" in namespace "projected-9371" to be "success or failure"
Apr  3 09:54:16.733: INFO: Pod "pod-projected-configmaps-7191dd4b-55f6-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.253463ms
Apr  3 09:54:18.737: INFO: Pod "pod-projected-configmaps-7191dd4b-55f6-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008914801s
Apr  3 09:54:20.740: INFO: Pod "pod-projected-configmaps-7191dd4b-55f6-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012503081s
STEP: Saw pod success
Apr  3 09:54:20.741: INFO: Pod "pod-projected-configmaps-7191dd4b-55f6-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:54:20.745: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-7191dd4b-55f6-11e9-a6c1-a20d030b39ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 09:54:20.768: INFO: Waiting for pod pod-projected-configmaps-7191dd4b-55f6-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:54:20.771: INFO: Pod pod-projected-configmaps-7191dd4b-55f6-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:54:20.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9371" for this suite.
Apr  3 09:54:26.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:54:26.872: INFO: namespace projected-9371 deletion completed in 6.092885384s

• [SLOW TEST:10.183 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:54:26.872: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-4hhm
STEP: Creating a pod to test atomic-volume-subpath
Apr  3 09:54:26.927: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-4hhm" in namespace "subpath-8996" to be "success or failure"
Apr  3 09:54:26.938: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Pending", Reason="", readiness=false. Elapsed: 11.124326ms
Apr  3 09:54:28.942: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015316827s
Apr  3 09:54:30.944: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 4.017805865s
Apr  3 09:54:32.948: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 6.02139648s
Apr  3 09:54:34.951: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 8.024152056s
Apr  3 09:54:36.954: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 10.027877373s
Apr  3 09:54:38.958: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 12.031701476s
Apr  3 09:54:40.961: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 14.03453874s
Apr  3 09:54:42.965: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 16.038150733s
Apr  3 09:54:44.967: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 18.040634126s
Apr  3 09:54:46.972: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 20.045639721s
Apr  3 09:54:48.976: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Running", Reason="", readiness=true. Elapsed: 22.049722851s
Apr  3 09:54:50.979: INFO: Pod "pod-subpath-test-projected-4hhm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.05242414s
STEP: Saw pod success
Apr  3 09:54:50.979: INFO: Pod "pod-subpath-test-projected-4hhm" satisfied condition "success or failure"
Apr  3 09:54:50.983: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-projected-4hhm container test-container-subpath-projected-4hhm: <nil>
STEP: delete the pod
Apr  3 09:54:51.004: INFO: Waiting for pod pod-subpath-test-projected-4hhm to disappear
Apr  3 09:54:51.006: INFO: Pod pod-subpath-test-projected-4hhm no longer exists
STEP: Deleting pod pod-subpath-test-projected-4hhm
Apr  3 09:54:51.006: INFO: Deleting pod "pod-subpath-test-projected-4hhm" in namespace "subpath-8996"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:54:51.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8996" for this suite.
Apr  3 09:54:57.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:54:57.164: INFO: namespace subpath-8996 deletion completed in 6.149727952s

• [SLOW TEST:30.292 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:54:57.164: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-89b6d4ba-55f6-11e9-a6c1-a20d030b39ea
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-89b6d4ba-55f6-11e9-a6c1-a20d030b39ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:56:29.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1409" for this suite.
Apr  3 09:56:51.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:56:51.882: INFO: namespace configmap-1409 deletion completed in 22.118456741s

• [SLOW TEST:114.716 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:56:51.890: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr  3 09:56:51.939: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Apr  3 09:56:58.981: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:56:58.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7447" for this suite.
Apr  3 09:57:05.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:57:05.087: INFO: namespace pods-7447 deletion completed in 6.094934357s

• [SLOW TEST:13.196 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:57:05.088: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 09:57:05.222: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5fdbd76-55f6-11e9-a6c1-a20d030b39ea" in namespace "downward-api-2848" to be "success or failure"
Apr  3 09:57:05.231: INFO: Pod "downwardapi-volume-d5fdbd76-55f6-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 9.04683ms
Apr  3 09:57:07.234: INFO: Pod "downwardapi-volume-d5fdbd76-55f6-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012484573s
STEP: Saw pod success
Apr  3 09:57:07.234: INFO: Pod "downwardapi-volume-d5fdbd76-55f6-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:57:07.237: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-d5fdbd76-55f6-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 09:57:07.259: INFO: Waiting for pod downwardapi-volume-d5fdbd76-55f6-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:57:07.262: INFO: Pod downwardapi-volume-d5fdbd76-55f6-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:57:07.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2848" for this suite.
Apr  3 09:57:13.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:57:13.388: INFO: namespace downward-api-2848 deletion completed in 6.122114769s

• [SLOW TEST:8.300 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:57:13.388: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0403 09:57:53.469832      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  3 09:57:53.469: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:57:53.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9548" for this suite.
Apr  3 09:57:59.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:57:59.794: INFO: namespace gc-9548 deletion completed in 6.318519969s

• [SLOW TEST:46.404 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:57:59.794: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-f6a4d527-55f6-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 09:58:00.051: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea" in namespace "projected-9415" to be "success or failure"
Apr  3 09:58:00.089: INFO: Pod "pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 38.314976ms
Apr  3 09:58:02.093: INFO: Pod "pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042400361s
Apr  3 09:58:04.096: INFO: Pod "pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044926639s
Apr  3 09:58:06.099: INFO: Pod "pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.048095271s
Apr  3 09:58:08.102: INFO: Pod "pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.051222783s
STEP: Saw pod success
Apr  3 09:58:08.102: INFO: Pod "pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:58:08.105: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 09:58:08.124: INFO: Waiting for pod pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:58:08.127: INFO: Pod pod-projected-configmaps-f6a93347-55f6-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:58:08.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9415" for this suite.
Apr  3 09:58:14.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:58:14.213: INFO: namespace projected-9415 deletion completed in 6.08263142s

• [SLOW TEST:14.419 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:58:14.220: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-ff265e19-55f6-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 09:58:14.269: INFO: Waiting up to 5m0s for pod "pod-configmaps-ff277448-55f6-11e9-a6c1-a20d030b39ea" in namespace "configmap-949" to be "success or failure"
Apr  3 09:58:14.282: INFO: Pod "pod-configmaps-ff277448-55f6-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 13.350565ms
Apr  3 09:58:16.285: INFO: Pod "pod-configmaps-ff277448-55f6-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01619035s
Apr  3 09:58:18.288: INFO: Pod "pod-configmaps-ff277448-55f6-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019262119s
STEP: Saw pod success
Apr  3 09:58:18.288: INFO: Pod "pod-configmaps-ff277448-55f6-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:58:18.293: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-ff277448-55f6-11e9-a6c1-a20d030b39ea container configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 09:58:18.311: INFO: Waiting for pod pod-configmaps-ff277448-55f6-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:58:18.318: INFO: Pod pod-configmaps-ff277448-55f6-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:58:18.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-949" for this suite.
Apr  3 09:58:24.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:58:24.404: INFO: namespace configmap-949 deletion completed in 6.077877953s

• [SLOW TEST:10.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:58:24.404: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 09:58:24.444: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr  3 09:58:29.448: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  3 09:58:29.448: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  3 09:58:33.474: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-4509,SelfLink:/apis/apps/v1/namespaces/deployment-4509/deployments/test-cleanup-deployment,UID:0835f8ca-55f7-11e9-ad16-025000000001,ResourceVersion:7116,Generation:1,CreationTimestamp:2019-04-03 09:58:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-03 09:58:29 +0000 UTC 2019-04-03 09:58:29 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-03 09:58:31 +0000 UTC 2019-04-03 09:58:29 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55cbfbc8f5" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  3 09:58:33.479: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-4509,SelfLink:/apis/apps/v1/namespaces/deployment-4509/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:08387782-55f7-11e9-ad16-025000000001,ResourceVersion:7105,Generation:1,CreationTimestamp:2019-04-03 09:58:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 0835f8ca-55f7-11e9-ad16-025000000001 0xc001eae2e7 0xc001eae2e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  3 09:58:33.487: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-r54mn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-r54mn,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-4509,SelfLink:/api/v1/namespaces/deployment-4509/pods/test-cleanup-deployment-55cbfbc8f5-r54mn,UID:08394796-55f7-11e9-ad16-025000000001,ResourceVersion:7104,Generation:0,CreationTimestamp:2019-04-03 09:58:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 08387782-55f7-11e9-ad16-025000000001 0xc001eae8c7 0xc001eae8c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-phwh9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-phwh9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-phwh9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001eae940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001eae960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:58:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:58:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:58:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 09:58:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.154,StartTime:2019-04-03 09:58:29 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-03 09:58:30 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://8737218570e045e3b5a0595e672b5e4a5b0b88a229ec7cb28eb3f7fd7ed64506}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:58:33.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4509" for this suite.
Apr  3 09:58:39.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:58:39.573: INFO: namespace deployment-4509 deletion completed in 6.08155724s

• [SLOW TEST:15.169 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:58:39.591: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr  3 09:58:39.627: INFO: Waiting up to 5m0s for pod "pod-0e44d734-55f7-11e9-a6c1-a20d030b39ea" in namespace "emptydir-9910" to be "success or failure"
Apr  3 09:58:39.630: INFO: Pod "pod-0e44d734-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.295648ms
Apr  3 09:58:41.634: INFO: Pod "pod-0e44d734-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007114041s
STEP: Saw pod success
Apr  3 09:58:41.634: INFO: Pod "pod-0e44d734-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:58:41.638: INFO: Trying to get logs from node docker-desktop pod pod-0e44d734-55f7-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 09:58:41.661: INFO: Waiting for pod pod-0e44d734-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:58:41.665: INFO: Pod pod-0e44d734-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:58:41.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9910" for this suite.
Apr  3 09:58:47.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:58:47.748: INFO: namespace emptydir-9910 deletion completed in 6.078955023s

• [SLOW TEST:8.157 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:58:47.748: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 09:58:47.788: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13220e8d-55f7-11e9-a6c1-a20d030b39ea" in namespace "projected-7645" to be "success or failure"
Apr  3 09:58:47.793: INFO: Pod "downwardapi-volume-13220e8d-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.57771ms
Apr  3 09:58:49.798: INFO: Pod "downwardapi-volume-13220e8d-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009235415s
STEP: Saw pod success
Apr  3 09:58:49.798: INFO: Pod "downwardapi-volume-13220e8d-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:58:49.803: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-13220e8d-55f7-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 09:58:49.823: INFO: Waiting for pod downwardapi-volume-13220e8d-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:58:49.827: INFO: Pod downwardapi-volume-13220e8d-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:58:49.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7645" for this suite.
Apr  3 09:58:55.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:58:55.931: INFO: namespace projected-7645 deletion completed in 6.098879972s

• [SLOW TEST:8.182 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:58:55.931: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr  3 09:58:57.993: INFO: Pod pod-hostip-18040e3a-55f7-11e9-a6c1-a20d030b39ea has hostIP: 192.168.65.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:58:57.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9100" for this suite.
Apr  3 09:59:20.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:59:20.087: INFO: namespace pods-9100 deletion completed in 22.090504826s

• [SLOW TEST:24.156 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:59:20.087: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-8161/configmap-test-2668c2df-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 09:59:20.137: INFO: Waiting up to 5m0s for pod "pod-configmaps-2669be37-55f7-11e9-a6c1-a20d030b39ea" in namespace "configmap-8161" to be "success or failure"
Apr  3 09:59:20.144: INFO: Pod "pod-configmaps-2669be37-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.946151ms
Apr  3 09:59:22.148: INFO: Pod "pod-configmaps-2669be37-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01121286s
Apr  3 09:59:24.152: INFO: Pod "pod-configmaps-2669be37-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015177589s
STEP: Saw pod success
Apr  3 09:59:24.152: INFO: Pod "pod-configmaps-2669be37-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:59:24.155: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-2669be37-55f7-11e9-a6c1-a20d030b39ea container env-test: <nil>
STEP: delete the pod
Apr  3 09:59:24.178: INFO: Waiting for pod pod-configmaps-2669be37-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:59:24.182: INFO: Pod pod-configmaps-2669be37-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:59:24.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8161" for this suite.
Apr  3 09:59:30.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:59:30.268: INFO: namespace configmap-8161 deletion completed in 6.098572468s

• [SLOW TEST:10.198 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:59:30.273: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-2c7aa624-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 09:59:30.316: INFO: Waiting up to 5m0s for pod "pod-secrets-2c7b4c7b-55f7-11e9-a6c1-a20d030b39ea" in namespace "secrets-5289" to be "success or failure"
Apr  3 09:59:30.323: INFO: Pod "pod-secrets-2c7b4c7b-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.059294ms
Apr  3 09:59:32.326: INFO: Pod "pod-secrets-2c7b4c7b-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01006892s
STEP: Saw pod success
Apr  3 09:59:32.326: INFO: Pod "pod-secrets-2c7b4c7b-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 09:59:32.329: INFO: Trying to get logs from node docker-desktop pod pod-secrets-2c7b4c7b-55f7-11e9-a6c1-a20d030b39ea container secret-volume-test: <nil>
STEP: delete the pod
Apr  3 09:59:32.354: INFO: Waiting for pod pod-secrets-2c7b4c7b-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 09:59:32.358: INFO: Pod pod-secrets-2c7b4c7b-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:59:32.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5289" for this suite.
Apr  3 09:59:38.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 09:59:38.479: INFO: namespace secrets-5289 deletion completed in 6.108856509s

• [SLOW TEST:8.207 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 09:59:38.479: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  3 09:59:42.577: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  3 09:59:42.581: INFO: Pod pod-with-poststart-http-hook still exists
Apr  3 09:59:44.582: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  3 09:59:44.585: INFO: Pod pod-with-poststart-http-hook still exists
Apr  3 09:59:46.582: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  3 09:59:46.586: INFO: Pod pod-with-poststart-http-hook still exists
Apr  3 09:59:48.582: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  3 09:59:48.585: INFO: Pod pod-with-poststart-http-hook still exists
Apr  3 09:59:50.582: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  3 09:59:50.585: INFO: Pod pod-with-poststart-http-hook still exists
Apr  3 09:59:52.582: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  3 09:59:52.585: INFO: Pod pod-with-poststart-http-hook still exists
Apr  3 09:59:54.582: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  3 09:59:54.587: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 09:59:54.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1063" for this suite.
Apr  3 10:00:16.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:00:16.676: INFO: namespace container-lifecycle-hook-1063 deletion completed in 22.086304713s

• [SLOW TEST:38.198 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:00:16.682: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  3 10:00:24.761: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  3 10:00:24.766: INFO: Pod pod-with-prestop-http-hook still exists
Apr  3 10:00:26.767: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  3 10:00:26.773: INFO: Pod pod-with-prestop-http-hook still exists
Apr  3 10:00:28.767: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  3 10:00:28.771: INFO: Pod pod-with-prestop-http-hook still exists
Apr  3 10:00:30.767: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  3 10:00:30.773: INFO: Pod pod-with-prestop-http-hook still exists
Apr  3 10:00:32.767: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  3 10:00:32.771: INFO: Pod pod-with-prestop-http-hook still exists
Apr  3 10:00:34.767: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  3 10:00:34.770: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:00:34.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9718" for this suite.
Apr  3 10:00:56.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:00:56.865: INFO: namespace container-lifecycle-hook-9718 deletion completed in 22.08221859s

• [SLOW TEST:40.182 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:00:56.870: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:00:56.911: INFO: Waiting up to 5m0s for pod "downwardapi-volume-601874b9-55f7-11e9-a6c1-a20d030b39ea" in namespace "projected-9050" to be "success or failure"
Apr  3 10:00:56.924: INFO: Pod "downwardapi-volume-601874b9-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 13.26067ms
Apr  3 10:00:58.928: INFO: Pod "downwardapi-volume-601874b9-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017085551s
STEP: Saw pod success
Apr  3 10:00:58.928: INFO: Pod "downwardapi-volume-601874b9-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:00:58.932: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-601874b9-55f7-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:00:58.949: INFO: Waiting for pod downwardapi-volume-601874b9-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:00:58.952: INFO: Pod downwardapi-volume-601874b9-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:00:58.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9050" for this suite.
Apr  3 10:01:04.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:01:05.041: INFO: namespace projected-9050 deletion completed in 6.082068978s

• [SLOW TEST:8.171 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:01:05.043: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:01:05.085: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64f7f547-55f7-11e9-a6c1-a20d030b39ea" in namespace "projected-8135" to be "success or failure"
Apr  3 10:01:05.091: INFO: Pod "downwardapi-volume-64f7f547-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.281954ms
Apr  3 10:01:07.095: INFO: Pod "downwardapi-volume-64f7f547-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009936479s
STEP: Saw pod success
Apr  3 10:01:07.095: INFO: Pod "downwardapi-volume-64f7f547-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:01:07.099: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-64f7f547-55f7-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:01:07.122: INFO: Waiting for pod downwardapi-volume-64f7f547-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:01:07.126: INFO: Pod downwardapi-volume-64f7f547-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:01:07.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8135" for this suite.
Apr  3 10:01:13.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:01:13.246: INFO: namespace projected-8135 deletion completed in 6.114155976s

• [SLOW TEST:8.203 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:01:13.246: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  3 10:01:13.283: INFO: Waiting up to 5m0s for pod "pod-69dae2f4-55f7-11e9-a6c1-a20d030b39ea" in namespace "emptydir-2234" to be "success or failure"
Apr  3 10:01:13.289: INFO: Pod "pod-69dae2f4-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.959584ms
Apr  3 10:01:15.292: INFO: Pod "pod-69dae2f4-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008689961s
STEP: Saw pod success
Apr  3 10:01:15.292: INFO: Pod "pod-69dae2f4-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:01:15.294: INFO: Trying to get logs from node docker-desktop pod pod-69dae2f4-55f7-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:01:15.313: INFO: Waiting for pod pod-69dae2f4-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:01:15.317: INFO: Pod pod-69dae2f4-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:01:15.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2234" for this suite.
Apr  3 10:01:21.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:01:21.411: INFO: namespace emptydir-2234 deletion completed in 6.089781249s

• [SLOW TEST:8.165 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:01:21.411: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-6eb91f5e-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:01:21.456: INFO: Waiting up to 5m0s for pod "pod-secrets-6eb9de3e-55f7-11e9-a6c1-a20d030b39ea" in namespace "secrets-6782" to be "success or failure"
Apr  3 10:01:21.471: INFO: Pod "pod-secrets-6eb9de3e-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 14.831139ms
Apr  3 10:01:23.473: INFO: Pod "pod-secrets-6eb9de3e-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017544736s
STEP: Saw pod success
Apr  3 10:01:23.473: INFO: Pod "pod-secrets-6eb9de3e-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:01:23.477: INFO: Trying to get logs from node docker-desktop pod pod-secrets-6eb9de3e-55f7-11e9-a6c1-a20d030b39ea container secret-env-test: <nil>
STEP: delete the pod
Apr  3 10:01:23.500: INFO: Waiting for pod pod-secrets-6eb9de3e-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:01:23.507: INFO: Pod pod-secrets-6eb9de3e-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:01:23.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6782" for this suite.
Apr  3 10:01:29.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:01:29.602: INFO: namespace secrets-6782 deletion completed in 6.085876962s

• [SLOW TEST:8.190 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:01:29.603: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-739c7883-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:01:31.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-296" for this suite.
Apr  3 10:01:53.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:01:53.762: INFO: namespace configmap-296 deletion completed in 22.081750252s

• [SLOW TEST:24.160 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:01:53.763: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-82017e7a-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:01:53.812: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8202b4f9-55f7-11e9-a6c1-a20d030b39ea" in namespace "projected-9946" to be "success or failure"
Apr  3 10:01:53.816: INFO: Pod "pod-projected-secrets-8202b4f9-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.61298ms
Apr  3 10:01:55.820: INFO: Pod "pod-projected-secrets-8202b4f9-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0078114s
STEP: Saw pod success
Apr  3 10:01:55.820: INFO: Pod "pod-projected-secrets-8202b4f9-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:01:55.824: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-8202b4f9-55f7-11e9-a6c1-a20d030b39ea container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  3 10:01:55.864: INFO: Waiting for pod pod-projected-secrets-8202b4f9-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:01:55.873: INFO: Pod pod-projected-secrets-8202b4f9-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:01:55.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9946" for this suite.
Apr  3 10:02:01.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:02:01.974: INFO: namespace projected-9946 deletion completed in 6.093356151s

• [SLOW TEST:8.210 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:02:01.975: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  3 10:02:02.022: INFO: Waiting up to 5m0s for pod "pod-86e7427a-55f7-11e9-a6c1-a20d030b39ea" in namespace "emptydir-7065" to be "success or failure"
Apr  3 10:02:02.027: INFO: Pod "pod-86e7427a-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.638215ms
Apr  3 10:02:04.032: INFO: Pod "pod-86e7427a-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009605866s
STEP: Saw pod success
Apr  3 10:02:04.032: INFO: Pod "pod-86e7427a-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:02:04.036: INFO: Trying to get logs from node docker-desktop pod pod-86e7427a-55f7-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:02:04.062: INFO: Waiting for pod pod-86e7427a-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:02:04.069: INFO: Pod pod-86e7427a-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:02:04.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7065" for this suite.
Apr  3 10:02:10.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:02:10.233: INFO: namespace emptydir-7065 deletion completed in 6.155432483s

• [SLOW TEST:8.258 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:02:10.233: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-8bd470bd-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 10:02:10.295: INFO: Waiting up to 5m0s for pod "pod-configmaps-8bd581bf-55f7-11e9-a6c1-a20d030b39ea" in namespace "configmap-1313" to be "success or failure"
Apr  3 10:02:10.307: INFO: Pod "pod-configmaps-8bd581bf-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 12.27019ms
Apr  3 10:02:12.311: INFO: Pod "pod-configmaps-8bd581bf-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016139114s
STEP: Saw pod success
Apr  3 10:02:12.311: INFO: Pod "pod-configmaps-8bd581bf-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:02:12.315: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-8bd581bf-55f7-11e9-a6c1-a20d030b39ea container configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 10:02:12.341: INFO: Waiting for pod pod-configmaps-8bd581bf-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:02:12.356: INFO: Pod pod-configmaps-8bd581bf-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:02:12.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1313" for this suite.
Apr  3 10:02:18.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:02:18.523: INFO: namespace configmap-1313 deletion completed in 6.162534637s

• [SLOW TEST:8.290 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:02:18.523: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-2048/secret-test-90c45a10-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:02:18.579: INFO: Waiting up to 5m0s for pod "pod-configmaps-90c581a6-55f7-11e9-a6c1-a20d030b39ea" in namespace "secrets-2048" to be "success or failure"
Apr  3 10:02:18.587: INFO: Pod "pod-configmaps-90c581a6-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.070176ms
Apr  3 10:02:20.590: INFO: Pod "pod-configmaps-90c581a6-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011350395s
STEP: Saw pod success
Apr  3 10:02:20.590: INFO: Pod "pod-configmaps-90c581a6-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:02:20.594: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-90c581a6-55f7-11e9-a6c1-a20d030b39ea container env-test: <nil>
STEP: delete the pod
Apr  3 10:02:20.619: INFO: Waiting for pod pod-configmaps-90c581a6-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:02:20.622: INFO: Pod pod-configmaps-90c581a6-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:02:20.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2048" for this suite.
Apr  3 10:02:26.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:02:26.713: INFO: namespace secrets-2048 deletion completed in 6.07795854s

• [SLOW TEST:8.189 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:02:26.715: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  3 10:02:26.754: INFO: Waiting up to 5m0s for pod "pod-95a57eab-55f7-11e9-a6c1-a20d030b39ea" in namespace "emptydir-9962" to be "success or failure"
Apr  3 10:02:26.759: INFO: Pod "pod-95a57eab-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.99956ms
Apr  3 10:02:28.762: INFO: Pod "pod-95a57eab-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008179102s
STEP: Saw pod success
Apr  3 10:02:28.762: INFO: Pod "pod-95a57eab-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:02:28.765: INFO: Trying to get logs from node docker-desktop pod pod-95a57eab-55f7-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:02:28.786: INFO: Waiting for pod pod-95a57eab-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:02:28.792: INFO: Pod pod-95a57eab-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:02:28.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9962" for this suite.
Apr  3 10:02:34.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:02:34.894: INFO: namespace emptydir-9962 deletion completed in 6.098173401s

• [SLOW TEST:8.179 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:02:34.894: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-9a88001d-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating configMap with name cm-test-opt-upd-9a88005c-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9a88001d-55f7-11e9-a6c1-a20d030b39ea
STEP: Updating configmap cm-test-opt-upd-9a88005c-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating configMap with name cm-test-opt-create-9a88008b-55f7-11e9-a6c1-a20d030b39ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:02:41.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3840" for this suite.
Apr  3 10:03:03.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:03:03.132: INFO: namespace projected-3840 deletion completed in 22.090732148s

• [SLOW TEST:28.237 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:03:03.132: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:03:07.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2653" for this suite.
Apr  3 10:03:57.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:03:57.286: INFO: namespace kubelet-test-2653 deletion completed in 50.094843428s

• [SLOW TEST:54.152 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:03:57.289: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-cba1df1e-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 10:03:57.327: INFO: Waiting up to 5m0s for pod "pod-configmaps-cba239d5-55f7-11e9-a6c1-a20d030b39ea" in namespace "configmap-1820" to be "success or failure"
Apr  3 10:03:57.333: INFO: Pod "pod-configmaps-cba239d5-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.726545ms
Apr  3 10:03:59.336: INFO: Pod "pod-configmaps-cba239d5-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008455554s
STEP: Saw pod success
Apr  3 10:03:59.336: INFO: Pod "pod-configmaps-cba239d5-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:03:59.339: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-cba239d5-55f7-11e9-a6c1-a20d030b39ea container configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 10:03:59.358: INFO: Waiting for pod pod-configmaps-cba239d5-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:03:59.361: INFO: Pod pod-configmaps-cba239d5-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:03:59.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1820" for this suite.
Apr  3 10:04:05.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:04:05.463: INFO: namespace configmap-1820 deletion completed in 6.09731761s

• [SLOW TEST:8.174 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:04:05.463: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  3 10:04:05.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2182'
Apr  3 10:04:05.709: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  3 10:04:05.709: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr  3 10:04:05.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete jobs e2e-test-nginx-job --namespace=kubectl-2182'
Apr  3 10:04:05.814: INFO: stderr: ""
Apr  3 10:04:05.814: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:04:05.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2182" for this suite.
Apr  3 10:04:11.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:04:11.901: INFO: namespace kubectl-2182 deletion completed in 6.079543659s

• [SLOW TEST:6.438 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:04:11.901: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-d4585e1e-55f7-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:04:11.947: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d459101d-55f7-11e9-a6c1-a20d030b39ea" in namespace "projected-1587" to be "success or failure"
Apr  3 10:04:11.953: INFO: Pod "pod-projected-secrets-d459101d-55f7-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.994356ms
Apr  3 10:04:13.956: INFO: Pod "pod-projected-secrets-d459101d-55f7-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009213408s
STEP: Saw pod success
Apr  3 10:04:13.956: INFO: Pod "pod-projected-secrets-d459101d-55f7-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:04:13.959: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-d459101d-55f7-11e9-a6c1-a20d030b39ea container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  3 10:04:13.976: INFO: Waiting for pod pod-projected-secrets-d459101d-55f7-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:04:13.982: INFO: Pod pod-projected-secrets-d459101d-55f7-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:04:13.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1587" for this suite.
Apr  3 10:04:20.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:04:20.181: INFO: namespace projected-1587 deletion completed in 6.195191335s

• [SLOW TEST:8.280 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:04:20.185: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  3 10:04:20.252: INFO: Number of nodes with available pods: 0
Apr  3 10:04:20.252: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:04:21.265: INFO: Number of nodes with available pods: 0
Apr  3 10:04:21.265: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:04:22.257: INFO: Number of nodes with available pods: 1
Apr  3 10:04:22.257: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr  3 10:04:22.279: INFO: Number of nodes with available pods: 0
Apr  3 10:04:22.283: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:04:23.289: INFO: Number of nodes with available pods: 0
Apr  3 10:04:23.290: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:04:24.290: INFO: Number of nodes with available pods: 0
Apr  3 10:04:24.290: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:04:25.288: INFO: Number of nodes with available pods: 1
Apr  3 10:04:25.289: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6005, will wait for the garbage collector to delete the pods
Apr  3 10:04:25.356: INFO: Deleting DaemonSet.extensions daemon-set took: 6.029385ms
Apr  3 10:04:25.457: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.781658ms
Apr  3 10:04:33.563: INFO: Number of nodes with available pods: 0
Apr  3 10:04:33.564: INFO: Number of running nodes: 0, number of available pods: 0
Apr  3 10:04:33.577: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6005/daemonsets","resourceVersion":"8240"},"items":null}

Apr  3 10:04:33.587: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6005/pods","resourceVersion":"8240"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:04:33.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6005" for this suite.
Apr  3 10:04:39.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:04:39.741: INFO: namespace daemonsets-6005 deletion completed in 6.117622632s

• [SLOW TEST:19.557 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:04:39.746: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2489
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  3 10:04:39.803: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  3 10:05:03.869: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.0.182:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2489 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:05:03.869: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:05:04.009: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:05:04.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2489" for this suite.
Apr  3 10:05:26.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:05:26.119: INFO: namespace pod-network-test-2489 deletion completed in 22.104436358s

• [SLOW TEST:46.373 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:05:26.126: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  3 10:05:26.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4762'
Apr  3 10:05:26.246: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  3 10:05:26.246: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr  3 10:05:26.262: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-rx9st]
Apr  3 10:05:26.262: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-rx9st" in namespace "kubectl-4762" to be "running and ready"
Apr  3 10:05:26.267: INFO: Pod "e2e-test-nginx-rc-rx9st": Phase="Pending", Reason="", readiness=false. Elapsed: 5.674168ms
Apr  3 10:05:28.270: INFO: Pod "e2e-test-nginx-rc-rx9st": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00849724s
Apr  3 10:05:30.274: INFO: Pod "e2e-test-nginx-rc-rx9st": Phase="Running", Reason="", readiness=true. Elapsed: 4.012212385s
Apr  3 10:05:30.274: INFO: Pod "e2e-test-nginx-rc-rx9st" satisfied condition "running and ready"
Apr  3 10:05:30.274: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-rx9st]
Apr  3 10:05:30.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 logs rc/e2e-test-nginx-rc --namespace=kubectl-4762'
Apr  3 10:05:30.380: INFO: stderr: ""
Apr  3 10:05:30.380: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr  3 10:05:30.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete rc e2e-test-nginx-rc --namespace=kubectl-4762'
Apr  3 10:05:30.468: INFO: stderr: ""
Apr  3 10:05:30.468: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:05:30.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4762" for this suite.
Apr  3 10:05:52.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:05:52.628: INFO: namespace kubectl-4762 deletion completed in 22.152713807s

• [SLOW TEST:26.503 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:05:52.628: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6742
Apr  3 10:05:56.702: INFO: Started pod liveness-http in namespace container-probe-6742
STEP: checking the pod's current state and verifying that restartCount is present
Apr  3 10:05:56.705: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:09:57.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6742" for this suite.
Apr  3 10:10:03.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:10:03.263: INFO: namespace container-probe-6742 deletion completed in 6.101337215s

• [SLOW TEST:250.628 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:10:03.263: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-a5c5d466-55f8-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 10:10:03.311: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a5c6aeef-55f8-11e9-a6c1-a20d030b39ea" in namespace "projected-28" to be "success or failure"
Apr  3 10:10:03.317: INFO: Pod "pod-projected-configmaps-a5c6aeef-55f8-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.718521ms
Apr  3 10:10:05.320: INFO: Pod "pod-projected-configmaps-a5c6aeef-55f8-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009310276s
STEP: Saw pod success
Apr  3 10:10:05.320: INFO: Pod "pod-projected-configmaps-a5c6aeef-55f8-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:10:05.324: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-a5c6aeef-55f8-11e9-a6c1-a20d030b39ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 10:10:05.352: INFO: Waiting for pod pod-projected-configmaps-a5c6aeef-55f8-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:10:05.357: INFO: Pod pod-projected-configmaps-a5c6aeef-55f8-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:10:05.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-28" for this suite.
Apr  3 10:10:11.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:10:11.442: INFO: namespace projected-28 deletion completed in 6.076968855s

• [SLOW TEST:8.179 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:10:11.444: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-aaa5c9e1-55f8-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:10:11.488: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aaa69656-55f8-11e9-a6c1-a20d030b39ea" in namespace "projected-3658" to be "success or failure"
Apr  3 10:10:11.493: INFO: Pod "pod-projected-secrets-aaa69656-55f8-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.805602ms
Apr  3 10:10:13.496: INFO: Pod "pod-projected-secrets-aaa69656-55f8-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008502621s
STEP: Saw pod success
Apr  3 10:10:13.496: INFO: Pod "pod-projected-secrets-aaa69656-55f8-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:10:13.499: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-aaa69656-55f8-11e9-a6c1-a20d030b39ea container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  3 10:10:13.525: INFO: Waiting for pod pod-projected-secrets-aaa69656-55f8-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:10:13.530: INFO: Pod pod-projected-secrets-aaa69656-55f8-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:10:13.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3658" for this suite.
Apr  3 10:10:19.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:10:19.628: INFO: namespace projected-3658 deletion completed in 6.094701719s

• [SLOW TEST:8.184 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:10:19.629: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:10:19.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af8776c0-55f8-11e9-a6c1-a20d030b39ea" in namespace "downward-api-4219" to be "success or failure"
Apr  3 10:10:19.684: INFO: Pod "downwardapi-volume-af8776c0-55f8-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.54742ms
Apr  3 10:10:21.688: INFO: Pod "downwardapi-volume-af8776c0-55f8-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009353085s
STEP: Saw pod success
Apr  3 10:10:21.688: INFO: Pod "downwardapi-volume-af8776c0-55f8-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:10:21.692: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-af8776c0-55f8-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:10:21.708: INFO: Waiting for pod downwardapi-volume-af8776c0-55f8-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:10:21.712: INFO: Pod downwardapi-volume-af8776c0-55f8-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:10:21.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4219" for this suite.
Apr  3 10:10:27.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:10:27.806: INFO: namespace downward-api-4219 deletion completed in 6.086732373s

• [SLOW TEST:8.177 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:10:27.806: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr  3 10:10:27.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-3837'
Apr  3 10:10:27.984: INFO: stderr: ""
Apr  3 10:10:27.984: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  3 10:10:27.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3837'
Apr  3 10:10:28.111: INFO: stderr: ""
Apr  3 10:10:28.111: INFO: stdout: "update-demo-nautilus-p68kz update-demo-nautilus-v8zzr "
Apr  3 10:10:28.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-p68kz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3837'
Apr  3 10:10:28.209: INFO: stderr: ""
Apr  3 10:10:28.209: INFO: stdout: ""
Apr  3 10:10:28.209: INFO: update-demo-nautilus-p68kz is created but not running
Apr  3 10:10:33.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3837'
Apr  3 10:10:33.295: INFO: stderr: ""
Apr  3 10:10:33.295: INFO: stdout: "update-demo-nautilus-p68kz update-demo-nautilus-v8zzr "
Apr  3 10:10:33.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-p68kz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3837'
Apr  3 10:10:33.376: INFO: stderr: ""
Apr  3 10:10:33.376: INFO: stdout: "true"
Apr  3 10:10:33.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-p68kz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3837'
Apr  3 10:10:33.454: INFO: stderr: ""
Apr  3 10:10:33.454: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  3 10:10:33.454: INFO: validating pod update-demo-nautilus-p68kz
Apr  3 10:10:33.459: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  3 10:10:33.459: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  3 10:10:33.459: INFO: update-demo-nautilus-p68kz is verified up and running
Apr  3 10:10:33.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-v8zzr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3837'
Apr  3 10:10:33.542: INFO: stderr: ""
Apr  3 10:10:33.542: INFO: stdout: "true"
Apr  3 10:10:33.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-v8zzr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3837'
Apr  3 10:10:33.617: INFO: stderr: ""
Apr  3 10:10:33.617: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  3 10:10:33.617: INFO: validating pod update-demo-nautilus-v8zzr
Apr  3 10:10:33.623: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  3 10:10:33.624: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  3 10:10:33.624: INFO: update-demo-nautilus-v8zzr is verified up and running
STEP: rolling-update to new replication controller
Apr  3 10:10:33.628: INFO: scanned /root for discovery docs: <nil>
Apr  3 10:10:33.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3837'
Apr  3 10:10:55.967: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  3 10:10:55.967: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  3 10:10:55.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3837'
Apr  3 10:10:56.050: INFO: stderr: ""
Apr  3 10:10:56.051: INFO: stdout: "update-demo-kitten-jvvl7 update-demo-kitten-w2tqc "
Apr  3 10:10:56.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-kitten-jvvl7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3837'
Apr  3 10:10:56.123: INFO: stderr: ""
Apr  3 10:10:56.123: INFO: stdout: "true"
Apr  3 10:10:56.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-kitten-jvvl7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3837'
Apr  3 10:10:56.200: INFO: stderr: ""
Apr  3 10:10:56.200: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  3 10:10:56.200: INFO: validating pod update-demo-kitten-jvvl7
Apr  3 10:10:56.206: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  3 10:10:56.206: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  3 10:10:56.206: INFO: update-demo-kitten-jvvl7 is verified up and running
Apr  3 10:10:56.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-kitten-w2tqc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3837'
Apr  3 10:10:56.284: INFO: stderr: ""
Apr  3 10:10:56.284: INFO: stdout: "true"
Apr  3 10:10:56.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-kitten-w2tqc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3837'
Apr  3 10:10:56.361: INFO: stderr: ""
Apr  3 10:10:56.361: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  3 10:10:56.361: INFO: validating pod update-demo-kitten-w2tqc
Apr  3 10:10:56.366: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  3 10:10:56.366: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  3 10:10:56.366: INFO: update-demo-kitten-w2tqc is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:10:56.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3837" for this suite.
Apr  3 10:11:20.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:11:20.513: INFO: namespace kubectl-3837 deletion completed in 24.141509998s

• [SLOW TEST:52.707 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:11:20.514: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-d3d188bc-55f8-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 10:11:20.567: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d3d2b6cd-55f8-11e9-a6c1-a20d030b39ea" in namespace "projected-7278" to be "success or failure"
Apr  3 10:11:20.572: INFO: Pod "pod-projected-configmaps-d3d2b6cd-55f8-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.755546ms
Apr  3 10:11:22.574: INFO: Pod "pod-projected-configmaps-d3d2b6cd-55f8-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007503383s
Apr  3 10:11:24.577: INFO: Pod "pod-projected-configmaps-d3d2b6cd-55f8-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010565446s
STEP: Saw pod success
Apr  3 10:11:24.578: INFO: Pod "pod-projected-configmaps-d3d2b6cd-55f8-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:11:24.581: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-d3d2b6cd-55f8-11e9-a6c1-a20d030b39ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 10:11:24.604: INFO: Waiting for pod pod-projected-configmaps-d3d2b6cd-55f8-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:11:24.607: INFO: Pod pod-projected-configmaps-d3d2b6cd-55f8-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:11:24.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7278" for this suite.
Apr  3 10:11:30.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:11:30.714: INFO: namespace projected-7278 deletion completed in 6.10000918s

• [SLOW TEST:10.200 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:11:30.714: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-4859
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4859
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4859
Apr  3 10:11:30.780: INFO: Found 0 stateful pods, waiting for 1
Apr  3 10:11:40.783: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr  3 10:11:40.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-4859 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:11:40.961: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:11:40.961: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:11:40.961: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  3 10:11:40.964: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  3 10:11:50.967: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  3 10:11:50.967: INFO: Waiting for statefulset status.replicas updated to 0
Apr  3 10:11:50.984: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999687s
Apr  3 10:11:51.987: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994812837s
Apr  3 10:11:52.992: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991778667s
Apr  3 10:11:53.995: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987498796s
Apr  3 10:11:54.998: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.984787475s
Apr  3 10:11:56.002: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.981558133s
Apr  3 10:11:57.005: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.978289797s
Apr  3 10:11:58.008: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.974897429s
Apr  3 10:11:59.011: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.972344277s
Apr  3 10:12:00.013: INFO: Verifying statefulset ss doesn't scale past 1 for another 969.395694ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4859
Apr  3 10:12:01.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-4859 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  3 10:12:01.192: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  3 10:12:01.192: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  3 10:12:01.192: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  3 10:12:01.196: INFO: Found 1 stateful pods, waiting for 3
Apr  3 10:12:11.200: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 10:12:11.200: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 10:12:11.200: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr  3 10:12:11.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-4859 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:12:11.374: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:12:11.374: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:12:11.374: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  3 10:12:11.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-4859 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:12:11.552: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:12:11.553: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:12:11.553: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  3 10:12:11.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-4859 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:12:11.749: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:12:11.749: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:12:11.749: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  3 10:12:11.749: INFO: Waiting for statefulset status.replicas updated to 0
Apr  3 10:12:11.756: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr  3 10:12:21.762: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  3 10:12:21.762: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  3 10:12:21.762: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  3 10:12:21.781: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999622s
Apr  3 10:12:22.787: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993126644s
Apr  3 10:12:23.791: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986600824s
Apr  3 10:12:24.799: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982961972s
Apr  3 10:12:25.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.974928044s
Apr  3 10:12:26.807: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.971629892s
Apr  3 10:12:27.813: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968568417s
Apr  3 10:12:28.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.961397352s
Apr  3 10:12:29.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95211202s
Apr  3 10:12:30.830: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.069444ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4859
Apr  3 10:12:31.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-4859 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  3 10:12:32.006: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  3 10:12:32.006: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  3 10:12:32.006: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  3 10:12:32.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-4859 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  3 10:12:32.184: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  3 10:12:32.184: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  3 10:12:32.184: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  3 10:12:32.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-4859 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  3 10:12:32.379: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  3 10:12:32.379: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  3 10:12:32.379: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  3 10:12:32.379: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  3 10:12:52.393: INFO: Deleting all statefulset in ns statefulset-4859
Apr  3 10:12:52.395: INFO: Scaling statefulset ss to 0
Apr  3 10:12:52.403: INFO: Waiting for statefulset status.replicas updated to 0
Apr  3 10:12:52.406: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:12:52.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4859" for this suite.
Apr  3 10:12:58.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:12:58.508: INFO: namespace statefulset-4859 deletion completed in 6.083006918s

• [SLOW TEST:87.792 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:12:58.508: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:12:58.546: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr  3 10:12:58.554: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr  3 10:13:03.557: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  3 10:13:03.557: INFO: Creating deployment "test-rolling-update-deployment"
Apr  3 10:13:03.568: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr  3 10:13:03.575: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr  3 10:13:05.581: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr  3 10:13:05.585: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  3 10:13:05.596: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-3143,SelfLink:/apis/apps/v1/namespaces/deployment-3143/deployments/test-rolling-update-deployment,UID:1137a362-55f9-11e9-ad16-025000000001,ResourceVersion:9471,Generation:1,CreationTimestamp:2019-04-03 10:13:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-03 10:13:03 +0000 UTC 2019-04-03 10:13:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-03 10:13:05 +0000 UTC 2019-04-03 10:13:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  3 10:13:05.602: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-3143,SelfLink:/apis/apps/v1/namespaces/deployment-3143/replicasets/test-rolling-update-deployment-67599b4d9,UID:113a1abd-55f9-11e9-ad16-025000000001,ResourceVersion:9460,Generation:1,CreationTimestamp:2019-04-03 10:13:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 1137a362-55f9-11e9-ad16-025000000001 0xc002a91ec0 0xc002a91ec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  3 10:13:05.602: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr  3 10:13:05.602: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-3143,SelfLink:/apis/apps/v1/namespaces/deployment-3143/replicasets/test-rolling-update-controller,UID:0e3b2ecd-55f9-11e9-ad16-025000000001,ResourceVersion:9470,Generation:2,CreationTimestamp:2019-04-03 10:12:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 1137a362-55f9-11e9-ad16-025000000001 0xc002a91ddf 0xc002a91df0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  3 10:13:05.613: INFO: Pod "test-rolling-update-deployment-67599b4d9-kj5jr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-kj5jr,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-3143,SelfLink:/api/v1/namespaces/deployment-3143/pods/test-rolling-update-deployment-67599b4d9-kj5jr,UID:113aee77-55f9-11e9-ad16-025000000001,ResourceVersion:9459,Generation:0,CreationTimestamp:2019-04-03 10:13:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 113a1abd-55f9-11e9-ad16-025000000001 0xc0004b6530 0xc0004b6531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-zfzx6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zfzx6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-zfzx6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0004b6860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004b7190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:13:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:13:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:13:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:13:03 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.198,StartTime:2019-04-03 10:13:03 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-03 10:13:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://0fd1919ff1fe8653a2e33c7b6c1865e2abc8efdf21c9745948fc0081d5389823}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:13:05.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3143" for this suite.
Apr  3 10:13:11.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:13:11.698: INFO: namespace deployment-3143 deletion completed in 6.08069138s

• [SLOW TEST:13.190 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:13:11.699: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr  3 10:13:14.775: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:13:14.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8340" for this suite.
Apr  3 10:13:36.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:13:36.898: INFO: namespace replicaset-8340 deletion completed in 22.090988573s

• [SLOW TEST:25.199 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:13:36.901: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr  3 10:13:36.957: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7323,SelfLink:/api/v1/namespaces/watch-7323/configmaps/e2e-watch-test-watch-closed,UID:251de30c-55f9-11e9-ad16-025000000001,ResourceVersion:9584,Generation:0,CreationTimestamp:2019-04-03 10:13:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  3 10:13:36.958: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7323,SelfLink:/api/v1/namespaces/watch-7323/configmaps/e2e-watch-test-watch-closed,UID:251de30c-55f9-11e9-ad16-025000000001,ResourceVersion:9585,Generation:0,CreationTimestamp:2019-04-03 10:13:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr  3 10:13:36.984: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7323,SelfLink:/api/v1/namespaces/watch-7323/configmaps/e2e-watch-test-watch-closed,UID:251de30c-55f9-11e9-ad16-025000000001,ResourceVersion:9586,Generation:0,CreationTimestamp:2019-04-03 10:13:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  3 10:13:36.986: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7323,SelfLink:/api/v1/namespaces/watch-7323/configmaps/e2e-watch-test-watch-closed,UID:251de30c-55f9-11e9-ad16-025000000001,ResourceVersion:9587,Generation:0,CreationTimestamp:2019-04-03 10:13:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:13:36.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7323" for this suite.
Apr  3 10:13:43.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:13:43.075: INFO: namespace watch-7323 deletion completed in 6.083684894s

• [SLOW TEST:6.174 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:13:43.075: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr  3 10:13:43.625: INFO: created pod pod-service-account-defaultsa
Apr  3 10:13:43.625: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr  3 10:13:43.640: INFO: created pod pod-service-account-mountsa
Apr  3 10:13:43.640: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr  3 10:13:43.653: INFO: created pod pod-service-account-nomountsa
Apr  3 10:13:43.653: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr  3 10:13:43.665: INFO: created pod pod-service-account-defaultsa-mountspec
Apr  3 10:13:43.665: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr  3 10:13:43.685: INFO: created pod pod-service-account-mountsa-mountspec
Apr  3 10:13:43.685: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr  3 10:13:43.693: INFO: created pod pod-service-account-nomountsa-mountspec
Apr  3 10:13:43.693: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr  3 10:13:43.705: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr  3 10:13:43.705: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr  3 10:13:43.710: INFO: created pod pod-service-account-mountsa-nomountspec
Apr  3 10:13:43.710: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr  3 10:13:43.717: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr  3 10:13:43.717: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:13:43.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3821" for this suite.
Apr  3 10:14:05.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:14:05.835: INFO: namespace svcaccounts-3821 deletion completed in 22.097503987s

• [SLOW TEST:22.760 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:14:05.850: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1727
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  3 10:14:05.896: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  3 10:14:25.961: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.0.211:8080/dial?request=hostName&protocol=udp&host=10.1.0.210&port=8081&tries=1'] Namespace:pod-network-test-1727 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:14:25.961: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:14:26.098: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:14:26.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1727" for this suite.
Apr  3 10:14:44.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:14:44.302: INFO: namespace pod-network-test-1727 deletion completed in 18.200283817s

• [SLOW TEST:38.451 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:14:44.304: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:14:44.388: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d4ded4f-55f9-11e9-a6c1-a20d030b39ea" in namespace "projected-5716" to be "success or failure"
Apr  3 10:14:44.398: INFO: Pod "downwardapi-volume-4d4ded4f-55f9-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 10.480352ms
Apr  3 10:14:46.401: INFO: Pod "downwardapi-volume-4d4ded4f-55f9-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013044178s
Apr  3 10:14:48.404: INFO: Pod "downwardapi-volume-4d4ded4f-55f9-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016798662s
STEP: Saw pod success
Apr  3 10:14:48.405: INFO: Pod "downwardapi-volume-4d4ded4f-55f9-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:14:48.412: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-4d4ded4f-55f9-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:14:48.446: INFO: Waiting for pod downwardapi-volume-4d4ded4f-55f9-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:14:48.455: INFO: Pod downwardapi-volume-4d4ded4f-55f9-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:14:48.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5716" for this suite.
Apr  3 10:14:54.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:14:54.593: INFO: namespace projected-5716 deletion completed in 6.131225133s

• [SLOW TEST:10.289 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:14:54.593: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-536c29cd-55f9-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:14:54.646: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-536d3357-55f9-11e9-a6c1-a20d030b39ea" in namespace "projected-5420" to be "success or failure"
Apr  3 10:14:54.651: INFO: Pod "pod-projected-secrets-536d3357-55f9-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.334574ms
Apr  3 10:14:56.655: INFO: Pod "pod-projected-secrets-536d3357-55f9-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007574241s
STEP: Saw pod success
Apr  3 10:14:56.655: INFO: Pod "pod-projected-secrets-536d3357-55f9-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:14:56.658: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-536d3357-55f9-11e9-a6c1-a20d030b39ea container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  3 10:14:56.684: INFO: Waiting for pod pod-projected-secrets-536d3357-55f9-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:14:56.687: INFO: Pod pod-projected-secrets-536d3357-55f9-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:14:56.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5420" for this suite.
Apr  3 10:15:02.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:15:02.816: INFO: namespace projected-5420 deletion completed in 6.1220829s

• [SLOW TEST:8.223 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:15:02.816: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-286
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  3 10:15:02.884: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  3 10:15:20.944: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.0.215:8080/dial?request=hostName&protocol=http&host=10.1.0.214&port=8080&tries=1'] Namespace:pod-network-test-286 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:15:20.944: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:15:21.058: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:15:21.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-286" for this suite.
Apr  3 10:15:43.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:15:43.155: INFO: namespace pod-network-test-286 deletion completed in 22.092228168s

• [SLOW TEST:40.338 seconds]
[sig-network] Networking
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:15:43.155: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3240
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3240
STEP: Creating statefulset with conflicting port in namespace statefulset-3240
STEP: Waiting until pod test-pod will start running in namespace statefulset-3240
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3240
Apr  3 10:15:47.277: INFO: Observed stateful pod in namespace: statefulset-3240, name: ss-0, uid: 728e99bd-55f9-11e9-ad16-025000000001, status phase: Pending. Waiting for statefulset controller to delete.
Apr  3 10:15:47.449: INFO: Observed stateful pod in namespace: statefulset-3240, name: ss-0, uid: 728e99bd-55f9-11e9-ad16-025000000001, status phase: Failed. Waiting for statefulset controller to delete.
Apr  3 10:15:47.455: INFO: Observed stateful pod in namespace: statefulset-3240, name: ss-0, uid: 728e99bd-55f9-11e9-ad16-025000000001, status phase: Failed. Waiting for statefulset controller to delete.
Apr  3 10:15:47.462: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3240
STEP: Removing pod with conflicting port in namespace statefulset-3240
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3240 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  3 10:15:51.487: INFO: Deleting all statefulset in ns statefulset-3240
Apr  3 10:15:51.490: INFO: Scaling statefulset ss to 0
Apr  3 10:16:11.509: INFO: Waiting for statefulset status.replicas updated to 0
Apr  3 10:16:11.512: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:16:11.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3240" for this suite.
Apr  3 10:16:17.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:16:17.605: INFO: namespace statefulset-3240 deletion completed in 6.075603285s

• [SLOW TEST:34.449 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:16:17.605: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:16:17.643: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84e542c5-55f9-11e9-a6c1-a20d030b39ea" in namespace "projected-8328" to be "success or failure"
Apr  3 10:16:17.647: INFO: Pod "downwardapi-volume-84e542c5-55f9-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.968896ms
Apr  3 10:16:19.651: INFO: Pod "downwardapi-volume-84e542c5-55f9-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008554871s
STEP: Saw pod success
Apr  3 10:16:19.651: INFO: Pod "downwardapi-volume-84e542c5-55f9-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:16:19.655: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-84e542c5-55f9-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:16:19.672: INFO: Waiting for pod downwardapi-volume-84e542c5-55f9-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:16:19.676: INFO: Pod downwardapi-volume-84e542c5-55f9-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:16:19.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8328" for this suite.
Apr  3 10:16:25.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:16:25.764: INFO: namespace projected-8328 deletion completed in 6.083692521s

• [SLOW TEST:8.159 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:16:25.764: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  3 10:16:29.861: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:29.866: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:31.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:31.870: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:33.867: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:33.870: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:35.867: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:35.872: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:37.867: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:37.878: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:39.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:39.874: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:41.867: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:41.869: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:43.867: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:43.870: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:45.867: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:45.870: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:47.867: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:47.870: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:49.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:49.870: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:51.867: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:51.869: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  3 10:16:53.867: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  3 10:16:53.871: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:16:53.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4243" for this suite.
Apr  3 10:17:15.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:17:15.959: INFO: namespace container-lifecycle-hook-4243 deletion completed in 22.078097791s

• [SLOW TEST:50.194 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:17:15.959: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  3 10:17:15.991: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  3 10:17:16.000: INFO: Waiting for terminating namespaces to be deleted...
Apr  3 10:17:16.003: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Apr  3 10:17:16.013: INFO: etcd-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 10:17:16.013: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-03 09:28:36 +0000 UTC (1 container statuses recorded)
Apr  3 10:17:16.013: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  3 10:17:16.013: INFO: kube-scheduler-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 10:17:16.013: INFO: compose-749b4b56db-j7lz7 from docker started at 2019-04-03 09:20:52 +0000 UTC (1 container statuses recorded)
Apr  3 10:17:16.013: INFO: 	Container compose ready: true, restart count 0
Apr  3 10:17:16.013: INFO: coredns-fb8b8dccf-zwcdc from kube-system started at 2019-04-03 09:19:39 +0000 UTC (1 container statuses recorded)
Apr  3 10:17:16.013: INFO: 	Container coredns ready: true, restart count 1
Apr  3 10:17:16.013: INFO: coredns-fb8b8dccf-tnbsj from kube-system started at 2019-04-03 09:19:39 +0000 UTC (1 container statuses recorded)
Apr  3 10:17:16.013: INFO: 	Container coredns ready: true, restart count 1
Apr  3 10:17:16.013: INFO: sonobuoy-systemd-logs-daemon-set-0adeda72764b486f-sj4sz from heptio-sonobuoy started at 2019-04-03 09:28:42 +0000 UTC (2 container statuses recorded)
Apr  3 10:17:16.013: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 14
Apr  3 10:17:16.013: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  3 10:17:16.013: INFO: compose-api-6fbb7b5685-6tssl from docker started at 2019-04-03 09:20:52 +0000 UTC (1 container statuses recorded)
Apr  3 10:17:16.014: INFO: 	Container compose ready: true, restart count 0
Apr  3 10:17:16.014: INFO: kube-proxy-p6h6h from kube-system started at 2019-04-03 09:19:39 +0000 UTC (1 container statuses recorded)
Apr  3 10:17:16.015: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  3 10:17:16.015: INFO: kube-apiserver-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Apr  3 10:17:16.015: INFO: sonobuoy-e2e-job-4831e90eb5a940fb from heptio-sonobuoy started at 2019-04-03 09:28:42 +0000 UTC (2 container statuses recorded)
Apr  3 10:17:16.015: INFO: 	Container e2e ready: true, restart count 0
Apr  3 10:17:16.015: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  3 10:17:16.015: INFO: kube-controller-manager-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node docker-desktop
Apr  3 10:17:16.040: INFO: Pod compose-749b4b56db-j7lz7 requesting resource cpu=0m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod compose-api-6fbb7b5685-6tssl requesting resource cpu=0m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod sonobuoy requesting resource cpu=0m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod sonobuoy-e2e-job-4831e90eb5a940fb requesting resource cpu=0m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod sonobuoy-systemd-logs-daemon-set-0adeda72764b486f-sj4sz requesting resource cpu=0m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod coredns-fb8b8dccf-tnbsj requesting resource cpu=100m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod coredns-fb8b8dccf-zwcdc requesting resource cpu=100m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod etcd-docker-desktop requesting resource cpu=0m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod kube-apiserver-docker-desktop requesting resource cpu=250m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod kube-controller-manager-docker-desktop requesting resource cpu=200m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod kube-proxy-p6h6h requesting resource cpu=0m on Node docker-desktop
Apr  3 10:17:16.040: INFO: Pod kube-scheduler-docker-desktop requesting resource cpu=100m on Node docker-desktop
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7b53d50-55f9-11e9-a6c1-a20d030b39ea.1591ef75e523a78d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-344/filler-pod-a7b53d50-55f9-11e9-a6c1-a20d030b39ea to docker-desktop]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7b53d50-55f9-11e9-a6c1-a20d030b39ea.1591ef761fc54667], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7b53d50-55f9-11e9-a6c1-a20d030b39ea.1591ef7626d38cba], Reason = [Created], Message = [Created container filler-pod-a7b53d50-55f9-11e9-a6c1-a20d030b39ea]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a7b53d50-55f9-11e9-a6c1-a20d030b39ea.1591ef76375baf6f], Reason = [Started], Message = [Started container filler-pod-a7b53d50-55f9-11e9-a6c1-a20d030b39ea]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1591ef76d455c803], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node docker-desktop
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:17:21.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-344" for this suite.
Apr  3 10:17:27.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:17:27.200: INFO: namespace sched-pred-344 deletion completed in 6.106447374s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.240 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:17:27.200: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-34
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  3 10:17:27.256: INFO: Found 0 stateful pods, waiting for 3
Apr  3 10:17:37.260: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 10:17:37.260: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 10:17:37.260: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 10:17:37.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-34 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:17:37.460: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:17:37.460: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:17:37.460: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  3 10:17:47.489: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr  3 10:17:57.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-34 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  3 10:17:57.711: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  3 10:17:57.711: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  3 10:17:57.711: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  3 10:18:17.728: INFO: Waiting for StatefulSet statefulset-34/ss2 to complete update
Apr  3 10:18:17.728: INFO: Waiting for Pod statefulset-34/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Apr  3 10:18:27.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-34 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:18:27.900: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:18:27.900: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:18:27.900: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  3 10:18:37.938: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr  3 10:18:47.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-34 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  3 10:18:48.118: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  3 10:18:48.118: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  3 10:18:48.118: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  3 10:19:08.143: INFO: Waiting for StatefulSet statefulset-34/ss2 to complete update
Apr  3 10:19:08.143: INFO: Waiting for Pod statefulset-34/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  3 10:19:18.147: INFO: Deleting all statefulset in ns statefulset-34
Apr  3 10:19:18.150: INFO: Scaling statefulset ss2 to 0
Apr  3 10:19:28.172: INFO: Waiting for statefulset status.replicas updated to 0
Apr  3 10:19:28.175: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:19:28.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-34" for this suite.
Apr  3 10:19:34.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:19:34.289: INFO: namespace statefulset-34 deletion completed in 6.100874634s

• [SLOW TEST:127.086 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:19:34.291: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-fa27f3e6-55f9-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:19:34.383: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fa28f952-55f9-11e9-a6c1-a20d030b39ea" in namespace "projected-4217" to be "success or failure"
Apr  3 10:19:34.395: INFO: Pod "pod-projected-secrets-fa28f952-55f9-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 11.608221ms
Apr  3 10:19:36.400: INFO: Pod "pod-projected-secrets-fa28f952-55f9-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017111176s
STEP: Saw pod success
Apr  3 10:19:36.400: INFO: Pod "pod-projected-secrets-fa28f952-55f9-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:19:36.408: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-fa28f952-55f9-11e9-a6c1-a20d030b39ea container secret-volume-test: <nil>
STEP: delete the pod
Apr  3 10:19:36.439: INFO: Waiting for pod pod-projected-secrets-fa28f952-55f9-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:19:36.443: INFO: Pod pod-projected-secrets-fa28f952-55f9-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:19:36.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4217" for this suite.
Apr  3 10:19:42.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:19:42.551: INFO: namespace projected-4217 deletion completed in 6.102338692s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:19:42.552: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr  3 10:19:42.605: INFO: Waiting up to 5m0s for pod "client-containers-ff0ed82b-55f9-11e9-a6c1-a20d030b39ea" in namespace "containers-9431" to be "success or failure"
Apr  3 10:19:42.610: INFO: Pod "client-containers-ff0ed82b-55f9-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.076175ms
Apr  3 10:19:44.613: INFO: Pod "client-containers-ff0ed82b-55f9-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007948391s
STEP: Saw pod success
Apr  3 10:19:44.613: INFO: Pod "client-containers-ff0ed82b-55f9-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:19:44.617: INFO: Trying to get logs from node docker-desktop pod client-containers-ff0ed82b-55f9-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:19:44.633: INFO: Waiting for pod client-containers-ff0ed82b-55f9-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:19:44.636: INFO: Pod client-containers-ff0ed82b-55f9-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:19:44.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9431" for this suite.
Apr  3 10:19:50.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:19:50.737: INFO: namespace containers-9431 deletion completed in 6.097632497s

• [SLOW TEST:8.186 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:19:50.738: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:19:50.782: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03efa44c-55fa-11e9-a6c1-a20d030b39ea" in namespace "projected-2645" to be "success or failure"
Apr  3 10:19:50.801: INFO: Pod "downwardapi-volume-03efa44c-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 18.778924ms
Apr  3 10:19:52.804: INFO: Pod "downwardapi-volume-03efa44c-55fa-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021943663s
STEP: Saw pod success
Apr  3 10:19:52.804: INFO: Pod "downwardapi-volume-03efa44c-55fa-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:19:52.807: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-03efa44c-55fa-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:19:52.832: INFO: Waiting for pod downwardapi-volume-03efa44c-55fa-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:19:52.837: INFO: Pod downwardapi-volume-03efa44c-55fa-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:19:52.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2645" for this suite.
Apr  3 10:19:58.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:19:58.955: INFO: namespace projected-2645 deletion completed in 6.109415062s

• [SLOW TEST:8.217 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:19:58.955: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr  3 10:19:58.997: INFO: Waiting up to 5m0s for pod "client-containers-08d50d07-55fa-11e9-a6c1-a20d030b39ea" in namespace "containers-9684" to be "success or failure"
Apr  3 10:19:59.012: INFO: Pod "client-containers-08d50d07-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 15.176744ms
Apr  3 10:20:01.015: INFO: Pod "client-containers-08d50d07-55fa-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018099373s
STEP: Saw pod success
Apr  3 10:20:01.015: INFO: Pod "client-containers-08d50d07-55fa-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:20:01.020: INFO: Trying to get logs from node docker-desktop pod client-containers-08d50d07-55fa-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:20:01.036: INFO: Waiting for pod client-containers-08d50d07-55fa-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:20:01.038: INFO: Pod client-containers-08d50d07-55fa-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:20:01.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9684" for this suite.
Apr  3 10:20:07.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:20:07.131: INFO: namespace containers-9684 deletion completed in 6.087509343s

• [SLOW TEST:8.176 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:20:07.131: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6095
Apr  3 10:20:09.186: INFO: Started pod liveness-http in namespace container-probe-6095
STEP: checking the pod's current state and verifying that restartCount is present
Apr  3 10:20:09.188: INFO: Initial restart count of pod liveness-http is 0
Apr  3 10:20:21.210: INFO: Restart count of pod container-probe-6095/liveness-http is now 1 (12.022053666s elapsed)
Apr  3 10:20:43.252: INFO: Restart count of pod container-probe-6095/liveness-http is now 2 (34.062525078s elapsed)
Apr  3 10:21:01.289: INFO: Restart count of pod container-probe-6095/liveness-http is now 3 (52.09905042s elapsed)
Apr  3 10:21:21.319: INFO: Restart count of pod container-probe-6095/liveness-http is now 4 (1m12.129140554s elapsed)
Apr  3 10:22:23.449: INFO: Restart count of pod container-probe-6095/liveness-http is now 5 (2m14.258283004s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:22:23.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6095" for this suite.
Apr  3 10:22:29.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:22:29.642: INFO: namespace container-probe-6095 deletion completed in 6.177502668s

• [SLOW TEST:142.507 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:22:29.642: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  3 10:22:32.216: INFO: Successfully updated pod "annotationupdate62a5cb3f-55fa-11e9-a6c1-a20d030b39ea"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:22:34.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5585" for this suite.
Apr  3 10:22:56.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:22:56.355: INFO: namespace projected-5585 deletion completed in 22.120157388s

• [SLOW TEST:26.712 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:22:56.355: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:22:56.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7291f4c9-55fa-11e9-a6c1-a20d030b39ea" in namespace "downward-api-4356" to be "success or failure"
Apr  3 10:22:56.406: INFO: Pod "downwardapi-volume-7291f4c9-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 10.234417ms
Apr  3 10:22:58.410: INFO: Pod "downwardapi-volume-7291f4c9-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01374531s
Apr  3 10:23:00.418: INFO: Pod "downwardapi-volume-7291f4c9-55fa-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021855472s
STEP: Saw pod success
Apr  3 10:23:00.418: INFO: Pod "downwardapi-volume-7291f4c9-55fa-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:23:00.424: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-7291f4c9-55fa-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:23:00.453: INFO: Waiting for pod downwardapi-volume-7291f4c9-55fa-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:23:00.455: INFO: Pod downwardapi-volume-7291f4c9-55fa-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:23:00.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4356" for this suite.
Apr  3 10:23:06.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:23:06.533: INFO: namespace downward-api-4356 deletion completed in 6.073244996s

• [SLOW TEST:10.178 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:23:06.533: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr  3 10:23:06.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 api-versions'
Apr  3 10:23:06.638: INFO: stderr: ""
Apr  3 10:23:06.638: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncompose.docker.com/v1alpha3\ncompose.docker.com/v1beta1\ncompose.docker.com/v1beta2\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:23:06.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3154" for this suite.
Apr  3 10:23:12.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:23:12.789: INFO: namespace kubectl-3154 deletion completed in 6.143624345s

• [SLOW TEST:6.256 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:23:12.795: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:23:12.839: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c5f094f-55fa-11e9-a6c1-a20d030b39ea" in namespace "downward-api-414" to be "success or failure"
Apr  3 10:23:12.844: INFO: Pod "downwardapi-volume-7c5f094f-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.286063ms
Apr  3 10:23:14.847: INFO: Pod "downwardapi-volume-7c5f094f-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008083531s
Apr  3 10:23:16.850: INFO: Pod "downwardapi-volume-7c5f094f-55fa-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010704214s
STEP: Saw pod success
Apr  3 10:23:16.850: INFO: Pod "downwardapi-volume-7c5f094f-55fa-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:23:16.855: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-7c5f094f-55fa-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:23:16.876: INFO: Waiting for pod downwardapi-volume-7c5f094f-55fa-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:23:16.883: INFO: Pod downwardapi-volume-7c5f094f-55fa-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:23:16.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-414" for this suite.
Apr  3 10:23:22.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:23:22.981: INFO: namespace downward-api-414 deletion completed in 6.094930328s

• [SLOW TEST:10.187 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:23:22.982: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  3 10:23:23.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-4896'
Apr  3 10:23:23.271: INFO: stderr: ""
Apr  3 10:23:23.271: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  3 10:23:23.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4896'
Apr  3 10:23:23.421: INFO: stderr: ""
Apr  3 10:23:23.421: INFO: stdout: "update-demo-nautilus-hrk2f update-demo-nautilus-j9j9h "
Apr  3 10:23:23.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-hrk2f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4896'
Apr  3 10:23:23.526: INFO: stderr: ""
Apr  3 10:23:23.526: INFO: stdout: ""
Apr  3 10:23:23.526: INFO: update-demo-nautilus-hrk2f is created but not running
Apr  3 10:23:28.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4896'
Apr  3 10:23:28.608: INFO: stderr: ""
Apr  3 10:23:28.608: INFO: stdout: "update-demo-nautilus-hrk2f update-demo-nautilus-j9j9h "
Apr  3 10:23:28.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-hrk2f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4896'
Apr  3 10:23:28.684: INFO: stderr: ""
Apr  3 10:23:28.684: INFO: stdout: "true"
Apr  3 10:23:28.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-hrk2f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4896'
Apr  3 10:23:28.766: INFO: stderr: ""
Apr  3 10:23:28.766: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  3 10:23:28.766: INFO: validating pod update-demo-nautilus-hrk2f
Apr  3 10:23:28.772: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  3 10:23:28.772: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  3 10:23:28.772: INFO: update-demo-nautilus-hrk2f is verified up and running
Apr  3 10:23:28.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-j9j9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4896'
Apr  3 10:23:28.854: INFO: stderr: ""
Apr  3 10:23:28.854: INFO: stdout: "true"
Apr  3 10:23:28.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods update-demo-nautilus-j9j9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4896'
Apr  3 10:23:28.933: INFO: stderr: ""
Apr  3 10:23:28.933: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  3 10:23:28.933: INFO: validating pod update-demo-nautilus-j9j9h
Apr  3 10:23:28.939: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  3 10:23:28.939: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  3 10:23:28.939: INFO: update-demo-nautilus-j9j9h is verified up and running
STEP: using delete to clean up resources
Apr  3 10:23:28.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-4896'
Apr  3 10:23:29.016: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 10:23:29.016: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  3 10:23:29.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4896'
Apr  3 10:23:29.106: INFO: stderr: "No resources found.\n"
Apr  3 10:23:29.106: INFO: stdout: ""
Apr  3 10:23:29.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -l name=update-demo --namespace=kubectl-4896 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  3 10:23:29.191: INFO: stderr: ""
Apr  3 10:23:29.191: INFO: stdout: "update-demo-nautilus-hrk2f\nupdate-demo-nautilus-j9j9h\n"
Apr  3 10:23:29.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4896'
Apr  3 10:23:29.811: INFO: stderr: "No resources found.\n"
Apr  3 10:23:29.811: INFO: stdout: ""
Apr  3 10:23:29.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -l name=update-demo --namespace=kubectl-4896 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  3 10:23:29.916: INFO: stderr: ""
Apr  3 10:23:29.916: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:23:29.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4896" for this suite.
Apr  3 10:23:35.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:23:36.018: INFO: namespace kubectl-4896 deletion completed in 6.095035493s

• [SLOW TEST:13.036 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:23:36.019: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-8a35d066-55fa-11e9-a6c1-a20d030b39ea
STEP: Creating secret with name secret-projected-all-test-volume-8a35d05a-55fa-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr  3 10:23:36.061: INFO: Waiting up to 5m0s for pod "projected-volume-8a35d032-55fa-11e9-a6c1-a20d030b39ea" in namespace "projected-2306" to be "success or failure"
Apr  3 10:23:36.067: INFO: Pod "projected-volume-8a35d032-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.42025ms
Apr  3 10:23:38.070: INFO: Pod "projected-volume-8a35d032-55fa-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00886702s
STEP: Saw pod success
Apr  3 10:23:38.070: INFO: Pod "projected-volume-8a35d032-55fa-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:23:38.075: INFO: Trying to get logs from node docker-desktop pod projected-volume-8a35d032-55fa-11e9-a6c1-a20d030b39ea container projected-all-volume-test: <nil>
STEP: delete the pod
Apr  3 10:23:38.093: INFO: Waiting for pod projected-volume-8a35d032-55fa-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:23:38.097: INFO: Pod projected-volume-8a35d032-55fa-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:23:38.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2306" for this suite.
Apr  3 10:23:44.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:23:44.185: INFO: namespace projected-2306 deletion completed in 6.080585231s

• [SLOW TEST:8.167 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:23:44.186: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  3 10:23:44.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2126'
Apr  3 10:23:44.331: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  3 10:23:44.331: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr  3 10:23:44.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2126'
Apr  3 10:23:44.444: INFO: stderr: ""
Apr  3 10:23:44.444: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:23:44.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2126" for this suite.
Apr  3 10:24:06.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:24:06.600: INFO: namespace kubectl-2126 deletion completed in 22.150758425s

• [SLOW TEST:22.414 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:24:06.600: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:24:28.672: INFO: Container started at 2019-04-03 10:24:08 +0000 UTC, pod became ready at 2019-04-03 10:24:27 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:24:28.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3395" for this suite.
Apr  3 10:24:44.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:24:44.818: INFO: namespace container-probe-3395 deletion completed in 16.142787427s

• [SLOW TEST:38.217 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:24:44.818: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-b337e1ec-55fa-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:24:44.860: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b338bb18-55fa-11e9-a6c1-a20d030b39ea" in namespace "projected-9863" to be "success or failure"
Apr  3 10:24:44.869: INFO: Pod "pod-projected-secrets-b338bb18-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.947481ms
Apr  3 10:24:46.873: INFO: Pod "pod-projected-secrets-b338bb18-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013143415s
Apr  3 10:24:48.876: INFO: Pod "pod-projected-secrets-b338bb18-55fa-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01597075s
STEP: Saw pod success
Apr  3 10:24:48.876: INFO: Pod "pod-projected-secrets-b338bb18-55fa-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:24:48.878: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-b338bb18-55fa-11e9-a6c1-a20d030b39ea container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  3 10:24:48.897: INFO: Waiting for pod pod-projected-secrets-b338bb18-55fa-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:24:48.904: INFO: Pod pod-projected-secrets-b338bb18-55fa-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:24:48.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9863" for this suite.
Apr  3 10:24:54.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:24:55.009: INFO: namespace projected-9863 deletion completed in 6.098147004s

• [SLOW TEST:10.191 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:24:55.010: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-b95099cd-55fa-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 10:24:55.095: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b951f4f6-55fa-11e9-a6c1-a20d030b39ea" in namespace "projected-4052" to be "success or failure"
Apr  3 10:24:55.099: INFO: Pod "pod-projected-configmaps-b951f4f6-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.809449ms
Apr  3 10:24:57.104: INFO: Pod "pod-projected-configmaps-b951f4f6-55fa-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008971081s
STEP: Saw pod success
Apr  3 10:24:57.104: INFO: Pod "pod-projected-configmaps-b951f4f6-55fa-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:24:57.109: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-b951f4f6-55fa-11e9-a6c1-a20d030b39ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 10:24:57.144: INFO: Waiting for pod pod-projected-configmaps-b951f4f6-55fa-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:24:57.151: INFO: Pod pod-projected-configmaps-b951f4f6-55fa-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:24:57.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4052" for this suite.
Apr  3 10:25:03.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:25:03.263: INFO: namespace projected-4052 deletion completed in 6.104308884s

• [SLOW TEST:8.253 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:25:03.267: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  3 10:25:05.895: INFO: Successfully updated pod "annotationupdatebe3f7f3d-55fa-11e9-a6c1-a20d030b39ea"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:25:07.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3379" for this suite.
Apr  3 10:25:29.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:25:30.029: INFO: namespace downward-api-3379 deletion completed in 22.111865721s

• [SLOW TEST:26.761 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:25:30.029: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:25:30.063: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:25:32.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2818" for this suite.
Apr  3 10:26:16.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:26:16.214: INFO: namespace pods-2818 deletion completed in 44.103996922s

• [SLOW TEST:46.185 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:26:16.217: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e9b32c96-55fa-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:26:16.271: INFO: Waiting up to 5m0s for pod "pod-secrets-e9b463d2-55fa-11e9-a6c1-a20d030b39ea" in namespace "secrets-5238" to be "success or failure"
Apr  3 10:26:16.275: INFO: Pod "pod-secrets-e9b463d2-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.747858ms
Apr  3 10:26:18.279: INFO: Pod "pod-secrets-e9b463d2-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008252538s
Apr  3 10:26:20.282: INFO: Pod "pod-secrets-e9b463d2-55fa-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010930205s
STEP: Saw pod success
Apr  3 10:26:20.282: INFO: Pod "pod-secrets-e9b463d2-55fa-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:26:20.285: INFO: Trying to get logs from node docker-desktop pod pod-secrets-e9b463d2-55fa-11e9-a6c1-a20d030b39ea container secret-volume-test: <nil>
STEP: delete the pod
Apr  3 10:26:20.305: INFO: Waiting for pod pod-secrets-e9b463d2-55fa-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:26:20.308: INFO: Pod pod-secrets-e9b463d2-55fa-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:26:20.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5238" for this suite.
Apr  3 10:26:26.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:26:26.412: INFO: namespace secrets-5238 deletion completed in 6.099491372s

• [SLOW TEST:10.195 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:26:26.412: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:26:26.447: INFO: Waiting up to 5m0s for pod "downwardapi-volume-efc5747b-55fa-11e9-a6c1-a20d030b39ea" in namespace "downward-api-9554" to be "success or failure"
Apr  3 10:26:26.463: INFO: Pod "downwardapi-volume-efc5747b-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 15.867854ms
Apr  3 10:26:28.468: INFO: Pod "downwardapi-volume-efc5747b-55fa-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020652997s
Apr  3 10:26:30.471: INFO: Pod "downwardapi-volume-efc5747b-55fa-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023985029s
STEP: Saw pod success
Apr  3 10:26:30.471: INFO: Pod "downwardapi-volume-efc5747b-55fa-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:26:30.476: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-efc5747b-55fa-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:26:30.492: INFO: Waiting for pod downwardapi-volume-efc5747b-55fa-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:26:30.496: INFO: Pod downwardapi-volume-efc5747b-55fa-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:26:30.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9554" for this suite.
Apr  3 10:26:36.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:26:36.582: INFO: namespace downward-api-9554 deletion completed in 6.081837893s

• [SLOW TEST:10.170 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:26:36.582: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:26:36.630: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr  3 10:26:36.644: INFO: Number of nodes with available pods: 0
Apr  3 10:26:36.645: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:26:37.650: INFO: Number of nodes with available pods: 0
Apr  3 10:26:37.650: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:26:38.652: INFO: Number of nodes with available pods: 0
Apr  3 10:26:38.652: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:26:39.654: INFO: Number of nodes with available pods: 1
Apr  3 10:26:39.654: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr  3 10:26:39.689: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:40.708: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:41.709: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:42.709: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:42.709: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:43.708: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:43.708: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:44.711: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:44.711: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:45.708: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:45.708: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:46.708: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:46.708: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:47.708: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:47.708: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:48.709: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:48.709: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:49.708: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:49.708: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:50.709: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:50.709: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:51.709: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:51.709: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:52.709: INFO: Wrong image for pod: daemon-set-dzq6c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  3 10:26:52.709: INFO: Pod daemon-set-dzq6c is not available
Apr  3 10:26:53.709: INFO: Pod daemon-set-kqnhz is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr  3 10:26:53.720: INFO: Number of nodes with available pods: 0
Apr  3 10:26:53.720: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:26:54.728: INFO: Number of nodes with available pods: 0
Apr  3 10:26:54.728: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:26:55.725: INFO: Number of nodes with available pods: 1
Apr  3 10:26:55.725: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7080, will wait for the garbage collector to delete the pods
Apr  3 10:26:55.803: INFO: Deleting DaemonSet.extensions daemon-set took: 5.101129ms
Apr  3 10:26:56.205: INFO: Terminating DaemonSet.extensions daemon-set pods took: 401.484491ms
Apr  3 10:27:03.608: INFO: Number of nodes with available pods: 0
Apr  3 10:27:03.608: INFO: Number of running nodes: 0, number of available pods: 0
Apr  3 10:27:03.611: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7080/daemonsets","resourceVersion":"11975"},"items":null}

Apr  3 10:27:03.617: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7080/pods","resourceVersion":"11975"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:27:03.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7080" for this suite.
Apr  3 10:27:09.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:27:09.703: INFO: namespace daemonsets-7080 deletion completed in 6.072676757s

• [SLOW TEST:33.120 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:27:09.710: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:27:09.757: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0995c0e1-55fb-11e9-a6c1-a20d030b39ea" in namespace "downward-api-9855" to be "success or failure"
Apr  3 10:27:09.766: INFO: Pod "downwardapi-volume-0995c0e1-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 9.40784ms
Apr  3 10:27:11.769: INFO: Pod "downwardapi-volume-0995c0e1-55fb-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012547108s
STEP: Saw pod success
Apr  3 10:27:11.769: INFO: Pod "downwardapi-volume-0995c0e1-55fb-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:27:11.772: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-0995c0e1-55fb-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:27:11.795: INFO: Waiting for pod downwardapi-volume-0995c0e1-55fb-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:27:11.799: INFO: Pod downwardapi-volume-0995c0e1-55fb-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:27:11.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9855" for this suite.
Apr  3 10:27:17.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:27:17.907: INFO: namespace downward-api-9855 deletion completed in 6.104553542s

• [SLOW TEST:8.198 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:27:17.911: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:27:19.973: INFO: Waiting up to 5m0s for pod "client-envvars-0fad4d54-55fb-11e9-a6c1-a20d030b39ea" in namespace "pods-7470" to be "success or failure"
Apr  3 10:27:19.979: INFO: Pod "client-envvars-0fad4d54-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.774391ms
Apr  3 10:27:21.983: INFO: Pod "client-envvars-0fad4d54-55fb-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009283407s
STEP: Saw pod success
Apr  3 10:27:21.983: INFO: Pod "client-envvars-0fad4d54-55fb-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:27:21.986: INFO: Trying to get logs from node docker-desktop pod client-envvars-0fad4d54-55fb-11e9-a6c1-a20d030b39ea container env3cont: <nil>
STEP: delete the pod
Apr  3 10:27:22.014: INFO: Waiting for pod client-envvars-0fad4d54-55fb-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:27:22.023: INFO: Pod client-envvars-0fad4d54-55fb-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:27:22.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7470" for this suite.
Apr  3 10:28:04.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:28:04.116: INFO: namespace pods-7470 deletion completed in 42.084143338s

• [SLOW TEST:46.204 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:28:04.117: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:28:04.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-629" for this suite.
Apr  3 10:28:26.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:28:26.273: INFO: namespace kubelet-test-629 deletion completed in 22.093875322s

• [SLOW TEST:22.155 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:28:26.273: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:28:26.317: INFO: Waiting up to 5m0s for pod "downwardapi-volume-373755bc-55fb-11e9-a6c1-a20d030b39ea" in namespace "downward-api-4045" to be "success or failure"
Apr  3 10:28:26.321: INFO: Pod "downwardapi-volume-373755bc-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.51996ms
Apr  3 10:28:28.326: INFO: Pod "downwardapi-volume-373755bc-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009078257s
Apr  3 10:28:30.328: INFO: Pod "downwardapi-volume-373755bc-55fb-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011911152s
STEP: Saw pod success
Apr  3 10:28:30.329: INFO: Pod "downwardapi-volume-373755bc-55fb-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:28:30.332: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-373755bc-55fb-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:28:30.363: INFO: Waiting for pod downwardapi-volume-373755bc-55fb-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:28:30.371: INFO: Pod downwardapi-volume-373755bc-55fb-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:28:30.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4045" for this suite.
Apr  3 10:28:36.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:28:36.466: INFO: namespace downward-api-4045 deletion completed in 6.082012918s

• [SLOW TEST:10.194 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:28:36.467: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr  3 10:28:36.515: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:28:37.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2389" for this suite.
Apr  3 10:28:43.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:28:43.631: INFO: namespace replication-controller-2389 deletion completed in 6.091165506s

• [SLOW TEST:7.164 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:28:43.633: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2302
I0403 10:28:43.674712      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2302, replica count: 1
I0403 10:28:44.725699      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0403 10:28:45.726091      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  3 10:28:45.838: INFO: Created: latency-svc-5rvsr
Apr  3 10:28:45.841: INFO: Got endpoints: latency-svc-5rvsr [14.89446ms]
Apr  3 10:28:45.856: INFO: Created: latency-svc-mzfhh
Apr  3 10:28:45.862: INFO: Got endpoints: latency-svc-mzfhh [20.608549ms]
Apr  3 10:28:45.869: INFO: Created: latency-svc-x8zqq
Apr  3 10:28:45.872: INFO: Got endpoints: latency-svc-x8zqq [30.435748ms]
Apr  3 10:28:45.882: INFO: Created: latency-svc-5dk75
Apr  3 10:28:45.898: INFO: Got endpoints: latency-svc-5dk75 [56.451074ms]
Apr  3 10:28:45.900: INFO: Created: latency-svc-dr5b5
Apr  3 10:28:45.900: INFO: Got endpoints: latency-svc-dr5b5 [57.95155ms]
Apr  3 10:28:45.907: INFO: Created: latency-svc-grz5t
Apr  3 10:28:45.911: INFO: Got endpoints: latency-svc-grz5t [66.78773ms]
Apr  3 10:28:45.926: INFO: Created: latency-svc-gthhq
Apr  3 10:28:45.930: INFO: Got endpoints: latency-svc-gthhq [86.062245ms]
Apr  3 10:28:45.937: INFO: Created: latency-svc-llm6f
Apr  3 10:28:45.947: INFO: Got endpoints: latency-svc-llm6f [103.734984ms]
Apr  3 10:28:45.951: INFO: Created: latency-svc-kxfpw
Apr  3 10:28:45.956: INFO: Got endpoints: latency-svc-kxfpw [111.476974ms]
Apr  3 10:28:45.966: INFO: Created: latency-svc-dkvjl
Apr  3 10:28:45.972: INFO: Got endpoints: latency-svc-dkvjl [127.596235ms]
Apr  3 10:28:45.981: INFO: Created: latency-svc-rdltq
Apr  3 10:28:45.986: INFO: Got endpoints: latency-svc-rdltq [141.170517ms]
Apr  3 10:28:45.996: INFO: Created: latency-svc-m565h
Apr  3 10:28:46.001: INFO: Got endpoints: latency-svc-m565h [156.486945ms]
Apr  3 10:28:46.011: INFO: Created: latency-svc-2ljm7
Apr  3 10:28:46.014: INFO: Got endpoints: latency-svc-2ljm7 [168.803396ms]
Apr  3 10:28:46.026: INFO: Created: latency-svc-hwtw6
Apr  3 10:28:46.032: INFO: Got endpoints: latency-svc-hwtw6 [187.294561ms]
Apr  3 10:28:46.050: INFO: Created: latency-svc-4vmv2
Apr  3 10:28:46.058: INFO: Got endpoints: latency-svc-4vmv2 [212.592419ms]
Apr  3 10:28:46.066: INFO: Created: latency-svc-7hr45
Apr  3 10:28:46.070: INFO: Got endpoints: latency-svc-7hr45 [224.339443ms]
Apr  3 10:28:46.082: INFO: Created: latency-svc-59f5j
Apr  3 10:28:46.087: INFO: Got endpoints: latency-svc-59f5j [224.679969ms]
Apr  3 10:28:46.101: INFO: Created: latency-svc-95zk8
Apr  3 10:28:46.109: INFO: Got endpoints: latency-svc-95zk8 [236.088911ms]
Apr  3 10:28:46.121: INFO: Created: latency-svc-xxjn4
Apr  3 10:28:46.160: INFO: Got endpoints: latency-svc-xxjn4 [261.886651ms]
Apr  3 10:28:46.160: INFO: Created: latency-svc-657rn
Apr  3 10:28:46.171: INFO: Got endpoints: latency-svc-657rn [271.229707ms]
Apr  3 10:28:46.180: INFO: Created: latency-svc-fd45b
Apr  3 10:28:46.195: INFO: Got endpoints: latency-svc-fd45b [284.383586ms]
Apr  3 10:28:46.199: INFO: Created: latency-svc-wq48r
Apr  3 10:28:46.201: INFO: Got endpoints: latency-svc-wq48r [271.211517ms]
Apr  3 10:28:46.210: INFO: Created: latency-svc-6jn5s
Apr  3 10:28:46.215: INFO: Got endpoints: latency-svc-6jn5s [268.166557ms]
Apr  3 10:28:46.224: INFO: Created: latency-svc-7lmjz
Apr  3 10:28:46.227: INFO: Got endpoints: latency-svc-7lmjz [271.229281ms]
Apr  3 10:28:46.235: INFO: Created: latency-svc-wqwmg
Apr  3 10:28:46.237: INFO: Got endpoints: latency-svc-wqwmg [264.981ms]
Apr  3 10:28:46.250: INFO: Created: latency-svc-crz27
Apr  3 10:28:46.261: INFO: Got endpoints: latency-svc-crz27 [274.667442ms]
Apr  3 10:28:46.266: INFO: Created: latency-svc-xgh7t
Apr  3 10:28:46.273: INFO: Got endpoints: latency-svc-xgh7t [271.435676ms]
Apr  3 10:28:46.276: INFO: Created: latency-svc-99snt
Apr  3 10:28:46.284: INFO: Got endpoints: latency-svc-99snt [270.355458ms]
Apr  3 10:28:46.292: INFO: Created: latency-svc-txc9n
Apr  3 10:28:46.302: INFO: Got endpoints: latency-svc-txc9n [270.014465ms]
Apr  3 10:28:46.308: INFO: Created: latency-svc-nbwqv
Apr  3 10:28:46.316: INFO: Got endpoints: latency-svc-nbwqv [258.145908ms]
Apr  3 10:28:46.321: INFO: Created: latency-svc-lvs4l
Apr  3 10:28:46.326: INFO: Got endpoints: latency-svc-lvs4l [256.609785ms]
Apr  3 10:28:46.333: INFO: Created: latency-svc-pllh8
Apr  3 10:28:46.341: INFO: Created: latency-svc-gd5xv
Apr  3 10:28:46.341: INFO: Got endpoints: latency-svc-pllh8 [254.282127ms]
Apr  3 10:28:46.349: INFO: Got endpoints: latency-svc-gd5xv [240.744122ms]
Apr  3 10:28:46.355: INFO: Created: latency-svc-rpb5n
Apr  3 10:28:46.360: INFO: Got endpoints: latency-svc-rpb5n [200.697716ms]
Apr  3 10:28:46.366: INFO: Created: latency-svc-vxmsj
Apr  3 10:28:46.368: INFO: Got endpoints: latency-svc-vxmsj [196.100006ms]
Apr  3 10:28:46.376: INFO: Created: latency-svc-4tzp4
Apr  3 10:28:46.384: INFO: Got endpoints: latency-svc-4tzp4 [189.277802ms]
Apr  3 10:28:46.388: INFO: Created: latency-svc-rzvjv
Apr  3 10:28:46.392: INFO: Got endpoints: latency-svc-rzvjv [191.260247ms]
Apr  3 10:28:46.404: INFO: Created: latency-svc-tc4wh
Apr  3 10:28:46.416: INFO: Got endpoints: latency-svc-tc4wh [200.542821ms]
Apr  3 10:28:46.417: INFO: Created: latency-svc-pglsl
Apr  3 10:28:46.429: INFO: Got endpoints: latency-svc-pglsl [201.561363ms]
Apr  3 10:28:46.437: INFO: Created: latency-svc-2hxzq
Apr  3 10:28:46.445: INFO: Created: latency-svc-thjt7
Apr  3 10:28:46.445: INFO: Got endpoints: latency-svc-2hxzq [207.832284ms]
Apr  3 10:28:46.455: INFO: Got endpoints: latency-svc-thjt7 [194.482794ms]
Apr  3 10:28:46.457: INFO: Created: latency-svc-6xmpt
Apr  3 10:28:46.464: INFO: Got endpoints: latency-svc-6xmpt [191.113378ms]
Apr  3 10:28:46.471: INFO: Created: latency-svc-58bnm
Apr  3 10:28:46.478: INFO: Created: latency-svc-9fhw4
Apr  3 10:28:46.494: INFO: Got endpoints: latency-svc-58bnm [210.105726ms]
Apr  3 10:28:46.501: INFO: Created: latency-svc-kjfnz
Apr  3 10:28:46.511: INFO: Created: latency-svc-x49n9
Apr  3 10:28:46.527: INFO: Created: latency-svc-sgrlr
Apr  3 10:28:46.537: INFO: Created: latency-svc-xvsjh
Apr  3 10:28:46.544: INFO: Got endpoints: latency-svc-9fhw4 [241.042148ms]
Apr  3 10:28:46.558: INFO: Created: latency-svc-9lq2q
Apr  3 10:28:46.565: INFO: Created: latency-svc-d7jgm
Apr  3 10:28:46.577: INFO: Created: latency-svc-fwngw
Apr  3 10:28:46.585: INFO: Created: latency-svc-h47sx
Apr  3 10:28:46.593: INFO: Got endpoints: latency-svc-kjfnz [276.504531ms]
Apr  3 10:28:46.600: INFO: Created: latency-svc-sdkfp
Apr  3 10:28:46.618: INFO: Created: latency-svc-dkrpp
Apr  3 10:28:46.631: INFO: Created: latency-svc-mg7ws
Apr  3 10:28:46.639: INFO: Created: latency-svc-r8pv7
Apr  3 10:28:46.649: INFO: Created: latency-svc-fln2m
Apr  3 10:28:46.649: INFO: Got endpoints: latency-svc-x49n9 [322.538397ms]
Apr  3 10:28:46.661: INFO: Created: latency-svc-wzvqx
Apr  3 10:28:46.671: INFO: Created: latency-svc-sp7l6
Apr  3 10:28:46.680: INFO: Created: latency-svc-49scb
Apr  3 10:28:46.689: INFO: Created: latency-svc-27ltg
Apr  3 10:28:46.690: INFO: Got endpoints: latency-svc-sgrlr [348.570072ms]
Apr  3 10:28:46.702: INFO: Created: latency-svc-4dpgl
Apr  3 10:28:46.740: INFO: Got endpoints: latency-svc-xvsjh [390.186532ms]
Apr  3 10:28:46.751: INFO: Created: latency-svc-d9n4x
Apr  3 10:28:46.790: INFO: Got endpoints: latency-svc-9lq2q [429.621558ms]
Apr  3 10:28:46.801: INFO: Created: latency-svc-4gmn9
Apr  3 10:28:46.843: INFO: Got endpoints: latency-svc-d7jgm [474.128357ms]
Apr  3 10:28:46.855: INFO: Created: latency-svc-h9v2g
Apr  3 10:28:46.890: INFO: Got endpoints: latency-svc-fwngw [505.47272ms]
Apr  3 10:28:46.900: INFO: Created: latency-svc-br988
Apr  3 10:28:46.940: INFO: Got endpoints: latency-svc-h47sx [548.089084ms]
Apr  3 10:28:46.983: INFO: Created: latency-svc-s52cc
Apr  3 10:28:46.991: INFO: Got endpoints: latency-svc-sdkfp [575.099673ms]
Apr  3 10:28:47.002: INFO: Created: latency-svc-gltvs
Apr  3 10:28:47.040: INFO: Got endpoints: latency-svc-dkrpp [611.595224ms]
Apr  3 10:28:47.058: INFO: Created: latency-svc-x82xk
Apr  3 10:28:47.092: INFO: Got endpoints: latency-svc-mg7ws [646.6212ms]
Apr  3 10:28:47.114: INFO: Created: latency-svc-htbgf
Apr  3 10:28:47.141: INFO: Got endpoints: latency-svc-r8pv7 [686.009058ms]
Apr  3 10:28:47.165: INFO: Created: latency-svc-lrclc
Apr  3 10:28:47.190: INFO: Got endpoints: latency-svc-fln2m [725.788732ms]
Apr  3 10:28:47.203: INFO: Created: latency-svc-5n9vh
Apr  3 10:28:47.240: INFO: Got endpoints: latency-svc-wzvqx [745.369917ms]
Apr  3 10:28:47.254: INFO: Created: latency-svc-r2ztl
Apr  3 10:28:47.291: INFO: Got endpoints: latency-svc-sp7l6 [742.664216ms]
Apr  3 10:28:47.305: INFO: Created: latency-svc-bj6ns
Apr  3 10:28:47.340: INFO: Got endpoints: latency-svc-49scb [747.088635ms]
Apr  3 10:28:47.355: INFO: Created: latency-svc-6xwrg
Apr  3 10:28:47.390: INFO: Got endpoints: latency-svc-27ltg [740.862099ms]
Apr  3 10:28:47.405: INFO: Created: latency-svc-9x44x
Apr  3 10:28:47.441: INFO: Got endpoints: latency-svc-4dpgl [750.64355ms]
Apr  3 10:28:47.456: INFO: Created: latency-svc-k2w2d
Apr  3 10:28:47.490: INFO: Got endpoints: latency-svc-d9n4x [750.355139ms]
Apr  3 10:28:47.509: INFO: Created: latency-svc-jxpck
Apr  3 10:28:47.546: INFO: Got endpoints: latency-svc-4gmn9 [755.326685ms]
Apr  3 10:28:47.563: INFO: Created: latency-svc-l95g7
Apr  3 10:28:47.591: INFO: Got endpoints: latency-svc-h9v2g [748.049682ms]
Apr  3 10:28:47.605: INFO: Created: latency-svc-sn7bc
Apr  3 10:28:47.641: INFO: Got endpoints: latency-svc-br988 [751.413483ms]
Apr  3 10:28:47.657: INFO: Created: latency-svc-kpn7b
Apr  3 10:28:47.689: INFO: Got endpoints: latency-svc-s52cc [748.858227ms]
Apr  3 10:28:47.705: INFO: Created: latency-svc-t644f
Apr  3 10:28:47.740: INFO: Got endpoints: latency-svc-gltvs [748.21121ms]
Apr  3 10:28:47.753: INFO: Created: latency-svc-66qwg
Apr  3 10:28:47.790: INFO: Got endpoints: latency-svc-x82xk [749.681859ms]
Apr  3 10:28:47.843: INFO: Got endpoints: latency-svc-htbgf [751.312258ms]
Apr  3 10:28:47.845: INFO: Created: latency-svc-w48pk
Apr  3 10:28:47.858: INFO: Created: latency-svc-8bknq
Apr  3 10:28:47.892: INFO: Got endpoints: latency-svc-lrclc [751.006225ms]
Apr  3 10:28:47.908: INFO: Created: latency-svc-fmsd8
Apr  3 10:28:47.941: INFO: Got endpoints: latency-svc-5n9vh [750.722687ms]
Apr  3 10:28:47.952: INFO: Created: latency-svc-cwgsr
Apr  3 10:28:47.991: INFO: Got endpoints: latency-svc-r2ztl [750.584243ms]
Apr  3 10:28:48.005: INFO: Created: latency-svc-dpntd
Apr  3 10:28:48.040: INFO: Got endpoints: latency-svc-bj6ns [748.991021ms]
Apr  3 10:28:48.051: INFO: Created: latency-svc-xf4nb
Apr  3 10:28:48.091: INFO: Got endpoints: latency-svc-6xwrg [750.839381ms]
Apr  3 10:28:48.108: INFO: Created: latency-svc-dz4k9
Apr  3 10:28:48.139: INFO: Got endpoints: latency-svc-9x44x [749.125442ms]
Apr  3 10:28:48.152: INFO: Created: latency-svc-6mdd5
Apr  3 10:28:48.190: INFO: Got endpoints: latency-svc-k2w2d [749.179508ms]
Apr  3 10:28:48.203: INFO: Created: latency-svc-l45wf
Apr  3 10:28:48.241: INFO: Got endpoints: latency-svc-jxpck [750.244066ms]
Apr  3 10:28:48.252: INFO: Created: latency-svc-9wgcw
Apr  3 10:28:48.290: INFO: Got endpoints: latency-svc-l95g7 [744.072804ms]
Apr  3 10:28:48.304: INFO: Created: latency-svc-9lv52
Apr  3 10:28:48.341: INFO: Got endpoints: latency-svc-sn7bc [749.774179ms]
Apr  3 10:28:48.354: INFO: Created: latency-svc-mnkmt
Apr  3 10:28:48.391: INFO: Got endpoints: latency-svc-kpn7b [749.281837ms]
Apr  3 10:28:48.402: INFO: Created: latency-svc-pb7wf
Apr  3 10:28:48.440: INFO: Got endpoints: latency-svc-t644f [750.468142ms]
Apr  3 10:28:48.455: INFO: Created: latency-svc-s7b2t
Apr  3 10:28:48.493: INFO: Got endpoints: latency-svc-66qwg [753.276554ms]
Apr  3 10:28:48.511: INFO: Created: latency-svc-dxkk6
Apr  3 10:28:48.541: INFO: Got endpoints: latency-svc-w48pk [750.731373ms]
Apr  3 10:28:48.554: INFO: Created: latency-svc-nh5b8
Apr  3 10:28:48.590: INFO: Got endpoints: latency-svc-8bknq [746.155404ms]
Apr  3 10:28:48.601: INFO: Created: latency-svc-6w4k6
Apr  3 10:28:48.640: INFO: Got endpoints: latency-svc-fmsd8 [747.72618ms]
Apr  3 10:28:48.652: INFO: Created: latency-svc-nqm9m
Apr  3 10:28:48.690: INFO: Got endpoints: latency-svc-cwgsr [749.314687ms]
Apr  3 10:28:48.703: INFO: Created: latency-svc-zqwrb
Apr  3 10:28:48.740: INFO: Got endpoints: latency-svc-dpntd [749.181319ms]
Apr  3 10:28:48.748: INFO: Created: latency-svc-gpjc8
Apr  3 10:28:48.790: INFO: Got endpoints: latency-svc-xf4nb [749.91864ms]
Apr  3 10:28:48.800: INFO: Created: latency-svc-dbzc4
Apr  3 10:28:48.840: INFO: Got endpoints: latency-svc-dz4k9 [748.792824ms]
Apr  3 10:28:48.854: INFO: Created: latency-svc-xdhf5
Apr  3 10:28:48.890: INFO: Got endpoints: latency-svc-6mdd5 [750.725566ms]
Apr  3 10:28:48.903: INFO: Created: latency-svc-6qj7t
Apr  3 10:28:48.939: INFO: Got endpoints: latency-svc-l45wf [748.744622ms]
Apr  3 10:28:48.952: INFO: Created: latency-svc-cpmwr
Apr  3 10:28:48.991: INFO: Got endpoints: latency-svc-9wgcw [749.994869ms]
Apr  3 10:28:49.003: INFO: Created: latency-svc-5wmpx
Apr  3 10:28:49.041: INFO: Got endpoints: latency-svc-9lv52 [750.507296ms]
Apr  3 10:28:49.051: INFO: Created: latency-svc-86fx5
Apr  3 10:28:49.090: INFO: Got endpoints: latency-svc-mnkmt [749.441392ms]
Apr  3 10:28:49.103: INFO: Created: latency-svc-fk9q5
Apr  3 10:28:49.140: INFO: Got endpoints: latency-svc-pb7wf [749.244172ms]
Apr  3 10:28:49.153: INFO: Created: latency-svc-xvdmx
Apr  3 10:28:49.190: INFO: Got endpoints: latency-svc-s7b2t [749.744411ms]
Apr  3 10:28:49.200: INFO: Created: latency-svc-wnqmx
Apr  3 10:28:49.239: INFO: Got endpoints: latency-svc-dxkk6 [746.313833ms]
Apr  3 10:28:49.255: INFO: Created: latency-svc-f2d6p
Apr  3 10:28:49.290: INFO: Got endpoints: latency-svc-nh5b8 [748.415097ms]
Apr  3 10:28:49.301: INFO: Created: latency-svc-zft58
Apr  3 10:28:49.340: INFO: Got endpoints: latency-svc-6w4k6 [750.301406ms]
Apr  3 10:28:49.359: INFO: Created: latency-svc-qfqg7
Apr  3 10:28:49.389: INFO: Got endpoints: latency-svc-nqm9m [749.296629ms]
Apr  3 10:28:49.405: INFO: Created: latency-svc-gjpq2
Apr  3 10:28:49.440: INFO: Got endpoints: latency-svc-zqwrb [749.746782ms]
Apr  3 10:28:49.456: INFO: Created: latency-svc-5g5mv
Apr  3 10:28:49.491: INFO: Got endpoints: latency-svc-gpjc8 [750.969945ms]
Apr  3 10:28:49.504: INFO: Created: latency-svc-9d62c
Apr  3 10:28:49.541: INFO: Got endpoints: latency-svc-dbzc4 [751.359112ms]
Apr  3 10:28:49.552: INFO: Created: latency-svc-kp99z
Apr  3 10:28:49.589: INFO: Got endpoints: latency-svc-xdhf5 [747.976143ms]
Apr  3 10:28:49.601: INFO: Created: latency-svc-tpv2g
Apr  3 10:28:49.640: INFO: Got endpoints: latency-svc-6qj7t [749.025776ms]
Apr  3 10:28:49.652: INFO: Created: latency-svc-7l78d
Apr  3 10:28:49.690: INFO: Got endpoints: latency-svc-cpmwr [750.855845ms]
Apr  3 10:28:49.699: INFO: Created: latency-svc-szk24
Apr  3 10:28:49.741: INFO: Got endpoints: latency-svc-5wmpx [750.83111ms]
Apr  3 10:28:49.758: INFO: Created: latency-svc-lx7tv
Apr  3 10:28:49.792: INFO: Got endpoints: latency-svc-86fx5 [751.332259ms]
Apr  3 10:28:49.813: INFO: Created: latency-svc-r8rjp
Apr  3 10:28:49.841: INFO: Got endpoints: latency-svc-fk9q5 [750.98492ms]
Apr  3 10:28:49.854: INFO: Created: latency-svc-v2x46
Apr  3 10:28:49.890: INFO: Got endpoints: latency-svc-xvdmx [749.732381ms]
Apr  3 10:28:49.903: INFO: Created: latency-svc-9mb6b
Apr  3 10:28:49.942: INFO: Got endpoints: latency-svc-wnqmx [751.730107ms]
Apr  3 10:28:49.959: INFO: Created: latency-svc-wx8wx
Apr  3 10:28:49.991: INFO: Got endpoints: latency-svc-f2d6p [751.224229ms]
Apr  3 10:28:50.003: INFO: Created: latency-svc-627h5
Apr  3 10:28:50.040: INFO: Got endpoints: latency-svc-zft58 [750.566551ms]
Apr  3 10:28:50.053: INFO: Created: latency-svc-dtnwb
Apr  3 10:28:50.090: INFO: Got endpoints: latency-svc-qfqg7 [749.793869ms]
Apr  3 10:28:50.102: INFO: Created: latency-svc-xdkmg
Apr  3 10:28:50.141: INFO: Got endpoints: latency-svc-gjpq2 [751.511734ms]
Apr  3 10:28:50.152: INFO: Created: latency-svc-qkjf8
Apr  3 10:28:50.190: INFO: Got endpoints: latency-svc-5g5mv [748.002551ms]
Apr  3 10:28:50.210: INFO: Created: latency-svc-kwtb5
Apr  3 10:28:50.239: INFO: Got endpoints: latency-svc-9d62c [748.197355ms]
Apr  3 10:28:50.249: INFO: Created: latency-svc-8dv5f
Apr  3 10:28:50.289: INFO: Got endpoints: latency-svc-kp99z [747.914879ms]
Apr  3 10:28:50.301: INFO: Created: latency-svc-7fp68
Apr  3 10:28:50.340: INFO: Got endpoints: latency-svc-tpv2g [751.162978ms]
Apr  3 10:28:50.349: INFO: Created: latency-svc-hpkr5
Apr  3 10:28:50.393: INFO: Got endpoints: latency-svc-7l78d [753.694655ms]
Apr  3 10:28:50.409: INFO: Created: latency-svc-kpjrg
Apr  3 10:28:50.440: INFO: Got endpoints: latency-svc-szk24 [749.947061ms]
Apr  3 10:28:50.451: INFO: Created: latency-svc-xrhkh
Apr  3 10:28:50.494: INFO: Got endpoints: latency-svc-lx7tv [752.646622ms]
Apr  3 10:28:50.506: INFO: Created: latency-svc-qhnp5
Apr  3 10:28:50.539: INFO: Got endpoints: latency-svc-r8rjp [746.646684ms]
Apr  3 10:28:50.556: INFO: Created: latency-svc-52rjv
Apr  3 10:28:50.589: INFO: Got endpoints: latency-svc-v2x46 [748.167355ms]
Apr  3 10:28:50.605: INFO: Created: latency-svc-tm6g5
Apr  3 10:28:50.640: INFO: Got endpoints: latency-svc-9mb6b [750.071112ms]
Apr  3 10:28:50.653: INFO: Created: latency-svc-4lqbm
Apr  3 10:28:50.689: INFO: Got endpoints: latency-svc-wx8wx [746.973315ms]
Apr  3 10:28:50.702: INFO: Created: latency-svc-ncvqh
Apr  3 10:28:50.740: INFO: Got endpoints: latency-svc-627h5 [749.165032ms]
Apr  3 10:28:50.751: INFO: Created: latency-svc-djh56
Apr  3 10:28:50.794: INFO: Got endpoints: latency-svc-dtnwb [753.009314ms]
Apr  3 10:28:50.806: INFO: Created: latency-svc-sn5dz
Apr  3 10:28:50.840: INFO: Got endpoints: latency-svc-xdkmg [750.423779ms]
Apr  3 10:28:50.853: INFO: Created: latency-svc-2kr2k
Apr  3 10:28:50.890: INFO: Got endpoints: latency-svc-qkjf8 [749.349883ms]
Apr  3 10:28:50.936: INFO: Created: latency-svc-8mwtl
Apr  3 10:28:50.946: INFO: Got endpoints: latency-svc-kwtb5 [755.898237ms]
Apr  3 10:28:50.961: INFO: Created: latency-svc-55bdv
Apr  3 10:28:50.990: INFO: Got endpoints: latency-svc-8dv5f [751.082572ms]
Apr  3 10:28:51.004: INFO: Created: latency-svc-dwp4n
Apr  3 10:28:51.040: INFO: Got endpoints: latency-svc-7fp68 [750.919283ms]
Apr  3 10:28:51.054: INFO: Created: latency-svc-bdbnq
Apr  3 10:28:51.090: INFO: Got endpoints: latency-svc-hpkr5 [749.873648ms]
Apr  3 10:28:51.105: INFO: Created: latency-svc-98ws9
Apr  3 10:28:51.142: INFO: Got endpoints: latency-svc-kpjrg [748.776968ms]
Apr  3 10:28:51.157: INFO: Created: latency-svc-72k6n
Apr  3 10:28:51.190: INFO: Got endpoints: latency-svc-xrhkh [749.98812ms]
Apr  3 10:28:51.204: INFO: Created: latency-svc-j4xlr
Apr  3 10:28:51.239: INFO: Got endpoints: latency-svc-qhnp5 [745.047686ms]
Apr  3 10:28:51.255: INFO: Created: latency-svc-7cnj4
Apr  3 10:28:51.290: INFO: Got endpoints: latency-svc-52rjv [750.462141ms]
Apr  3 10:28:51.303: INFO: Created: latency-svc-v7vbc
Apr  3 10:28:51.342: INFO: Got endpoints: latency-svc-tm6g5 [752.861598ms]
Apr  3 10:28:51.361: INFO: Created: latency-svc-lms2n
Apr  3 10:28:51.391: INFO: Got endpoints: latency-svc-4lqbm [750.618903ms]
Apr  3 10:28:51.413: INFO: Created: latency-svc-pv4zk
Apr  3 10:28:51.440: INFO: Got endpoints: latency-svc-ncvqh [750.893367ms]
Apr  3 10:28:51.457: INFO: Created: latency-svc-s2tbh
Apr  3 10:28:51.490: INFO: Got endpoints: latency-svc-djh56 [749.681348ms]
Apr  3 10:28:51.506: INFO: Created: latency-svc-wd8kp
Apr  3 10:28:51.542: INFO: Got endpoints: latency-svc-sn5dz [748.12598ms]
Apr  3 10:28:51.558: INFO: Created: latency-svc-hj9k8
Apr  3 10:28:51.597: INFO: Got endpoints: latency-svc-2kr2k [756.168361ms]
Apr  3 10:28:51.618: INFO: Created: latency-svc-6qlrl
Apr  3 10:28:51.644: INFO: Got endpoints: latency-svc-8mwtl [753.728334ms]
Apr  3 10:28:51.663: INFO: Created: latency-svc-67gd9
Apr  3 10:28:51.691: INFO: Got endpoints: latency-svc-55bdv [744.972454ms]
Apr  3 10:28:51.705: INFO: Created: latency-svc-gv7gc
Apr  3 10:28:51.740: INFO: Got endpoints: latency-svc-dwp4n [749.304419ms]
Apr  3 10:28:51.753: INFO: Created: latency-svc-ppr8s
Apr  3 10:28:51.791: INFO: Got endpoints: latency-svc-bdbnq [751.190576ms]
Apr  3 10:28:51.806: INFO: Created: latency-svc-7fhfd
Apr  3 10:28:51.840: INFO: Got endpoints: latency-svc-98ws9 [750.448091ms]
Apr  3 10:28:51.855: INFO: Created: latency-svc-ggcvd
Apr  3 10:28:51.892: INFO: Got endpoints: latency-svc-72k6n [749.541506ms]
Apr  3 10:28:51.907: INFO: Created: latency-svc-g6rxc
Apr  3 10:28:51.939: INFO: Got endpoints: latency-svc-j4xlr [749.247754ms]
Apr  3 10:28:51.952: INFO: Created: latency-svc-zjxpx
Apr  3 10:28:51.990: INFO: Got endpoints: latency-svc-7cnj4 [749.964341ms]
Apr  3 10:28:52.001: INFO: Created: latency-svc-k9rvz
Apr  3 10:28:52.039: INFO: Got endpoints: latency-svc-v7vbc [748.892904ms]
Apr  3 10:28:52.050: INFO: Created: latency-svc-nhf2d
Apr  3 10:28:52.089: INFO: Got endpoints: latency-svc-lms2n [745.530778ms]
Apr  3 10:28:52.101: INFO: Created: latency-svc-bth8t
Apr  3 10:28:52.141: INFO: Got endpoints: latency-svc-pv4zk [750.131314ms]
Apr  3 10:28:52.155: INFO: Created: latency-svc-c5njt
Apr  3 10:28:52.191: INFO: Got endpoints: latency-svc-s2tbh [750.883055ms]
Apr  3 10:28:52.206: INFO: Created: latency-svc-pfbv2
Apr  3 10:28:52.240: INFO: Got endpoints: latency-svc-wd8kp [750.49403ms]
Apr  3 10:28:52.258: INFO: Created: latency-svc-lcpdt
Apr  3 10:28:52.289: INFO: Got endpoints: latency-svc-hj9k8 [747.482379ms]
Apr  3 10:28:52.303: INFO: Created: latency-svc-dhwgz
Apr  3 10:28:52.341: INFO: Got endpoints: latency-svc-6qlrl [744.145461ms]
Apr  3 10:28:52.353: INFO: Created: latency-svc-z9tl9
Apr  3 10:28:52.391: INFO: Got endpoints: latency-svc-67gd9 [747.131135ms]
Apr  3 10:28:52.404: INFO: Created: latency-svc-m8jf4
Apr  3 10:28:52.440: INFO: Got endpoints: latency-svc-gv7gc [748.744191ms]
Apr  3 10:28:52.451: INFO: Created: latency-svc-9cm9g
Apr  3 10:28:52.490: INFO: Got endpoints: latency-svc-ppr8s [750.194969ms]
Apr  3 10:28:52.503: INFO: Created: latency-svc-zk9cc
Apr  3 10:28:52.540: INFO: Got endpoints: latency-svc-7fhfd [748.780886ms]
Apr  3 10:28:52.551: INFO: Created: latency-svc-z7j68
Apr  3 10:28:52.590: INFO: Got endpoints: latency-svc-ggcvd [749.515099ms]
Apr  3 10:28:52.602: INFO: Created: latency-svc-vjltw
Apr  3 10:28:52.639: INFO: Got endpoints: latency-svc-g6rxc [747.569023ms]
Apr  3 10:28:52.652: INFO: Created: latency-svc-gwdf9
Apr  3 10:28:52.690: INFO: Got endpoints: latency-svc-zjxpx [750.922598ms]
Apr  3 10:28:52.704: INFO: Created: latency-svc-hfsdf
Apr  3 10:28:52.740: INFO: Got endpoints: latency-svc-k9rvz [750.212408ms]
Apr  3 10:28:52.752: INFO: Created: latency-svc-2t84k
Apr  3 10:28:52.790: INFO: Got endpoints: latency-svc-nhf2d [751.048695ms]
Apr  3 10:28:52.801: INFO: Created: latency-svc-mdst6
Apr  3 10:28:52.840: INFO: Got endpoints: latency-svc-bth8t [750.249057ms]
Apr  3 10:28:52.851: INFO: Created: latency-svc-8fvb8
Apr  3 10:28:52.890: INFO: Got endpoints: latency-svc-c5njt [748.346409ms]
Apr  3 10:28:52.906: INFO: Created: latency-svc-hf9sm
Apr  3 10:28:52.940: INFO: Got endpoints: latency-svc-pfbv2 [748.651417ms]
Apr  3 10:28:52.953: INFO: Created: latency-svc-r2z89
Apr  3 10:28:52.991: INFO: Got endpoints: latency-svc-lcpdt [750.908246ms]
Apr  3 10:28:53.007: INFO: Created: latency-svc-j6488
Apr  3 10:28:53.041: INFO: Got endpoints: latency-svc-dhwgz [751.829941ms]
Apr  3 10:28:53.056: INFO: Created: latency-svc-jwzbf
Apr  3 10:28:53.090: INFO: Got endpoints: latency-svc-z9tl9 [749.291411ms]
Apr  3 10:28:53.104: INFO: Created: latency-svc-vcs9h
Apr  3 10:28:53.139: INFO: Got endpoints: latency-svc-m8jf4 [747.490736ms]
Apr  3 10:28:53.151: INFO: Created: latency-svc-px4z2
Apr  3 10:28:53.190: INFO: Got endpoints: latency-svc-9cm9g [750.24333ms]
Apr  3 10:28:53.203: INFO: Created: latency-svc-f52tv
Apr  3 10:28:53.239: INFO: Got endpoints: latency-svc-zk9cc [749.526408ms]
Apr  3 10:28:53.248: INFO: Created: latency-svc-h2clz
Apr  3 10:28:53.290: INFO: Got endpoints: latency-svc-z7j68 [749.177083ms]
Apr  3 10:28:53.305: INFO: Created: latency-svc-mmk4x
Apr  3 10:28:53.340: INFO: Got endpoints: latency-svc-vjltw [749.779742ms]
Apr  3 10:28:53.354: INFO: Created: latency-svc-8f4xc
Apr  3 10:28:53.389: INFO: Got endpoints: latency-svc-gwdf9 [749.796226ms]
Apr  3 10:28:53.399: INFO: Created: latency-svc-dz4vd
Apr  3 10:28:53.440: INFO: Got endpoints: latency-svc-hfsdf [749.396144ms]
Apr  3 10:28:53.450: INFO: Created: latency-svc-l84r4
Apr  3 10:28:53.490: INFO: Got endpoints: latency-svc-2t84k [749.771665ms]
Apr  3 10:28:53.500: INFO: Created: latency-svc-5qtzb
Apr  3 10:28:53.540: INFO: Got endpoints: latency-svc-mdst6 [749.489517ms]
Apr  3 10:28:53.552: INFO: Created: latency-svc-749bp
Apr  3 10:28:53.592: INFO: Got endpoints: latency-svc-8fvb8 [752.32937ms]
Apr  3 10:28:53.605: INFO: Created: latency-svc-pt9hx
Apr  3 10:28:53.640: INFO: Got endpoints: latency-svc-hf9sm [750.414875ms]
Apr  3 10:28:53.653: INFO: Created: latency-svc-7jf9b
Apr  3 10:28:53.690: INFO: Got endpoints: latency-svc-r2z89 [750.168052ms]
Apr  3 10:28:53.740: INFO: Got endpoints: latency-svc-j6488 [748.473963ms]
Apr  3 10:28:53.790: INFO: Got endpoints: latency-svc-jwzbf [748.940086ms]
Apr  3 10:28:53.841: INFO: Got endpoints: latency-svc-vcs9h [750.926571ms]
Apr  3 10:28:53.890: INFO: Got endpoints: latency-svc-px4z2 [750.785643ms]
Apr  3 10:28:53.940: INFO: Got endpoints: latency-svc-f52tv [750.130164ms]
Apr  3 10:28:53.991: INFO: Got endpoints: latency-svc-h2clz [751.269332ms]
Apr  3 10:28:54.039: INFO: Got endpoints: latency-svc-mmk4x [749.870715ms]
Apr  3 10:28:54.090: INFO: Got endpoints: latency-svc-8f4xc [749.859401ms]
Apr  3 10:28:54.141: INFO: Got endpoints: latency-svc-dz4vd [751.588581ms]
Apr  3 10:28:54.190: INFO: Got endpoints: latency-svc-l84r4 [750.50897ms]
Apr  3 10:28:54.239: INFO: Got endpoints: latency-svc-5qtzb [749.420385ms]
Apr  3 10:28:54.290: INFO: Got endpoints: latency-svc-749bp [750.331599ms]
Apr  3 10:28:54.342: INFO: Got endpoints: latency-svc-pt9hx [749.236373ms]
Apr  3 10:28:54.392: INFO: Got endpoints: latency-svc-7jf9b [751.997475ms]
Apr  3 10:28:54.393: INFO: Latencies: [20.608549ms 30.435748ms 56.451074ms 57.95155ms 66.78773ms 86.062245ms 103.734984ms 111.476974ms 127.596235ms 141.170517ms 156.486945ms 168.803396ms 187.294561ms 189.277802ms 191.113378ms 191.260247ms 194.482794ms 196.100006ms 200.542821ms 200.697716ms 201.561363ms 207.832284ms 210.105726ms 212.592419ms 224.339443ms 224.679969ms 236.088911ms 240.744122ms 241.042148ms 254.282127ms 256.609785ms 258.145908ms 261.886651ms 264.981ms 268.166557ms 270.014465ms 270.355458ms 271.211517ms 271.229281ms 271.229707ms 271.435676ms 274.667442ms 276.504531ms 284.383586ms 322.538397ms 348.570072ms 390.186532ms 429.621558ms 474.128357ms 505.47272ms 548.089084ms 575.099673ms 611.595224ms 646.6212ms 686.009058ms 725.788732ms 740.862099ms 742.664216ms 744.072804ms 744.145461ms 744.972454ms 745.047686ms 745.369917ms 745.530778ms 746.155404ms 746.313833ms 746.646684ms 746.973315ms 747.088635ms 747.131135ms 747.482379ms 747.490736ms 747.569023ms 747.72618ms 747.914879ms 747.976143ms 748.002551ms 748.049682ms 748.12598ms 748.167355ms 748.197355ms 748.21121ms 748.346409ms 748.415097ms 748.473963ms 748.651417ms 748.744191ms 748.744622ms 748.776968ms 748.780886ms 748.792824ms 748.858227ms 748.892904ms 748.940086ms 748.991021ms 749.025776ms 749.125442ms 749.165032ms 749.177083ms 749.179508ms 749.181319ms 749.236373ms 749.244172ms 749.247754ms 749.281837ms 749.291411ms 749.296629ms 749.304419ms 749.314687ms 749.349883ms 749.396144ms 749.420385ms 749.441392ms 749.489517ms 749.515099ms 749.526408ms 749.541506ms 749.681348ms 749.681859ms 749.732381ms 749.744411ms 749.746782ms 749.771665ms 749.774179ms 749.779742ms 749.793869ms 749.796226ms 749.859401ms 749.870715ms 749.873648ms 749.91864ms 749.947061ms 749.964341ms 749.98812ms 749.994869ms 750.071112ms 750.130164ms 750.131314ms 750.168052ms 750.194969ms 750.212408ms 750.24333ms 750.244066ms 750.249057ms 750.301406ms 750.331599ms 750.355139ms 750.414875ms 750.423779ms 750.448091ms 750.462141ms 750.468142ms 750.49403ms 750.507296ms 750.50897ms 750.566551ms 750.584243ms 750.618903ms 750.64355ms 750.722687ms 750.725566ms 750.731373ms 750.785643ms 750.83111ms 750.839381ms 750.855845ms 750.883055ms 750.893367ms 750.908246ms 750.919283ms 750.922598ms 750.926571ms 750.969945ms 750.98492ms 751.006225ms 751.048695ms 751.082572ms 751.162978ms 751.190576ms 751.224229ms 751.269332ms 751.312258ms 751.332259ms 751.359112ms 751.413483ms 751.511734ms 751.588581ms 751.730107ms 751.829941ms 751.997475ms 752.32937ms 752.646622ms 752.861598ms 753.009314ms 753.276554ms 753.694655ms 753.728334ms 755.326685ms 755.898237ms 756.168361ms]
Apr  3 10:28:54.394: INFO: 50 %ile: 749.181319ms
Apr  3 10:28:54.394: INFO: 90 %ile: 751.269332ms
Apr  3 10:28:54.394: INFO: 99 %ile: 755.898237ms
Apr  3 10:28:54.394: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:28:54.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2302" for this suite.
Apr  3 10:29:04.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:29:04.511: INFO: namespace svc-latency-2302 deletion completed in 10.102578676s

• [SLOW TEST:20.878 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:29:04.512: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  3 10:29:04.568: INFO: Number of nodes with available pods: 0
Apr  3 10:29:04.568: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:05.574: INFO: Number of nodes with available pods: 0
Apr  3 10:29:05.574: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:06.573: INFO: Number of nodes with available pods: 1
Apr  3 10:29:06.573: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr  3 10:29:06.592: INFO: Number of nodes with available pods: 0
Apr  3 10:29:06.592: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:07.599: INFO: Number of nodes with available pods: 0
Apr  3 10:29:07.599: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:08.599: INFO: Number of nodes with available pods: 0
Apr  3 10:29:08.599: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:09.599: INFO: Number of nodes with available pods: 0
Apr  3 10:29:09.599: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:10.598: INFO: Number of nodes with available pods: 0
Apr  3 10:29:10.598: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:11.598: INFO: Number of nodes with available pods: 0
Apr  3 10:29:11.598: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:12.597: INFO: Number of nodes with available pods: 0
Apr  3 10:29:12.597: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:13.598: INFO: Number of nodes with available pods: 0
Apr  3 10:29:13.598: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:14.597: INFO: Number of nodes with available pods: 0
Apr  3 10:29:14.598: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:29:15.597: INFO: Number of nodes with available pods: 1
Apr  3 10:29:15.597: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-136, will wait for the garbage collector to delete the pods
Apr  3 10:29:15.664: INFO: Deleting DaemonSet.extensions daemon-set took: 5.557184ms
Apr  3 10:29:16.065: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.642997ms
Apr  3 10:29:19.668: INFO: Number of nodes with available pods: 0
Apr  3 10:29:19.668: INFO: Number of running nodes: 0, number of available pods: 0
Apr  3 10:29:19.671: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-136/daemonsets","resourceVersion":"13658"},"items":null}

Apr  3 10:29:19.675: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-136/pods","resourceVersion":"13658"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:29:19.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-136" for this suite.
Apr  3 10:29:25.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:29:25.771: INFO: namespace daemonsets-136 deletion completed in 6.079536479s

• [SLOW TEST:21.259 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:29:25.771: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-5aae41fb-55fb-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 10:29:25.817: INFO: Waiting up to 5m0s for pod "pod-configmaps-5aaf0f1e-55fb-11e9-a6c1-a20d030b39ea" in namespace "configmap-9247" to be "success or failure"
Apr  3 10:29:25.824: INFO: Pod "pod-configmaps-5aaf0f1e-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.948425ms
Apr  3 10:29:27.827: INFO: Pod "pod-configmaps-5aaf0f1e-55fb-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009438755s
STEP: Saw pod success
Apr  3 10:29:27.827: INFO: Pod "pod-configmaps-5aaf0f1e-55fb-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:29:27.829: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-5aaf0f1e-55fb-11e9-a6c1-a20d030b39ea container configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 10:29:27.848: INFO: Waiting for pod pod-configmaps-5aaf0f1e-55fb-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:29:27.858: INFO: Pod pod-configmaps-5aaf0f1e-55fb-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:29:27.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9247" for this suite.
Apr  3 10:29:33.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:29:33.953: INFO: namespace configmap-9247 deletion completed in 6.088887848s

• [SLOW TEST:8.182 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:29:33.955: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  3 10:29:33.997: INFO: Waiting up to 5m0s for pod "downward-api-5f8f2139-55fb-11e9-a6c1-a20d030b39ea" in namespace "downward-api-8772" to be "success or failure"
Apr  3 10:29:34.003: INFO: Pod "downward-api-5f8f2139-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.384589ms
Apr  3 10:29:36.006: INFO: Pod "downward-api-5f8f2139-55fb-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009393767s
STEP: Saw pod success
Apr  3 10:29:36.006: INFO: Pod "downward-api-5f8f2139-55fb-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:29:36.010: INFO: Trying to get logs from node docker-desktop pod downward-api-5f8f2139-55fb-11e9-a6c1-a20d030b39ea container dapi-container: <nil>
STEP: delete the pod
Apr  3 10:29:36.028: INFO: Waiting for pod downward-api-5f8f2139-55fb-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:29:36.036: INFO: Pod downward-api-5f8f2139-55fb-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:29:36.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8772" for this suite.
Apr  3 10:29:42.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:29:42.229: INFO: namespace downward-api-8772 deletion completed in 6.189091795s

• [SLOW TEST:8.275 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:29:42.230: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr  3 10:29:42.326: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-a,UID:6485b037-55fb-11e9-ad16-025000000001,ResourceVersion:13759,Generation:0,CreationTimestamp:2019-04-03 10:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  3 10:29:42.326: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-a,UID:6485b037-55fb-11e9-ad16-025000000001,ResourceVersion:13759,Generation:0,CreationTimestamp:2019-04-03 10:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr  3 10:29:52.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-a,UID:6485b037-55fb-11e9-ad16-025000000001,ResourceVersion:13772,Generation:0,CreationTimestamp:2019-04-03 10:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  3 10:29:52.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-a,UID:6485b037-55fb-11e9-ad16-025000000001,ResourceVersion:13772,Generation:0,CreationTimestamp:2019-04-03 10:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr  3 10:30:02.343: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-a,UID:6485b037-55fb-11e9-ad16-025000000001,ResourceVersion:13785,Generation:0,CreationTimestamp:2019-04-03 10:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  3 10:30:02.343: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-a,UID:6485b037-55fb-11e9-ad16-025000000001,ResourceVersion:13785,Generation:0,CreationTimestamp:2019-04-03 10:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr  3 10:30:12.352: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-a,UID:6485b037-55fb-11e9-ad16-025000000001,ResourceVersion:13799,Generation:0,CreationTimestamp:2019-04-03 10:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  3 10:30:12.352: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-a,UID:6485b037-55fb-11e9-ad16-025000000001,ResourceVersion:13799,Generation:0,CreationTimestamp:2019-04-03 10:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr  3 10:30:22.360: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-b,UID:7c6349cc-55fb-11e9-ad16-025000000001,ResourceVersion:13812,Generation:0,CreationTimestamp:2019-04-03 10:30:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  3 10:30:22.360: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-b,UID:7c6349cc-55fb-11e9-ad16-025000000001,ResourceVersion:13812,Generation:0,CreationTimestamp:2019-04-03 10:30:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr  3 10:30:32.385: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-b,UID:7c6349cc-55fb-11e9-ad16-025000000001,ResourceVersion:13825,Generation:0,CreationTimestamp:2019-04-03 10:30:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  3 10:30:32.386: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3077,SelfLink:/api/v1/namespaces/watch-3077/configmaps/e2e-watch-test-configmap-b,UID:7c6349cc-55fb-11e9-ad16-025000000001,ResourceVersion:13825,Generation:0,CreationTimestamp:2019-04-03 10:30:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:30:42.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3077" for this suite.
Apr  3 10:30:48.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:30:48.500: INFO: namespace watch-3077 deletion completed in 6.109892619s

• [SLOW TEST:66.269 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:30:48.503: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  3 10:30:48.551: INFO: Waiting up to 5m0s for pod "pod-8bfe856e-55fb-11e9-a6c1-a20d030b39ea" in namespace "emptydir-222" to be "success or failure"
Apr  3 10:30:48.561: INFO: Pod "pod-8bfe856e-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 10.252132ms
Apr  3 10:30:50.564: INFO: Pod "pod-8bfe856e-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013432914s
Apr  3 10:30:52.569: INFO: Pod "pod-8bfe856e-55fb-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017675664s
STEP: Saw pod success
Apr  3 10:30:52.569: INFO: Pod "pod-8bfe856e-55fb-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:30:52.574: INFO: Trying to get logs from node docker-desktop pod pod-8bfe856e-55fb-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:30:52.603: INFO: Waiting for pod pod-8bfe856e-55fb-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:30:52.614: INFO: Pod pod-8bfe856e-55fb-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:30:52.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-222" for this suite.
Apr  3 10:30:58.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:30:58.722: INFO: namespace emptydir-222 deletion completed in 6.098856965s

• [SLOW TEST:10.218 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:30:58.723: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:30:58.775: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92173ae1-55fb-11e9-a6c1-a20d030b39ea" in namespace "projected-1103" to be "success or failure"
Apr  3 10:30:58.780: INFO: Pod "downwardapi-volume-92173ae1-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.056164ms
Apr  3 10:31:00.785: INFO: Pod "downwardapi-volume-92173ae1-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009447486s
Apr  3 10:31:02.788: INFO: Pod "downwardapi-volume-92173ae1-55fb-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012433961s
STEP: Saw pod success
Apr  3 10:31:02.788: INFO: Pod "downwardapi-volume-92173ae1-55fb-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:31:02.790: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-92173ae1-55fb-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:31:02.808: INFO: Waiting for pod downwardapi-volume-92173ae1-55fb-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:31:02.810: INFO: Pod downwardapi-volume-92173ae1-55fb-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:31:02.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1103" for this suite.
Apr  3 10:31:08.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:31:08.914: INFO: namespace projected-1103 deletion completed in 6.094867197s

• [SLOW TEST:10.192 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:31:08.916: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-982a35fb-55fb-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 10:31:08.971: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-982b2280-55fb-11e9-a6c1-a20d030b39ea" in namespace "projected-4452" to be "success or failure"
Apr  3 10:31:08.976: INFO: Pod "pod-projected-configmaps-982b2280-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.194311ms
Apr  3 10:31:10.981: INFO: Pod "pod-projected-configmaps-982b2280-55fb-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009898562s
STEP: Saw pod success
Apr  3 10:31:10.981: INFO: Pod "pod-projected-configmaps-982b2280-55fb-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:31:10.988: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-982b2280-55fb-11e9-a6c1-a20d030b39ea container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 10:31:11.010: INFO: Waiting for pod pod-projected-configmaps-982b2280-55fb-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:31:11.022: INFO: Pod pod-projected-configmaps-982b2280-55fb-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:31:11.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4452" for this suite.
Apr  3 10:31:17.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:31:17.152: INFO: namespace projected-4452 deletion completed in 6.105980231s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:31:17.153: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7135.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7135.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  3 10:31:21.265: INFO: DNS probes using dns-7135/dns-test-9d124816-55fb-11e9-a6c1-a20d030b39ea succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:31:21.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7135" for this suite.
Apr  3 10:31:27.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:31:27.409: INFO: namespace dns-7135 deletion completed in 6.112688183s

• [SLOW TEST:10.256 seconds]
[sig-network] DNS
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:31:27.410: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-a32fe918-55fb-11e9-a6c1-a20d030b39ea
STEP: Creating configMap with name cm-test-opt-upd-a32fe959-55fb-11e9-a6c1-a20d030b39ea
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a32fe918-55fb-11e9-a6c1-a20d030b39ea
STEP: Updating configmap cm-test-opt-upd-a32fe959-55fb-11e9-a6c1-a20d030b39ea
STEP: Creating configMap with name cm-test-opt-create-a32fe966-55fb-11e9-a6c1-a20d030b39ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:31:35.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7544" for this suite.
Apr  3 10:31:57.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:31:57.774: INFO: namespace configmap-7544 deletion completed in 22.197822994s

• [SLOW TEST:30.364 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:31:57.774: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  3 10:31:57.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-8618'
Apr  3 10:31:58.175: INFO: stderr: ""
Apr  3 10:31:58.175: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  3 10:31:59.179: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 10:31:59.179: INFO: Found 0 / 1
Apr  3 10:32:00.178: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 10:32:00.178: INFO: Found 1 / 1
Apr  3 10:32:00.178: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr  3 10:32:00.180: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 10:32:00.180: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  3 10:32:00.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 patch pod redis-master-nwh7d --namespace=kubectl-8618 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr  3 10:32:00.264: INFO: stderr: ""
Apr  3 10:32:00.264: INFO: stdout: "pod/redis-master-nwh7d patched\n"
STEP: checking annotations
Apr  3 10:32:00.267: INFO: Selector matched 1 pods for map[app:redis]
Apr  3 10:32:00.267: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:32:00.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8618" for this suite.
Apr  3 10:32:22.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:32:22.350: INFO: namespace kubectl-8618 deletion completed in 22.07759903s

• [SLOW TEST:24.576 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:32:22.350: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:32:22.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3ee2970-55fb-11e9-a6c1-a20d030b39ea" in namespace "downward-api-4967" to be "success or failure"
Apr  3 10:32:22.400: INFO: Pod "downwardapi-volume-c3ee2970-55fb-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.401197ms
Apr  3 10:32:24.403: INFO: Pod "downwardapi-volume-c3ee2970-55fb-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009386009s
STEP: Saw pod success
Apr  3 10:32:24.403: INFO: Pod "downwardapi-volume-c3ee2970-55fb-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:32:24.405: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-c3ee2970-55fb-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:32:24.422: INFO: Waiting for pod downwardapi-volume-c3ee2970-55fb-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:32:24.425: INFO: Pod downwardapi-volume-c3ee2970-55fb-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:32:24.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4967" for this suite.
Apr  3 10:32:30.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:32:30.505: INFO: namespace downward-api-4967 deletion completed in 6.075593008s

• [SLOW TEST:8.154 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:32:30.505: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr  3 10:32:30.781: INFO: Pod name wrapped-volume-race-c8dbe786-55fb-11e9-a6c1-a20d030b39ea: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c8dbe786-55fb-11e9-a6c1-a20d030b39ea in namespace emptydir-wrapper-508, will wait for the garbage collector to delete the pods
Apr  3 10:32:46.891: INFO: Deleting ReplicationController wrapped-volume-race-c8dbe786-55fb-11e9-a6c1-a20d030b39ea took: 5.995949ms
Apr  3 10:32:47.294: INFO: Terminating ReplicationController wrapped-volume-race-c8dbe786-55fb-11e9-a6c1-a20d030b39ea pods took: 402.608256ms
STEP: Creating RC which spawns configmap-volume pods
Apr  3 10:33:24.608: INFO: Pod name wrapped-volume-race-e9030e7f-55fb-11e9-a6c1-a20d030b39ea: Found 0 pods out of 5
Apr  3 10:33:29.615: INFO: Pod name wrapped-volume-race-e9030e7f-55fb-11e9-a6c1-a20d030b39ea: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e9030e7f-55fb-11e9-a6c1-a20d030b39ea in namespace emptydir-wrapper-508, will wait for the garbage collector to delete the pods
Apr  3 10:33:39.696: INFO: Deleting ReplicationController wrapped-volume-race-e9030e7f-55fb-11e9-a6c1-a20d030b39ea took: 4.754752ms
Apr  3 10:33:40.096: INFO: Terminating ReplicationController wrapped-volume-race-e9030e7f-55fb-11e9-a6c1-a20d030b39ea pods took: 400.322253ms
STEP: Creating RC which spawns configmap-volume pods
Apr  3 10:34:15.913: INFO: Pod name wrapped-volume-race-079740d2-55fc-11e9-a6c1-a20d030b39ea: Found 0 pods out of 5
Apr  3 10:34:20.918: INFO: Pod name wrapped-volume-race-079740d2-55fc-11e9-a6c1-a20d030b39ea: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-079740d2-55fc-11e9-a6c1-a20d030b39ea in namespace emptydir-wrapper-508, will wait for the garbage collector to delete the pods
Apr  3 10:34:31.001: INFO: Deleting ReplicationController wrapped-volume-race-079740d2-55fc-11e9-a6c1-a20d030b39ea took: 5.417507ms
Apr  3 10:34:31.401: INFO: Terminating ReplicationController wrapped-volume-race-079740d2-55fc-11e9-a6c1-a20d030b39ea pods took: 400.784664ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:35:13.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-508" for this suite.
Apr  3 10:35:19.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:35:19.955: INFO: namespace emptydir-wrapper-508 deletion completed in 6.08792148s

• [SLOW TEST:169.447 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:35:19.956: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0403 10:35:21.056200      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  3 10:35:21.056: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:35:21.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5713" for this suite.
Apr  3 10:35:27.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:35:27.265: INFO: namespace gc-5713 deletion completed in 6.20484523s

• [SLOW TEST:7.308 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:35:27.265: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:35:31.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7523" for this suite.
Apr  3 10:35:37.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:35:37.500: INFO: namespace kubelet-test-7523 deletion completed in 6.152017412s

• [SLOW TEST:10.236 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:35:37.501: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr  3 10:35:45.624: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:45.624: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:45.732: INFO: Exec stderr: ""
Apr  3 10:35:45.732: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:45.732: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:45.839: INFO: Exec stderr: ""
Apr  3 10:35:45.839: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:45.839: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:45.937: INFO: Exec stderr: ""
Apr  3 10:35:45.937: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:45.937: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:46.048: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr  3 10:35:46.049: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:46.049: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:46.154: INFO: Exec stderr: ""
Apr  3 10:35:46.154: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:46.154: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:46.265: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr  3 10:35:46.265: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:46.265: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:46.370: INFO: Exec stderr: ""
Apr  3 10:35:46.370: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:46.370: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:46.474: INFO: Exec stderr: ""
Apr  3 10:35:46.474: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:46.474: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:46.585: INFO: Exec stderr: ""
Apr  3 10:35:46.585: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2066 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  3 10:35:46.585: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
Apr  3 10:35:46.702: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:35:46.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2066" for this suite.
Apr  3 10:36:36.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:36:36.775: INFO: namespace e2e-kubelet-etc-hosts-2066 deletion completed in 50.089306814s

• [SLOW TEST:59.298 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:36:36.775: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr  3 10:36:36.841: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3172,SelfLink:/api/v1/namespaces/watch-3172/configmaps/e2e-watch-test-resource-version,UID:5b94be83-55fc-11e9-ad16-025000000001,ResourceVersion:15467,Generation:0,CreationTimestamp:2019-04-03 10:36:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  3 10:36:36.841: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-3172,SelfLink:/api/v1/namespaces/watch-3172/configmaps/e2e-watch-test-resource-version,UID:5b94be83-55fc-11e9-ad16-025000000001,ResourceVersion:15468,Generation:0,CreationTimestamp:2019-04-03 10:36:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:36:36.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3172" for this suite.
Apr  3 10:36:42.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:36:42.932: INFO: namespace watch-3172 deletion completed in 6.086376999s

• [SLOW TEST:6.157 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:36:42.932: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr  3 10:36:46.988: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-5f3fa5e3-55fc-11e9-a6c1-a20d030b39ea,GenerateName:,Namespace:events-2617,SelfLink:/api/v1/namespaces/events-2617/pods/send-events-5f3fa5e3-55fc-11e9-a6c1-a20d030b39ea,UID:5f414b23-55fc-11e9-ad16-025000000001,ResourceVersion:15496,Generation:0,CreationTimestamp:2019-04-03 10:36:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 963714079,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-275f9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-275f9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-275f9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c1f7a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c1f7c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:36:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:36:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:36:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:36:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.1.32,StartTime:2019-04-03 10:36:42 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-03 10:36:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://5c5bdae2b62183c1ccf34aed144b6cff67dcb9c8e8a0591d4512b822fa3785a7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr  3 10:36:48.992: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr  3 10:36:51.000: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:36:51.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2617" for this suite.
Apr  3 10:37:29.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:37:29.124: INFO: namespace events-2617 deletion completed in 38.099473418s

• [SLOW TEST:46.194 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:37:29.124: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  3 10:37:29.160: INFO: Waiting up to 5m0s for pod "downward-api-7ac77ca2-55fc-11e9-a6c1-a20d030b39ea" in namespace "downward-api-9461" to be "success or failure"
Apr  3 10:37:29.166: INFO: Pod "downward-api-7ac77ca2-55fc-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.702185ms
Apr  3 10:37:31.169: INFO: Pod "downward-api-7ac77ca2-55fc-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009163988s
STEP: Saw pod success
Apr  3 10:37:31.169: INFO: Pod "downward-api-7ac77ca2-55fc-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:37:31.174: INFO: Trying to get logs from node docker-desktop pod downward-api-7ac77ca2-55fc-11e9-a6c1-a20d030b39ea container dapi-container: <nil>
STEP: delete the pod
Apr  3 10:37:31.201: INFO: Waiting for pod downward-api-7ac77ca2-55fc-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:37:31.211: INFO: Pod downward-api-7ac77ca2-55fc-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:37:31.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9461" for this suite.
Apr  3 10:37:37.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:37:37.309: INFO: namespace downward-api-9461 deletion completed in 6.091627795s

• [SLOW TEST:8.186 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:37:37.320: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  3 10:37:37.355: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:37:40.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1654" for this suite.
Apr  3 10:37:46.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:37:46.445: INFO: namespace init-container-1654 deletion completed in 6.091187799s

• [SLOW TEST:9.126 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:37:46.447: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:37:46.544: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr  3 10:37:46.558: INFO: Number of nodes with available pods: 0
Apr  3 10:37:46.558: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr  3 10:37:46.572: INFO: Number of nodes with available pods: 0
Apr  3 10:37:46.573: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:47.576: INFO: Number of nodes with available pods: 0
Apr  3 10:37:47.576: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:48.576: INFO: Number of nodes with available pods: 1
Apr  3 10:37:48.576: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr  3 10:37:48.596: INFO: Number of nodes with available pods: 1
Apr  3 10:37:48.596: INFO: Number of running nodes: 0, number of available pods: 1
Apr  3 10:37:49.599: INFO: Number of nodes with available pods: 0
Apr  3 10:37:49.599: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr  3 10:37:49.608: INFO: Number of nodes with available pods: 0
Apr  3 10:37:49.608: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:50.611: INFO: Number of nodes with available pods: 0
Apr  3 10:37:50.611: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:51.611: INFO: Number of nodes with available pods: 0
Apr  3 10:37:51.611: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:52.611: INFO: Number of nodes with available pods: 0
Apr  3 10:37:52.611: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:53.610: INFO: Number of nodes with available pods: 0
Apr  3 10:37:53.610: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:54.611: INFO: Number of nodes with available pods: 0
Apr  3 10:37:54.611: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:55.612: INFO: Number of nodes with available pods: 0
Apr  3 10:37:55.612: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:56.611: INFO: Number of nodes with available pods: 0
Apr  3 10:37:56.611: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:57.612: INFO: Number of nodes with available pods: 0
Apr  3 10:37:57.612: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:58.612: INFO: Number of nodes with available pods: 0
Apr  3 10:37:58.612: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:37:59.612: INFO: Number of nodes with available pods: 0
Apr  3 10:37:59.612: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:38:00.612: INFO: Number of nodes with available pods: 0
Apr  3 10:38:00.612: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:38:01.612: INFO: Number of nodes with available pods: 0
Apr  3 10:38:01.612: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:38:02.612: INFO: Number of nodes with available pods: 0
Apr  3 10:38:02.612: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:38:03.611: INFO: Number of nodes with available pods: 0
Apr  3 10:38:03.611: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:38:04.612: INFO: Number of nodes with available pods: 0
Apr  3 10:38:04.612: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:38:05.614: INFO: Number of nodes with available pods: 0
Apr  3 10:38:05.614: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:38:06.612: INFO: Number of nodes with available pods: 1
Apr  3 10:38:06.612: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5533, will wait for the garbage collector to delete the pods
Apr  3 10:38:06.678: INFO: Deleting DaemonSet.extensions daemon-set took: 4.689126ms
Apr  3 10:38:07.080: INFO: Terminating DaemonSet.extensions daemon-set pods took: 401.953021ms
Apr  3 10:38:09.983: INFO: Number of nodes with available pods: 0
Apr  3 10:38:09.983: INFO: Number of running nodes: 0, number of available pods: 0
Apr  3 10:38:09.986: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5533/daemonsets","resourceVersion":"15720"},"items":null}

Apr  3 10:38:09.988: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5533/pods","resourceVersion":"15720"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:38:10.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5533" for this suite.
Apr  3 10:38:16.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:38:16.095: INFO: namespace daemonsets-5533 deletion completed in 6.087578125s

• [SLOW TEST:29.648 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:38:16.096: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:38:16.144: INFO: Waiting up to 5m0s for pod "downwardapi-volume-96c7b0c9-55fc-11e9-a6c1-a20d030b39ea" in namespace "downward-api-8646" to be "success or failure"
Apr  3 10:38:16.148: INFO: Pod "downwardapi-volume-96c7b0c9-55fc-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.347228ms
Apr  3 10:38:18.151: INFO: Pod "downwardapi-volume-96c7b0c9-55fc-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006854388s
STEP: Saw pod success
Apr  3 10:38:18.151: INFO: Pod "downwardapi-volume-96c7b0c9-55fc-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:38:18.154: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-96c7b0c9-55fc-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:38:18.175: INFO: Waiting for pod downwardapi-volume-96c7b0c9-55fc-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:38:18.180: INFO: Pod downwardapi-volume-96c7b0c9-55fc-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:38:18.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8646" for this suite.
Apr  3 10:38:24.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:38:24.275: INFO: namespace downward-api-8646 deletion completed in 6.090846666s

• [SLOW TEST:8.180 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:38:24.275: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:38:24.335: INFO: Conformance test suite needs a cluster with at least 2 nodes.
Apr  3 10:38:24.335: INFO: Create a RollingUpdate DaemonSet
Apr  3 10:38:24.347: INFO: Check that daemon pods launch on every node of the cluster
Apr  3 10:38:24.361: INFO: Number of nodes with available pods: 0
Apr  3 10:38:24.361: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:38:25.368: INFO: Number of nodes with available pods: 0
Apr  3 10:38:25.368: INFO: Node docker-desktop is running more than one daemon pod
Apr  3 10:38:26.369: INFO: Number of nodes with available pods: 1
Apr  3 10:38:26.369: INFO: Number of running nodes: 1, number of available pods: 1
Apr  3 10:38:26.369: INFO: Update the DaemonSet to trigger a rollout
Apr  3 10:38:26.378: INFO: Updating DaemonSet daemon-set
Apr  3 10:38:30.395: INFO: Roll back the DaemonSet before rollout is complete
Apr  3 10:38:30.405: INFO: Updating DaemonSet daemon-set
Apr  3 10:38:30.405: INFO: Make sure DaemonSet rollback is complete
Apr  3 10:38:30.412: INFO: Wrong image for pod: daemon-set-qsspk. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  3 10:38:30.412: INFO: Pod daemon-set-qsspk is not available
Apr  3 10:38:31.433: INFO: Wrong image for pod: daemon-set-qsspk. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  3 10:38:31.433: INFO: Pod daemon-set-qsspk is not available
Apr  3 10:38:32.435: INFO: Pod daemon-set-4brnq is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2229, will wait for the garbage collector to delete the pods
Apr  3 10:38:32.509: INFO: Deleting DaemonSet.extensions daemon-set took: 6.197534ms
Apr  3 10:38:32.909: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.437416ms
Apr  3 10:38:43.613: INFO: Number of nodes with available pods: 0
Apr  3 10:38:43.613: INFO: Number of running nodes: 0, number of available pods: 0
Apr  3 10:38:43.619: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2229/daemonsets","resourceVersion":"15868"},"items":null}

Apr  3 10:38:43.625: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2229/pods","resourceVersion":"15868"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:38:43.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2229" for this suite.
Apr  3 10:38:49.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:38:49.797: INFO: namespace daemonsets-2229 deletion completed in 6.143632392s

• [SLOW TEST:25.521 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:38:49.800: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr  3 10:38:49.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 create -f - --namespace=kubectl-8295'
Apr  3 10:38:50.134: INFO: stderr: ""
Apr  3 10:38:50.134: INFO: stdout: "pod/pause created\n"
Apr  3 10:38:50.134: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr  3 10:38:50.134: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8295" to be "running and ready"
Apr  3 10:38:50.154: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 19.943585ms
Apr  3 10:38:52.157: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.023091413s
Apr  3 10:38:52.157: INFO: Pod "pause" satisfied condition "running and ready"
Apr  3 10:38:52.157: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr  3 10:38:52.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 label pods pause testing-label=testing-label-value --namespace=kubectl-8295'
Apr  3 10:38:52.244: INFO: stderr: ""
Apr  3 10:38:52.244: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr  3 10:38:52.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pod pause -L testing-label --namespace=kubectl-8295'
Apr  3 10:38:52.339: INFO: stderr: ""
Apr  3 10:38:52.339: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr  3 10:38:52.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 label pods pause testing-label- --namespace=kubectl-8295'
Apr  3 10:38:52.429: INFO: stderr: ""
Apr  3 10:38:52.429: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr  3 10:38:52.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pod pause -L testing-label --namespace=kubectl-8295'
Apr  3 10:38:52.511: INFO: stderr: ""
Apr  3 10:38:52.511: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr  3 10:38:52.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete --grace-period=0 --force -f - --namespace=kubectl-8295'
Apr  3 10:38:52.600: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  3 10:38:52.600: INFO: stdout: "pod \"pause\" force deleted\n"
Apr  3 10:38:52.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get rc,svc -l name=pause --no-headers --namespace=kubectl-8295'
Apr  3 10:38:52.705: INFO: stderr: "No resources found.\n"
Apr  3 10:38:52.705: INFO: stdout: ""
Apr  3 10:38:52.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -l name=pause --namespace=kubectl-8295 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  3 10:38:52.789: INFO: stderr: ""
Apr  3 10:38:52.789: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:38:52.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8295" for this suite.
Apr  3 10:38:58.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:38:58.883: INFO: namespace kubectl-8295 deletion completed in 6.087973978s

• [SLOW TEST:9.082 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:38:58.883: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  3 10:38:58.926: INFO: Waiting up to 5m0s for pod "pod-b0487546-55fc-11e9-a6c1-a20d030b39ea" in namespace "emptydir-6218" to be "success or failure"
Apr  3 10:38:58.929: INFO: Pod "pod-b0487546-55fc-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.913803ms
Apr  3 10:39:00.933: INFO: Pod "pod-b0487546-55fc-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007038587s
STEP: Saw pod success
Apr  3 10:39:00.933: INFO: Pod "pod-b0487546-55fc-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:39:00.935: INFO: Trying to get logs from node docker-desktop pod pod-b0487546-55fc-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:39:00.957: INFO: Waiting for pod pod-b0487546-55fc-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:39:00.965: INFO: Pod pod-b0487546-55fc-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:39:00.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6218" for this suite.
Apr  3 10:39:06.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:39:07.054: INFO: namespace emptydir-6218 deletion completed in 6.081880149s

• [SLOW TEST:8.171 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:39:07.064: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr  3 10:39:07.114: INFO: Waiting up to 5m0s for pod "var-expansion-b528fcc5-55fc-11e9-a6c1-a20d030b39ea" in namespace "var-expansion-4805" to be "success or failure"
Apr  3 10:39:07.122: INFO: Pod "var-expansion-b528fcc5-55fc-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.908641ms
Apr  3 10:39:09.126: INFO: Pod "var-expansion-b528fcc5-55fc-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011999529s
STEP: Saw pod success
Apr  3 10:39:09.126: INFO: Pod "var-expansion-b528fcc5-55fc-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:39:09.128: INFO: Trying to get logs from node docker-desktop pod var-expansion-b528fcc5-55fc-11e9-a6c1-a20d030b39ea container dapi-container: <nil>
STEP: delete the pod
Apr  3 10:39:09.145: INFO: Waiting for pod var-expansion-b528fcc5-55fc-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:39:09.148: INFO: Pod var-expansion-b528fcc5-55fc-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:39:09.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4805" for this suite.
Apr  3 10:39:15.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:39:15.240: INFO: namespace var-expansion-4805 deletion completed in 6.087173147s

• [SLOW TEST:8.176 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:39:15.240: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  3 10:39:15.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-3742'
Apr  3 10:39:15.360: INFO: stderr: ""
Apr  3 10:39:15.360: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr  3 10:39:20.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pod e2e-test-nginx-pod --namespace=kubectl-3742 -o json'
Apr  3 10:39:20.506: INFO: stderr: ""
Apr  3 10:39:20.507: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-04-03T10:39:15Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-3742\",\n        \"resourceVersion\": \"16027\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3742/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ba11d037-55fc-11e9-ad16-025000000001\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-66mwn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"docker-desktop\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-66mwn\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-66mwn\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-03T10:39:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-03T10:39:17Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-03T10:39:17Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-03T10:39:15Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://efc3928a92b40b5ad6a9784585d75f70be1958fd6d0443d2ba473185c577c85b\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-03T10:39:16Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.65.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.1.45\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-03T10:39:15Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr  3 10:39:20.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 replace -f - --namespace=kubectl-3742'
Apr  3 10:39:20.651: INFO: stderr: ""
Apr  3 10:39:20.651: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr  3 10:39:20.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete pods e2e-test-nginx-pod --namespace=kubectl-3742'
Apr  3 10:39:33.529: INFO: stderr: ""
Apr  3 10:39:33.529: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:39:33.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3742" for this suite.
Apr  3 10:39:39.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:39:39.642: INFO: namespace kubectl-3742 deletion completed in 6.10861504s

• [SLOW TEST:24.401 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:39:39.643: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr  3 10:39:39.689: INFO: Waiting up to 5m0s for pod "var-expansion-c893f391-55fc-11e9-a6c1-a20d030b39ea" in namespace "var-expansion-7232" to be "success or failure"
Apr  3 10:39:39.697: INFO: Pod "var-expansion-c893f391-55fc-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.967835ms
Apr  3 10:39:41.700: INFO: Pod "var-expansion-c893f391-55fc-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010993457s
STEP: Saw pod success
Apr  3 10:39:41.700: INFO: Pod "var-expansion-c893f391-55fc-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:39:41.702: INFO: Trying to get logs from node docker-desktop pod var-expansion-c893f391-55fc-11e9-a6c1-a20d030b39ea container dapi-container: <nil>
STEP: delete the pod
Apr  3 10:39:41.723: INFO: Waiting for pod var-expansion-c893f391-55fc-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:39:41.727: INFO: Pod var-expansion-c893f391-55fc-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:39:41.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7232" for this suite.
Apr  3 10:39:47.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:39:47.821: INFO: namespace var-expansion-7232 deletion completed in 6.089640418s

• [SLOW TEST:8.178 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:39:47.821: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  3 10:39:47.862: INFO: Waiting up to 5m0s for pod "downward-api-cd735d84-55fc-11e9-a6c1-a20d030b39ea" in namespace "downward-api-6052" to be "success or failure"
Apr  3 10:39:47.872: INFO: Pod "downward-api-cd735d84-55fc-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 9.613997ms
Apr  3 10:39:49.875: INFO: Pod "downward-api-cd735d84-55fc-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012236948s
STEP: Saw pod success
Apr  3 10:39:49.875: INFO: Pod "downward-api-cd735d84-55fc-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:39:49.877: INFO: Trying to get logs from node docker-desktop pod downward-api-cd735d84-55fc-11e9-a6c1-a20d030b39ea container dapi-container: <nil>
STEP: delete the pod
Apr  3 10:39:49.900: INFO: Waiting for pod downward-api-cd735d84-55fc-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:39:49.908: INFO: Pod downward-api-cd735d84-55fc-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:39:49.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6052" for this suite.
Apr  3 10:39:55.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:39:55.995: INFO: namespace downward-api-6052 deletion completed in 6.078589474s

• [SLOW TEST:8.173 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:39:55.995: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:39:56.052: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d25521af-55fc-11e9-ad16-025000000001", Controller:(*bool)(0xc002b51446), BlockOwnerDeletion:(*bool)(0xc002b51447)}}
Apr  3 10:39:56.066: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d2533292-55fc-11e9-ad16-025000000001", Controller:(*bool)(0xc0028241a6), BlockOwnerDeletion:(*bool)(0xc0028241a7)}}
Apr  3 10:39:56.074: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d253d04b-55fc-11e9-ad16-025000000001", Controller:(*bool)(0xc002b51656), BlockOwnerDeletion:(*bool)(0xc002b51657)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:40:01.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6203" for this suite.
Apr  3 10:40:07.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:40:07.173: INFO: namespace gc-6203 deletion completed in 6.085414645s

• [SLOW TEST:11.178 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:40:07.174: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  3 10:40:09.736: INFO: Successfully updated pod "labelsupdated8fc1d14-55fc-11e9-a6c1-a20d030b39ea"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:40:11.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-809" for this suite.
Apr  3 10:40:33.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:40:33.832: INFO: namespace projected-809 deletion completed in 22.070820091s

• [SLOW TEST:26.657 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:40:33.832: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr  3 10:40:33.886: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3919,SelfLink:/api/v1/namespaces/watch-3919/configmaps/e2e-watch-test-label-changed,UID:e8e09042-55fc-11e9-ad16-025000000001,ResourceVersion:16265,Generation:0,CreationTimestamp:2019-04-03 10:40:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  3 10:40:33.886: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3919,SelfLink:/api/v1/namespaces/watch-3919/configmaps/e2e-watch-test-label-changed,UID:e8e09042-55fc-11e9-ad16-025000000001,ResourceVersion:16266,Generation:0,CreationTimestamp:2019-04-03 10:40:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  3 10:40:33.886: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3919,SelfLink:/api/v1/namespaces/watch-3919/configmaps/e2e-watch-test-label-changed,UID:e8e09042-55fc-11e9-ad16-025000000001,ResourceVersion:16267,Generation:0,CreationTimestamp:2019-04-03 10:40:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr  3 10:40:43.920: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3919,SelfLink:/api/v1/namespaces/watch-3919/configmaps/e2e-watch-test-label-changed,UID:e8e09042-55fc-11e9-ad16-025000000001,ResourceVersion:16281,Generation:0,CreationTimestamp:2019-04-03 10:40:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  3 10:40:43.920: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3919,SelfLink:/api/v1/namespaces/watch-3919/configmaps/e2e-watch-test-label-changed,UID:e8e09042-55fc-11e9-ad16-025000000001,ResourceVersion:16282,Generation:0,CreationTimestamp:2019-04-03 10:40:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr  3 10:40:43.920: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-3919,SelfLink:/api/v1/namespaces/watch-3919/configmaps/e2e-watch-test-label-changed,UID:e8e09042-55fc-11e9-ad16-025000000001,ResourceVersion:16283,Generation:0,CreationTimestamp:2019-04-03 10:40:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:40:43.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3919" for this suite.
Apr  3 10:40:49.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:40:50.006: INFO: namespace watch-3919 deletion completed in 6.082404072s

• [SLOW TEST:16.173 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:40:50.006: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:40:50.041: INFO: Creating deployment "test-recreate-deployment"
Apr  3 10:40:50.047: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr  3 10:40:50.062: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr  3 10:40:52.068: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr  3 10:40:52.072: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr  3 10:40:52.079: INFO: Updating deployment test-recreate-deployment
Apr  3 10:40:52.079: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  3 10:40:52.165: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1308,SelfLink:/apis/apps/v1/namespaces/deployment-1308/deployments/test-recreate-deployment,UID:f284ce48-55fc-11e9-ad16-025000000001,ResourceVersion:16342,Generation:2,CreationTimestamp:2019-04-03 10:40:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-03 10:40:52 +0000 UTC 2019-04-03 10:40:52 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-03 10:40:52 +0000 UTC 2019-04-03 10:40:50 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr  3 10:40:52.172: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-1308,SelfLink:/apis/apps/v1/namespaces/deployment-1308/replicasets/test-recreate-deployment-c9cbd8684,UID:f3c236b6-55fc-11e9-ad16-025000000001,ResourceVersion:16340,Generation:1,CreationTimestamp:2019-04-03 10:40:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f284ce48-55fc-11e9-ad16-025000000001 0xc002c390c0 0xc002c390c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  3 10:40:52.172: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr  3 10:40:52.172: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-1308,SelfLink:/apis/apps/v1/namespaces/deployment-1308/replicasets/test-recreate-deployment-7d57d5ff7c,UID:f285b4ac-55fc-11e9-ad16-025000000001,ResourceVersion:16332,Generation:2,CreationTimestamp:2019-04-03 10:40:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f284ce48-55fc-11e9-ad16-025000000001 0xc002c38ff7 0xc002c38ff8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  3 10:40:52.179: INFO: Pod "test-recreate-deployment-c9cbd8684-hnrts" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-hnrts,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-1308,SelfLink:/api/v1/namespaces/deployment-1308/pods/test-recreate-deployment-c9cbd8684-hnrts,UID:f3c2f3eb-55fc-11e9-ad16-025000000001,ResourceVersion:16344,Generation:0,CreationTimestamp:2019-04-03 10:40:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 f3c236b6-55fc-11e9-ad16-025000000001 0xc0029d6150 0xc0029d6151}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hp4v4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hp4v4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hp4v4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029d61c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029d61e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:40:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:40:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:40:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:40:52 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-04-03 10:40:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:40:52.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1308" for this suite.
Apr  3 10:40:58.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:40:58.271: INFO: namespace deployment-1308 deletion completed in 6.086843143s

• [SLOW TEST:8.265 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:40:58.271: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  3 10:40:58.304: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:41:02.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1" for this suite.
Apr  3 10:41:08.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:41:08.337: INFO: namespace init-container-1 deletion completed in 6.104193188s

• [SLOW TEST:10.066 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:41:08.340: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:41:08.398: INFO: (0) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 9.913145ms)
Apr  3 10:41:08.405: INFO: (1) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.241694ms)
Apr  3 10:41:08.410: INFO: (2) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.645571ms)
Apr  3 10:41:08.418: INFO: (3) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 7.890955ms)
Apr  3 10:41:08.425: INFO: (4) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.40287ms)
Apr  3 10:41:08.431: INFO: (5) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.024484ms)
Apr  3 10:41:08.441: INFO: (6) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 10.273667ms)
Apr  3 10:41:08.450: INFO: (7) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 8.030389ms)
Apr  3 10:41:08.458: INFO: (8) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 7.993982ms)
Apr  3 10:41:08.465: INFO: (9) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 7.009054ms)
Apr  3 10:41:08.471: INFO: (10) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.563265ms)
Apr  3 10:41:08.483: INFO: (11) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 12.545044ms)
Apr  3 10:41:08.493: INFO: (12) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 9.274058ms)
Apr  3 10:41:08.502: INFO: (13) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 9.312931ms)
Apr  3 10:41:08.509: INFO: (14) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.493212ms)
Apr  3 10:41:08.515: INFO: (15) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.249298ms)
Apr  3 10:41:08.521: INFO: (16) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.286455ms)
Apr  3 10:41:08.527: INFO: (17) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.21229ms)
Apr  3 10:41:08.530: INFO: (18) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 3.753262ms)
Apr  3 10:41:08.535: INFO: (19) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 4.310929ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:41:08.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4073" for this suite.
Apr  3 10:41:14.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:41:14.621: INFO: namespace proxy-4073 deletion completed in 6.082186422s

• [SLOW TEST:6.280 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:41:14.621: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr  3 10:41:14.668: INFO: Waiting up to 5m0s for pod "client-containers-01302c5c-55fd-11e9-a6c1-a20d030b39ea" in namespace "containers-713" to be "success or failure"
Apr  3 10:41:14.676: INFO: Pod "client-containers-01302c5c-55fd-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.900465ms
Apr  3 10:41:16.679: INFO: Pod "client-containers-01302c5c-55fd-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010988035s
STEP: Saw pod success
Apr  3 10:41:16.679: INFO: Pod "client-containers-01302c5c-55fd-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:41:16.682: INFO: Trying to get logs from node docker-desktop pod client-containers-01302c5c-55fd-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:41:16.704: INFO: Waiting for pod client-containers-01302c5c-55fd-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:41:16.708: INFO: Pod client-containers-01302c5c-55fd-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:41:16.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-713" for this suite.
Apr  3 10:41:22.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:41:22.802: INFO: namespace containers-713 deletion completed in 6.089679676s

• [SLOW TEST:8.181 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:41:22.802: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-ldgl
STEP: Creating a pod to test atomic-volume-subpath
Apr  3 10:41:22.861: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ldgl" in namespace "subpath-6033" to be "success or failure"
Apr  3 10:41:22.864: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Pending", Reason="", readiness=false. Elapsed: 3.229463ms
Apr  3 10:41:24.868: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 2.007443702s
Apr  3 10:41:26.872: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 4.010572854s
Apr  3 10:41:28.876: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 6.013926889s
Apr  3 10:41:30.880: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 8.017809174s
Apr  3 10:41:32.883: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 10.021507177s
Apr  3 10:41:34.887: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 12.025174046s
Apr  3 10:41:36.891: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 14.029505172s
Apr  3 10:41:38.895: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 16.03352985s
Apr  3 10:41:40.899: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 18.037528148s
Apr  3 10:41:42.902: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 20.040540076s
Apr  3 10:41:44.907: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Running", Reason="", readiness=true. Elapsed: 22.044759054s
Apr  3 10:41:46.911: INFO: Pod "pod-subpath-test-configmap-ldgl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.049047617s
STEP: Saw pod success
Apr  3 10:41:46.911: INFO: Pod "pod-subpath-test-configmap-ldgl" satisfied condition "success or failure"
Apr  3 10:41:46.914: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-configmap-ldgl container test-container-subpath-configmap-ldgl: <nil>
STEP: delete the pod
Apr  3 10:41:46.932: INFO: Waiting for pod pod-subpath-test-configmap-ldgl to disappear
Apr  3 10:41:46.938: INFO: Pod pod-subpath-test-configmap-ldgl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ldgl
Apr  3 10:41:46.939: INFO: Deleting pod "pod-subpath-test-configmap-ldgl" in namespace "subpath-6033"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:41:46.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6033" for this suite.
Apr  3 10:41:52.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:41:53.081: INFO: namespace subpath-6033 deletion completed in 6.128003478s

• [SLOW TEST:30.278 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:41:53.086: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-181e4c10-55fd-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 10:41:53.143: INFO: Waiting up to 5m0s for pod "pod-configmaps-1820121d-55fd-11e9-a6c1-a20d030b39ea" in namespace "configmap-3722" to be "success or failure"
Apr  3 10:41:53.147: INFO: Pod "pod-configmaps-1820121d-55fd-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.506327ms
Apr  3 10:41:55.149: INFO: Pod "pod-configmaps-1820121d-55fd-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006142803s
STEP: Saw pod success
Apr  3 10:41:55.150: INFO: Pod "pod-configmaps-1820121d-55fd-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:41:55.152: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-1820121d-55fd-11e9-a6c1-a20d030b39ea container configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 10:41:55.170: INFO: Waiting for pod pod-configmaps-1820121d-55fd-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:41:55.172: INFO: Pod pod-configmaps-1820121d-55fd-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:41:55.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3722" for this suite.
Apr  3 10:42:01.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:42:01.265: INFO: namespace configmap-3722 deletion completed in 6.087088355s

• [SLOW TEST:8.179 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:42:01.265: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  3 10:42:01.310: INFO: Waiting up to 5m0s for pod "pod-1cfd447e-55fd-11e9-a6c1-a20d030b39ea" in namespace "emptydir-5700" to be "success or failure"
Apr  3 10:42:01.316: INFO: Pod "pod-1cfd447e-55fd-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.323615ms
Apr  3 10:42:03.319: INFO: Pod "pod-1cfd447e-55fd-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009132601s
STEP: Saw pod success
Apr  3 10:42:03.319: INFO: Pod "pod-1cfd447e-55fd-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:42:03.323: INFO: Trying to get logs from node docker-desktop pod pod-1cfd447e-55fd-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:42:03.342: INFO: Waiting for pod pod-1cfd447e-55fd-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:42:03.344: INFO: Pod pod-1cfd447e-55fd-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:42:03.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5700" for this suite.
Apr  3 10:42:09.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:42:09.432: INFO: namespace emptydir-5700 deletion completed in 6.085017177s

• [SLOW TEST:8.167 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:42:09.433: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-21dba56f-55fd-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:42:09.506: INFO: Waiting up to 5m0s for pod "pod-secrets-21e09b8e-55fd-11e9-a6c1-a20d030b39ea" in namespace "secrets-6467" to be "success or failure"
Apr  3 10:42:09.512: INFO: Pod "pod-secrets-21e09b8e-55fd-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.999715ms
Apr  3 10:42:11.515: INFO: Pod "pod-secrets-21e09b8e-55fd-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009009116s
STEP: Saw pod success
Apr  3 10:42:11.515: INFO: Pod "pod-secrets-21e09b8e-55fd-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:42:11.521: INFO: Trying to get logs from node docker-desktop pod pod-secrets-21e09b8e-55fd-11e9-a6c1-a20d030b39ea container secret-volume-test: <nil>
STEP: delete the pod
Apr  3 10:42:11.547: INFO: Waiting for pod pod-secrets-21e09b8e-55fd-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:42:11.554: INFO: Pod pod-secrets-21e09b8e-55fd-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:42:11.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6467" for this suite.
Apr  3 10:42:17.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:42:17.654: INFO: namespace secrets-6467 deletion completed in 6.091838207s
STEP: Destroying namespace "secret-namespace-6558" for this suite.
Apr  3 10:42:23.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:42:23.753: INFO: namespace secret-namespace-6558 deletion completed in 6.098985032s

• [SLOW TEST:14.320 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:42:23.753: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-6844
Apr  3 10:42:25.820: INFO: Started pod liveness-exec in namespace container-probe-6844
STEP: checking the pod's current state and verifying that restartCount is present
Apr  3 10:42:25.825: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:46:26.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6844" for this suite.
Apr  3 10:46:32.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:46:32.402: INFO: namespace container-probe-6844 deletion completed in 6.11890983s

• [SLOW TEST:248.641 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:46:32.403: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  3 10:46:32.455: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be9ab493-55fd-11e9-a6c1-a20d030b39ea" in namespace "projected-996" to be "success or failure"
Apr  3 10:46:32.470: INFO: Pod "downwardapi-volume-be9ab493-55fd-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 15.023118ms
Apr  3 10:46:34.474: INFO: Pod "downwardapi-volume-be9ab493-55fd-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018571564s
STEP: Saw pod success
Apr  3 10:46:34.474: INFO: Pod "downwardapi-volume-be9ab493-55fd-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:46:34.477: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-be9ab493-55fd-11e9-a6c1-a20d030b39ea container client-container: <nil>
STEP: delete the pod
Apr  3 10:46:34.501: INFO: Waiting for pod downwardapi-volume-be9ab493-55fd-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:46:34.504: INFO: Pod downwardapi-volume-be9ab493-55fd-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:46:34.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-996" for this suite.
Apr  3 10:46:40.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:46:40.617: INFO: namespace projected-996 deletion completed in 6.105653923s

• [SLOW TEST:8.213 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:46:40.617: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-jmxj
STEP: Creating a pod to test atomic-volume-subpath
Apr  3 10:46:40.675: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-jmxj" in namespace "subpath-934" to be "success or failure"
Apr  3 10:46:40.684: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.983687ms
Apr  3 10:46:42.687: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 2.012651583s
Apr  3 10:46:44.691: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 4.016262287s
Apr  3 10:46:46.695: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 6.020180816s
Apr  3 10:46:48.699: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 8.023923585s
Apr  3 10:46:50.703: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 10.027786938s
Apr  3 10:46:52.707: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 12.032656133s
Apr  3 10:46:54.710: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 14.035268175s
Apr  3 10:46:56.714: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 16.03870049s
Apr  3 10:46:58.718: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 18.04199697s
Apr  3 10:47:00.722: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 20.046247618s
Apr  3 10:47:02.725: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Running", Reason="", readiness=true. Elapsed: 22.049125971s
Apr  3 10:47:04.729: INFO: Pod "pod-subpath-test-downwardapi-jmxj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.053191997s
STEP: Saw pod success
Apr  3 10:47:04.729: INFO: Pod "pod-subpath-test-downwardapi-jmxj" satisfied condition "success or failure"
Apr  3 10:47:04.733: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-downwardapi-jmxj container test-container-subpath-downwardapi-jmxj: <nil>
STEP: delete the pod
Apr  3 10:47:04.756: INFO: Waiting for pod pod-subpath-test-downwardapi-jmxj to disappear
Apr  3 10:47:04.759: INFO: Pod pod-subpath-test-downwardapi-jmxj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-jmxj
Apr  3 10:47:04.759: INFO: Deleting pod "pod-subpath-test-downwardapi-jmxj" in namespace "subpath-934"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:47:04.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-934" for this suite.
Apr  3 10:47:10.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:47:10.865: INFO: namespace subpath-934 deletion completed in 6.096461307s

• [SLOW TEST:30.248 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:47:10.865: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:47:13.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-750" for this suite.
Apr  3 10:47:35.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:47:36.018: INFO: namespace replication-controller-750 deletion completed in 22.087490656s

• [SLOW TEST:25.151 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:47:36.018: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  3 10:47:36.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4768'
Apr  3 10:47:36.149: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  3 10:47:36.149: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Apr  3 10:47:36.164: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr  3 10:47:36.177: INFO: scanned /root for discovery docs: <nil>
Apr  3 10:47:36.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4768'
Apr  3 10:47:51.990: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  3 10:47:51.990: INFO: stdout: "Created e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065\nScaling up e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr  3 10:47:51.990: INFO: stdout: "Created e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065\nScaling up e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr  3 10:47:51.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4768'
Apr  3 10:47:52.071: INFO: stderr: ""
Apr  3 10:47:52.071: INFO: stdout: "e2e-test-nginx-rc-f5qrt e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065-z2bxn "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Apr  3 10:47:57.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4768'
Apr  3 10:47:57.153: INFO: stderr: ""
Apr  3 10:47:57.153: INFO: stdout: "e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065-z2bxn "
Apr  3 10:47:57.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065-z2bxn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4768'
Apr  3 10:47:57.232: INFO: stderr: ""
Apr  3 10:47:57.232: INFO: stdout: "true"
Apr  3 10:47:57.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 get pods e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065-z2bxn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4768'
Apr  3 10:47:57.307: INFO: stderr: ""
Apr  3 10:47:57.307: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr  3 10:47:57.307: INFO: e2e-test-nginx-rc-fa302874c150dfb042972277e33d1065-z2bxn is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr  3 10:47:57.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete rc e2e-test-nginx-rc --namespace=kubectl-4768'
Apr  3 10:47:57.389: INFO: stderr: ""
Apr  3 10:47:57.389: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:47:57.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4768" for this suite.
Apr  3 10:48:03.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:48:03.487: INFO: namespace kubectl-4768 deletion completed in 6.090021871s

• [SLOW TEST:27.469 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:48:03.487: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-f4e51d16-55fd-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume configMaps
Apr  3 10:48:03.543: INFO: Waiting up to 5m0s for pod "pod-configmaps-f4e69362-55fd-11e9-a6c1-a20d030b39ea" in namespace "configmap-2369" to be "success or failure"
Apr  3 10:48:03.548: INFO: Pod "pod-configmaps-f4e69362-55fd-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.519174ms
Apr  3 10:48:05.551: INFO: Pod "pod-configmaps-f4e69362-55fd-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008077152s
Apr  3 10:48:07.554: INFO: Pod "pod-configmaps-f4e69362-55fd-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011322377s
STEP: Saw pod success
Apr  3 10:48:07.554: INFO: Pod "pod-configmaps-f4e69362-55fd-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:48:07.558: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-f4e69362-55fd-11e9-a6c1-a20d030b39ea container configmap-volume-test: <nil>
STEP: delete the pod
Apr  3 10:48:07.574: INFO: Waiting for pod pod-configmaps-f4e69362-55fd-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:48:07.577: INFO: Pod pod-configmaps-f4e69362-55fd-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:48:07.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2369" for this suite.
Apr  3 10:48:13.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:48:13.677: INFO: namespace configmap-2369 deletion completed in 6.095657273s

• [SLOW TEST:10.189 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:48:13.679: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  3 10:48:13.725: INFO: Waiting up to 5m0s for pod "downward-api-faf82ab5-55fd-11e9-a6c1-a20d030b39ea" in namespace "downward-api-5686" to be "success or failure"
Apr  3 10:48:13.733: INFO: Pod "downward-api-faf82ab5-55fd-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.693918ms
Apr  3 10:48:15.736: INFO: Pod "downward-api-faf82ab5-55fd-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011271014s
Apr  3 10:48:17.740: INFO: Pod "downward-api-faf82ab5-55fd-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014463127s
STEP: Saw pod success
Apr  3 10:48:17.740: INFO: Pod "downward-api-faf82ab5-55fd-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:48:17.742: INFO: Trying to get logs from node docker-desktop pod downward-api-faf82ab5-55fd-11e9-a6c1-a20d030b39ea container dapi-container: <nil>
STEP: delete the pod
Apr  3 10:48:17.759: INFO: Waiting for pod downward-api-faf82ab5-55fd-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:48:17.765: INFO: Pod downward-api-faf82ab5-55fd-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:48:17.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5686" for this suite.
Apr  3 10:48:23.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:48:23.869: INFO: namespace downward-api-5686 deletion completed in 6.097274019s

• [SLOW TEST:10.190 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:48:23.869: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-010b5a69-55fe-11e9-a6c1-a20d030b39ea
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-010b5a69-55fe-11e9-a6c1-a20d030b39ea
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:48:27.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-450" for this suite.
Apr  3 10:48:49.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:48:50.033: INFO: namespace projected-450 deletion completed in 22.068231215s

• [SLOW TEST:26.164 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:48:50.033: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:48:50.063: INFO: Creating ReplicaSet my-hostname-basic-10a2573d-55fe-11e9-a6c1-a20d030b39ea
Apr  3 10:48:50.071: INFO: Pod name my-hostname-basic-10a2573d-55fe-11e9-a6c1-a20d030b39ea: Found 0 pods out of 1
Apr  3 10:48:55.074: INFO: Pod name my-hostname-basic-10a2573d-55fe-11e9-a6c1-a20d030b39ea: Found 1 pods out of 1
Apr  3 10:48:55.074: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-10a2573d-55fe-11e9-a6c1-a20d030b39ea" is running
Apr  3 10:48:55.080: INFO: Pod "my-hostname-basic-10a2573d-55fe-11e9-a6c1-a20d030b39ea-f6j6q" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-03 10:48:50 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-03 10:48:51 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-03 10:48:51 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-03 10:48:50 +0000 UTC Reason: Message:}])
Apr  3 10:48:55.080: INFO: Trying to dial the pod
Apr  3 10:49:00.093: INFO: Controller my-hostname-basic-10a2573d-55fe-11e9-a6c1-a20d030b39ea: Got expected result from replica 1 [my-hostname-basic-10a2573d-55fe-11e9-a6c1-a20d030b39ea-f6j6q]: "my-hostname-basic-10a2573d-55fe-11e9-a6c1-a20d030b39ea-f6j6q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:49:00.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7196" for this suite.
Apr  3 10:49:06.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:49:06.180: INFO: namespace replicaset-7196 deletion completed in 6.081337156s

• [SLOW TEST:16.146 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:49:06.180: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-dkk4
STEP: Creating a pod to test atomic-volume-subpath
Apr  3 10:49:06.232: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-dkk4" in namespace "subpath-3940" to be "success or failure"
Apr  3 10:49:06.240: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.359871ms
Apr  3 10:49:08.244: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 2.011977681s
Apr  3 10:49:10.248: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 4.015959379s
Apr  3 10:49:12.253: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 6.021552349s
Apr  3 10:49:14.256: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 8.024375403s
Apr  3 10:49:16.260: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 10.028555952s
Apr  3 10:49:18.264: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 12.032025692s
Apr  3 10:49:20.267: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 14.035537347s
Apr  3 10:49:22.271: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 16.038863893s
Apr  3 10:49:24.274: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 18.042080129s
Apr  3 10:49:26.278: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 20.045153194s
Apr  3 10:49:28.282: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Running", Reason="", readiness=true. Elapsed: 22.049906841s
Apr  3 10:49:30.286: INFO: Pod "pod-subpath-test-secret-dkk4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.053558587s
STEP: Saw pod success
Apr  3 10:49:30.286: INFO: Pod "pod-subpath-test-secret-dkk4" satisfied condition "success or failure"
Apr  3 10:49:30.291: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-secret-dkk4 container test-container-subpath-secret-dkk4: <nil>
STEP: delete the pod
Apr  3 10:49:30.309: INFO: Waiting for pod pod-subpath-test-secret-dkk4 to disappear
Apr  3 10:49:30.313: INFO: Pod pod-subpath-test-secret-dkk4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-dkk4
Apr  3 10:49:30.313: INFO: Deleting pod "pod-subpath-test-secret-dkk4" in namespace "subpath-3940"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:49:30.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3940" for this suite.
Apr  3 10:49:36.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:49:36.417: INFO: namespace subpath-3940 deletion completed in 6.096571277s

• [SLOW TEST:30.236 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:49:36.417: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  3 10:49:38.976: INFO: Successfully updated pod "pod-update-2c47b523-55fe-11e9-a6c1-a20d030b39ea"
STEP: verifying the updated pod is in kubernetes
Apr  3 10:49:38.986: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:49:38.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5103" for this suite.
Apr  3 10:50:01.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:50:01.077: INFO: namespace pods-5103 deletion completed in 22.085124197s

• [SLOW TEST:24.659 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:50:01.077: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  3 10:50:01.117: INFO: Waiting up to 5m0s for pod "pod-3afb286f-55fe-11e9-a6c1-a20d030b39ea" in namespace "emptydir-6937" to be "success or failure"
Apr  3 10:50:01.125: INFO: Pod "pod-3afb286f-55fe-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 7.647426ms
Apr  3 10:50:03.128: INFO: Pod "pod-3afb286f-55fe-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010973791s
STEP: Saw pod success
Apr  3 10:50:03.128: INFO: Pod "pod-3afb286f-55fe-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:50:03.132: INFO: Trying to get logs from node docker-desktop pod pod-3afb286f-55fe-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:50:03.152: INFO: Waiting for pod pod-3afb286f-55fe-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:50:03.158: INFO: Pod pod-3afb286f-55fe-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:50:03.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6937" for this suite.
Apr  3 10:50:09.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:50:09.265: INFO: namespace emptydir-6937 deletion completed in 6.10479305s

• [SLOW TEST:8.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:50:09.265: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  3 10:50:09.299: INFO: Waiting up to 5m0s for pod "pod-3fdb8113-55fe-11e9-a6c1-a20d030b39ea" in namespace "emptydir-4652" to be "success or failure"
Apr  3 10:50:09.303: INFO: Pod "pod-3fdb8113-55fe-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.667626ms
Apr  3 10:50:11.307: INFO: Pod "pod-3fdb8113-55fe-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0080237s
STEP: Saw pod success
Apr  3 10:50:11.307: INFO: Pod "pod-3fdb8113-55fe-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:50:11.310: INFO: Trying to get logs from node docker-desktop pod pod-3fdb8113-55fe-11e9-a6c1-a20d030b39ea container test-container: <nil>
STEP: delete the pod
Apr  3 10:50:11.327: INFO: Waiting for pod pod-3fdb8113-55fe-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:50:11.332: INFO: Pod pod-3fdb8113-55fe-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:50:11.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4652" for this suite.
Apr  3 10:50:17.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:50:17.420: INFO: namespace emptydir-4652 deletion completed in 6.083462454s

• [SLOW TEST:8.154 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:50:17.420: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  3 10:50:17.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3792'
Apr  3 10:50:17.630: INFO: stderr: ""
Apr  3 10:50:17.630: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr  3 10:50:17.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 delete pods e2e-test-nginx-pod --namespace=kubectl-3792'
Apr  3 10:50:23.553: INFO: stderr: ""
Apr  3 10:50:23.553: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:50:23.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3792" for this suite.
Apr  3 10:50:29.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:50:29.652: INFO: namespace kubectl-3792 deletion completed in 6.086365516s

• [SLOW TEST:12.232 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:50:29.653: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-sn7f
STEP: Creating a pod to test atomic-volume-subpath
Apr  3 10:50:29.699: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sn7f" in namespace "subpath-3550" to be "success or failure"
Apr  3 10:50:29.712: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.853478ms
Apr  3 10:50:31.716: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 2.017492145s
Apr  3 10:50:33.720: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 4.02125984s
Apr  3 10:50:35.724: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 6.02469675s
Apr  3 10:50:37.727: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 8.028007813s
Apr  3 10:50:39.730: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 10.031432785s
Apr  3 10:50:41.734: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 12.034741245s
Apr  3 10:50:43.737: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 14.038125591s
Apr  3 10:50:45.741: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 16.041978842s
Apr  3 10:50:47.743: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 18.04435912s
Apr  3 10:50:49.748: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Running", Reason="", readiness=true. Elapsed: 20.048934892s
Apr  3 10:50:51.751: INFO: Pod "pod-subpath-test-configmap-sn7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.052140358s
STEP: Saw pod success
Apr  3 10:50:51.751: INFO: Pod "pod-subpath-test-configmap-sn7f" satisfied condition "success or failure"
Apr  3 10:50:51.753: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-configmap-sn7f container test-container-subpath-configmap-sn7f: <nil>
STEP: delete the pod
Apr  3 10:50:51.771: INFO: Waiting for pod pod-subpath-test-configmap-sn7f to disappear
Apr  3 10:50:51.774: INFO: Pod pod-subpath-test-configmap-sn7f no longer exists
STEP: Deleting pod pod-subpath-test-configmap-sn7f
Apr  3 10:50:51.774: INFO: Deleting pod "pod-subpath-test-configmap-sn7f" in namespace "subpath-3550"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:50:51.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3550" for this suite.
Apr  3 10:50:57.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:50:57.888: INFO: namespace subpath-3550 deletion completed in 6.10719549s

• [SLOW TEST:28.235 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:50:57.896: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0403 10:51:27.984643      17 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  3 10:51:27.984: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:51:27.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7782" for this suite.
Apr  3 10:51:34.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:51:34.070: INFO: namespace gc-7782 deletion completed in 6.079426971s

• [SLOW TEST:36.173 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:51:34.070: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[]
Apr  3 10:51:34.114: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[] (5.48579ms elapsed)
STEP: Creating pod pod1 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[pod1:[80]]
Apr  3 10:51:37.149: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[pod1:[80]] (3.025053102s elapsed)
STEP: Creating pod pod2 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[pod1:[80] pod2:[80]]
Apr  3 10:51:39.184: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[pod1:[80] pod2:[80]] (2.030019367s elapsed)
STEP: Deleting pod pod1 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[pod2:[80]]
Apr  3 10:51:39.204: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[pod2:[80]] (11.448037ms elapsed)
STEP: Deleting pod pod2 in namespace services-404
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-404 to expose endpoints map[]
Apr  3 10:51:40.223: INFO: successfully validated that service endpoint-test2 in namespace services-404 exposes endpoints map[] (1.009924738s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:51:40.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-404" for this suite.
Apr  3 10:52:02.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:52:02.335: INFO: namespace services-404 deletion completed in 22.088589791s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:28.265 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:52:02.339: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr  3 10:52:02.380: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4754" to be "success or failure"
Apr  3 10:52:02.384: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.163955ms
Apr  3 10:52:04.390: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009917586s
STEP: Saw pod success
Apr  3 10:52:04.390: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr  3 10:52:04.394: INFO: Trying to get logs from node docker-desktop pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr  3 10:52:04.413: INFO: Waiting for pod pod-host-path-test to disappear
Apr  3 10:52:04.419: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:52:04.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4754" for this suite.
Apr  3 10:52:10.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:52:10.531: INFO: namespace hostpath-4754 deletion completed in 6.104830966s

• [SLOW TEST:8.192 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:52:10.531: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-8825ebff-55fe-11e9-a6c1-a20d030b39ea
STEP: Creating a pod to test consume secrets
Apr  3 10:52:10.593: INFO: Waiting up to 5m0s for pod "pod-secrets-88271ad4-55fe-11e9-a6c1-a20d030b39ea" in namespace "secrets-1267" to be "success or failure"
Apr  3 10:52:10.600: INFO: Pod "pod-secrets-88271ad4-55fe-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.99386ms
Apr  3 10:52:12.603: INFO: Pod "pod-secrets-88271ad4-55fe-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010062444s
STEP: Saw pod success
Apr  3 10:52:12.603: INFO: Pod "pod-secrets-88271ad4-55fe-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:52:12.606: INFO: Trying to get logs from node docker-desktop pod pod-secrets-88271ad4-55fe-11e9-a6c1-a20d030b39ea container secret-volume-test: <nil>
STEP: delete the pod
Apr  3 10:52:12.621: INFO: Waiting for pod pod-secrets-88271ad4-55fe-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:52:12.624: INFO: Pod pod-secrets-88271ad4-55fe-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:52:12.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1267" for this suite.
Apr  3 10:52:18.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:52:18.735: INFO: namespace secrets-1267 deletion completed in 6.105416779s

• [SLOW TEST:8.203 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:52:18.735: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:52:24.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5069" for this suite.
Apr  3 10:52:30.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:52:30.961: INFO: namespace namespaces-5069 deletion completed in 6.095038942s
STEP: Destroying namespace "nsdeletetest-3800" for this suite.
Apr  3 10:52:30.966: INFO: Namespace nsdeletetest-3800 was already deleted
STEP: Destroying namespace "nsdeletetest-4749" for this suite.
Apr  3 10:52:36.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:52:37.072: INFO: namespace nsdeletetest-4749 deletion completed in 6.106078848s

• [SLOW TEST:18.337 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:52:37.077: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr  3 10:52:37.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 cluster-info'
Apr  3 10:52:37.192: INFO: stderr: ""
Apr  3 10:52:37.192: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:52:37.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4969" for this suite.
Apr  3 10:52:43.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:52:43.267: INFO: namespace kubectl-4969 deletion completed in 6.068941856s

• [SLOW TEST:6.190 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:52:43.267: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  3 10:52:45.824: INFO: Successfully updated pod "labelsupdate9ba68055-55fe-11e9-a6c1-a20d030b39ea"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:52:49.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9040" for this suite.
Apr  3 10:53:11.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:53:11.944: INFO: namespace downward-api-9040 deletion completed in 22.083942298s

• [SLOW TEST:28.676 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:53:11.944: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr  3 10:53:11.987: INFO: Waiting up to 5m0s for pod "var-expansion-acbef4a8-55fe-11e9-a6c1-a20d030b39ea" in namespace "var-expansion-3033" to be "success or failure"
Apr  3 10:53:11.992: INFO: Pod "var-expansion-acbef4a8-55fe-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029266ms
Apr  3 10:53:13.995: INFO: Pod "var-expansion-acbef4a8-55fe-11e9-a6c1-a20d030b39ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007570568s
Apr  3 10:53:15.998: INFO: Pod "var-expansion-acbef4a8-55fe-11e9-a6c1-a20d030b39ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010412765s
STEP: Saw pod success
Apr  3 10:53:15.998: INFO: Pod "var-expansion-acbef4a8-55fe-11e9-a6c1-a20d030b39ea" satisfied condition "success or failure"
Apr  3 10:53:16.003: INFO: Trying to get logs from node docker-desktop pod var-expansion-acbef4a8-55fe-11e9-a6c1-a20d030b39ea container dapi-container: <nil>
STEP: delete the pod
Apr  3 10:53:16.025: INFO: Waiting for pod var-expansion-acbef4a8-55fe-11e9-a6c1-a20d030b39ea to disappear
Apr  3 10:53:16.030: INFO: Pod var-expansion-acbef4a8-55fe-11e9-a6c1-a20d030b39ea no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:53:16.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3033" for this suite.
Apr  3 10:53:22.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:53:22.121: INFO: namespace var-expansion-3033 deletion completed in 6.084602406s

• [SLOW TEST:10.176 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:53:22.121: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:53:22.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4126" for this suite.
Apr  3 10:53:28.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:53:28.285: INFO: namespace services-4126 deletion completed in 6.120642504s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.164 seconds]
[sig-network] Services
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:53:28.286: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-ntwjk in namespace proxy-2309
I0403 10:53:28.343337      17 runners.go:184] Created replication controller with name: proxy-service-ntwjk, namespace: proxy-2309, replica count: 1
I0403 10:53:29.394279      17 runners.go:184] proxy-service-ntwjk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0403 10:53:30.394851      17 runners.go:184] proxy-service-ntwjk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0403 10:53:31.395127      17 runners.go:184] proxy-service-ntwjk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0403 10:53:32.395881      17 runners.go:184] proxy-service-ntwjk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0403 10:53:33.396707      17 runners.go:184] proxy-service-ntwjk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0403 10:53:34.397357      17 runners.go:184] proxy-service-ntwjk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0403 10:53:35.397821      17 runners.go:184] proxy-service-ntwjk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0403 10:53:36.399473      17 runners.go:184] proxy-service-ntwjk Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  3 10:53:36.405: INFO: setup took 8.086462115s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr  3 10:53:36.413: INFO: (0) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 5.917721ms)
Apr  3 10:53:36.413: INFO: (0) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 8.156492ms)
Apr  3 10:53:36.414: INFO: (0) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 7.605357ms)
Apr  3 10:53:36.415: INFO: (0) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 9.037535ms)
Apr  3 10:53:36.415: INFO: (0) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 10.46413ms)
Apr  3 10:53:36.415: INFO: (0) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 9.686196ms)
Apr  3 10:53:36.415: INFO: (0) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 10.026503ms)
Apr  3 10:53:36.418: INFO: (0) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 9.735638ms)
Apr  3 10:53:36.424: INFO: (0) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 18.427699ms)
Apr  3 10:53:36.435: INFO: (0) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 30.172079ms)
Apr  3 10:53:36.435: INFO: (0) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 29.628316ms)
Apr  3 10:53:36.438: INFO: (0) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 32.43879ms)
Apr  3 10:53:36.438: INFO: (0) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 33.56048ms)
Apr  3 10:53:36.438: INFO: (0) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 31.829182ms)
Apr  3 10:53:36.438: INFO: (0) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 33.074359ms)
Apr  3 10:53:36.440: INFO: (0) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 34.120111ms)
Apr  3 10:53:36.460: INFO: (1) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 19.147066ms)
Apr  3 10:53:36.461: INFO: (1) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 20.14727ms)
Apr  3 10:53:36.461: INFO: (1) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 20.438558ms)
Apr  3 10:53:36.461: INFO: (1) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 20.624267ms)
Apr  3 10:53:36.462: INFO: (1) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 21.379684ms)
Apr  3 10:53:36.462: INFO: (1) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 21.605742ms)
Apr  3 10:53:36.463: INFO: (1) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 21.843544ms)
Apr  3 10:53:36.463: INFO: (1) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 22.627635ms)
Apr  3 10:53:36.463: INFO: (1) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 21.991856ms)
Apr  3 10:53:36.463: INFO: (1) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 22.185956ms)
Apr  3 10:53:36.464: INFO: (1) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 23.927478ms)
Apr  3 10:53:36.464: INFO: (1) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 23.59648ms)
Apr  3 10:53:36.464: INFO: (1) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 23.507255ms)
Apr  3 10:53:36.464: INFO: (1) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 23.423157ms)
Apr  3 10:53:36.464: INFO: (1) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 23.616743ms)
Apr  3 10:53:36.464: INFO: (1) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 23.566243ms)
Apr  3 10:53:36.478: INFO: (2) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 13.679988ms)
Apr  3 10:53:36.478: INFO: (2) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 13.662335ms)
Apr  3 10:53:36.478: INFO: (2) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 13.818724ms)
Apr  3 10:53:36.479: INFO: (2) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 14.168202ms)
Apr  3 10:53:36.479: INFO: (2) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 13.772942ms)
Apr  3 10:53:36.479: INFO: (2) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 13.57188ms)
Apr  3 10:53:36.479: INFO: (2) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 13.649914ms)
Apr  3 10:53:36.479: INFO: (2) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 14.492573ms)
Apr  3 10:53:36.479: INFO: (2) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 14.182628ms)
Apr  3 10:53:36.480: INFO: (2) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 14.728289ms)
Apr  3 10:53:36.486: INFO: (2) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 20.752785ms)
Apr  3 10:53:36.486: INFO: (2) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 20.443242ms)
Apr  3 10:53:36.486: INFO: (2) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 21.535807ms)
Apr  3 10:53:36.486: INFO: (2) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 21.299952ms)
Apr  3 10:53:36.491: INFO: (2) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 26.745711ms)
Apr  3 10:53:36.494: INFO: (2) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 29.875836ms)
Apr  3 10:53:36.507: INFO: (3) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 12.225655ms)
Apr  3 10:53:36.507: INFO: (3) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 11.797ms)
Apr  3 10:53:36.507: INFO: (3) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 12.557072ms)
Apr  3 10:53:36.507: INFO: (3) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 12.162836ms)
Apr  3 10:53:36.507: INFO: (3) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 12.476729ms)
Apr  3 10:53:36.507: INFO: (3) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 12.88488ms)
Apr  3 10:53:36.507: INFO: (3) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 12.253841ms)
Apr  3 10:53:36.507: INFO: (3) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 12.433142ms)
Apr  3 10:53:36.507: INFO: (3) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 12.546219ms)
Apr  3 10:53:36.508: INFO: (3) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 12.537626ms)
Apr  3 10:53:36.509: INFO: (3) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 13.884571ms)
Apr  3 10:53:36.509: INFO: (3) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 13.733024ms)
Apr  3 10:53:36.510: INFO: (3) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 14.308171ms)
Apr  3 10:53:36.514: INFO: (3) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 19.3256ms)
Apr  3 10:53:36.514: INFO: (3) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 19.468534ms)
Apr  3 10:53:36.514: INFO: (3) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 19.075418ms)
Apr  3 10:53:36.523: INFO: (4) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 7.972316ms)
Apr  3 10:53:36.523: INFO: (4) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 7.437409ms)
Apr  3 10:53:36.523: INFO: (4) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 7.69066ms)
Apr  3 10:53:36.523: INFO: (4) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 8.777728ms)
Apr  3 10:53:36.524: INFO: (4) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 8.2953ms)
Apr  3 10:53:36.524: INFO: (4) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 8.008826ms)
Apr  3 10:53:36.524: INFO: (4) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 8.26476ms)
Apr  3 10:53:36.524: INFO: (4) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 9.883789ms)
Apr  3 10:53:36.524: INFO: (4) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 8.512119ms)
Apr  3 10:53:36.524: INFO: (4) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 6.842135ms)
Apr  3 10:53:36.524: INFO: (4) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 9.220037ms)
Apr  3 10:53:36.525: INFO: (4) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 10.552229ms)
Apr  3 10:53:36.527: INFO: (4) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 11.018928ms)
Apr  3 10:53:36.531: INFO: (4) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 12.42457ms)
Apr  3 10:53:36.531: INFO: (4) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 14.722417ms)
Apr  3 10:53:36.532: INFO: (4) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 15.835492ms)
Apr  3 10:53:36.539: INFO: (5) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 6.194686ms)
Apr  3 10:53:36.541: INFO: (5) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 8.277423ms)
Apr  3 10:53:36.544: INFO: (5) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 11.189327ms)
Apr  3 10:53:36.544: INFO: (5) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 11.046682ms)
Apr  3 10:53:36.544: INFO: (5) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 11.036ms)
Apr  3 10:53:36.544: INFO: (5) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 11.396539ms)
Apr  3 10:53:36.544: INFO: (5) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 11.256213ms)
Apr  3 10:53:36.544: INFO: (5) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 11.191849ms)
Apr  3 10:53:36.544: INFO: (5) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 11.360697ms)
Apr  3 10:53:36.544: INFO: (5) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 11.990337ms)
Apr  3 10:53:36.547: INFO: (5) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 14.391386ms)
Apr  3 10:53:36.555: INFO: (5) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 22.015827ms)
Apr  3 10:53:36.556: INFO: (5) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 23.495964ms)
Apr  3 10:53:36.556: INFO: (5) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 23.093699ms)
Apr  3 10:53:36.556: INFO: (5) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 23.32045ms)
Apr  3 10:53:36.557: INFO: (5) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 23.842361ms)
Apr  3 10:53:36.570: INFO: (6) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 11.205794ms)
Apr  3 10:53:36.570: INFO: (6) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 11.197587ms)
Apr  3 10:53:36.570: INFO: (6) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 11.975988ms)
Apr  3 10:53:36.570: INFO: (6) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 9.489258ms)
Apr  3 10:53:36.575: INFO: (6) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 12.839243ms)
Apr  3 10:53:36.579: INFO: (6) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 16.578896ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 19.240977ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 19.274673ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 19.236706ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 19.181481ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 19.203925ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 19.308518ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 19.196447ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 19.288796ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 20.718305ms)
Apr  3 10:53:36.581: INFO: (6) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 19.481759ms)
Apr  3 10:53:36.592: INFO: (7) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 8.998944ms)
Apr  3 10:53:36.592: INFO: (7) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 10.440415ms)
Apr  3 10:53:36.592: INFO: (7) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 9.020024ms)
Apr  3 10:53:36.592: INFO: (7) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 9.139007ms)
Apr  3 10:53:36.592: INFO: (7) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 8.936358ms)
Apr  3 10:53:36.592: INFO: (7) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 9.097902ms)
Apr  3 10:53:36.592: INFO: (7) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 8.932026ms)
Apr  3 10:53:36.592: INFO: (7) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 9.01903ms)
Apr  3 10:53:36.592: INFO: (7) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 9.773271ms)
Apr  3 10:53:36.597: INFO: (7) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 15.70574ms)
Apr  3 10:53:36.597: INFO: (7) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 14.652978ms)
Apr  3 10:53:36.597: INFO: (7) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 15.859978ms)
Apr  3 10:53:36.597: INFO: (7) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 14.779172ms)
Apr  3 10:53:36.598: INFO: (7) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 15.835889ms)
Apr  3 10:53:36.598: INFO: (7) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 15.9518ms)
Apr  3 10:53:36.598: INFO: (7) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 14.881319ms)
Apr  3 10:53:36.607: INFO: (8) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 9.484534ms)
Apr  3 10:53:36.607: INFO: (8) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 9.715513ms)
Apr  3 10:53:36.612: INFO: (8) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 13.196329ms)
Apr  3 10:53:36.612: INFO: (8) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 13.04326ms)
Apr  3 10:53:36.612: INFO: (8) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 13.007126ms)
Apr  3 10:53:36.615: INFO: (8) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 16.499526ms)
Apr  3 10:53:36.616: INFO: (8) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 16.990577ms)
Apr  3 10:53:36.616: INFO: (8) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 17.025179ms)
Apr  3 10:53:36.616: INFO: (8) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 17.198919ms)
Apr  3 10:53:36.616: INFO: (8) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 17.113298ms)
Apr  3 10:53:36.616: INFO: (8) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 17.051267ms)
Apr  3 10:53:36.621: INFO: (8) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 21.538707ms)
Apr  3 10:53:36.627: INFO: (8) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 27.561885ms)
Apr  3 10:53:36.627: INFO: (8) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 27.662039ms)
Apr  3 10:53:36.627: INFO: (8) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 27.679662ms)
Apr  3 10:53:36.627: INFO: (8) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 27.671411ms)
Apr  3 10:53:36.635: INFO: (9) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 7.593483ms)
Apr  3 10:53:36.636: INFO: (9) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 8.681847ms)
Apr  3 10:53:36.636: INFO: (9) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 8.78765ms)
Apr  3 10:53:36.636: INFO: (9) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 8.873025ms)
Apr  3 10:53:36.636: INFO: (9) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 8.989251ms)
Apr  3 10:53:36.637: INFO: (9) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 10.103582ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 10.181489ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 10.23963ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 10.480488ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 10.40539ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 10.305765ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 10.216205ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 10.259037ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 10.534477ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 10.211501ms)
Apr  3 10:53:36.638: INFO: (9) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 10.875288ms)
Apr  3 10:53:36.649: INFO: (10) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 10.407952ms)
Apr  3 10:53:36.649: INFO: (10) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 10.380393ms)
Apr  3 10:53:36.649: INFO: (10) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 10.510183ms)
Apr  3 10:53:36.649: INFO: (10) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 10.738747ms)
Apr  3 10:53:36.649: INFO: (10) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 10.499605ms)
Apr  3 10:53:36.649: INFO: (10) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 10.367399ms)
Apr  3 10:53:36.651: INFO: (10) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 12.61825ms)
Apr  3 10:53:36.653: INFO: (10) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 14.227694ms)
Apr  3 10:53:36.653: INFO: (10) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 14.479988ms)
Apr  3 10:53:36.653: INFO: (10) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 14.199929ms)
Apr  3 10:53:36.653: INFO: (10) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 14.229955ms)
Apr  3 10:53:36.653: INFO: (10) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 14.485779ms)
Apr  3 10:53:36.653: INFO: (10) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 14.636565ms)
Apr  3 10:53:36.654: INFO: (10) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 15.189663ms)
Apr  3 10:53:36.654: INFO: (10) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 15.464842ms)
Apr  3 10:53:36.655: INFO: (10) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 16.921234ms)
Apr  3 10:53:36.676: INFO: (11) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 20.419458ms)
Apr  3 10:53:36.676: INFO: (11) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 20.317661ms)
Apr  3 10:53:36.676: INFO: (11) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 19.620401ms)
Apr  3 10:53:36.676: INFO: (11) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 20.261948ms)
Apr  3 10:53:36.676: INFO: (11) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 19.816914ms)
Apr  3 10:53:36.676: INFO: (11) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 19.445662ms)
Apr  3 10:53:36.676: INFO: (11) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 19.491272ms)
Apr  3 10:53:36.679: INFO: (11) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 22.253298ms)
Apr  3 10:53:36.679: INFO: (11) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 23.013728ms)
Apr  3 10:53:36.679: INFO: (11) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 22.381745ms)
Apr  3 10:53:36.679: INFO: (11) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 22.974598ms)
Apr  3 10:53:36.679: INFO: (11) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 23.63734ms)
Apr  3 10:53:36.679: INFO: (11) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 23.198799ms)
Apr  3 10:53:36.679: INFO: (11) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 22.587014ms)
Apr  3 10:53:36.679: INFO: (11) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 23.031739ms)
Apr  3 10:53:36.679: INFO: (11) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 22.872404ms)
Apr  3 10:53:36.691: INFO: (12) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 11.134335ms)
Apr  3 10:53:36.694: INFO: (12) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 14.103365ms)
Apr  3 10:53:36.694: INFO: (12) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 15.243021ms)
Apr  3 10:53:36.695: INFO: (12) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 14.962884ms)
Apr  3 10:53:36.695: INFO: (12) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 14.928363ms)
Apr  3 10:53:36.697: INFO: (12) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 16.927334ms)
Apr  3 10:53:36.697: INFO: (12) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 16.98236ms)
Apr  3 10:53:36.697: INFO: (12) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 17.710818ms)
Apr  3 10:53:36.697: INFO: (12) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 17.362656ms)
Apr  3 10:53:36.697: INFO: (12) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 17.362158ms)
Apr  3 10:53:36.697: INFO: (12) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 17.619166ms)
Apr  3 10:53:36.697: INFO: (12) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 17.358921ms)
Apr  3 10:53:36.697: INFO: (12) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 17.727958ms)
Apr  3 10:53:36.697: INFO: (12) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 18.418182ms)
Apr  3 10:53:36.698: INFO: (12) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 17.75227ms)
Apr  3 10:53:36.698: INFO: (12) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 18.524669ms)
Apr  3 10:53:36.709: INFO: (13) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 10.812368ms)
Apr  3 10:53:36.710: INFO: (13) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 11.181983ms)
Apr  3 10:53:36.710: INFO: (13) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 12.144736ms)
Apr  3 10:53:36.710: INFO: (13) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 11.660006ms)
Apr  3 10:53:36.710: INFO: (13) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 11.31638ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 11.148138ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 10.550508ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 11.422508ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 11.387229ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 11.955356ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 12.052297ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 11.733751ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 11.6887ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 10.837589ms)
Apr  3 10:53:36.711: INFO: (13) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 12.261062ms)
Apr  3 10:53:36.714: INFO: (13) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 14.919022ms)
Apr  3 10:53:36.726: INFO: (14) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 11.563577ms)
Apr  3 10:53:36.726: INFO: (14) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 11.748235ms)
Apr  3 10:53:36.726: INFO: (14) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 12.146532ms)
Apr  3 10:53:36.726: INFO: (14) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 11.03704ms)
Apr  3 10:53:36.726: INFO: (14) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 11.055818ms)
Apr  3 10:53:36.734: INFO: (14) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 19.353636ms)
Apr  3 10:53:36.735: INFO: (14) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 20.095276ms)
Apr  3 10:53:36.735: INFO: (14) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 20.633158ms)
Apr  3 10:53:36.735: INFO: (14) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 20.776222ms)
Apr  3 10:53:36.735: INFO: (14) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 15.564892ms)
Apr  3 10:53:36.736: INFO: (14) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 21.368271ms)
Apr  3 10:53:36.739: INFO: (14) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 24.257273ms)
Apr  3 10:53:36.739: INFO: (14) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 24.75405ms)
Apr  3 10:53:36.739: INFO: (14) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 24.762751ms)
Apr  3 10:53:36.739: INFO: (14) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 24.783279ms)
Apr  3 10:53:36.740: INFO: (14) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 26.01959ms)
Apr  3 10:53:36.751: INFO: (15) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 9.956405ms)
Apr  3 10:53:36.751: INFO: (15) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 10.151144ms)
Apr  3 10:53:36.751: INFO: (15) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 10.919588ms)
Apr  3 10:53:36.753: INFO: (15) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 11.63991ms)
Apr  3 10:53:36.753: INFO: (15) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 11.978517ms)
Apr  3 10:53:36.753: INFO: (15) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 11.883738ms)
Apr  3 10:53:36.753: INFO: (15) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 11.892652ms)
Apr  3 10:53:36.754: INFO: (15) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 12.872968ms)
Apr  3 10:53:36.754: INFO: (15) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 13.296491ms)
Apr  3 10:53:36.754: INFO: (15) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 13.78151ms)
Apr  3 10:53:36.755: INFO: (15) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 13.657267ms)
Apr  3 10:53:36.755: INFO: (15) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 13.169113ms)
Apr  3 10:53:36.755: INFO: (15) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 13.233104ms)
Apr  3 10:53:36.755: INFO: (15) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 13.21294ms)
Apr  3 10:53:36.756: INFO: (15) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 14.881011ms)
Apr  3 10:53:36.756: INFO: (15) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 15.2238ms)
Apr  3 10:53:36.769: INFO: (16) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 12.716702ms)
Apr  3 10:53:36.770: INFO: (16) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 12.344104ms)
Apr  3 10:53:36.770: INFO: (16) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 13.014722ms)
Apr  3 10:53:36.770: INFO: (16) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 12.90149ms)
Apr  3 10:53:36.770: INFO: (16) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 12.916185ms)
Apr  3 10:53:36.770: INFO: (16) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 12.296673ms)
Apr  3 10:53:36.770: INFO: (16) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 12.628142ms)
Apr  3 10:53:36.770: INFO: (16) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 12.856815ms)
Apr  3 10:53:36.771: INFO: (16) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 13.610409ms)
Apr  3 10:53:36.771: INFO: (16) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 14.421166ms)
Apr  3 10:53:36.775: INFO: (16) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 19.00179ms)
Apr  3 10:53:36.775: INFO: (16) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 18.168967ms)
Apr  3 10:53:36.776: INFO: (16) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 18.658945ms)
Apr  3 10:53:36.776: INFO: (16) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 18.804273ms)
Apr  3 10:53:36.776: INFO: (16) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 19.880907ms)
Apr  3 10:53:36.778: INFO: (16) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 20.440066ms)
Apr  3 10:53:36.786: INFO: (17) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 8.407588ms)
Apr  3 10:53:36.788: INFO: (17) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 10.467184ms)
Apr  3 10:53:36.788: INFO: (17) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 10.424926ms)
Apr  3 10:53:36.790: INFO: (17) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 11.156794ms)
Apr  3 10:53:36.790: INFO: (17) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 11.198431ms)
Apr  3 10:53:36.798: INFO: (17) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 19.379272ms)
Apr  3 10:53:36.798: INFO: (17) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 19.956009ms)
Apr  3 10:53:36.798: INFO: (17) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 20.200682ms)
Apr  3 10:53:36.800: INFO: (17) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 21.305607ms)
Apr  3 10:53:36.806: INFO: (17) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 27.504602ms)
Apr  3 10:53:36.806: INFO: (17) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 27.481283ms)
Apr  3 10:53:36.806: INFO: (17) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 27.780481ms)
Apr  3 10:53:36.806: INFO: (17) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 27.009615ms)
Apr  3 10:53:36.806: INFO: (17) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 26.987564ms)
Apr  3 10:53:36.806: INFO: (17) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 27.138577ms)
Apr  3 10:53:36.806: INFO: (17) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 28.183779ms)
Apr  3 10:53:36.813: INFO: (18) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 6.648431ms)
Apr  3 10:53:36.825: INFO: (18) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 17.71591ms)
Apr  3 10:53:36.825: INFO: (18) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 17.815914ms)
Apr  3 10:53:36.825: INFO: (18) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 17.878974ms)
Apr  3 10:53:36.825: INFO: (18) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 17.913042ms)
Apr  3 10:53:36.825: INFO: (18) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 17.850133ms)
Apr  3 10:53:36.825: INFO: (18) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 18.042175ms)
Apr  3 10:53:36.826: INFO: (18) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 18.336857ms)
Apr  3 10:53:36.826: INFO: (18) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 19.141899ms)
Apr  3 10:53:36.826: INFO: (18) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 18.731894ms)
Apr  3 10:53:36.826: INFO: (18) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 19.267356ms)
Apr  3 10:53:36.826: INFO: (18) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 19.331219ms)
Apr  3 10:53:36.827: INFO: (18) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 17.69307ms)
Apr  3 10:53:36.829: INFO: (18) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 21.587175ms)
Apr  3 10:53:36.829: INFO: (18) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 21.714724ms)
Apr  3 10:53:36.832: INFO: (18) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 24.946179ms)
Apr  3 10:53:36.845: INFO: (19) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">test<... (200; 12.901115ms)
Apr  3 10:53:36.845: INFO: (19) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:1080/proxy/rewriteme">... (200; 12.450981ms)
Apr  3 10:53:36.848: INFO: (19) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 15.081838ms)
Apr  3 10:53:36.848: INFO: (19) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw/proxy/rewriteme">test</a> (200; 14.118789ms)
Apr  3 10:53:36.848: INFO: (19) /api/v1/namespaces/proxy-2309/pods/http:proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 14.136754ms)
Apr  3 10:53:36.848: INFO: (19) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:162/proxy/: bar (200; 14.28318ms)
Apr  3 10:53:36.848: INFO: (19) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:462/proxy/: tls qux (200; 14.345244ms)
Apr  3 10:53:36.848: INFO: (19) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/: <a href="/api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:443/proxy/tlsrewritem... (200; 15.056844ms)
Apr  3 10:53:36.848: INFO: (19) /api/v1/namespaces/proxy-2309/pods/proxy-service-ntwjk-7rdmw:160/proxy/: foo (200; 14.264849ms)
Apr  3 10:53:36.849: INFO: (19) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname2/proxy/: tls qux (200; 14.862674ms)
Apr  3 10:53:36.854: INFO: (19) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname2/proxy/: bar (200; 20.944115ms)
Apr  3 10:53:36.854: INFO: (19) /api/v1/namespaces/proxy-2309/pods/https:proxy-service-ntwjk-7rdmw:460/proxy/: tls baz (200; 20.577063ms)
Apr  3 10:53:36.854: INFO: (19) /api/v1/namespaces/proxy-2309/services/proxy-service-ntwjk:portname1/proxy/: foo (200; 20.647052ms)
Apr  3 10:53:36.854: INFO: (19) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname1/proxy/: foo (200; 21.076526ms)
Apr  3 10:53:36.854: INFO: (19) /api/v1/namespaces/proxy-2309/services/https:proxy-service-ntwjk:tlsportname1/proxy/: tls baz (200; 21.526558ms)
Apr  3 10:53:36.854: INFO: (19) /api/v1/namespaces/proxy-2309/services/http:proxy-service-ntwjk:portname2/proxy/: bar (200; 20.721604ms)
STEP: deleting ReplicationController proxy-service-ntwjk in namespace proxy-2309, will wait for the garbage collector to delete the pods
Apr  3 10:53:36.915: INFO: Deleting ReplicationController proxy-service-ntwjk took: 4.449184ms
Apr  3 10:53:37.315: INFO: Terminating ReplicationController proxy-service-ntwjk pods took: 400.433476ms
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:53:39.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2309" for this suite.
Apr  3 10:53:45.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:53:45.803: INFO: namespace proxy-2309 deletion completed in 6.081632027s

• [SLOW TEST:17.516 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:53:45.803: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9608
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-9608
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9608
Apr  3 10:53:45.861: INFO: Found 0 stateful pods, waiting for 1
Apr  3 10:53:55.865: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr  3 10:53:55.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-9608 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:53:56.053: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:53:56.053: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:53:56.053: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  3 10:53:56.057: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  3 10:54:06.062: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  3 10:54:06.062: INFO: Waiting for statefulset status.replicas updated to 0
Apr  3 10:54:06.076: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  3 10:54:06.076: INFO: ss-0  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  }]
Apr  3 10:54:06.076: INFO: ss-1                  Pending         []
Apr  3 10:54:06.076: INFO: 
Apr  3 10:54:06.076: INFO: StatefulSet ss has not reached scale 3, at 2
Apr  3 10:54:07.079: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994629692s
Apr  3 10:54:08.083: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991495697s
Apr  3 10:54:09.087: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987522826s
Apr  3 10:54:10.091: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984279311s
Apr  3 10:54:11.094: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980019048s
Apr  3 10:54:12.098: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976637002s
Apr  3 10:54:13.102: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.972562273s
Apr  3 10:54:14.105: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.969134267s
Apr  3 10:54:15.109: INFO: Verifying statefulset ss doesn't scale past 3 for another 965.581133ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9608
Apr  3 10:54:16.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-9608 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  3 10:54:16.299: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  3 10:54:16.299: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  3 10:54:16.299: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  3 10:54:16.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-9608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  3 10:54:16.476: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  3 10:54:16.476: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  3 10:54:16.476: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  3 10:54:16.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-9608 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  3 10:54:16.653: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  3 10:54:16.653: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  3 10:54:16.653: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  3 10:54:16.657: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Apr  3 10:54:26.662: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 10:54:26.662: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  3 10:54:26.662: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr  3 10:54:26.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-9608 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:54:26.848: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:54:26.848: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:54:26.848: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  3 10:54:26.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-9608 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:54:27.023: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:54:27.023: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:54:27.023: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  3 10:54:27.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-398250616 exec --namespace=statefulset-9608 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  3 10:54:27.232: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  3 10:54:27.232: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  3 10:54:27.232: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  3 10:54:27.232: INFO: Waiting for statefulset status.replicas updated to 0
Apr  3 10:54:27.235: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr  3 10:54:37.241: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  3 10:54:37.241: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  3 10:54:37.241: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  3 10:54:37.252: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  3 10:54:37.252: INFO: ss-0  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  }]
Apr  3 10:54:37.252: INFO: ss-1  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:37.252: INFO: ss-2  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:37.252: INFO: 
Apr  3 10:54:37.252: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  3 10:54:38.255: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  3 10:54:38.255: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  }]
Apr  3 10:54:38.255: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:38.255: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:38.255: INFO: 
Apr  3 10:54:38.255: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  3 10:54:39.259: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  3 10:54:39.259: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  }]
Apr  3 10:54:39.259: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:39.259: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:39.259: INFO: 
Apr  3 10:54:39.259: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  3 10:54:40.263: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  3 10:54:40.263: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  }]
Apr  3 10:54:40.263: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:40.263: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:40.263: INFO: 
Apr  3 10:54:40.263: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  3 10:54:41.266: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  3 10:54:41.266: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  }]
Apr  3 10:54:41.266: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:41.266: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:41.266: INFO: 
Apr  3 10:54:41.266: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  3 10:54:42.272: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  3 10:54:42.272: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  }]
Apr  3 10:54:42.272: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:42.272: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:42.272: INFO: 
Apr  3 10:54:42.272: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  3 10:54:43.275: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr  3 10:54:43.275: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:53:45 +0000 UTC  }]
Apr  3 10:54:43.275: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:43.275: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-03 10:54:06 +0000 UTC  }]
Apr  3 10:54:43.275: INFO: 
Apr  3 10:54:43.275: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  3 10:54:44.280: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.972720567s
Apr  3 10:54:45.284: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.968559449s
Apr  3 10:54:46.288: INFO: Verifying statefulset ss doesn't scale past 0 for another 963.961415ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9608
Apr  3 10:54:47.294: INFO: Scaling statefulset ss to 0
Apr  3 10:54:47.322: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  3 10:54:47.345: INFO: Deleting all statefulset in ns statefulset-9608
Apr  3 10:54:47.352: INFO: Scaling statefulset ss to 0
Apr  3 10:54:47.365: INFO: Waiting for statefulset status.replicas updated to 0
Apr  3 10:54:47.369: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:54:47.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9608" for this suite.
Apr  3 10:54:53.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:54:53.469: INFO: namespace statefulset-9608 deletion completed in 6.081163035s

• [SLOW TEST:67.664 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  3 10:54:53.469: INFO: >>> kubeConfig: /tmp/kubeconfig-398250616
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  3 10:54:53.520: INFO: (0) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.590736ms)
Apr  3 10:54:53.529: INFO: (1) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 8.565441ms)
Apr  3 10:54:53.537: INFO: (2) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 7.907381ms)
Apr  3 10:54:53.540: INFO: (3) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 3.231544ms)
Apr  3 10:54:53.544: INFO: (4) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 3.866627ms)
Apr  3 10:54:53.550: INFO: (5) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.509606ms)
Apr  3 10:54:53.556: INFO: (6) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.312579ms)
Apr  3 10:54:53.562: INFO: (7) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.769562ms)
Apr  3 10:54:53.569: INFO: (8) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 6.280778ms)
Apr  3 10:54:53.574: INFO: (9) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.283053ms)
Apr  3 10:54:53.579: INFO: (10) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 4.31831ms)
Apr  3 10:54:53.583: INFO: (11) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 3.806374ms)
Apr  3 10:54:53.592: INFO: (12) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 9.035825ms)
Apr  3 10:54:53.597: INFO: (13) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.602128ms)
Apr  3 10:54:53.601: INFO: (14) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 3.402117ms)
Apr  3 10:54:53.606: INFO: (15) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 4.946986ms)
Apr  3 10:54:53.609: INFO: (16) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.772718ms)
Apr  3 10:54:53.614: INFO: (17) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.359648ms)
Apr  3 10:54:53.620: INFO: (18) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 5.840993ms)
Apr  3 10:54:53.625: INFO: (19) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 4.497316ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  3 10:54:53.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6679" for this suite.
Apr  3 10:54:59.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  3 10:54:59.713: INFO: namespace proxy-6679 deletion completed in 6.082818501s

• [SLOW TEST:6.243 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSApr  3 10:54:59.714: INFO: Running AfterSuite actions on all nodes
Apr  3 10:54:59.718: INFO: Running AfterSuite actions on node 1
Apr  3 10:54:59.719: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5152.693 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h25m53.691890129s
Test Suite Passed

Conformance test: not doing test setup.
I0409 06:29:23.370443    5079 e2e.go:240] Starting e2e run "d00a4a67-5a90-11e9-8d38-4647074cf119" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1554791362 - Will randomize all specs
Will run 204 of 3584 specs

Apr  9 06:29:23.594: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:29:23.596: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr  9 06:29:23.721: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr  9 06:29:23.824: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr  9 06:29:23.824: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Apr  9 06:29:23.824: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr  9 06:29:23.854: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr  9 06:29:23.854: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr  9 06:29:23.854: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Apr  9 06:29:23.854: INFO: e2e test version: v1.14.0
Apr  9 06:29:23.873: INFO: kube-apiserver version: v1.14.0
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:29:23.873: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
Apr  9 06:29:24.055: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Apr  9 06:29:24.123: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7284
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-d1363abe-5a90-11e9-8d38-4647074cf119
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-d1363abe-5a90-11e9-8d38-4647074cf119
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:30:36.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7284" for this suite.
Apr  9 06:31:00.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:31:00.985: INFO: namespace configmap-7284 deletion completed in 24.841058622s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:31:00.985: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8958
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr  9 06:31:02.493: INFO: Pod name wrapped-volume-race-0ba7c8c8-5a91-11e9-8d38-4647074cf119: Found 1 pods out of 5
Apr  9 06:31:07.535: INFO: Pod name wrapped-volume-race-0ba7c8c8-5a91-11e9-8d38-4647074cf119: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0ba7c8c8-5a91-11e9-8d38-4647074cf119 in namespace emptydir-wrapper-8958, will wait for the garbage collector to delete the pods
Apr  9 06:31:13.795: INFO: Deleting ReplicationController wrapped-volume-race-0ba7c8c8-5a91-11e9-8d38-4647074cf119 took: 25.282053ms
Apr  9 06:31:13.895: INFO: Terminating ReplicationController wrapped-volume-race-0ba7c8c8-5a91-11e9-8d38-4647074cf119 pods took: 100.251754ms
STEP: Creating RC which spawns configmap-volume pods
Apr  9 06:31:56.675: INFO: Pod name wrapped-volume-race-2bf84134-5a91-11e9-8d38-4647074cf119: Found 2 pods out of 5
Apr  9 06:32:01.717: INFO: Pod name wrapped-volume-race-2bf84134-5a91-11e9-8d38-4647074cf119: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2bf84134-5a91-11e9-8d38-4647074cf119 in namespace emptydir-wrapper-8958, will wait for the garbage collector to delete the pods
Apr  9 06:32:01.929: INFO: Deleting ReplicationController wrapped-volume-race-2bf84134-5a91-11e9-8d38-4647074cf119 took: 26.707904ms
Apr  9 06:32:02.729: INFO: Terminating ReplicationController wrapped-volume-race-2bf84134-5a91-11e9-8d38-4647074cf119 pods took: 800.260732ms
STEP: Creating RC which spawns configmap-volume pods
Apr  9 06:32:35.206: INFO: Pod name wrapped-volume-race-42f015df-5a91-11e9-8d38-4647074cf119: Found 3 pods out of 5
Apr  9 06:32:40.249: INFO: Pod name wrapped-volume-race-42f015df-5a91-11e9-8d38-4647074cf119: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-42f015df-5a91-11e9-8d38-4647074cf119 in namespace emptydir-wrapper-8958, will wait for the garbage collector to delete the pods
Apr  9 06:32:40.466: INFO: Deleting ReplicationController wrapped-volume-race-42f015df-5a91-11e9-8d38-4647074cf119 took: 24.52322ms
Apr  9 06:32:40.566: INFO: Terminating ReplicationController wrapped-volume-race-42f015df-5a91-11e9-8d38-4647074cf119 pods took: 100.293318ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:33:17.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8958" for this suite.
Apr  9 06:33:23.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:33:24.597: INFO: namespace emptydir-wrapper-8958 deletion completed in 6.852100377s
•SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:33:24.597: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2256
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 06:33:49.078: INFO: Container started at 2019-04-09 06:33:27 +0000 UTC, pod became ready at 2019-04-09 06:33:48 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:33:49.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2256" for this suite.
Apr  9 06:34:13.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:34:13.952: INFO: namespace container-probe-2256 deletion completed in 24.851411086s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:34:13.952: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2068
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-7e0a7bc4-5a91-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 06:34:14.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-7e0dcfda-5a91-11e9-8d38-4647074cf119" in namespace "configmap-2068" to be "success or failure"
Apr  9 06:34:14.358: INFO: Pod "pod-configmaps-7e0dcfda-5a91-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.004687ms
Apr  9 06:34:16.380: INFO: Pod "pod-configmaps-7e0dcfda-5a91-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043073354s
STEP: Saw pod success
Apr  9 06:34:16.380: INFO: Pod "pod-configmaps-7e0dcfda-5a91-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:34:16.402: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-7e0dcfda-5a91-11e9-8d38-4647074cf119 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 06:34:16.461: INFO: Waiting for pod pod-configmaps-7e0dcfda-5a91-11e9-8d38-4647074cf119 to disappear
Apr  9 06:34:16.482: INFO: Pod pod-configmaps-7e0dcfda-5a91-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:34:16.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2068" for this suite.
Apr  9 06:34:22.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:34:23.353: INFO: namespace configmap-2068 deletion completed in 6.849615407s
•S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:34:23.354: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  9 06:34:23.679: INFO: namespace kubectl-4964
Apr  9 06:34:23.679: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-4964'
Apr  9 06:34:24.077: INFO: stderr: ""
Apr  9 06:34:24.077: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  9 06:34:25.100: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 06:34:25.100: INFO: Found 0 / 1
Apr  9 06:34:26.100: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 06:34:26.100: INFO: Found 0 / 1
Apr  9 06:34:27.100: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 06:34:27.100: INFO: Found 1 / 1
Apr  9 06:34:27.100: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  9 06:34:27.122: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 06:34:27.122: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  9 06:34:27.122: INFO: wait on redis-master startup in kubectl-4964 
Apr  9 06:34:27.122: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config logs redis-master-lwmw2 redis-master --namespace=kubectl-4964'
Apr  9 06:34:27.308: INFO: stderr: ""
Apr  9 06:34:27.308: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Apr 06:34:26.385 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Apr 06:34:26.385 # Server started, Redis version 3.2.12\n1:M 09 Apr 06:34:26.385 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Apr 06:34:26.385 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr  9 06:34:27.308: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4964'
Apr  9 06:34:27.496: INFO: stderr: ""
Apr  9 06:34:27.496: INFO: stdout: "service/rm2 exposed\n"
Apr  9 06:34:27.517: INFO: Service rm2 in namespace kubectl-4964 found.
STEP: exposing service
Apr  9 06:34:29.563: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4964'
Apr  9 06:34:29.782: INFO: stderr: ""
Apr  9 06:34:29.783: INFO: stdout: "service/rm3 exposed\n"
Apr  9 06:34:29.804: INFO: Service rm3 in namespace kubectl-4964 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:34:31.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4964" for this suite.
Apr  9 06:34:55.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:34:56.773: INFO: namespace kubectl-4964 deletion completed in 24.902683707s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:34:56.774: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4914
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 06:34:57.205: INFO: Waiting up to 5m0s for pod "downwardapi-volume-979b283b-5a91-11e9-8d38-4647074cf119" in namespace "downward-api-4914" to be "success or failure"
Apr  9 06:34:57.227: INFO: Pod "downwardapi-volume-979b283b-5a91-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.96259ms
Apr  9 06:34:59.250: INFO: Pod "downwardapi-volume-979b283b-5a91-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044940444s
STEP: Saw pod success
Apr  9 06:34:59.251: INFO: Pod "downwardapi-volume-979b283b-5a91-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:34:59.272: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-979b283b-5a91-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 06:34:59.334: INFO: Waiting for pod downwardapi-volume-979b283b-5a91-11e9-8d38-4647074cf119 to disappear
Apr  9 06:34:59.355: INFO: Pod downwardapi-volume-979b283b-5a91-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:34:59.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4914" for this suite.
Apr  9 06:35:05.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:35:06.254: INFO: namespace downward-api-4914 deletion completed in 6.876778293s
•SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:35:06.254: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4635
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 06:35:06.612: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d3669be-5a91-11e9-8d38-4647074cf119" in namespace "downward-api-4635" to be "success or failure"
Apr  9 06:35:06.634: INFO: Pod "downwardapi-volume-9d3669be-5a91-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.540271ms
Apr  9 06:35:08.657: INFO: Pod "downwardapi-volume-9d3669be-5a91-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045659095s
STEP: Saw pod success
Apr  9 06:35:08.657: INFO: Pod "downwardapi-volume-9d3669be-5a91-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:35:08.680: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-9d3669be-5a91-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 06:35:08.737: INFO: Waiting for pod downwardapi-volume-9d3669be-5a91-11e9-8d38-4647074cf119 to disappear
Apr  9 06:35:08.758: INFO: Pod downwardapi-volume-9d3669be-5a91-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:35:08.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4635" for this suite.
Apr  9 06:35:14.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:35:15.628: INFO: namespace downward-api-4635 deletion completed in 6.847968822s
•SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:35:15.628: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-541
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Apr  9 06:35:15.895: INFO: Asynchronously running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:35:16.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-541" for this suite.
Apr  9 06:35:22.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:35:22.969: INFO: namespace kubectl-541 deletion completed in 6.879066445s
•SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:35:22.969: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-56
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Apr  9 06:35:23.380: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-56'
Apr  9 06:35:23.700: INFO: stderr: ""
Apr  9 06:35:23.700: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Apr  9 06:35:24.721: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 06:35:24.721: INFO: Found 0 / 1
Apr  9 06:35:25.722: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 06:35:25.722: INFO: Found 1 / 1
Apr  9 06:35:25.722: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  9 06:35:25.744: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 06:35:25.744: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr  9 06:35:25.744: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config logs redis-master-txdpm redis-master --namespace=kubectl-56'
Apr  9 06:35:25.970: INFO: stderr: ""
Apr  9 06:35:25.970: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Apr 06:35:24.611 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Apr 06:35:24.611 # Server started, Redis version 3.2.12\n1:M 09 Apr 06:35:24.611 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Apr 06:35:24.611 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr  9 06:35:25.970: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-txdpm redis-master --namespace=kubectl-56 --tail=1'
Apr  9 06:35:26.158: INFO: stderr: ""
Apr  9 06:35:26.158: INFO: stdout: "1:M 09 Apr 06:35:24.611 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr  9 06:35:26.158: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-txdpm redis-master --namespace=kubectl-56 --limit-bytes=1'
Apr  9 06:35:26.368: INFO: stderr: ""
Apr  9 06:35:26.368: INFO: stdout: " "
STEP: exposing timestamps
Apr  9 06:35:26.368: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-txdpm redis-master --namespace=kubectl-56 --tail=1 --timestamps'
Apr  9 06:35:26.585: INFO: stderr: ""
Apr  9 06:35:26.585: INFO: stdout: "2019-04-09T06:35:24.611912202Z 1:M 09 Apr 06:35:24.611 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr  9 06:35:29.085: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-txdpm redis-master --namespace=kubectl-56 --since=1s'
Apr  9 06:35:29.258: INFO: stderr: ""
Apr  9 06:35:29.258: INFO: stdout: ""
Apr  9 06:35:29.258: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config log redis-master-txdpm redis-master --namespace=kubectl-56 --since=24h'
Apr  9 06:35:29.463: INFO: stderr: ""
Apr  9 06:35:29.463: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Apr 06:35:24.611 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Apr 06:35:24.611 # Server started, Redis version 3.2.12\n1:M 09 Apr 06:35:24.611 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Apr 06:35:24.611 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Apr  9 06:35:29.463: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-56'
Apr  9 06:35:29.658: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 06:35:29.658: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr  9 06:35:29.658: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get rc,svc -l name=nginx --no-headers --namespace=kubectl-56'
Apr  9 06:35:29.842: INFO: stderr: "No resources found.\n"
Apr  9 06:35:29.842: INFO: stdout: ""
Apr  9 06:35:29.842: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -l name=nginx --namespace=kubectl-56 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  9 06:35:29.990: INFO: stderr: ""
Apr  9 06:35:29.990: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:35:29.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-56" for this suite.
Apr  9 06:35:36.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:35:36.867: INFO: namespace kubectl-56 deletion completed in 6.854426937s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:35:36.868: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7562
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0409 06:35:47.421639    5079 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  9 06:35:47.421: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:35:47.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7562" for this suite.
Apr  9 06:35:53.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:35:54.344: INFO: namespace gc-7562 deletion completed in 6.900551805s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:35:54.345: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9037
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  9 06:35:54.686: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9037'
Apr  9 06:35:54.892: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  9 06:35:54.892: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Apr  9 06:35:54.913: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete jobs e2e-test-nginx-job --namespace=kubectl-9037'
Apr  9 06:35:55.112: INFO: stderr: ""
Apr  9 06:35:55.112: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:35:55.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9037" for this suite.
Apr  9 06:36:01.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:36:02.000: INFO: namespace kubectl-9037 deletion completed in 6.866581517s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:36:02.001: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9832
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Apr  9 06:36:02.319: INFO: Waiting up to 5m0s for pod "pod-be6abfce-5a91-11e9-8d38-4647074cf119" in namespace "emptydir-9832" to be "success or failure"
Apr  9 06:36:02.342: INFO: Pod "pod-be6abfce-5a91-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 23.392517ms
Apr  9 06:36:04.365: INFO: Pod "pod-be6abfce-5a91-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045711942s
STEP: Saw pod success
Apr  9 06:36:04.365: INFO: Pod "pod-be6abfce-5a91-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:36:04.386: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-be6abfce-5a91-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 06:36:04.443: INFO: Waiting for pod pod-be6abfce-5a91-11e9-8d38-4647074cf119 to disappear
Apr  9 06:36:04.464: INFO: Pod pod-be6abfce-5a91-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:36:04.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9832" for this suite.
Apr  9 06:36:10.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:36:11.341: INFO: namespace emptydir-9832 deletion completed in 6.854816647s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:36:11.342: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8881
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  9 06:36:11.858: INFO: Number of nodes with available pods: 0
Apr  9 06:36:11.858: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 06:36:12.903: INFO: Number of nodes with available pods: 0
Apr  9 06:36:12.903: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 06:36:13.903: INFO: Number of nodes with available pods: 2
Apr  9 06:36:13.903: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr  9 06:36:14.195: INFO: Number of nodes with available pods: 1
Apr  9 06:36:14.195: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 06:36:15.239: INFO: Number of nodes with available pods: 1
Apr  9 06:36:15.239: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 06:36:16.240: INFO: Number of nodes with available pods: 2
Apr  9 06:36:16.240: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8881, will wait for the garbage collector to delete the pods
Apr  9 06:36:16.381: INFO: Deleting DaemonSet.extensions daemon-set took: 26.070747ms
Apr  9 06:36:16.482: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.292623ms
Apr  9 06:36:26.503: INFO: Number of nodes with available pods: 0
Apr  9 06:36:26.503: INFO: Number of running nodes: 0, number of available pods: 0
Apr  9 06:36:26.527: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8881/daemonsets","resourceVersion":"2977"},"items":null}

Apr  9 06:36:26.549: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8881/pods","resourceVersion":"2978"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:36:26.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8881" for this suite.
Apr  9 06:36:32.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:36:33.518: INFO: namespace daemonsets-8881 deletion completed in 6.88053704s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:36:33.519: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-58
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 06:36:33.919: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1404243-5a91-11e9-8d38-4647074cf119" in namespace "downward-api-58" to be "success or failure"
Apr  9 06:36:33.942: INFO: Pod "downwardapi-volume-d1404243-5a91-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 23.390879ms
Apr  9 06:36:35.964: INFO: Pod "downwardapi-volume-d1404243-5a91-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045231459s
STEP: Saw pod success
Apr  9 06:36:35.964: INFO: Pod "downwardapi-volume-d1404243-5a91-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:36:35.987: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-d1404243-5a91-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 06:36:36.044: INFO: Waiting for pod downwardapi-volume-d1404243-5a91-11e9-8d38-4647074cf119 to disappear
Apr  9 06:36:36.065: INFO: Pod downwardapi-volume-d1404243-5a91-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:36:36.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-58" for this suite.
Apr  9 06:36:42.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:36:42.945: INFO: namespace downward-api-58 deletion completed in 6.857788104s
•SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:36:42.945: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2276
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 06:36:43.239: INFO: (0) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 26.093823ms)
Apr  9 06:36:43.282: INFO: (1) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 42.816659ms)
Apr  9 06:36:43.305: INFO: (2) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.242693ms)
Apr  9 06:36:43.329: INFO: (3) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.919362ms)
Apr  9 06:36:43.353: INFO: (4) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.402842ms)
Apr  9 06:36:43.376: INFO: (5) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.602824ms)
Apr  9 06:36:43.400: INFO: (6) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 24.102464ms)
Apr  9 06:36:43.424: INFO: (7) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.639704ms)
Apr  9 06:36:43.448: INFO: (8) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.686297ms)
Apr  9 06:36:43.472: INFO: (9) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.930346ms)
Apr  9 06:36:43.497: INFO: (10) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 24.73916ms)
Apr  9 06:36:43.520: INFO: (11) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.824286ms)
Apr  9 06:36:43.545: INFO: (12) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 24.122273ms)
Apr  9 06:36:43.568: INFO: (13) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.791665ms)
Apr  9 06:36:43.592: INFO: (14) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.248539ms)
Apr  9 06:36:43.615: INFO: (15) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.005322ms)
Apr  9 06:36:43.638: INFO: (16) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.448271ms)
Apr  9 06:36:43.662: INFO: (17) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.595307ms)
Apr  9 06:36:43.686: INFO: (18) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.984978ms)
Apr  9 06:36:43.710: INFO: (19) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.915001ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:36:43.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2276" for this suite.
Apr  9 06:36:49.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:36:50.599: INFO: namespace proxy-2276 deletion completed in 6.867167045s
•SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:36:50.599: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2214
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 06:36:50.994: INFO: Creating deployment "test-recreate-deployment"
Apr  9 06:36:51.017: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr  9 06:36:51.060: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr  9 06:36:51.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388611, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388611, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388611, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388611, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 06:36:53.105: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr  9 06:36:53.150: INFO: Updating deployment test-recreate-deployment
Apr  9 06:36:53.150: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  9 06:36:53.344: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-2214,SelfLink:/apis/apps/v1/namespaces/deployment-2214/deployments/test-recreate-deployment,UID:db73a070-5a91-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:3107,Generation:2,CreationTimestamp:2019-04-09 06:36:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-09 06:36:53 +0000 UTC 2019-04-09 06:36:53 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-09 06:36:53 +0000 UTC 2019-04-09 06:36:51 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr  9 06:36:53.366: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-2214,SelfLink:/apis/apps/v1/namespaces/deployment-2214/replicasets/test-recreate-deployment-c9cbd8684,UID:dcc42ddb-5a91-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:3106,Generation:1,CreationTimestamp:2019-04-09 06:36:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment db73a070-5a91-11e9-8ec1-5e80bdd8d9d6 0xc002b7b440 0xc002b7b441}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  9 06:36:53.366: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr  9 06:36:53.366: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-2214,SelfLink:/apis/apps/v1/namespaces/deployment-2214/replicasets/test-recreate-deployment-7d57d5ff7c,UID:db748b6d-5a91-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:3098,Generation:2,CreationTimestamp:2019-04-09 06:36:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment db73a070-5a91-11e9-8ec1-5e80bdd8d9d6 0xc002b7b387 0xc002b7b388}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  9 06:36:53.388: INFO: Pod "test-recreate-deployment-c9cbd8684-rv5mm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-rv5mm,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-2214,SelfLink:/api/v1/namespaces/deployment-2214/pods/test-recreate-deployment-c9cbd8684-rv5mm,UID:dcc4f457-5a91-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:3104,Generation:0,CreationTimestamp:2019-04-09 06:36:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 dcc42ddb-5a91-11e9-8ec1-5e80bdd8d9d6 0xc002524630 0xc002524631}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-hcw62 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hcw62,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hcw62 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002524690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025246b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:36:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:36:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:36:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:36:53 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 06:36:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:36:53.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2214" for this suite.
Apr  9 06:36:59.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:37:00.266: INFO: namespace deployment-2214 deletion completed in 6.854828667s
•
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:37:00.266: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4774
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Apr  9 06:37:00.593: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config cluster-info'
Apr  9 06:37:00.789: INFO: stderr: ""
Apr  9 06:37:00.789: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:37:00.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4774" for this suite.
Apr  9 06:37:07.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:37:07.925: INFO: namespace kubectl-4774 deletion completed in 7.114804101s
•SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:37:07.926: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8212
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  9 06:37:08.193: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-8212'
Apr  9 06:37:08.525: INFO: stderr: ""
Apr  9 06:37:08.525: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr  9 06:37:13.575: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pod e2e-test-nginx-pod --namespace=kubectl-8212 -o json'
Apr  9 06:37:13.734: INFO: stderr: ""
Apr  9 06:37:13.734: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.0.20/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-04-09T06:37:08Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-8212\",\n        \"resourceVersion\": \"3184\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8212/pods/e2e-test-nginx-pod\",\n        \"uid\": \"e5e088b3-5a91-11e9-8ec1-5e80bdd8d9d6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-ddz96\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-ddz96\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-ddz96\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-09T06:37:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-09T06:37:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-09T06:37:09Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-09T06:37:08Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://49607c6689aacdaed9e07e44fa37608ee39fbd246bfadb6f0fb2fad317cd2269\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-09T06:37:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.2\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.0.20\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-09T06:37:08Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr  9 06:37:13.734: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config replace -f - --namespace=kubectl-8212'
Apr  9 06:37:14.081: INFO: stderr: ""
Apr  9 06:37:14.081: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Apr  9 06:37:14.103: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-8212'
Apr  9 06:37:17.857: INFO: stderr: ""
Apr  9 06:37:17.857: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:37:17.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8212" for this suite.
Apr  9 06:37:23.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:37:24.733: INFO: namespace kubectl-8212 deletion completed in 6.854321654s
•S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:37:24.733: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-efb5cee7-5a91-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 06:37:25.042: INFO: Waiting up to 5m0s for pod "pod-secrets-efb931a5-5a91-11e9-8d38-4647074cf119" in namespace "secrets-4566" to be "success or failure"
Apr  9 06:37:25.063: INFO: Pod "pod-secrets-efb931a5-5a91-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.237765ms
Apr  9 06:37:27.086: INFO: Pod "pod-secrets-efb931a5-5a91-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043638943s
STEP: Saw pod success
Apr  9 06:37:27.086: INFO: Pod "pod-secrets-efb931a5-5a91-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:37:27.107: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-secrets-efb931a5-5a91-11e9-8d38-4647074cf119 container secret-volume-test: <nil>
STEP: delete the pod
Apr  9 06:37:27.165: INFO: Waiting for pod pod-secrets-efb931a5-5a91-11e9-8d38-4647074cf119 to disappear
Apr  9 06:37:27.186: INFO: Pod pod-secrets-efb931a5-5a91-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:37:27.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4566" for this suite.
Apr  9 06:37:33.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:37:34.061: INFO: namespace secrets-4566 deletion completed in 6.852848751s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:37:34.062: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7207
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  9 06:37:34.397: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7207'
Apr  9 06:37:34.598: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  9 06:37:34.598: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Apr  9 06:37:34.645: INFO: scanned /root for discovery docs: <nil>
Apr  9 06:37:34.645: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7207'
Apr  9 06:37:45.843: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  9 06:37:45.843: INFO: stdout: "Created e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda\nScaling up e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr  9 06:37:45.843: INFO: stdout: "Created e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda\nScaling up e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr  9 06:37:45.843: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7207'
Apr  9 06:37:45.996: INFO: stderr: ""
Apr  9 06:37:45.997: INFO: stdout: "e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda-ljk9s "
Apr  9 06:37:45.997: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda-ljk9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7207'
Apr  9 06:37:46.155: INFO: stderr: ""
Apr  9 06:37:46.155: INFO: stdout: "true"
Apr  9 06:37:46.155: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda-ljk9s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7207'
Apr  9 06:37:46.304: INFO: stderr: ""
Apr  9 06:37:46.304: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr  9 06:37:46.304: INFO: e2e-test-nginx-rc-e85568af5997da221116080fe32d5fda-ljk9s is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Apr  9 06:37:46.304: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-7207'
Apr  9 06:37:46.478: INFO: stderr: ""
Apr  9 06:37:46.478: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:37:46.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7207" for this suite.
Apr  9 06:37:52.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:37:53.343: INFO: namespace kubectl-7207 deletion completed in 6.842412424s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:37:53.343: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2115
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 06:37:53.640: INFO: (0) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 24.085278ms)
Apr  9 06:37:53.683: INFO: (1) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.040287ms)
Apr  9 06:37:53.707: INFO: (2) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.995125ms)
Apr  9 06:37:53.731: INFO: (3) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.66751ms)
Apr  9 06:37:53.754: INFO: (4) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.442652ms)
Apr  9 06:37:53.778: INFO: (5) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.368107ms)
Apr  9 06:37:53.801: INFO: (6) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.478744ms)
Apr  9 06:37:53.825: INFO: (7) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.876528ms)
Apr  9 06:37:53.849: INFO: (8) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.714373ms)
Apr  9 06:37:53.873: INFO: (9) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.810419ms)
Apr  9 06:37:53.897: INFO: (10) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 24.047986ms)
Apr  9 06:37:53.921: INFO: (11) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 24.12171ms)
Apr  9 06:37:53.945: INFO: (12) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.872896ms)
Apr  9 06:37:53.969: INFO: (13) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.560032ms)
Apr  9 06:37:53.993: INFO: (14) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.766285ms)
Apr  9 06:37:54.016: INFO: (15) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.751566ms)
Apr  9 06:37:54.040: INFO: (16) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.4988ms)
Apr  9 06:37:54.064: INFO: (17) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.642478ms)
Apr  9 06:37:54.087: INFO: (18) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 23.775988ms)
Apr  9 06:37:54.112: INFO: (19) /api/v1/nodes/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 24.602517ms)
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:37:54.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2115" for this suite.
Apr  9 06:38:02.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:38:03.031: INFO: namespace proxy-2115 deletion completed in 8.880865583s
•SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:38:03.032: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1089
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-1089
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  9 06:38:03.379: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  9 06:38:29.781: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.25 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1089 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:38:29.781: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:38:31.294: INFO: Found all expected endpoints: [netserver-0]
Apr  9 06:38:31.316: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.0.23 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1089 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:38:31.316: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:38:32.796: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:38:32.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1089" for this suite.
Apr  9 06:38:56.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:38:57.667: INFO: namespace pod-network-test-1089 deletion completed in 24.848986241s
•SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:38:57.667: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3567
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  9 06:38:58.015: INFO: Waiting up to 5m0s for pod "downward-api-2723de9c-5a92-11e9-8d38-4647074cf119" in namespace "downward-api-3567" to be "success or failure"
Apr  9 06:38:58.035: INFO: Pod "downward-api-2723de9c-5a92-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.508456ms
Apr  9 06:39:00.058: INFO: Pod "downward-api-2723de9c-5a92-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042877484s
STEP: Saw pod success
Apr  9 06:39:00.058: INFO: Pod "downward-api-2723de9c-5a92-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:39:00.080: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downward-api-2723de9c-5a92-11e9-8d38-4647074cf119 container dapi-container: <nil>
STEP: delete the pod
Apr  9 06:39:00.139: INFO: Waiting for pod downward-api-2723de9c-5a92-11e9-8d38-4647074cf119 to disappear
Apr  9 06:39:00.160: INFO: Pod downward-api-2723de9c-5a92-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:39:00.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3567" for this suite.
Apr  9 06:39:06.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:39:07.034: INFO: namespace downward-api-3567 deletion completed in 6.851461429s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:39:07.034: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2393
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6830
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3743
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:39:14.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2393" for this suite.
Apr  9 06:39:20.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:39:21.008: INFO: namespace namespaces-2393 deletion completed in 6.892810934s
STEP: Destroying namespace "nsdeletetest-6830" for this suite.
Apr  9 06:39:21.029: INFO: Namespace nsdeletetest-6830 was already deleted
STEP: Destroying namespace "nsdeletetest-3743" for this suite.
Apr  9 06:39:27.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:39:27.886: INFO: namespace nsdeletetest-3743 deletion completed in 6.856312706s
•
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:39:27.886: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-392508e6-5a92-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 06:39:28.245: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3928acbd-5a92-11e9-8d38-4647074cf119" in namespace "projected-4110" to be "success or failure"
Apr  9 06:39:28.267: INFO: Pod "pod-projected-configmaps-3928acbd-5a92-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.426889ms
Apr  9 06:39:30.289: INFO: Pod "pod-projected-configmaps-3928acbd-5a92-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043530198s
STEP: Saw pod success
Apr  9 06:39:30.289: INFO: Pod "pod-projected-configmaps-3928acbd-5a92-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:39:30.311: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-configmaps-3928acbd-5a92-11e9-8d38-4647074cf119 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 06:39:30.418: INFO: Waiting for pod pod-projected-configmaps-3928acbd-5a92-11e9-8d38-4647074cf119 to disappear
Apr  9 06:39:30.439: INFO: Pod pod-projected-configmaps-3928acbd-5a92-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:39:30.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4110" for this suite.
Apr  9 06:39:36.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:39:37.318: INFO: namespace projected-4110 deletion completed in 6.856196902s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:39:37.318: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-192
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 06:39:37.705: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3ecc235a-5a92-11e9-8d38-4647074cf119" in namespace "projected-192" to be "success or failure"
Apr  9 06:39:37.726: INFO: Pod "downwardapi-volume-3ecc235a-5a92-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.909297ms
Apr  9 06:39:39.749: INFO: Pod "downwardapi-volume-3ecc235a-5a92-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043634143s
STEP: Saw pod success
Apr  9 06:39:39.749: INFO: Pod "downwardapi-volume-3ecc235a-5a92-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:39:39.771: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-3ecc235a-5a92-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 06:39:39.828: INFO: Waiting for pod downwardapi-volume-3ecc235a-5a92-11e9-8d38-4647074cf119 to disappear
Apr  9 06:39:39.850: INFO: Pod downwardapi-volume-3ecc235a-5a92-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:39:39.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-192" for this suite.
Apr  9 06:39:45.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:39:46.725: INFO: namespace projected-192 deletion completed in 6.85384218s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:39:46.726: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-606
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:39:47.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-606" for this suite.
Apr  9 06:40:11.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:40:11.931: INFO: namespace pods-606 deletion completed in 24.867648136s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:40:11.931: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4147
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0409 06:40:18.355920    5079 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  9 06:40:18.355: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:40:18.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4147" for this suite.
Apr  9 06:40:24.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:40:25.222: INFO: namespace gc-4147 deletion completed in 6.844557808s
•SSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:40:25.222: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-7103
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Apr  9 06:40:26.063: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 06:40:28.086: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 06:40:30.085: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 06:40:32.087: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690388825, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 06:40:35.736: INFO: Waited 1.627416622s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:40:37.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7103" for this suite.
Apr  9 06:40:43.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:40:44.157: INFO: namespace aggregator-7103 deletion completed in 6.918801317s
•SSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:40:44.157: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-7837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr  9 06:40:48.668: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:48.668: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:49.153: INFO: Exec stderr: ""
Apr  9 06:40:49.153: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:49.153: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:49.635: INFO: Exec stderr: ""
Apr  9 06:40:49.635: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:49.635: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:50.198: INFO: Exec stderr: ""
Apr  9 06:40:50.198: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:50.198: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:50.746: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr  9 06:40:50.746: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:50.746: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:51.192: INFO: Exec stderr: ""
Apr  9 06:40:51.192: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:51.192: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:51.664: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr  9 06:40:51.664: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:51.664: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:52.174: INFO: Exec stderr: ""
Apr  9 06:40:52.175: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:52.175: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:52.701: INFO: Exec stderr: ""
Apr  9 06:40:52.701: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:52.701: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:53.222: INFO: Exec stderr: ""
Apr  9 06:40:53.222: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7837 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 06:40:53.222: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 06:40:53.793: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:40:53.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-7837" for this suite.
Apr  9 06:41:37.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:41:38.909: INFO: namespace e2e-kubelet-etc-hosts-7837 deletion completed in 45.094788423s
•SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:41:38.909: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2565
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  9 06:41:39.224: INFO: Waiting up to 5m0s for pod "pod-87396d38-5a92-11e9-8d38-4647074cf119" in namespace "emptydir-2565" to be "success or failure"
Apr  9 06:41:39.245: INFO: Pod "pod-87396d38-5a92-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.805082ms
Apr  9 06:41:41.267: INFO: Pod "pod-87396d38-5a92-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042861698s
STEP: Saw pod success
Apr  9 06:41:41.267: INFO: Pod "pod-87396d38-5a92-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:41:41.289: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-87396d38-5a92-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 06:41:41.351: INFO: Waiting for pod pod-87396d38-5a92-11e9-8d38-4647074cf119 to disappear
Apr  9 06:41:41.373: INFO: Pod pod-87396d38-5a92-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:41:41.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2565" for this suite.
Apr  9 06:41:47.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:41:48.245: INFO: namespace emptydir-2565 deletion completed in 6.85077982s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:41:48.245: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8297
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 06:41:48.516: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8cc40af0-5a92-11e9-8d38-4647074cf119" in namespace "downward-api-8297" to be "success or failure"
Apr  9 06:41:48.537: INFO: Pod "downwardapi-volume-8cc40af0-5a92-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.94316ms
Apr  9 06:41:50.558: INFO: Pod "downwardapi-volume-8cc40af0-5a92-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042565151s
STEP: Saw pod success
Apr  9 06:41:50.558: INFO: Pod "downwardapi-volume-8cc40af0-5a92-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:41:50.580: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-8cc40af0-5a92-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 06:41:50.636: INFO: Waiting for pod downwardapi-volume-8cc40af0-5a92-11e9-8d38-4647074cf119 to disappear
Apr  9 06:41:50.657: INFO: Pod downwardapi-volume-8cc40af0-5a92-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:41:50.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8297" for this suite.
Apr  9 06:41:56.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:41:57.577: INFO: namespace downward-api-8297 deletion completed in 6.897954175s
•SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:41:57.577: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6177
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9vw84 in namespace proxy-6177
I0409 06:41:58.032874    5079 runners.go:184] Created replication controller with name: proxy-service-9vw84, namespace: proxy-6177, replica count: 1
I0409 06:41:59.083513    5079 runners.go:184] proxy-service-9vw84 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0409 06:42:00.083784    5079 runners.go:184] proxy-service-9vw84 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0409 06:42:01.084087    5079 runners.go:184] proxy-service-9vw84 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0409 06:42:02.084378    5079 runners.go:184] proxy-service-9vw84 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  9 06:42:02.106: INFO: setup took 4.126158369s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr  9 06:42:02.133: INFO: (0) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 26.657001ms)
Apr  9 06:42:02.134: INFO: (0) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 27.913016ms)
Apr  9 06:42:02.134: INFO: (0) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 27.925774ms)
Apr  9 06:42:02.134: INFO: (0) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 27.961758ms)
Apr  9 06:42:02.134: INFO: (0) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 27.999606ms)
Apr  9 06:42:02.134: INFO: (0) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 28.384772ms)
Apr  9 06:42:02.134: INFO: (0) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 28.245783ms)
Apr  9 06:42:02.134: INFO: (0) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 28.01258ms)
Apr  9 06:42:02.142: INFO: (0) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 35.502534ms)
Apr  9 06:42:02.143: INFO: (0) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 37.059054ms)
Apr  9 06:42:02.151: INFO: (0) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 44.766582ms)
Apr  9 06:42:02.151: INFO: (0) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 44.826785ms)
Apr  9 06:42:02.151: INFO: (0) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 44.8445ms)
Apr  9 06:42:02.152: INFO: (0) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 45.856857ms)
Apr  9 06:42:02.287: INFO: (0) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 180.182422ms)
Apr  9 06:42:02.287: INFO: (0) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 180.268011ms)
Apr  9 06:42:02.311: INFO: (1) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 23.704661ms)
Apr  9 06:42:02.311: INFO: (1) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 23.83124ms)
Apr  9 06:42:02.311: INFO: (1) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 23.791929ms)
Apr  9 06:42:02.311: INFO: (1) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 23.835815ms)
Apr  9 06:42:02.311: INFO: (1) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 23.816075ms)
Apr  9 06:42:02.311: INFO: (1) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 24.337043ms)
Apr  9 06:42:02.312: INFO: (1) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 24.369759ms)
Apr  9 06:42:02.312: INFO: (1) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 24.351708ms)
Apr  9 06:42:02.312: INFO: (1) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 24.38429ms)
Apr  9 06:42:02.312: INFO: (1) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 25.144256ms)
Apr  9 06:42:02.313: INFO: (1) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 25.85859ms)
Apr  9 06:42:02.313: INFO: (1) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 25.954322ms)
Apr  9 06:42:02.313: INFO: (1) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 25.631227ms)
Apr  9 06:42:02.313: INFO: (1) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 26.191706ms)
Apr  9 06:42:02.313: INFO: (1) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 25.812268ms)
Apr  9 06:42:02.313: INFO: (1) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 25.627624ms)
Apr  9 06:42:02.342: INFO: (2) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 27.894992ms)
Apr  9 06:42:02.342: INFO: (2) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 28.035055ms)
Apr  9 06:42:02.342: INFO: (2) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 29.016222ms)
Apr  9 06:42:02.342: INFO: (2) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 28.440808ms)
Apr  9 06:42:02.342: INFO: (2) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 28.53062ms)
Apr  9 06:42:02.342: INFO: (2) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 28.969597ms)
Apr  9 06:42:02.343: INFO: (2) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 28.652146ms)
Apr  9 06:42:02.343: INFO: (2) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 28.383292ms)
Apr  9 06:42:02.343: INFO: (2) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 29.341826ms)
Apr  9 06:42:02.343: INFO: (2) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 28.9818ms)
Apr  9 06:42:02.343: INFO: (2) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 28.28585ms)
Apr  9 06:42:02.343: INFO: (2) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 29.316823ms)
Apr  9 06:42:02.343: INFO: (2) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 29.115579ms)
Apr  9 06:42:02.343: INFO: (2) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 29.196746ms)
Apr  9 06:42:02.343: INFO: (2) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 28.812355ms)
Apr  9 06:42:02.344: INFO: (2) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 30.212132ms)
Apr  9 06:42:02.370: INFO: (3) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 25.651519ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.76719ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.997928ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 25.897637ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 25.830115ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 25.863415ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.813424ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 26.071809ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 25.830057ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 26.052467ms)
Apr  9 06:42:02.371: INFO: (3) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 26.001047ms)
Apr  9 06:42:02.392: INFO: (3) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 47.29226ms)
Apr  9 06:42:02.414: INFO: (3) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 69.137844ms)
Apr  9 06:42:02.414: INFO: (3) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 69.120989ms)
Apr  9 06:42:02.414: INFO: (3) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 69.177026ms)
Apr  9 06:42:02.414: INFO: (3) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 69.20443ms)
Apr  9 06:42:02.439: INFO: (4) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 24.949944ms)
Apr  9 06:42:02.439: INFO: (4) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.985191ms)
Apr  9 06:42:02.439: INFO: (4) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 24.978ms)
Apr  9 06:42:02.439: INFO: (4) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 24.902761ms)
Apr  9 06:42:02.439: INFO: (4) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.939288ms)
Apr  9 06:42:02.439: INFO: (4) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 25.037973ms)
Apr  9 06:42:02.440: INFO: (4) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 25.83789ms)
Apr  9 06:42:02.440: INFO: (4) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.675862ms)
Apr  9 06:42:02.440: INFO: (4) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 26.03288ms)
Apr  9 06:42:02.440: INFO: (4) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 25.925614ms)
Apr  9 06:42:02.440: INFO: (4) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 25.967751ms)
Apr  9 06:42:02.440: INFO: (4) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 26.03186ms)
Apr  9 06:42:02.482: INFO: (4) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 67.544436ms)
Apr  9 06:42:02.482: INFO: (4) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 67.729397ms)
Apr  9 06:42:02.482: INFO: (4) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 67.607816ms)
Apr  9 06:42:02.483: INFO: (4) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 68.743852ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 23.918007ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 24.458985ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 24.505182ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 24.973191ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 24.983873ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 25.119199ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.97277ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 24.994286ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.047198ms)
Apr  9 06:42:02.508: INFO: (5) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 25.1086ms)
Apr  9 06:42:02.509: INFO: (5) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 26.381525ms)
Apr  9 06:42:02.509: INFO: (5) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 26.227908ms)
Apr  9 06:42:02.509: INFO: (5) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 26.421894ms)
Apr  9 06:42:02.551: INFO: (5) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 68.170396ms)
Apr  9 06:42:02.551: INFO: (5) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 68.21768ms)
Apr  9 06:42:02.551: INFO: (5) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 68.328993ms)
Apr  9 06:42:02.576: INFO: (6) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.178579ms)
Apr  9 06:42:02.576: INFO: (6) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 24.566887ms)
Apr  9 06:42:02.576: INFO: (6) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 24.404885ms)
Apr  9 06:42:02.576: INFO: (6) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.351843ms)
Apr  9 06:42:02.576: INFO: (6) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 24.493579ms)
Apr  9 06:42:02.576: INFO: (6) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 24.703634ms)
Apr  9 06:42:02.576: INFO: (6) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 24.744856ms)
Apr  9 06:42:02.576: INFO: (6) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 24.582225ms)
Apr  9 06:42:02.576: INFO: (6) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 24.750961ms)
Apr  9 06:42:02.577: INFO: (6) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 24.721397ms)
Apr  9 06:42:02.577: INFO: (6) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 25.41867ms)
Apr  9 06:42:02.577: INFO: (6) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 25.50961ms)
Apr  9 06:42:02.577: INFO: (6) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 25.743374ms)
Apr  9 06:42:02.577: INFO: (6) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 25.799957ms)
Apr  9 06:42:02.577: INFO: (6) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 25.50291ms)
Apr  9 06:42:02.577: INFO: (6) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 25.585595ms)
Apr  9 06:42:02.602: INFO: (7) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.306932ms)
Apr  9 06:42:02.602: INFO: (7) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 24.278677ms)
Apr  9 06:42:02.602: INFO: (7) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.219847ms)
Apr  9 06:42:02.602: INFO: (7) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 24.186056ms)
Apr  9 06:42:02.602: INFO: (7) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 24.271368ms)
Apr  9 06:42:02.606: INFO: (7) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 27.983492ms)
Apr  9 06:42:02.606: INFO: (7) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 28.043342ms)
Apr  9 06:42:02.607: INFO: (7) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 29.035108ms)
Apr  9 06:42:02.607: INFO: (7) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 29.113246ms)
Apr  9 06:42:02.607: INFO: (7) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 29.230619ms)
Apr  9 06:42:02.607: INFO: (7) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 29.16215ms)
Apr  9 06:42:02.607: INFO: (7) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 29.128005ms)
Apr  9 06:42:02.607: INFO: (7) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 29.126876ms)
Apr  9 06:42:02.607: INFO: (7) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 29.158193ms)
Apr  9 06:42:02.608: INFO: (7) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 30.357605ms)
Apr  9 06:42:02.609: INFO: (7) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 30.90326ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.269199ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 24.45648ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 24.6366ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 24.739707ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.684101ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 25.445353ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.057869ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.012135ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 25.186466ms)
Apr  9 06:42:02.634: INFO: (8) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 25.425012ms)
Apr  9 06:42:02.635: INFO: (8) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 25.889114ms)
Apr  9 06:42:02.635: INFO: (8) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 26.238056ms)
Apr  9 06:42:02.636: INFO: (8) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 25.733419ms)
Apr  9 06:42:02.636: INFO: (8) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 27.376441ms)
Apr  9 06:42:02.636: INFO: (8) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 27.684841ms)
Apr  9 06:42:02.637: INFO: (8) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 26.663399ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 55.535895ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 55.637224ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 55.840971ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 56.395021ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 55.764375ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 55.806091ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 55.749636ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 56.026784ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 55.765762ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 55.91417ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 55.827215ms)
Apr  9 06:42:02.693: INFO: (9) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 56.235141ms)
Apr  9 06:42:02.704: INFO: (9) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 66.578049ms)
Apr  9 06:42:02.704: INFO: (9) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 66.898015ms)
Apr  9 06:42:02.704: INFO: (9) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 67.053728ms)
Apr  9 06:42:02.704: INFO: (9) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 66.583507ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 24.648661ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.664626ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 24.762324ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.625945ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 24.780576ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 24.871855ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 24.717735ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 24.660047ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 24.908958ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 25.039271ms)
Apr  9 06:42:02.729: INFO: (10) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 25.192569ms)
Apr  9 06:42:02.730: INFO: (10) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 26.43517ms)
Apr  9 06:42:02.730: INFO: (10) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 26.509717ms)
Apr  9 06:42:02.730: INFO: (10) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 26.441916ms)
Apr  9 06:42:02.730: INFO: (10) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 26.553902ms)
Apr  9 06:42:02.730: INFO: (10) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 26.436367ms)
Apr  9 06:42:02.755: INFO: (11) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 24.681697ms)
Apr  9 06:42:02.755: INFO: (11) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 24.815971ms)
Apr  9 06:42:02.755: INFO: (11) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 24.646969ms)
Apr  9 06:42:02.756: INFO: (11) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 24.847394ms)
Apr  9 06:42:02.756: INFO: (11) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 24.913345ms)
Apr  9 06:42:02.756: INFO: (11) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.079597ms)
Apr  9 06:42:02.756: INFO: (11) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 24.95036ms)
Apr  9 06:42:02.756: INFO: (11) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 25.082151ms)
Apr  9 06:42:02.756: INFO: (11) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 25.419613ms)
Apr  9 06:42:02.756: INFO: (11) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 25.301235ms)
Apr  9 06:42:02.756: INFO: (11) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 25.362055ms)
Apr  9 06:42:02.756: INFO: (11) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 25.454038ms)
Apr  9 06:42:02.758: INFO: (11) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 27.658967ms)
Apr  9 06:42:02.758: INFO: (11) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 27.521549ms)
Apr  9 06:42:02.758: INFO: (11) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 27.771171ms)
Apr  9 06:42:02.758: INFO: (11) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 27.66039ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 38.56705ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 38.342263ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 38.420261ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 39.374517ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 38.957703ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 38.559684ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 38.692996ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 39.12825ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 38.974067ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 39.101386ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 39.287202ms)
Apr  9 06:42:02.798: INFO: (12) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 39.139579ms)
Apr  9 06:42:02.799: INFO: (12) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 40.731832ms)
Apr  9 06:42:02.840: INFO: (12) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 81.343412ms)
Apr  9 06:42:02.840: INFO: (12) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 81.458891ms)
Apr  9 06:42:02.840: INFO: (12) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 81.157235ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 26.702895ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 26.507243ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 26.425366ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 26.585471ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 26.385005ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 26.484577ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 26.755666ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 26.877085ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 26.562552ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 26.412571ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 26.960975ms)
Apr  9 06:42:02.867: INFO: (13) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 26.735738ms)
Apr  9 06:42:02.911: INFO: (13) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 70.467529ms)
Apr  9 06:42:02.911: INFO: (13) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 70.358481ms)
Apr  9 06:42:02.911: INFO: (13) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 70.694526ms)
Apr  9 06:42:02.911: INFO: (13) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 70.817949ms)
Apr  9 06:42:02.936: INFO: (14) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.050726ms)
Apr  9 06:42:02.936: INFO: (14) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 24.800574ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.350077ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 25.271591ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 25.475952ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.450018ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 25.378738ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 25.492244ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.376189ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 25.566495ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 25.616043ms)
Apr  9 06:42:02.937: INFO: (14) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 25.544913ms)
Apr  9 06:42:02.974: INFO: (14) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 62.241208ms)
Apr  9 06:42:02.974: INFO: (14) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 62.048575ms)
Apr  9 06:42:02.974: INFO: (14) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 62.197006ms)
Apr  9 06:42:02.974: INFO: (14) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 62.386274ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.00843ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 25.122426ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 24.944624ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 25.41446ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.369051ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 25.013073ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.111839ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 25.230593ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 25.190603ms)
Apr  9 06:42:02.999: INFO: (15) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 25.587689ms)
Apr  9 06:42:03.000: INFO: (15) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 26.01602ms)
Apr  9 06:42:03.000: INFO: (15) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 26.002022ms)
Apr  9 06:42:03.000: INFO: (15) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 26.566371ms)
Apr  9 06:42:03.000: INFO: (15) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 26.50772ms)
Apr  9 06:42:03.001: INFO: (15) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 26.797087ms)
Apr  9 06:42:03.001: INFO: (15) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 26.795353ms)
Apr  9 06:42:03.027: INFO: (16) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 26.201988ms)
Apr  9 06:42:03.027: INFO: (16) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 26.165729ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 26.307763ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 26.561436ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 26.171397ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 26.47144ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 26.097628ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 26.586142ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 27.05327ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 26.834995ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 27.115788ms)
Apr  9 06:42:03.028: INFO: (16) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 27.042141ms)
Apr  9 06:42:03.029: INFO: (16) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 27.818918ms)
Apr  9 06:42:03.029: INFO: (16) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 27.674162ms)
Apr  9 06:42:03.029: INFO: (16) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 27.916ms)
Apr  9 06:42:03.029: INFO: (16) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 27.781593ms)
Apr  9 06:42:03.053: INFO: (17) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 23.427791ms)
Apr  9 06:42:03.053: INFO: (17) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 23.882819ms)
Apr  9 06:42:03.053: INFO: (17) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 23.778925ms)
Apr  9 06:42:03.053: INFO: (17) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 23.675298ms)
Apr  9 06:42:03.053: INFO: (17) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 23.076295ms)
Apr  9 06:42:03.055: INFO: (17) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 24.29344ms)
Apr  9 06:42:03.055: INFO: (17) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 24.696279ms)
Apr  9 06:42:03.055: INFO: (17) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 24.920091ms)
Apr  9 06:42:03.055: INFO: (17) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 24.866211ms)
Apr  9 06:42:03.055: INFO: (17) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 24.697601ms)
Apr  9 06:42:03.055: INFO: (17) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 24.566745ms)
Apr  9 06:42:03.055: INFO: (17) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 24.98762ms)
Apr  9 06:42:03.055: INFO: (17) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 24.775336ms)
Apr  9 06:42:03.096: INFO: (17) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 66.106898ms)
Apr  9 06:42:03.097: INFO: (17) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 66.427377ms)
Apr  9 06:42:03.098: INFO: (17) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 67.873093ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 25.082697ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 25.457961ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.372022ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 25.226302ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.320557ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 25.307754ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 25.556699ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.457915ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 25.329026ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.456611ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 25.546847ms)
Apr  9 06:42:03.123: INFO: (18) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 25.541059ms)
Apr  9 06:42:03.125: INFO: (18) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 26.776445ms)
Apr  9 06:42:03.167: INFO: (18) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 68.71443ms)
Apr  9 06:42:03.167: INFO: (18) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 68.641562ms)
Apr  9 06:42:03.167: INFO: (18) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 68.607025ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.890667ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp/proxy/rewriteme">test</a> (200; 25.732306ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.920489ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:160/proxy/: foo (200; 25.996928ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:162/proxy/: bar (200; 25.937664ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">test<... (200; 26.141992ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:460/proxy/: tls baz (200; 25.880691ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/http:proxy-service-9vw84-r4gvp:1080/proxy/rewriteme">... (200; 25.920359ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/: <a href="/api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:443/proxy/tlsrewritem... (200; 25.844056ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/pods/https:proxy-service-9vw84-r4gvp:462/proxy/: tls qux (200; 26.213222ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname2/proxy/: tls qux (200; 26.233605ms)
Apr  9 06:42:03.193: INFO: (19) /api/v1/namespaces/proxy-6177/services/https:proxy-service-9vw84:tlsportname1/proxy/: tls baz (200; 26.235179ms)
Apr  9 06:42:03.194: INFO: (19) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname1/proxy/: foo (200; 27.339045ms)
Apr  9 06:42:03.194: INFO: (19) /api/v1/namespaces/proxy-6177/services/http:proxy-service-9vw84:portname2/proxy/: bar (200; 27.472401ms)
Apr  9 06:42:03.194: INFO: (19) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname1/proxy/: foo (200; 27.139169ms)
Apr  9 06:42:03.194: INFO: (19) /api/v1/namespaces/proxy-6177/services/proxy-service-9vw84:portname2/proxy/: bar (200; 27.427971ms)
STEP: deleting ReplicationController proxy-service-9vw84 in namespace proxy-6177, will wait for the garbage collector to delete the pods
Apr  9 06:42:03.295: INFO: Deleting ReplicationController proxy-service-9vw84 took: 27.943753ms
Apr  9 06:42:03.695: INFO: Terminating ReplicationController proxy-service-9vw84 pods took: 400.260669ms
[AfterEach] version v1
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:42:05.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6177" for this suite.
Apr  9 06:42:11.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:42:12.696: INFO: namespace proxy-6177 deletion completed in 6.879133808s
•SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:42:12.696: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1032
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-wcd7
STEP: Creating a pod to test atomic-volume-subpath
Apr  9 06:42:13.066: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-wcd7" in namespace "subpath-1032" to be "success or failure"
Apr  9 06:42:13.087: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Pending", Reason="", readiness=false. Elapsed: 21.067675ms
Apr  9 06:42:15.109: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 2.043525495s
Apr  9 06:42:17.131: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 4.065544163s
Apr  9 06:42:19.154: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 6.08774881s
Apr  9 06:42:21.176: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 8.110555805s
Apr  9 06:42:23.198: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 10.132090094s
Apr  9 06:42:25.221: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 12.155022099s
Apr  9 06:42:27.243: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 14.177334231s
Apr  9 06:42:29.266: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 16.200052136s
Apr  9 06:42:31.289: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 18.223511006s
Apr  9 06:42:33.312: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Running", Reason="", readiness=true. Elapsed: 20.246106331s
Apr  9 06:42:35.335: INFO: Pod "pod-subpath-test-downwardapi-wcd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.26911792s
STEP: Saw pod success
Apr  9 06:42:35.335: INFO: Pod "pod-subpath-test-downwardapi-wcd7" satisfied condition "success or failure"
Apr  9 06:42:35.357: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-subpath-test-downwardapi-wcd7 container test-container-subpath-downwardapi-wcd7: <nil>
STEP: delete the pod
Apr  9 06:42:35.416: INFO: Waiting for pod pod-subpath-test-downwardapi-wcd7 to disappear
Apr  9 06:42:35.436: INFO: Pod pod-subpath-test-downwardapi-wcd7 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-wcd7
Apr  9 06:42:35.437: INFO: Deleting pod "pod-subpath-test-downwardapi-wcd7" in namespace "subpath-1032"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:42:35.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1032" for this suite.
Apr  9 06:42:43.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:42:44.332: INFO: namespace subpath-1032 deletion completed in 8.852307359s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:42:44.333: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7025
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-7025/configmap-test-ae3464fb-5a92-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 06:42:44.638: INFO: Waiting up to 5m0s for pod "pod-configmaps-ae37c346-5a92-11e9-8d38-4647074cf119" in namespace "configmap-7025" to be "success or failure"
Apr  9 06:42:44.659: INFO: Pod "pod-configmaps-ae37c346-5a92-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.372038ms
Apr  9 06:42:46.682: INFO: Pod "pod-configmaps-ae37c346-5a92-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044117526s
STEP: Saw pod success
Apr  9 06:42:46.682: INFO: Pod "pod-configmaps-ae37c346-5a92-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:42:46.704: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-ae37c346-5a92-11e9-8d38-4647074cf119 container env-test: <nil>
STEP: delete the pod
Apr  9 06:42:46.759: INFO: Waiting for pod pod-configmaps-ae37c346-5a92-11e9-8d38-4647074cf119 to disappear
Apr  9 06:42:46.781: INFO: Pod pod-configmaps-ae37c346-5a92-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:42:46.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7025" for this suite.
Apr  9 06:42:52.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:42:53.688: INFO: namespace configmap-7025 deletion completed in 6.883476354s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:42:53.688: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:42:56.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6400" for this suite.
Apr  9 06:43:20.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:43:21.044: INFO: namespace replication-controller-6400 deletion completed in 24.896794674s
•
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:43:21.044: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7278
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-c4234e3e-5a92-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 06:43:21.436: INFO: Waiting up to 5m0s for pod "pod-secrets-c426a857-5a92-11e9-8d38-4647074cf119" in namespace "secrets-7278" to be "success or failure"
Apr  9 06:43:21.456: INFO: Pod "pod-secrets-c426a857-5a92-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.529383ms
Apr  9 06:43:23.478: INFO: Pod "pod-secrets-c426a857-5a92-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042352861s
STEP: Saw pod success
Apr  9 06:43:23.478: INFO: Pod "pod-secrets-c426a857-5a92-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:43:23.500: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-secrets-c426a857-5a92-11e9-8d38-4647074cf119 container secret-volume-test: <nil>
STEP: delete the pod
Apr  9 06:43:23.556: INFO: Waiting for pod pod-secrets-c426a857-5a92-11e9-8d38-4647074cf119 to disappear
Apr  9 06:43:23.577: INFO: Pod pod-secrets-c426a857-5a92-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:43:23.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7278" for this suite.
Apr  9 06:43:29.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:43:30.473: INFO: namespace secrets-7278 deletion completed in 6.874504442s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:43:30.474: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2172
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-3136
STEP: Creating secret with name secret-test-c9be0f33-5a92-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 06:43:31.237: INFO: Waiting up to 5m0s for pod "pod-secrets-c9fdb10d-5a92-11e9-8d38-4647074cf119" in namespace "secrets-2172" to be "success or failure"
Apr  9 06:43:31.259: INFO: Pod "pod-secrets-c9fdb10d-5a92-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.099397ms
Apr  9 06:43:33.280: INFO: Pod "pod-secrets-c9fdb10d-5a92-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043811514s
STEP: Saw pod success
Apr  9 06:43:33.280: INFO: Pod "pod-secrets-c9fdb10d-5a92-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:43:33.302: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-secrets-c9fdb10d-5a92-11e9-8d38-4647074cf119 container secret-volume-test: <nil>
STEP: delete the pod
Apr  9 06:43:33.360: INFO: Waiting for pod pod-secrets-c9fdb10d-5a92-11e9-8d38-4647074cf119 to disappear
Apr  9 06:43:33.381: INFO: Pod pod-secrets-c9fdb10d-5a92-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:43:33.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2172" for this suite.
Apr  9 06:43:41.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:43:42.295: INFO: namespace secrets-2172 deletion completed in 8.891473336s
STEP: Destroying namespace "secret-namespace-3136" for this suite.
Apr  9 06:43:48.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:43:49.177: INFO: namespace secret-namespace-3136 deletion completed in 6.881987174s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:43:49.177: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-8265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8265
I0409 06:43:49.517993    5079 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8265, replica count: 1
I0409 06:43:50.568375    5079 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0409 06:43:51.568634    5079 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  9 06:43:51.697: INFO: Created: latency-svc-f7jzk
Apr  9 06:43:51.701: INFO: Got endpoints: latency-svc-f7jzk [33.022983ms]
Apr  9 06:43:51.731: INFO: Created: latency-svc-xn5kl
Apr  9 06:43:51.737: INFO: Created: latency-svc-nq4lw
Apr  9 06:43:51.737: INFO: Got endpoints: latency-svc-xn5kl [35.105247ms]
Apr  9 06:43:51.748: INFO: Created: latency-svc-jqpqt
Apr  9 06:43:51.749: INFO: Created: latency-svc-lftnx
Apr  9 06:43:51.749: INFO: Got endpoints: latency-svc-lftnx [46.777363ms]
Apr  9 06:43:51.749: INFO: Got endpoints: latency-svc-nq4lw [47.268531ms]
Apr  9 06:43:51.753: INFO: Got endpoints: latency-svc-jqpqt [51.230559ms]
Apr  9 06:43:51.759: INFO: Created: latency-svc-zj5rd
Apr  9 06:43:51.759: INFO: Got endpoints: latency-svc-zj5rd [56.507977ms]
Apr  9 06:43:51.762: INFO: Created: latency-svc-vtlhm
Apr  9 06:43:51.765: INFO: Got endpoints: latency-svc-vtlhm [62.811701ms]
Apr  9 06:43:51.770: INFO: Created: latency-svc-ssqkc
Apr  9 06:43:51.800: INFO: Created: latency-svc-s5bqg
Apr  9 06:43:51.806: INFO: Got endpoints: latency-svc-s5bqg [103.547291ms]
Apr  9 06:43:51.806: INFO: Created: latency-svc-j2gm6
Apr  9 06:43:51.816: INFO: Created: latency-svc-4hgh5
Apr  9 06:43:51.822: INFO: Created: latency-svc-p8w6s
Apr  9 06:43:51.844: INFO: Got endpoints: latency-svc-j2gm6 [142.012109ms]
Apr  9 06:43:51.849: INFO: Got endpoints: latency-svc-4hgh5 [146.513857ms]
Apr  9 06:43:51.849: INFO: Got endpoints: latency-svc-p8w6s [146.623989ms]
Apr  9 06:43:51.849: INFO: Got endpoints: latency-svc-ssqkc [147.0305ms]
Apr  9 06:43:51.851: INFO: Created: latency-svc-47jbb
Apr  9 06:43:51.858: INFO: Created: latency-svc-s2gdn
Apr  9 06:43:51.858: INFO: Got endpoints: latency-svc-47jbb [155.098977ms]
Apr  9 06:43:51.893: INFO: Got endpoints: latency-svc-s2gdn [190.267617ms]
Apr  9 06:43:51.900: INFO: Created: latency-svc-zlll9
Apr  9 06:43:51.995: INFO: Got endpoints: latency-svc-zlll9 [292.637291ms]
Apr  9 06:43:51.998: INFO: Created: latency-svc-vptkz
Apr  9 06:43:51.999: INFO: Got endpoints: latency-svc-vptkz [295.94424ms]
Apr  9 06:43:52.114: INFO: Created: latency-svc-nfhch
Apr  9 06:43:52.193: INFO: Got endpoints: latency-svc-nfhch [455.497703ms]
Apr  9 06:43:52.196: INFO: Created: latency-svc-wlh7n
Apr  9 06:43:52.199: INFO: Got endpoints: latency-svc-wlh7n [450.56686ms]
Apr  9 06:43:52.210: INFO: Created: latency-svc-cx7x2
Apr  9 06:43:52.216: INFO: Got endpoints: latency-svc-cx7x2 [467.821646ms]
Apr  9 06:43:52.217: INFO: Created: latency-svc-vzwhr
Apr  9 06:43:52.223: INFO: Got endpoints: latency-svc-vzwhr [464.237326ms]
Apr  9 06:43:52.223: INFO: Created: latency-svc-x5cns
Apr  9 06:43:52.226: INFO: Got endpoints: latency-svc-x5cns [472.681763ms]
Apr  9 06:43:52.231: INFO: Created: latency-svc-vrrp7
Apr  9 06:43:52.238: INFO: Created: latency-svc-lgtj7
Apr  9 06:43:52.238: INFO: Got endpoints: latency-svc-vrrp7 [472.906345ms]
Apr  9 06:43:52.244: INFO: Created: latency-svc-7csw4
Apr  9 06:43:52.244: INFO: Got endpoints: latency-svc-lgtj7 [438.208057ms]
Apr  9 06:43:52.295: INFO: Created: latency-svc-5sc2j
Apr  9 06:43:52.295: INFO: Got endpoints: latency-svc-7csw4 [450.471451ms]
Apr  9 06:43:52.301: INFO: Got endpoints: latency-svc-5sc2j [451.638892ms]
Apr  9 06:43:52.305: INFO: Created: latency-svc-4zfpg
Apr  9 06:43:52.312: INFO: Created: latency-svc-g9kpw
Apr  9 06:43:52.312: INFO: Got endpoints: latency-svc-4zfpg [85.816937ms]
Apr  9 06:43:52.320: INFO: Created: latency-svc-4gmt8
Apr  9 06:43:52.324: INFO: Got endpoints: latency-svc-g9kpw [465.964945ms]
Apr  9 06:43:52.325: INFO: Created: latency-svc-m2h94
Apr  9 06:43:52.323: INFO: Got endpoints: latency-svc-4gmt8 [474.045796ms]
Apr  9 06:43:52.327: INFO: Got endpoints: latency-svc-m2h94 [478.077822ms]
Apr  9 06:43:52.350: INFO: Created: latency-svc-sxmkk
Apr  9 06:43:52.351: INFO: Got endpoints: latency-svc-sxmkk [457.804405ms]
Apr  9 06:43:52.351: INFO: Created: latency-svc-6zg6k
Apr  9 06:43:52.356: INFO: Got endpoints: latency-svc-6zg6k [360.826213ms]
Apr  9 06:43:52.357: INFO: Created: latency-svc-zzcrg
Apr  9 06:43:52.362: INFO: Created: latency-svc-mbpn6
Apr  9 06:43:52.362: INFO: Got endpoints: latency-svc-zzcrg [363.368754ms]
Apr  9 06:43:52.365: INFO: Got endpoints: latency-svc-mbpn6 [172.260323ms]
Apr  9 06:43:52.394: INFO: Created: latency-svc-jhff2
Apr  9 06:43:52.400: INFO: Got endpoints: latency-svc-jhff2 [200.133607ms]
Apr  9 06:43:52.400: INFO: Created: latency-svc-78k5n
Apr  9 06:43:52.406: INFO: Got endpoints: latency-svc-78k5n [189.136397ms]
Apr  9 06:43:52.406: INFO: Created: latency-svc-kjgc4
Apr  9 06:43:52.412: INFO: Got endpoints: latency-svc-kjgc4 [188.951567ms]
Apr  9 06:43:52.412: INFO: Created: latency-svc-hknqz
Apr  9 06:43:52.418: INFO: Got endpoints: latency-svc-hknqz [179.526558ms]
Apr  9 06:43:52.418: INFO: Created: latency-svc-cjgz9
Apr  9 06:43:52.434: INFO: Got endpoints: latency-svc-cjgz9 [189.926676ms]
Apr  9 06:43:52.434: INFO: Created: latency-svc-6v4q9
Apr  9 06:43:52.440: INFO: Got endpoints: latency-svc-6v4q9 [145.317704ms]
Apr  9 06:43:52.440: INFO: Created: latency-svc-jtldj
Apr  9 06:43:52.443: INFO: Got endpoints: latency-svc-jtldj [142.161471ms]
Apr  9 06:43:52.447: INFO: Created: latency-svc-lbnbl
Apr  9 06:43:52.501: INFO: Created: latency-svc-c9d9g
Apr  9 06:43:52.501: INFO: Created: latency-svc-grbn5
Apr  9 06:43:52.501: INFO: Created: latency-svc-9jbvv
Apr  9 06:43:52.501: INFO: Created: latency-svc-llr5w
Apr  9 06:43:52.501: INFO: Got endpoints: latency-svc-c9d9g [177.267472ms]
Apr  9 06:43:52.501: INFO: Got endpoints: latency-svc-llr5w [173.783624ms]
Apr  9 06:43:52.501: INFO: Got endpoints: latency-svc-lbnbl [189.238865ms]
Apr  9 06:43:52.518: INFO: Created: latency-svc-vfd2z
Apr  9 06:43:52.523: INFO: Created: latency-svc-9tq7q
Apr  9 06:43:52.524: INFO: Got endpoints: latency-svc-9jbvv [197.117498ms]
Apr  9 06:43:52.524: INFO: Got endpoints: latency-svc-vfd2z [162.182192ms]
Apr  9 06:43:52.524: INFO: Got endpoints: latency-svc-grbn5 [173.557713ms]
Apr  9 06:43:52.529: INFO: Created: latency-svc-cwl86
Apr  9 06:43:52.553: INFO: Got endpoints: latency-svc-9tq7q [187.696298ms]
Apr  9 06:43:52.553: INFO: Created: latency-svc-tpsh4
Apr  9 06:43:52.562: INFO: Created: latency-svc-8l4jk
Apr  9 06:43:52.572: INFO: Created: latency-svc-4mb9j
Apr  9 06:43:52.572: INFO: Created: latency-svc-qqm2t
Apr  9 06:43:52.597: INFO: Created: latency-svc-fwpmr
Apr  9 06:43:52.598: INFO: Created: latency-svc-mcjbk
Apr  9 06:43:52.601: INFO: Got endpoints: latency-svc-cwl86 [244.46738ms]
Apr  9 06:43:52.605: INFO: Created: latency-svc-99hkp
Apr  9 06:43:52.611: INFO: Created: latency-svc-pp79l
Apr  9 06:43:52.617: INFO: Created: latency-svc-gqhcm
Apr  9 06:43:52.623: INFO: Created: latency-svc-kxkkv
Apr  9 06:43:52.629: INFO: Created: latency-svc-8ncfd
Apr  9 06:43:52.643: INFO: Created: latency-svc-rqhxv
Apr  9 06:43:52.650: INFO: Created: latency-svc-pzkfw
Apr  9 06:43:52.662: INFO: Got endpoints: latency-svc-tpsh4 [262.571944ms]
Apr  9 06:43:52.664: INFO: Created: latency-svc-l9955
Apr  9 06:43:52.670: INFO: Created: latency-svc-pmcsc
Apr  9 06:43:52.691: INFO: Created: latency-svc-9hb6d
Apr  9 06:43:52.701: INFO: Got endpoints: latency-svc-8l4jk [295.087069ms]
Apr  9 06:43:52.730: INFO: Created: latency-svc-mvlt2
Apr  9 06:43:52.752: INFO: Got endpoints: latency-svc-4mb9j [339.566206ms]
Apr  9 06:43:52.780: INFO: Created: latency-svc-nh7c5
Apr  9 06:43:52.802: INFO: Got endpoints: latency-svc-qqm2t [384.375356ms]
Apr  9 06:43:52.831: INFO: Created: latency-svc-m6h2q
Apr  9 06:43:52.852: INFO: Got endpoints: latency-svc-fwpmr [417.52324ms]
Apr  9 06:43:52.881: INFO: Created: latency-svc-jgh5l
Apr  9 06:43:52.902: INFO: Got endpoints: latency-svc-mcjbk [461.726998ms]
Apr  9 06:43:52.930: INFO: Created: latency-svc-xrf8l
Apr  9 06:43:52.956: INFO: Got endpoints: latency-svc-99hkp [513.294071ms]
Apr  9 06:43:52.986: INFO: Created: latency-svc-ch9mr
Apr  9 06:43:53.002: INFO: Got endpoints: latency-svc-pp79l [500.789216ms]
Apr  9 06:43:53.031: INFO: Created: latency-svc-t2ltq
Apr  9 06:43:53.051: INFO: Got endpoints: latency-svc-gqhcm [550.2098ms]
Apr  9 06:43:53.088: INFO: Created: latency-svc-kd8zq
Apr  9 06:43:53.107: INFO: Got endpoints: latency-svc-kxkkv [605.5623ms]
Apr  9 06:43:53.148: INFO: Created: latency-svc-b5b8r
Apr  9 06:43:53.156: INFO: Got endpoints: latency-svc-8ncfd [632.037776ms]
Apr  9 06:43:53.184: INFO: Created: latency-svc-tmtvb
Apr  9 06:43:53.210: INFO: Got endpoints: latency-svc-rqhxv [685.543703ms]
Apr  9 06:43:53.242: INFO: Created: latency-svc-jxmsf
Apr  9 06:43:53.253: INFO: Got endpoints: latency-svc-pzkfw [728.869237ms]
Apr  9 06:43:53.285: INFO: Created: latency-svc-p8kgw
Apr  9 06:43:53.302: INFO: Got endpoints: latency-svc-l9955 [749.318016ms]
Apr  9 06:43:53.340: INFO: Created: latency-svc-thjc2
Apr  9 06:43:53.352: INFO: Got endpoints: latency-svc-pmcsc [751.283203ms]
Apr  9 06:43:53.380: INFO: Created: latency-svc-f52cs
Apr  9 06:43:53.402: INFO: Got endpoints: latency-svc-9hb6d [739.908761ms]
Apr  9 06:43:53.430: INFO: Created: latency-svc-bgpzg
Apr  9 06:43:53.452: INFO: Got endpoints: latency-svc-mvlt2 [751.087453ms]
Apr  9 06:43:53.484: INFO: Created: latency-svc-dstkn
Apr  9 06:43:53.507: INFO: Got endpoints: latency-svc-nh7c5 [755.206455ms]
Apr  9 06:43:53.535: INFO: Created: latency-svc-rdmqr
Apr  9 06:43:53.552: INFO: Got endpoints: latency-svc-m6h2q [749.996687ms]
Apr  9 06:43:53.580: INFO: Created: latency-svc-htsnx
Apr  9 06:43:53.611: INFO: Got endpoints: latency-svc-jgh5l [759.544917ms]
Apr  9 06:43:53.640: INFO: Created: latency-svc-lhvnl
Apr  9 06:43:53.652: INFO: Got endpoints: latency-svc-xrf8l [749.422054ms]
Apr  9 06:43:53.683: INFO: Created: latency-svc-q2wct
Apr  9 06:43:53.706: INFO: Got endpoints: latency-svc-ch9mr [749.458233ms]
Apr  9 06:43:53.734: INFO: Created: latency-svc-mrfxl
Apr  9 06:43:53.752: INFO: Got endpoints: latency-svc-t2ltq [749.695213ms]
Apr  9 06:43:53.780: INFO: Created: latency-svc-b58tn
Apr  9 06:43:53.818: INFO: Got endpoints: latency-svc-kd8zq [766.265472ms]
Apr  9 06:43:53.847: INFO: Created: latency-svc-p6cv5
Apr  9 06:43:53.854: INFO: Got endpoints: latency-svc-b5b8r [747.304003ms]
Apr  9 06:43:53.882: INFO: Created: latency-svc-t6rmv
Apr  9 06:43:53.901: INFO: Got endpoints: latency-svc-tmtvb [745.566521ms]
Apr  9 06:43:53.935: INFO: Created: latency-svc-4frbg
Apr  9 06:43:53.953: INFO: Got endpoints: latency-svc-jxmsf [742.926469ms]
Apr  9 06:43:53.981: INFO: Created: latency-svc-hqvns
Apr  9 06:43:54.005: INFO: Got endpoints: latency-svc-p8kgw [752.274366ms]
Apr  9 06:43:54.039: INFO: Created: latency-svc-9n6g7
Apr  9 06:43:54.052: INFO: Got endpoints: latency-svc-thjc2 [749.896769ms]
Apr  9 06:43:54.081: INFO: Created: latency-svc-qjxsw
Apr  9 06:43:54.102: INFO: Got endpoints: latency-svc-f52cs [749.955486ms]
Apr  9 06:43:54.129: INFO: Created: latency-svc-s9k4n
Apr  9 06:43:54.151: INFO: Got endpoints: latency-svc-bgpzg [749.1556ms]
Apr  9 06:43:54.180: INFO: Created: latency-svc-7fjr8
Apr  9 06:43:54.203: INFO: Got endpoints: latency-svc-dstkn [750.348825ms]
Apr  9 06:43:54.232: INFO: Created: latency-svc-vrc8g
Apr  9 06:43:54.252: INFO: Got endpoints: latency-svc-rdmqr [745.338536ms]
Apr  9 06:43:54.283: INFO: Created: latency-svc-g7z7r
Apr  9 06:43:54.302: INFO: Got endpoints: latency-svc-htsnx [750.025891ms]
Apr  9 06:43:54.331: INFO: Created: latency-svc-gp7hl
Apr  9 06:43:54.352: INFO: Got endpoints: latency-svc-lhvnl [740.190101ms]
Apr  9 06:43:54.383: INFO: Created: latency-svc-btx85
Apr  9 06:43:54.402: INFO: Got endpoints: latency-svc-q2wct [750.374102ms]
Apr  9 06:43:54.431: INFO: Created: latency-svc-rxxlr
Apr  9 06:43:54.453: INFO: Got endpoints: latency-svc-mrfxl [747.21262ms]
Apr  9 06:43:54.481: INFO: Created: latency-svc-52lmb
Apr  9 06:43:54.502: INFO: Got endpoints: latency-svc-b58tn [750.510638ms]
Apr  9 06:43:54.531: INFO: Created: latency-svc-dtgvc
Apr  9 06:43:54.553: INFO: Got endpoints: latency-svc-p6cv5 [734.732504ms]
Apr  9 06:43:54.582: INFO: Created: latency-svc-rq8ck
Apr  9 06:43:54.602: INFO: Got endpoints: latency-svc-t6rmv [747.979984ms]
Apr  9 06:43:54.632: INFO: Created: latency-svc-pgfhh
Apr  9 06:43:54.652: INFO: Got endpoints: latency-svc-4frbg [750.701396ms]
Apr  9 06:43:54.681: INFO: Created: latency-svc-j5mxl
Apr  9 06:43:54.703: INFO: Got endpoints: latency-svc-hqvns [750.425337ms]
Apr  9 06:43:54.732: INFO: Created: latency-svc-bld8x
Apr  9 06:43:54.752: INFO: Got endpoints: latency-svc-9n6g7 [746.931145ms]
Apr  9 06:43:54.781: INFO: Created: latency-svc-lv95q
Apr  9 06:43:54.802: INFO: Got endpoints: latency-svc-qjxsw [750.323815ms]
Apr  9 06:43:54.832: INFO: Created: latency-svc-qlnb4
Apr  9 06:43:54.852: INFO: Got endpoints: latency-svc-s9k4n [750.070014ms]
Apr  9 06:43:54.880: INFO: Created: latency-svc-sd65f
Apr  9 06:43:54.903: INFO: Got endpoints: latency-svc-7fjr8 [751.072361ms]
Apr  9 06:43:54.932: INFO: Created: latency-svc-69c9t
Apr  9 06:43:54.952: INFO: Got endpoints: latency-svc-vrc8g [749.374443ms]
Apr  9 06:43:54.987: INFO: Created: latency-svc-xkgzq
Apr  9 06:43:55.002: INFO: Got endpoints: latency-svc-g7z7r [749.507607ms]
Apr  9 06:43:55.041: INFO: Created: latency-svc-hkcrh
Apr  9 06:43:55.052: INFO: Got endpoints: latency-svc-gp7hl [749.62507ms]
Apr  9 06:43:55.085: INFO: Created: latency-svc-4s4dn
Apr  9 06:43:55.102: INFO: Got endpoints: latency-svc-btx85 [750.333939ms]
Apr  9 06:43:55.130: INFO: Created: latency-svc-crbbd
Apr  9 06:43:55.152: INFO: Got endpoints: latency-svc-rxxlr [749.985132ms]
Apr  9 06:43:55.182: INFO: Created: latency-svc-2hf5f
Apr  9 06:43:55.202: INFO: Got endpoints: latency-svc-52lmb [748.727893ms]
Apr  9 06:43:55.231: INFO: Created: latency-svc-67mc4
Apr  9 06:43:55.251: INFO: Got endpoints: latency-svc-dtgvc [748.403061ms]
Apr  9 06:43:55.279: INFO: Created: latency-svc-l4rxd
Apr  9 06:43:55.307: INFO: Got endpoints: latency-svc-rq8ck [754.413499ms]
Apr  9 06:43:55.344: INFO: Created: latency-svc-d8787
Apr  9 06:43:55.351: INFO: Got endpoints: latency-svc-pgfhh [749.158462ms]
Apr  9 06:43:55.380: INFO: Created: latency-svc-dfx5m
Apr  9 06:43:55.402: INFO: Got endpoints: latency-svc-j5mxl [750.253017ms]
Apr  9 06:43:55.441: INFO: Created: latency-svc-9c5zl
Apr  9 06:43:55.452: INFO: Got endpoints: latency-svc-bld8x [748.345151ms]
Apr  9 06:43:55.480: INFO: Created: latency-svc-qj2pt
Apr  9 06:43:55.506: INFO: Got endpoints: latency-svc-lv95q [753.191698ms]
Apr  9 06:43:55.535: INFO: Created: latency-svc-vwrg9
Apr  9 06:43:55.553: INFO: Got endpoints: latency-svc-qlnb4 [750.288377ms]
Apr  9 06:43:55.582: INFO: Created: latency-svc-dpjcd
Apr  9 06:43:55.603: INFO: Got endpoints: latency-svc-sd65f [750.421321ms]
Apr  9 06:43:55.633: INFO: Created: latency-svc-xxnrx
Apr  9 06:43:55.653: INFO: Got endpoints: latency-svc-69c9t [749.968327ms]
Apr  9 06:43:55.684: INFO: Created: latency-svc-2wnvc
Apr  9 06:43:55.702: INFO: Got endpoints: latency-svc-xkgzq [750.099052ms]
Apr  9 06:43:55.732: INFO: Created: latency-svc-nlmjl
Apr  9 06:43:55.752: INFO: Got endpoints: latency-svc-hkcrh [750.397072ms]
Apr  9 06:43:55.782: INFO: Created: latency-svc-jjk9s
Apr  9 06:43:55.802: INFO: Got endpoints: latency-svc-4s4dn [750.174114ms]
Apr  9 06:43:55.832: INFO: Created: latency-svc-6vrvb
Apr  9 06:43:55.852: INFO: Got endpoints: latency-svc-crbbd [749.661609ms]
Apr  9 06:43:55.882: INFO: Created: latency-svc-bqp6z
Apr  9 06:43:55.903: INFO: Got endpoints: latency-svc-2hf5f [750.502656ms]
Apr  9 06:43:55.946: INFO: Created: latency-svc-7k8m8
Apr  9 06:43:55.952: INFO: Got endpoints: latency-svc-67mc4 [750.521517ms]
Apr  9 06:43:55.982: INFO: Created: latency-svc-m4s8n
Apr  9 06:43:56.002: INFO: Got endpoints: latency-svc-l4rxd [751.376933ms]
Apr  9 06:43:56.033: INFO: Created: latency-svc-sjrkc
Apr  9 06:43:56.052: INFO: Got endpoints: latency-svc-d8787 [737.249875ms]
Apr  9 06:43:56.082: INFO: Created: latency-svc-w4g5q
Apr  9 06:43:56.103: INFO: Got endpoints: latency-svc-dfx5m [751.181036ms]
Apr  9 06:43:56.195: INFO: Created: latency-svc-5sk9v
Apr  9 06:43:56.196: INFO: Got endpoints: latency-svc-9c5zl [793.264817ms]
Apr  9 06:43:56.293: INFO: Got endpoints: latency-svc-qj2pt [841.11103ms]
Apr  9 06:43:56.393: INFO: Created: latency-svc-2w58q
Apr  9 06:43:56.397: INFO: Got endpoints: latency-svc-xxnrx [794.638794ms]
Apr  9 06:43:56.397: INFO: Got endpoints: latency-svc-vwrg9 [891.419398ms]
Apr  9 06:43:56.399: INFO: Got endpoints: latency-svc-dpjcd [846.70688ms]
Apr  9 06:43:56.403: INFO: Got endpoints: latency-svc-2wnvc [750.652558ms]
Apr  9 06:43:56.404: INFO: Created: latency-svc-kk9qf
Apr  9 06:43:56.425: INFO: Created: latency-svc-l5tzd
Apr  9 06:43:56.432: INFO: Created: latency-svc-qs54j
Apr  9 06:43:56.493: INFO: Created: latency-svc-f72t4
Apr  9 06:43:56.495: INFO: Created: latency-svc-zmpjs
Apr  9 06:43:56.495: INFO: Got endpoints: latency-svc-nlmjl [792.969508ms]
Apr  9 06:43:56.502: INFO: Got endpoints: latency-svc-jjk9s [749.229574ms]
Apr  9 06:43:56.524: INFO: Created: latency-svc-zbslw
Apr  9 06:43:56.529: INFO: Created: latency-svc-rjxp7
Apr  9 06:43:56.552: INFO: Got endpoints: latency-svc-6vrvb [749.553403ms]
Apr  9 06:43:56.581: INFO: Created: latency-svc-b9hz2
Apr  9 06:43:56.602: INFO: Got endpoints: latency-svc-bqp6z [750.691499ms]
Apr  9 06:43:56.632: INFO: Created: latency-svc-nbnph
Apr  9 06:43:56.653: INFO: Got endpoints: latency-svc-7k8m8 [750.179752ms]
Apr  9 06:43:56.682: INFO: Created: latency-svc-2kvxn
Apr  9 06:43:56.702: INFO: Got endpoints: latency-svc-m4s8n [749.660868ms]
Apr  9 06:43:56.733: INFO: Created: latency-svc-j7sqt
Apr  9 06:43:56.752: INFO: Got endpoints: latency-svc-sjrkc [749.869138ms]
Apr  9 06:43:56.780: INFO: Created: latency-svc-cxksp
Apr  9 06:43:56.802: INFO: Got endpoints: latency-svc-w4g5q [750.069308ms]
Apr  9 06:43:56.831: INFO: Created: latency-svc-mgnfd
Apr  9 06:43:56.852: INFO: Got endpoints: latency-svc-5sk9v [749.614438ms]
Apr  9 06:43:56.882: INFO: Created: latency-svc-j7vkd
Apr  9 06:43:56.902: INFO: Got endpoints: latency-svc-2w58q [706.727437ms]
Apr  9 06:43:56.931: INFO: Created: latency-svc-zzt9z
Apr  9 06:43:56.952: INFO: Got endpoints: latency-svc-kk9qf [659.273349ms]
Apr  9 06:43:56.983: INFO: Created: latency-svc-sjx64
Apr  9 06:43:57.002: INFO: Got endpoints: latency-svc-l5tzd [605.04034ms]
Apr  9 06:43:57.032: INFO: Created: latency-svc-rlg5f
Apr  9 06:43:57.052: INFO: Got endpoints: latency-svc-qs54j [654.989696ms]
Apr  9 06:43:57.081: INFO: Created: latency-svc-crrwv
Apr  9 06:43:57.102: INFO: Got endpoints: latency-svc-f72t4 [702.660261ms]
Apr  9 06:43:57.130: INFO: Created: latency-svc-vjqlh
Apr  9 06:43:57.152: INFO: Got endpoints: latency-svc-zmpjs [749.018439ms]
Apr  9 06:43:57.182: INFO: Created: latency-svc-62587
Apr  9 06:43:57.201: INFO: Got endpoints: latency-svc-zbslw [705.767386ms]
Apr  9 06:43:57.231: INFO: Created: latency-svc-grgxv
Apr  9 06:43:57.252: INFO: Got endpoints: latency-svc-rjxp7 [750.794082ms]
Apr  9 06:43:57.282: INFO: Created: latency-svc-2jwj9
Apr  9 06:43:57.302: INFO: Got endpoints: latency-svc-b9hz2 [750.609446ms]
Apr  9 06:43:57.332: INFO: Created: latency-svc-t5ncc
Apr  9 06:43:57.353: INFO: Got endpoints: latency-svc-nbnph [749.95594ms]
Apr  9 06:43:57.382: INFO: Created: latency-svc-88htg
Apr  9 06:43:57.403: INFO: Got endpoints: latency-svc-2kvxn [749.891741ms]
Apr  9 06:43:57.432: INFO: Created: latency-svc-7xn2m
Apr  9 06:43:57.452: INFO: Got endpoints: latency-svc-j7sqt [749.89151ms]
Apr  9 06:43:57.481: INFO: Created: latency-svc-djlj4
Apr  9 06:43:57.502: INFO: Got endpoints: latency-svc-cxksp [750.027ms]
Apr  9 06:43:57.531: INFO: Created: latency-svc-d94zv
Apr  9 06:43:57.552: INFO: Got endpoints: latency-svc-mgnfd [749.590401ms]
Apr  9 06:43:57.581: INFO: Created: latency-svc-hmfn2
Apr  9 06:43:57.602: INFO: Got endpoints: latency-svc-j7vkd [749.259985ms]
Apr  9 06:43:57.630: INFO: Created: latency-svc-wjf6p
Apr  9 06:43:57.651: INFO: Got endpoints: latency-svc-zzt9z [748.909083ms]
Apr  9 06:43:57.681: INFO: Created: latency-svc-gwpkk
Apr  9 06:43:57.702: INFO: Got endpoints: latency-svc-sjx64 [749.786257ms]
Apr  9 06:43:57.732: INFO: Created: latency-svc-qxvtm
Apr  9 06:43:57.752: INFO: Got endpoints: latency-svc-rlg5f [749.877287ms]
Apr  9 06:43:57.779: INFO: Created: latency-svc-h75gd
Apr  9 06:43:57.803: INFO: Got endpoints: latency-svc-crrwv [750.299755ms]
Apr  9 06:43:57.833: INFO: Created: latency-svc-fqqbf
Apr  9 06:43:57.853: INFO: Got endpoints: latency-svc-vjqlh [750.353678ms]
Apr  9 06:43:57.881: INFO: Created: latency-svc-5jx2l
Apr  9 06:43:57.902: INFO: Got endpoints: latency-svc-62587 [749.4635ms]
Apr  9 06:43:57.933: INFO: Created: latency-svc-29l88
Apr  9 06:43:57.952: INFO: Got endpoints: latency-svc-grgxv [750.931628ms]
Apr  9 06:43:57.990: INFO: Created: latency-svc-9kbh7
Apr  9 06:43:58.002: INFO: Got endpoints: latency-svc-2jwj9 [750.013086ms]
Apr  9 06:43:58.036: INFO: Created: latency-svc-695dq
Apr  9 06:43:58.052: INFO: Got endpoints: latency-svc-t5ncc [749.646773ms]
Apr  9 06:43:58.081: INFO: Created: latency-svc-m6t9k
Apr  9 06:43:58.102: INFO: Got endpoints: latency-svc-88htg [749.555053ms]
Apr  9 06:43:58.131: INFO: Created: latency-svc-nntrr
Apr  9 06:43:58.155: INFO: Got endpoints: latency-svc-7xn2m [752.311472ms]
Apr  9 06:43:58.184: INFO: Created: latency-svc-kt5jb
Apr  9 06:43:58.202: INFO: Got endpoints: latency-svc-djlj4 [750.343887ms]
Apr  9 06:43:58.231: INFO: Created: latency-svc-ljj57
Apr  9 06:43:58.255: INFO: Got endpoints: latency-svc-d94zv [752.855163ms]
Apr  9 06:43:58.284: INFO: Created: latency-svc-rkr4d
Apr  9 06:43:58.302: INFO: Got endpoints: latency-svc-hmfn2 [749.98683ms]
Apr  9 06:43:58.332: INFO: Created: latency-svc-szxwr
Apr  9 06:43:58.353: INFO: Got endpoints: latency-svc-wjf6p [751.423854ms]
Apr  9 06:43:58.381: INFO: Created: latency-svc-brcpn
Apr  9 06:43:58.402: INFO: Got endpoints: latency-svc-gwpkk [750.450531ms]
Apr  9 06:43:58.432: INFO: Created: latency-svc-vqdnv
Apr  9 06:43:58.452: INFO: Got endpoints: latency-svc-qxvtm [749.738307ms]
Apr  9 06:43:58.481: INFO: Created: latency-svc-btzwh
Apr  9 06:43:58.503: INFO: Got endpoints: latency-svc-h75gd [750.38378ms]
Apr  9 06:43:58.532: INFO: Created: latency-svc-dn26d
Apr  9 06:43:58.552: INFO: Got endpoints: latency-svc-fqqbf [749.033898ms]
Apr  9 06:43:58.581: INFO: Created: latency-svc-gnvgr
Apr  9 06:43:58.602: INFO: Got endpoints: latency-svc-5jx2l [749.372179ms]
Apr  9 06:43:58.630: INFO: Created: latency-svc-frp9r
Apr  9 06:43:58.652: INFO: Got endpoints: latency-svc-29l88 [749.644367ms]
Apr  9 06:43:58.680: INFO: Created: latency-svc-vh6bw
Apr  9 06:43:58.701: INFO: Got endpoints: latency-svc-9kbh7 [748.803225ms]
Apr  9 06:43:58.730: INFO: Created: latency-svc-fhf2v
Apr  9 06:43:58.754: INFO: Got endpoints: latency-svc-695dq [751.129062ms]
Apr  9 06:43:58.782: INFO: Created: latency-svc-l57rp
Apr  9 06:43:58.802: INFO: Got endpoints: latency-svc-m6t9k [749.627514ms]
Apr  9 06:43:58.831: INFO: Created: latency-svc-8qxzs
Apr  9 06:43:58.852: INFO: Got endpoints: latency-svc-nntrr [749.518152ms]
Apr  9 06:43:58.882: INFO: Created: latency-svc-r9jwj
Apr  9 06:43:58.902: INFO: Got endpoints: latency-svc-kt5jb [746.844569ms]
Apr  9 06:43:58.931: INFO: Created: latency-svc-xwclf
Apr  9 06:43:58.952: INFO: Got endpoints: latency-svc-ljj57 [749.462416ms]
Apr  9 06:43:58.985: INFO: Created: latency-svc-st8k7
Apr  9 06:43:59.002: INFO: Got endpoints: latency-svc-rkr4d [746.761809ms]
Apr  9 06:43:59.031: INFO: Created: latency-svc-ztbwb
Apr  9 06:43:59.052: INFO: Got endpoints: latency-svc-szxwr [750.117377ms]
Apr  9 06:43:59.080: INFO: Created: latency-svc-v5vtw
Apr  9 06:43:59.102: INFO: Got endpoints: latency-svc-brcpn [749.018273ms]
Apr  9 06:43:59.131: INFO: Created: latency-svc-2t9lv
Apr  9 06:43:59.152: INFO: Got endpoints: latency-svc-vqdnv [750.227469ms]
Apr  9 06:43:59.181: INFO: Created: latency-svc-cm5xs
Apr  9 06:43:59.203: INFO: Got endpoints: latency-svc-btzwh [750.851584ms]
Apr  9 06:43:59.231: INFO: Created: latency-svc-nthtk
Apr  9 06:43:59.252: INFO: Got endpoints: latency-svc-dn26d [749.5252ms]
Apr  9 06:43:59.282: INFO: Created: latency-svc-5brsm
Apr  9 06:43:59.302: INFO: Got endpoints: latency-svc-gnvgr [750.389661ms]
Apr  9 06:43:59.331: INFO: Created: latency-svc-sxb4c
Apr  9 06:43:59.352: INFO: Got endpoints: latency-svc-frp9r [749.857513ms]
Apr  9 06:43:59.382: INFO: Created: latency-svc-psz9p
Apr  9 06:43:59.407: INFO: Got endpoints: latency-svc-vh6bw [755.152205ms]
Apr  9 06:43:59.437: INFO: Created: latency-svc-lrzsh
Apr  9 06:43:59.452: INFO: Got endpoints: latency-svc-fhf2v [750.856327ms]
Apr  9 06:43:59.480: INFO: Created: latency-svc-tpvmj
Apr  9 06:43:59.503: INFO: Got endpoints: latency-svc-l57rp [748.911073ms]
Apr  9 06:43:59.531: INFO: Created: latency-svc-vjft4
Apr  9 06:43:59.552: INFO: Got endpoints: latency-svc-8qxzs [750.204111ms]
Apr  9 06:43:59.606: INFO: Got endpoints: latency-svc-r9jwj [754.249841ms]
Apr  9 06:43:59.652: INFO: Got endpoints: latency-svc-xwclf [750.054656ms]
Apr  9 06:43:59.704: INFO: Got endpoints: latency-svc-st8k7 [752.28405ms]
Apr  9 06:43:59.753: INFO: Got endpoints: latency-svc-ztbwb [751.441912ms]
Apr  9 06:43:59.802: INFO: Got endpoints: latency-svc-v5vtw [750.175838ms]
Apr  9 06:43:59.852: INFO: Got endpoints: latency-svc-2t9lv [749.960653ms]
Apr  9 06:43:59.902: INFO: Got endpoints: latency-svc-cm5xs [750.060952ms]
Apr  9 06:43:59.952: INFO: Got endpoints: latency-svc-nthtk [749.619414ms]
Apr  9 06:44:00.002: INFO: Got endpoints: latency-svc-5brsm [750.021829ms]
Apr  9 06:44:00.052: INFO: Got endpoints: latency-svc-sxb4c [749.786709ms]
Apr  9 06:44:00.102: INFO: Got endpoints: latency-svc-psz9p [750.493958ms]
Apr  9 06:44:00.152: INFO: Got endpoints: latency-svc-lrzsh [744.955686ms]
Apr  9 06:44:00.202: INFO: Got endpoints: latency-svc-tpvmj [750.206851ms]
Apr  9 06:44:00.252: INFO: Got endpoints: latency-svc-vjft4 [749.301942ms]
Apr  9 06:44:00.252: INFO: Latencies: [35.105247ms 46.777363ms 47.268531ms 51.230559ms 56.507977ms 62.811701ms 85.816937ms 103.547291ms 142.012109ms 142.161471ms 145.317704ms 146.513857ms 146.623989ms 147.0305ms 155.098977ms 162.182192ms 172.260323ms 173.557713ms 173.783624ms 177.267472ms 179.526558ms 187.696298ms 188.951567ms 189.136397ms 189.238865ms 189.926676ms 190.267617ms 197.117498ms 200.133607ms 244.46738ms 262.571944ms 292.637291ms 295.087069ms 295.94424ms 339.566206ms 360.826213ms 363.368754ms 384.375356ms 417.52324ms 438.208057ms 450.471451ms 450.56686ms 451.638892ms 455.497703ms 457.804405ms 461.726998ms 464.237326ms 465.964945ms 467.821646ms 472.681763ms 472.906345ms 474.045796ms 478.077822ms 500.789216ms 513.294071ms 550.2098ms 605.04034ms 605.5623ms 632.037776ms 654.989696ms 659.273349ms 685.543703ms 702.660261ms 705.767386ms 706.727437ms 728.869237ms 734.732504ms 737.249875ms 739.908761ms 740.190101ms 742.926469ms 744.955686ms 745.338536ms 745.566521ms 746.761809ms 746.844569ms 746.931145ms 747.21262ms 747.304003ms 747.979984ms 748.345151ms 748.403061ms 748.727893ms 748.803225ms 748.909083ms 748.911073ms 749.018273ms 749.018439ms 749.033898ms 749.1556ms 749.158462ms 749.229574ms 749.259985ms 749.301942ms 749.318016ms 749.372179ms 749.374443ms 749.422054ms 749.458233ms 749.462416ms 749.4635ms 749.507607ms 749.518152ms 749.5252ms 749.553403ms 749.555053ms 749.590401ms 749.614438ms 749.619414ms 749.62507ms 749.627514ms 749.644367ms 749.646773ms 749.660868ms 749.661609ms 749.695213ms 749.738307ms 749.786257ms 749.786709ms 749.857513ms 749.869138ms 749.877287ms 749.89151ms 749.891741ms 749.896769ms 749.955486ms 749.95594ms 749.960653ms 749.968327ms 749.985132ms 749.98683ms 749.996687ms 750.013086ms 750.021829ms 750.025891ms 750.027ms 750.054656ms 750.060952ms 750.069308ms 750.070014ms 750.099052ms 750.117377ms 750.174114ms 750.175838ms 750.179752ms 750.204111ms 750.206851ms 750.227469ms 750.253017ms 750.288377ms 750.299755ms 750.323815ms 750.333939ms 750.343887ms 750.348825ms 750.353678ms 750.374102ms 750.38378ms 750.389661ms 750.397072ms 750.421321ms 750.425337ms 750.450531ms 750.493958ms 750.502656ms 750.510638ms 750.521517ms 750.609446ms 750.652558ms 750.691499ms 750.701396ms 750.794082ms 750.851584ms 750.856327ms 750.931628ms 751.072361ms 751.087453ms 751.129062ms 751.181036ms 751.283203ms 751.376933ms 751.423854ms 751.441912ms 752.274366ms 752.28405ms 752.311472ms 752.855163ms 753.191698ms 754.249841ms 754.413499ms 755.152205ms 755.206455ms 759.544917ms 766.265472ms 792.969508ms 793.264817ms 794.638794ms 841.11103ms 846.70688ms 891.419398ms]
Apr  9 06:44:00.252: INFO: 50 %ile: 749.4635ms
Apr  9 06:44:00.252: INFO: 90 %ile: 751.376933ms
Apr  9 06:44:00.252: INFO: 99 %ile: 846.70688ms
Apr  9 06:44:00.252: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:44:00.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8265" for this suite.
Apr  9 06:44:14.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:44:15.127: INFO: namespace svc-latency-8265 deletion completed in 14.851815249s
•SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:44:15.127: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-3808
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr  9 06:44:19.510: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-e454358a-5a92-11e9-8d38-4647074cf119,GenerateName:,Namespace:events-3808,SelfLink:/api/v1/namespaces/events-3808/pods/send-events-e454358a-5a92-11e9-8d38-4647074cf119,UID:e45641d6-5a92-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:5995,Generation:0,CreationTimestamp:2019-04-09 06:44:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 395987540,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.45/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sqrgp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sqrgp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-sqrgp true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d73f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d73f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:44:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:44:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:44:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:44:15 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.45,StartTime:2019-04-09 06:44:15 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-09 06:44:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://e120788c12c9ea23e6ba252e45feff88271aa7fdc0698d4a25123e5f98324739}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr  9 06:44:21.534: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr  9 06:44:23.556: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:44:23.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3808" for this suite.
Apr  9 06:45:03.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:45:04.487: INFO: namespace events-3808 deletion completed in 40.885178783s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:45:04.487: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4094
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr  9 06:45:04.874: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-a,UID:01d05079-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6110,Generation:0,CreationTimestamp:2019-04-09 06:45:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  9 06:45:04.875: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-a,UID:01d05079-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6110,Generation:0,CreationTimestamp:2019-04-09 06:45:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr  9 06:45:14.920: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-a,UID:01d05079-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6132,Generation:0,CreationTimestamp:2019-04-09 06:45:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  9 06:45:14.920: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-a,UID:01d05079-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6132,Generation:0,CreationTimestamp:2019-04-09 06:45:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr  9 06:45:24.964: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-a,UID:01d05079-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6155,Generation:0,CreationTimestamp:2019-04-09 06:45:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  9 06:45:24.964: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-a,UID:01d05079-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6155,Generation:0,CreationTimestamp:2019-04-09 06:45:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr  9 06:45:34.989: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-a,UID:01d05079-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6177,Generation:0,CreationTimestamp:2019-04-09 06:45:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  9 06:45:34.989: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-a,UID:01d05079-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6177,Generation:0,CreationTimestamp:2019-04-09 06:45:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr  9 06:45:45.016: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-b,UID:19bcea07-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6199,Generation:0,CreationTimestamp:2019-04-09 06:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  9 06:45:45.016: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-b,UID:19bcea07-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6199,Generation:0,CreationTimestamp:2019-04-09 06:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr  9 06:45:55.041: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-b,UID:19bcea07-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6222,Generation:0,CreationTimestamp:2019-04-09 06:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  9 06:45:55.041: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-4094,SelfLink:/api/v1/namespaces/watch-4094/configmaps/e2e-watch-test-configmap-b,UID:19bcea07-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:6222,Generation:0,CreationTimestamp:2019-04-09 06:45:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:46:05.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4094" for this suite.
Apr  9 06:46:11.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:46:11.915: INFO: namespace watch-4094 deletion completed in 6.849817914s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:46:11.915: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9354
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9354
Apr  9 06:46:16.265: INFO: Started pod liveness-http in namespace container-probe-9354
STEP: checking the pod's current state and verifying that restartCount is present
Apr  9 06:46:16.287: INFO: Initial restart count of pod liveness-http is 0
Apr  9 06:46:28.449: INFO: Restart count of pod container-probe-9354/liveness-http is now 1 (12.161525097s elapsed)
Apr  9 06:46:48.676: INFO: Restart count of pod container-probe-9354/liveness-http is now 2 (32.388359453s elapsed)
Apr  9 06:47:08.920: INFO: Restart count of pod container-probe-9354/liveness-http is now 3 (52.632758452s elapsed)
Apr  9 06:47:29.144: INFO: Restart count of pod container-probe-9354/liveness-http is now 4 (1m12.856690564s elapsed)
Apr  9 06:48:29.822: INFO: Restart count of pod container-probe-9354/liveness-http is now 5 (2m13.534331956s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:48:29.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9354" for this suite.
Apr  9 06:48:35.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:48:36.735: INFO: namespace container-probe-9354 deletion completed in 6.862206835s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:48:36.735: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2711
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Apr  9 06:48:37.020: INFO: Waiting up to 5m0s for pod "client-containers-8040daec-5a93-11e9-8d38-4647074cf119" in namespace "containers-2711" to be "success or failure"
Apr  9 06:48:37.042: INFO: Pod "client-containers-8040daec-5a93-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.50391ms
Apr  9 06:48:39.064: INFO: Pod "client-containers-8040daec-5a93-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043599942s
Apr  9 06:48:41.086: INFO: Pod "client-containers-8040daec-5a93-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06615988s
STEP: Saw pod success
Apr  9 06:48:41.086: INFO: Pod "client-containers-8040daec-5a93-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:48:41.108: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod client-containers-8040daec-5a93-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 06:48:41.170: INFO: Waiting for pod client-containers-8040daec-5a93-11e9-8d38-4647074cf119 to disappear
Apr  9 06:48:41.191: INFO: Pod client-containers-8040daec-5a93-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:48:41.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2711" for this suite.
Apr  9 06:48:47.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:48:48.073: INFO: namespace containers-2711 deletion completed in 6.8592957s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:48:48.074: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7115
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  9 06:48:48.426: INFO: Waiting up to 5m0s for pod "pod-870d59e0-5a93-11e9-8d38-4647074cf119" in namespace "emptydir-7115" to be "success or failure"
Apr  9 06:48:48.447: INFO: Pod "pod-870d59e0-5a93-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.353232ms
Apr  9 06:48:50.470: INFO: Pod "pod-870d59e0-5a93-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044190326s
Apr  9 06:48:52.493: INFO: Pod "pod-870d59e0-5a93-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067276397s
STEP: Saw pod success
Apr  9 06:48:52.493: INFO: Pod "pod-870d59e0-5a93-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:48:52.516: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-870d59e0-5a93-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 06:48:52.574: INFO: Waiting for pod pod-870d59e0-5a93-11e9-8d38-4647074cf119 to disappear
Apr  9 06:48:52.595: INFO: Pod pod-870d59e0-5a93-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:48:52.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7115" for this suite.
Apr  9 06:48:58.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:48:59.485: INFO: namespace emptydir-7115 deletion completed in 6.867634146s
•SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:48:59.485: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9030
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 06:48:59.906: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8de506c0-5a93-11e9-8d38-4647074cf119" in namespace "projected-9030" to be "success or failure"
Apr  9 06:48:59.928: INFO: Pod "downwardapi-volume-8de506c0-5a93-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.102798ms
Apr  9 06:49:01.950: INFO: Pod "downwardapi-volume-8de506c0-5a93-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044150188s
STEP: Saw pod success
Apr  9 06:49:01.950: INFO: Pod "downwardapi-volume-8de506c0-5a93-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:49:01.972: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-8de506c0-5a93-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 06:49:02.031: INFO: Waiting for pod downwardapi-volume-8de506c0-5a93-11e9-8d38-4647074cf119 to disappear
Apr  9 06:49:02.052: INFO: Pod downwardapi-volume-8de506c0-5a93-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:49:02.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9030" for this suite.
Apr  9 06:49:08.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:49:08.946: INFO: namespace projected-9030 deletion completed in 6.871940111s
•
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:49:08.946: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8686
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-2kg4
STEP: Creating a pod to test atomic-volume-subpath
Apr  9 06:49:09.354: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2kg4" in namespace "subpath-8686" to be "success or failure"
Apr  9 06:49:09.375: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.006008ms
Apr  9 06:49:11.398: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 2.043248976s
Apr  9 06:49:13.420: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 4.065789683s
Apr  9 06:49:15.444: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 6.089355101s
Apr  9 06:49:17.466: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 8.111429187s
Apr  9 06:49:19.488: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 10.133669624s
Apr  9 06:49:21.511: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 12.156452092s
Apr  9 06:49:23.534: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 14.179166599s
Apr  9 06:49:25.556: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 16.202001397s
Apr  9 06:49:27.581: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 18.226243437s
Apr  9 06:49:29.604: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Running", Reason="", readiness=true. Elapsed: 20.249999788s
Apr  9 06:49:31.627: INFO: Pod "pod-subpath-test-configmap-2kg4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.272250099s
STEP: Saw pod success
Apr  9 06:49:31.627: INFO: Pod "pod-subpath-test-configmap-2kg4" satisfied condition "success or failure"
Apr  9 06:49:31.649: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-subpath-test-configmap-2kg4 container test-container-subpath-configmap-2kg4: <nil>
STEP: delete the pod
Apr  9 06:49:31.708: INFO: Waiting for pod pod-subpath-test-configmap-2kg4 to disappear
Apr  9 06:49:31.729: INFO: Pod pod-subpath-test-configmap-2kg4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2kg4
Apr  9 06:49:31.729: INFO: Deleting pod "pod-subpath-test-configmap-2kg4" in namespace "subpath-8686"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:49:31.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8686" for this suite.
Apr  9 06:49:37.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:49:38.630: INFO: namespace subpath-8686 deletion completed in 6.857655155s
•SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:49:38.630: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  9 06:49:38.898: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-3493'
Apr  9 06:49:40.835: INFO: stderr: ""
Apr  9 06:49:40.835: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  9 06:49:40.836: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3493'
Apr  9 06:49:40.998: INFO: stderr: ""
Apr  9 06:49:40.998: INFO: stdout: "update-demo-nautilus-b7d4r update-demo-nautilus-hpzvq "
Apr  9 06:49:40.998: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-b7d4r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:41.169: INFO: stderr: ""
Apr  9 06:49:41.169: INFO: stdout: ""
Apr  9 06:49:41.169: INFO: update-demo-nautilus-b7d4r is created but not running
Apr  9 06:49:46.169: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3493'
Apr  9 06:49:46.323: INFO: stderr: ""
Apr  9 06:49:46.323: INFO: stdout: "update-demo-nautilus-b7d4r update-demo-nautilus-hpzvq "
Apr  9 06:49:46.323: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-b7d4r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:46.492: INFO: stderr: ""
Apr  9 06:49:46.492: INFO: stdout: "true"
Apr  9 06:49:46.492: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-b7d4r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:46.664: INFO: stderr: ""
Apr  9 06:49:46.664: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 06:49:46.664: INFO: validating pod update-demo-nautilus-b7d4r
Apr  9 06:49:46.771: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 06:49:46.771: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 06:49:46.771: INFO: update-demo-nautilus-b7d4r is verified up and running
Apr  9 06:49:46.771: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-hpzvq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:46.920: INFO: stderr: ""
Apr  9 06:49:46.920: INFO: stdout: "true"
Apr  9 06:49:46.920: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-hpzvq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:47.068: INFO: stderr: ""
Apr  9 06:49:47.068: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 06:49:47.068: INFO: validating pod update-demo-nautilus-hpzvq
Apr  9 06:49:47.174: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 06:49:47.174: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 06:49:47.174: INFO: update-demo-nautilus-hpzvq is verified up and running
STEP: scaling down the replication controller
Apr  9 06:49:47.181: INFO: scanned /root for discovery docs: <nil>
Apr  9 06:49:47.181: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3493'
Apr  9 06:49:47.433: INFO: stderr: ""
Apr  9 06:49:47.434: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  9 06:49:47.434: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3493'
Apr  9 06:49:47.612: INFO: stderr: ""
Apr  9 06:49:47.612: INFO: stdout: "update-demo-nautilus-b7d4r update-demo-nautilus-hpzvq "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  9 06:49:52.612: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3493'
Apr  9 06:49:52.790: INFO: stderr: ""
Apr  9 06:49:52.791: INFO: stdout: "update-demo-nautilus-b7d4r update-demo-nautilus-hpzvq "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  9 06:49:57.791: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3493'
Apr  9 06:49:57.944: INFO: stderr: ""
Apr  9 06:49:57.944: INFO: stdout: "update-demo-nautilus-hpzvq "
Apr  9 06:49:57.944: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-hpzvq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:58.143: INFO: stderr: ""
Apr  9 06:49:58.143: INFO: stdout: "true"
Apr  9 06:49:58.143: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-hpzvq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:58.322: INFO: stderr: ""
Apr  9 06:49:58.322: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 06:49:58.322: INFO: validating pod update-demo-nautilus-hpzvq
Apr  9 06:49:58.345: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 06:49:58.345: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 06:49:58.345: INFO: update-demo-nautilus-hpzvq is verified up and running
STEP: scaling up the replication controller
Apr  9 06:49:58.351: INFO: scanned /root for discovery docs: <nil>
Apr  9 06:49:58.351: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3493'
Apr  9 06:49:58.577: INFO: stderr: ""
Apr  9 06:49:58.577: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  9 06:49:58.577: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3493'
Apr  9 06:49:58.762: INFO: stderr: ""
Apr  9 06:49:58.762: INFO: stdout: "update-demo-nautilus-hpzvq update-demo-nautilus-rsr8x "
Apr  9 06:49:58.762: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-hpzvq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:58.913: INFO: stderr: ""
Apr  9 06:49:58.913: INFO: stdout: "true"
Apr  9 06:49:58.913: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-hpzvq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:59.084: INFO: stderr: ""
Apr  9 06:49:59.085: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 06:49:59.085: INFO: validating pod update-demo-nautilus-hpzvq
Apr  9 06:49:59.109: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 06:49:59.109: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 06:49:59.109: INFO: update-demo-nautilus-hpzvq is verified up and running
Apr  9 06:49:59.109: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-rsr8x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:49:59.285: INFO: stderr: ""
Apr  9 06:49:59.285: INFO: stdout: ""
Apr  9 06:49:59.285: INFO: update-demo-nautilus-rsr8x is created but not running
Apr  9 06:50:04.287: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3493'
Apr  9 06:50:04.471: INFO: stderr: ""
Apr  9 06:50:04.471: INFO: stdout: "update-demo-nautilus-hpzvq update-demo-nautilus-rsr8x "
Apr  9 06:50:04.471: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-hpzvq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:50:04.804: INFO: stderr: ""
Apr  9 06:50:04.804: INFO: stdout: "true"
Apr  9 06:50:04.804: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-hpzvq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:50:05.010: INFO: stderr: ""
Apr  9 06:50:05.010: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 06:50:05.010: INFO: validating pod update-demo-nautilus-hpzvq
Apr  9 06:50:05.035: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 06:50:05.035: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 06:50:05.035: INFO: update-demo-nautilus-hpzvq is verified up and running
Apr  9 06:50:05.035: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-rsr8x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:50:05.221: INFO: stderr: ""
Apr  9 06:50:05.221: INFO: stdout: "true"
Apr  9 06:50:05.221: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-rsr8x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3493'
Apr  9 06:50:05.410: INFO: stderr: ""
Apr  9 06:50:05.410: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 06:50:05.410: INFO: validating pod update-demo-nautilus-rsr8x
Apr  9 06:50:05.514: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 06:50:05.514: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 06:50:05.514: INFO: update-demo-nautilus-rsr8x is verified up and running
STEP: using delete to clean up resources
Apr  9 06:50:05.514: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-3493'
Apr  9 06:50:05.695: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 06:50:05.695: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  9 06:50:05.695: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3493'
Apr  9 06:50:05.899: INFO: stderr: "No resources found.\n"
Apr  9 06:50:05.899: INFO: stdout: ""
Apr  9 06:50:05.899: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -l name=update-demo --namespace=kubectl-3493 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  9 06:50:06.091: INFO: stderr: ""
Apr  9 06:50:06.091: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:50:06.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3493" for this suite.
Apr  9 06:50:28.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:50:28.973: INFO: namespace kubectl-3493 deletion completed in 22.858995256s
•SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:50:28.974: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  9 06:50:29.300: INFO: PodSpec: initContainers in spec.initContainers
Apr  9 06:51:11.872: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c3317572-5a93-11e9-8d38-4647074cf119", GenerateName:"", Namespace:"init-container-7302", SelfLink:"/api/v1/namespaces/init-container-7302/pods/pod-init-c3317572-5a93-11e9-8d38-4647074cf119", UID:"c33380a0-5a93-11e9-8ec1-5e80bdd8d9d6", ResourceVersion:"7081", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63690389429, loc:(*time.Location)(0x89f10e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"300163052"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.0.53/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4jbsp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002af6440), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4jbsp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4jbsp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4jbsp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001fabaf8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002441080), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001fabb70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001fabb90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001fabb98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001fabb9c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690389429, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690389429, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690389429, loc:(*time.Location)(0x89f10e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690389429, loc:(*time.Location)(0x89f10e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.2", PodIP:"100.96.0.53", StartTime:(*v1.Time)(0xc001d5bac0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00259e1c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00259e230)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://301a111b0a27b055a62830d36d7ba6506d29b48f712ef4afcec4f3b85f9b8123"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001d5bb00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001d5bae0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:51:11.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7302" for this suite.
Apr  9 06:51:33.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:51:34.780: INFO: namespace init-container-7302 deletion completed in 22.884877574s
•SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:51:34.780: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9241
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  9 06:51:35.119: INFO: Waiting up to 5m0s for pod "pod-ea68bc8e-5a93-11e9-8d38-4647074cf119" in namespace "emptydir-9241" to be "success or failure"
Apr  9 06:51:35.149: INFO: Pod "pod-ea68bc8e-5a93-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 29.892263ms
Apr  9 06:51:37.171: INFO: Pod "pod-ea68bc8e-5a93-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052074891s
STEP: Saw pod success
Apr  9 06:51:37.171: INFO: Pod "pod-ea68bc8e-5a93-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:51:37.194: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-ea68bc8e-5a93-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 06:51:37.254: INFO: Waiting for pod pod-ea68bc8e-5a93-11e9-8d38-4647074cf119 to disappear
Apr  9 06:51:37.275: INFO: Pod pod-ea68bc8e-5a93-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:51:37.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9241" for this suite.
Apr  9 06:51:43.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:51:44.180: INFO: namespace emptydir-9241 deletion completed in 6.88299741s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:51:44.180: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1712
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-f0130ff3-5a93-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 06:51:44.648: INFO: Waiting up to 5m0s for pod "pod-configmaps-f01684b7-5a93-11e9-8d38-4647074cf119" in namespace "configmap-1712" to be "success or failure"
Apr  9 06:51:44.669: INFO: Pod "pod-configmaps-f01684b7-5a93-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.056308ms
Apr  9 06:51:46.691: INFO: Pod "pod-configmaps-f01684b7-5a93-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043527561s
STEP: Saw pod success
Apr  9 06:51:46.691: INFO: Pod "pod-configmaps-f01684b7-5a93-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:51:46.714: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-f01684b7-5a93-11e9-8d38-4647074cf119 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 06:51:46.770: INFO: Waiting for pod pod-configmaps-f01684b7-5a93-11e9-8d38-4647074cf119 to disappear
Apr  9 06:51:46.791: INFO: Pod pod-configmaps-f01684b7-5a93-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:51:46.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1712" for this suite.
Apr  9 06:51:52.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:51:53.662: INFO: namespace configmap-1712 deletion completed in 6.848411117s
•SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:51:53.662: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  9 06:51:53.991: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:51:57.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2739" for this suite.
Apr  9 06:52:04.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:52:05.433: INFO: namespace init-container-2739 deletion completed in 7.847791166s
•
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:52:05.433: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8303
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr  9 06:52:05.933: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8303,SelfLink:/api/v1/namespaces/watch-8303/configmaps/e2e-watch-test-label-changed,UID:fcbb52ca-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7271,Generation:0,CreationTimestamp:2019-04-09 06:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  9 06:52:05.933: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8303,SelfLink:/api/v1/namespaces/watch-8303/configmaps/e2e-watch-test-label-changed,UID:fcbb52ca-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7272,Generation:0,CreationTimestamp:2019-04-09 06:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  9 06:52:05.933: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8303,SelfLink:/api/v1/namespaces/watch-8303/configmaps/e2e-watch-test-label-changed,UID:fcbb52ca-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7273,Generation:0,CreationTimestamp:2019-04-09 06:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr  9 06:52:16.095: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8303,SelfLink:/api/v1/namespaces/watch-8303/configmaps/e2e-watch-test-label-changed,UID:fcbb52ca-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7297,Generation:0,CreationTimestamp:2019-04-09 06:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  9 06:52:16.095: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8303,SelfLink:/api/v1/namespaces/watch-8303/configmaps/e2e-watch-test-label-changed,UID:fcbb52ca-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7298,Generation:0,CreationTimestamp:2019-04-09 06:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr  9 06:52:16.095: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8303,SelfLink:/api/v1/namespaces/watch-8303/configmaps/e2e-watch-test-label-changed,UID:fcbb52ca-5a93-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7299,Generation:0,CreationTimestamp:2019-04-09 06:52:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:52:16.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8303" for this suite.
Apr  9 06:52:24.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:52:25.016: INFO: namespace watch-8303 deletion completed in 8.89890782s
•SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:52:25.016: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8300
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-085471af-5a94-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 06:52:25.340: INFO: Waiting up to 5m0s for pod "pod-secrets-0857c92e-5a94-11e9-8d38-4647074cf119" in namespace "secrets-8300" to be "success or failure"
Apr  9 06:52:25.362: INFO: Pod "pod-secrets-0857c92e-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.615862ms
Apr  9 06:52:27.384: INFO: Pod "pod-secrets-0857c92e-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044174785s
STEP: Saw pod success
Apr  9 06:52:27.385: INFO: Pod "pod-secrets-0857c92e-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:52:27.407: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-secrets-0857c92e-5a94-11e9-8d38-4647074cf119 container secret-volume-test: <nil>
STEP: delete the pod
Apr  9 06:52:27.466: INFO: Waiting for pod pod-secrets-0857c92e-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:52:27.488: INFO: Pod pod-secrets-0857c92e-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:52:27.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8300" for this suite.
Apr  9 06:52:33.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:52:34.375: INFO: namespace secrets-8300 deletion completed in 6.864700686s
•SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:52:34.375: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-6362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-6362
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6362
STEP: Deleting pre-stop pod
Apr  9 06:52:47.339: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:52:47.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6362" for this suite.
Apr  9 06:53:29.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:53:30.236: INFO: namespace prestop-6362 deletion completed in 42.851834413s
•SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:53:30.237: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7655
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  9 06:53:30.523: INFO: Waiting up to 5m0s for pod "pod-2f31e167-5a94-11e9-8d38-4647074cf119" in namespace "emptydir-7655" to be "success or failure"
Apr  9 06:53:30.544: INFO: Pod "pod-2f31e167-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.817511ms
Apr  9 06:53:32.566: INFO: Pod "pod-2f31e167-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04332878s
STEP: Saw pod success
Apr  9 06:53:32.566: INFO: Pod "pod-2f31e167-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:53:32.588: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-2f31e167-5a94-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 06:53:32.645: INFO: Waiting for pod pod-2f31e167-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:53:32.667: INFO: Pod pod-2f31e167-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:53:32.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7655" for this suite.
Apr  9 06:53:40.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:53:41.564: INFO: namespace emptydir-7655 deletion completed in 8.875237748s
•SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:53:41.564: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8656
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 06:53:41.898: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr  9 06:53:41.942: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  9 06:53:43.986: INFO: Creating deployment "test-rolling-update-deployment"
Apr  9 06:53:44.008: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr  9 06:53:44.056: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr  9 06:53:44.078: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690389624, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690389624, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690389624, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690389624, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67599b4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 06:53:46.100: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  9 06:53:46.166: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-8656,SelfLink:/apis/apps/v1/namespaces/deployment-8656/deployments/test-rolling-update-deployment,UID:373dcad4-5a94-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7600,Generation:1,CreationTimestamp:2019-04-09 06:53:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-09 06:53:44 +0000 UTC 2019-04-09 06:53:44 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-09 06:53:45 +0000 UTC 2019-04-09 06:53:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  9 06:53:46.189: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-8656,SelfLink:/apis/apps/v1/namespaces/deployment-8656/replicasets/test-rolling-update-deployment-67599b4d9,UID:3740401b-5a94-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7593,Generation:1,CreationTimestamp:2019-04-09 06:53:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 373dcad4-5a94-11e9-8ec1-5e80bdd8d9d6 0xc002c90f90 0xc002c90f91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  9 06:53:46.189: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr  9 06:53:46.189: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-8656,SelfLink:/apis/apps/v1/namespaces/deployment-8656/replicasets/test-rolling-update-controller,UID:35ff277c-5a94-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7599,Generation:2,CreationTimestamp:2019-04-09 06:53:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 373dcad4-5a94-11e9-8ec1-5e80bdd8d9d6 0xc002c90ebf 0xc002c90ed0}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  9 06:53:46.211: INFO: Pod "test-rolling-update-deployment-67599b4d9-pkbdc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-pkbdc,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-8656,SelfLink:/api/v1/namespaces/deployment-8656/pods/test-rolling-update-deployment-67599b4d9-pkbdc,UID:3740dc73-5a94-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:7592,Generation:0,CreationTimestamp:2019-04-09 06:53:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.61/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 3740401b-5a94-11e9-8ec1-5e80bdd8d9d6 0xc002c91820 0xc002c91821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ptl5z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ptl5z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ptl5z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c91880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c918a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:53:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:53:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:53:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 06:53:44 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.61,StartTime:2019-04-09 06:53:44 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-09 06:53:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://4576c0e21f786f2fd010c54e11a097dca63a4c548ad45ac271de6a8401a59cbd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:53:46.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8656" for this suite.
Apr  9 06:53:52.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:53:53.082: INFO: namespace deployment-8656 deletion completed in 6.848906402s
•SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:53:53.082: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-3ce5dcc5-5a94-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 06:53:53.535: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ce92116-5a94-11e9-8d38-4647074cf119" in namespace "configmap-6558" to be "success or failure"
Apr  9 06:53:53.557: INFO: Pod "pod-configmaps-3ce92116-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.100363ms
Apr  9 06:53:55.579: INFO: Pod "pod-configmaps-3ce92116-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044401734s
STEP: Saw pod success
Apr  9 06:53:55.579: INFO: Pod "pod-configmaps-3ce92116-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:53:55.601: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-3ce92116-5a94-11e9-8d38-4647074cf119 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 06:53:55.660: INFO: Waiting for pod pod-configmaps-3ce92116-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:53:55.682: INFO: Pod pod-configmaps-3ce92116-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:53:55.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6558" for this suite.
Apr  9 06:54:01.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:54:02.642: INFO: namespace configmap-6558 deletion completed in 6.938111842s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:54:02.643: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5311
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  9 06:54:02.895: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-5311'
Apr  9 06:54:03.073: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  9 06:54:03.073: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr  9 06:54:03.195: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-7pnqw]
Apr  9 06:54:03.195: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-7pnqw" in namespace "kubectl-5311" to be "running and ready"
Apr  9 06:54:03.295: INFO: Pod "e2e-test-nginx-rc-7pnqw": Phase="Pending", Reason="", readiness=false. Elapsed: 100.425171ms
Apr  9 06:54:05.317: INFO: Pod "e2e-test-nginx-rc-7pnqw": Phase="Running", Reason="", readiness=true. Elapsed: 2.122174347s
Apr  9 06:54:05.317: INFO: Pod "e2e-test-nginx-rc-7pnqw" satisfied condition "running and ready"
Apr  9 06:54:05.317: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-7pnqw]
Apr  9 06:54:05.317: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config logs rc/e2e-test-nginx-rc --namespace=kubectl-5311'
Apr  9 06:54:05.611: INFO: stderr: ""
Apr  9 06:54:05.611: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Apr  9 06:54:05.611: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-5311'
Apr  9 06:54:05.781: INFO: stderr: ""
Apr  9 06:54:05.781: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:54:05.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5311" for this suite.
Apr  9 06:54:29.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:54:30.681: INFO: namespace kubectl-5311 deletion completed in 24.877789818s
•
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:54:30.681: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Apr  9 06:54:31.080: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config --namespace=kubectl-416 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr  9 06:54:33.316: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr  9 06:54:33.316: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:54:35.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-416" for this suite.
Apr  9 06:54:41.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:54:42.238: INFO: namespace kubectl-416 deletion completed in 6.855021576s
•
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:54:42.238: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7297
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-5a1f12a2-5a94-11e9-8d38-4647074cf119
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:54:46.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7297" for this suite.
Apr  9 06:55:08.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:55:09.679: INFO: namespace configmap-7297 deletion completed in 22.914647059s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:55:09.680: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9776
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-jzmz
STEP: Creating a pod to test atomic-volume-subpath
Apr  9 06:55:10.252: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jzmz" in namespace "subpath-9776" to be "success or failure"
Apr  9 06:55:10.274: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Pending", Reason="", readiness=false. Elapsed: 21.350116ms
Apr  9 06:55:12.296: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 2.043378654s
Apr  9 06:55:14.318: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 4.065859572s
Apr  9 06:55:16.340: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 6.0878796s
Apr  9 06:55:18.363: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 8.110039213s
Apr  9 06:55:20.385: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 10.132043355s
Apr  9 06:55:22.409: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 12.156164446s
Apr  9 06:55:24.432: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 14.179222041s
Apr  9 06:55:26.454: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 16.201375389s
Apr  9 06:55:28.476: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 18.223597375s
Apr  9 06:55:30.499: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Running", Reason="", readiness=true. Elapsed: 20.246747367s
Apr  9 06:55:32.522: INFO: Pod "pod-subpath-test-configmap-jzmz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.269420365s
STEP: Saw pod success
Apr  9 06:55:32.522: INFO: Pod "pod-subpath-test-configmap-jzmz" satisfied condition "success or failure"
Apr  9 06:55:32.545: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-subpath-test-configmap-jzmz container test-container-subpath-configmap-jzmz: <nil>
STEP: delete the pod
Apr  9 06:55:32.602: INFO: Waiting for pod pod-subpath-test-configmap-jzmz to disappear
Apr  9 06:55:32.624: INFO: Pod pod-subpath-test-configmap-jzmz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jzmz
Apr  9 06:55:32.624: INFO: Deleting pod "pod-subpath-test-configmap-jzmz" in namespace "subpath-9776"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:55:32.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9776" for this suite.
Apr  9 06:55:38.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:55:39.547: INFO: namespace subpath-9776 deletion completed in 6.878714393s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:55:39.547: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9512
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7158
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5874
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:56:05.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9512" for this suite.
Apr  9 06:56:11.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:56:12.570: INFO: namespace namespaces-9512 deletion completed in 6.866343176s
STEP: Destroying namespace "nsdeletetest-7158" for this suite.
Apr  9 06:56:12.592: INFO: Namespace nsdeletetest-7158 was already deleted
STEP: Destroying namespace "nsdeletetest-5874" for this suite.
Apr  9 06:56:18.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:56:19.575: INFO: namespace nsdeletetest-5874 deletion completed in 6.982884788s
•SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:56:19.575: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5496
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  9 06:56:22.649: INFO: Successfully updated pod "labelsupdate9436fec1-5a94-11e9-8d38-4647074cf119"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:56:24.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5496" for this suite.
Apr  9 06:56:48.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:56:49.618: INFO: namespace projected-5496 deletion completed in 24.887742808s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:56:49.618: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8969
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-a60b73ce-5a94-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 06:56:49.942: INFO: Waiting up to 5m0s for pod "pod-configmaps-a60edd2f-5a94-11e9-8d38-4647074cf119" in namespace "configmap-8969" to be "success or failure"
Apr  9 06:56:49.963: INFO: Pod "pod-configmaps-a60edd2f-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.668749ms
Apr  9 06:56:51.985: INFO: Pod "pod-configmaps-a60edd2f-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042776507s
STEP: Saw pod success
Apr  9 06:56:51.985: INFO: Pod "pod-configmaps-a60edd2f-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:56:52.007: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-a60edd2f-5a94-11e9-8d38-4647074cf119 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 06:56:52.063: INFO: Waiting for pod pod-configmaps-a60edd2f-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:56:52.084: INFO: Pod pod-configmaps-a60edd2f-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:56:52.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8969" for this suite.
Apr  9 06:56:58.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:56:58.956: INFO: namespace configmap-8969 deletion completed in 6.850312608s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:56:58.956: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3789
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 06:56:59.386: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"abaed48e-5a94-11e9-8ec1-5e80bdd8d9d6", Controller:(*bool)(0xc002dfadfa), BlockOwnerDeletion:(*bool)(0xc002dfadfb)}}
Apr  9 06:56:59.410: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"aba7009e-5a94-11e9-8ec1-5e80bdd8d9d6", Controller:(*bool)(0xc002995d76), BlockOwnerDeletion:(*bool)(0xc002995d77)}}
Apr  9 06:56:59.433: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"abaa5e94-5a94-11e9-8ec1-5e80bdd8d9d6", Controller:(*bool)(0xc0027fc966), BlockOwnerDeletion:(*bool)(0xc0027fc967)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:57:04.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3789" for this suite.
Apr  9 06:57:10.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:57:11.381: INFO: namespace gc-3789 deletion completed in 6.880641114s
•
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:57:11.382: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3594
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  9 06:57:11.783: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-3594'
Apr  9 06:57:11.976: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  9 06:57:11.976: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Apr  9 06:57:14.020: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-3594'
Apr  9 06:57:14.192: INFO: stderr: ""
Apr  9 06:57:14.193: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:57:14.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3594" for this suite.
Apr  9 06:57:38.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:57:39.090: INFO: namespace kubectl-3594 deletion completed in 24.873787514s
•SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:57:39.090: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-709
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-c38d5955-5a94-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 06:57:39.447: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c390b382-5a94-11e9-8d38-4647074cf119" in namespace "projected-709" to be "success or failure"
Apr  9 06:57:39.470: INFO: Pod "pod-projected-secrets-c390b382-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 23.161673ms
Apr  9 06:57:41.493: INFO: Pod "pod-projected-secrets-c390b382-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046078624s
STEP: Saw pod success
Apr  9 06:57:41.493: INFO: Pod "pod-projected-secrets-c390b382-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:57:41.517: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-secrets-c390b382-5a94-11e9-8d38-4647074cf119 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  9 06:57:41.576: INFO: Waiting for pod pod-projected-secrets-c390b382-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:57:41.598: INFO: Pod pod-projected-secrets-c390b382-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:57:41.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-709" for this suite.
Apr  9 06:57:47.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:57:48.514: INFO: namespace projected-709 deletion completed in 6.893698566s
•SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:57:48.514: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9525
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 06:57:48.905: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9340571-5a94-11e9-8d38-4647074cf119" in namespace "downward-api-9525" to be "success or failure"
Apr  9 06:57:48.926: INFO: Pod "downwardapi-volume-c9340571-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.3059ms
Apr  9 06:57:50.948: INFO: Pod "downwardapi-volume-c9340571-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042745689s
STEP: Saw pod success
Apr  9 06:57:50.948: INFO: Pod "downwardapi-volume-c9340571-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:57:50.969: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-c9340571-5a94-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 06:57:51.025: INFO: Waiting for pod downwardapi-volume-c9340571-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:57:51.046: INFO: Pod downwardapi-volume-c9340571-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:57:51.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9525" for this suite.
Apr  9 06:57:57.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:57:57.915: INFO: namespace downward-api-9525 deletion completed in 6.847711261s
•SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:57:57.918: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3081
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0409 06:58:28.461378    5079 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  9 06:58:28.461: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:58:28.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3081" for this suite.
Apr  9 06:58:34.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:58:35.363: INFO: namespace gc-3081 deletion completed in 6.880472798s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:58:35.364: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6616
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-e52a9ef7-5a94-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 06:58:35.841: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e52de5a5-5a94-11e9-8d38-4647074cf119" in namespace "projected-6616" to be "success or failure"
Apr  9 06:58:35.862: INFO: Pod "pod-projected-secrets-e52de5a5-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.267966ms
Apr  9 06:58:37.884: INFO: Pod "pod-projected-secrets-e52de5a5-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042955877s
STEP: Saw pod success
Apr  9 06:58:37.884: INFO: Pod "pod-projected-secrets-e52de5a5-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:58:37.906: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-secrets-e52de5a5-5a94-11e9-8d38-4647074cf119 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  9 06:58:37.963: INFO: Waiting for pod pod-projected-secrets-e52de5a5-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:58:37.984: INFO: Pod pod-projected-secrets-e52de5a5-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:58:37.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6616" for this suite.
Apr  9 06:58:44.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:58:44.901: INFO: namespace projected-6616 deletion completed in 6.893319086s
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:58:44.902: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1136
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-eac4855f-5a94-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 06:58:45.241: INFO: Waiting up to 5m0s for pod "pod-secrets-eac7ef8a-5a94-11e9-8d38-4647074cf119" in namespace "secrets-1136" to be "success or failure"
Apr  9 06:58:45.262: INFO: Pod "pod-secrets-eac7ef8a-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.899045ms
Apr  9 06:58:47.285: INFO: Pod "pod-secrets-eac7ef8a-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043666689s
STEP: Saw pod success
Apr  9 06:58:47.285: INFO: Pod "pod-secrets-eac7ef8a-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:58:47.307: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-secrets-eac7ef8a-5a94-11e9-8d38-4647074cf119 container secret-volume-test: <nil>
STEP: delete the pod
Apr  9 06:58:47.365: INFO: Waiting for pod pod-secrets-eac7ef8a-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:58:47.386: INFO: Pod pod-secrets-eac7ef8a-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:58:47.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1136" for this suite.
Apr  9 06:58:53.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:58:54.259: INFO: namespace secrets-1136 deletion completed in 6.849630971s
•SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:58:54.259: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8166
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  9 06:58:54.717: INFO: Waiting up to 5m0s for pod "pod-f06e0dcb-5a94-11e9-8d38-4647074cf119" in namespace "emptydir-8166" to be "success or failure"
Apr  9 06:58:54.738: INFO: Pod "pod-f06e0dcb-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.880756ms
Apr  9 06:58:56.760: INFO: Pod "pod-f06e0dcb-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043475299s
STEP: Saw pod success
Apr  9 06:58:56.760: INFO: Pod "pod-f06e0dcb-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:58:56.782: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-f06e0dcb-5a94-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 06:58:56.844: INFO: Waiting for pod pod-f06e0dcb-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:58:56.865: INFO: Pod pod-f06e0dcb-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:58:56.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8166" for this suite.
Apr  9 06:59:02.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:59:03.741: INFO: namespace emptydir-8166 deletion completed in 6.853187765s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:59:03.741: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3465
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f606b54f-5a94-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 06:59:04.130: INFO: Waiting up to 5m0s for pod "pod-secrets-f60a5999-5a94-11e9-8d38-4647074cf119" in namespace "secrets-3465" to be "success or failure"
Apr  9 06:59:04.152: INFO: Pod "pod-secrets-f60a5999-5a94-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.302112ms
Apr  9 06:59:06.174: INFO: Pod "pod-secrets-f60a5999-5a94-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043297426s
STEP: Saw pod success
Apr  9 06:59:06.174: INFO: Pod "pod-secrets-f60a5999-5a94-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:59:06.196: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-secrets-f60a5999-5a94-11e9-8d38-4647074cf119 container secret-env-test: <nil>
STEP: delete the pod
Apr  9 06:59:06.253: INFO: Waiting for pod pod-secrets-f60a5999-5a94-11e9-8d38-4647074cf119 to disappear
Apr  9 06:59:06.273: INFO: Pod pod-secrets-f60a5999-5a94-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:59:06.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3465" for this suite.
Apr  9 06:59:12.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:59:13.146: INFO: namespace secrets-3465 deletion completed in 6.850341596s
•SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:59:13.146: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1393
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-1393
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1393 to expose endpoints map[]
Apr  9 06:59:13.539: INFO: successfully validated that service multi-endpoint-test in namespace services-1393 exposes endpoints map[] (21.458254ms elapsed)
STEP: Creating pod pod1 in namespace services-1393
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1393 to expose endpoints map[pod1:[100]]
Apr  9 06:59:15.694: INFO: successfully validated that service multi-endpoint-test in namespace services-1393 exposes endpoints map[pod1:[100]] (2.129911263s elapsed)
STEP: Creating pod pod2 in namespace services-1393
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1393 to expose endpoints map[pod1:[100] pod2:[101]]
Apr  9 06:59:18.979: INFO: successfully validated that service multi-endpoint-test in namespace services-1393 exposes endpoints map[pod1:[100] pod2:[101]] (3.261405947s elapsed)
STEP: Deleting pod pod1 in namespace services-1393
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1393 to expose endpoints map[pod2:[101]]
Apr  9 06:59:19.046: INFO: successfully validated that service multi-endpoint-test in namespace services-1393 exposes endpoints map[pod2:[101]] (42.599475ms elapsed)
STEP: Deleting pod pod2 in namespace services-1393
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1393 to expose endpoints map[]
Apr  9 06:59:19.092: INFO: successfully validated that service multi-endpoint-test in namespace services-1393 exposes endpoints map[] (21.522366ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:59:19.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1393" for this suite.
Apr  9 06:59:43.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:59:44.009: INFO: namespace services-1393 deletion completed in 24.861734418s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
•SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:59:44.010: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-235
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Apr  9 06:59:44.324: INFO: Waiting up to 5m0s for pod "client-containers-0dff6c4a-5a95-11e9-8d38-4647074cf119" in namespace "containers-235" to be "success or failure"
Apr  9 06:59:44.345: INFO: Pod "client-containers-0dff6c4a-5a95-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.862106ms
Apr  9 06:59:46.367: INFO: Pod "client-containers-0dff6c4a-5a95-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042484925s
STEP: Saw pod success
Apr  9 06:59:46.367: INFO: Pod "client-containers-0dff6c4a-5a95-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 06:59:46.388: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod client-containers-0dff6c4a-5a95-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 06:59:46.447: INFO: Waiting for pod client-containers-0dff6c4a-5a95-11e9-8d38-4647074cf119 to disappear
Apr  9 06:59:46.470: INFO: Pod client-containers-0dff6c4a-5a95-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:59:46.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-235" for this suite.
Apr  9 06:59:52.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 06:59:53.347: INFO: namespace containers-235 deletion completed in 6.854930382s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 06:59:53.347: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 06:59:55.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6782" for this suite.
Apr  9 07:00:01.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:00:02.697: INFO: namespace emptydir-wrapper-6782 deletion completed in 6.866306709s
•SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:00:02.698: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9284
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:00:03.083: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config version --client'
Apr  9 07:00:03.161: INFO: stderr: ""
Apr  9 07:00:03.161: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:57:14Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr  9 07:00:03.182: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-9284'
Apr  9 07:00:04.795: INFO: stderr: ""
Apr  9 07:00:04.795: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr  9 07:00:04.795: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-9284'
Apr  9 07:00:05.110: INFO: stderr: ""
Apr  9 07:00:05.110: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  9 07:00:06.145: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 07:00:06.145: INFO: Found 0 / 1
Apr  9 07:00:07.133: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 07:00:07.133: INFO: Found 1 / 1
Apr  9 07:00:07.133: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  9 07:00:07.155: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 07:00:07.155: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  9 07:00:07.155: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe pod redis-master-mnbm2 --namespace=kubectl-9284'
Apr  9 07:00:07.365: INFO: stderr: ""
Apr  9 07:00:07.365: INFO: stdout: "Name:               redis-master-mnbm2\nNamespace:          kubectl-9284\nPriority:           0\nPriorityClassName:  <none>\nNode:               shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk/10.250.0.2\nStart Time:         Tue, 09 Apr 2019 07:00:04 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 100.96.0.81/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 100.96.0.81\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://9920e0476211dcb223f5ab124792e8799032cce3ecbdd29066517fc8214ff8b6\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 09 Apr 2019 07:00:05 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-km9w9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-km9w9:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-km9w9\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                              Message\n  ----    ------     ----  ----                                                              -------\n  Normal  Scheduled  3s    default-scheduler                                                 Successfully assigned kubectl-9284/redis-master-mnbm2 to shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk\n  Normal  Pulled     2s    kubelet, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk  Created container redis-master\n  Normal  Started    2s    kubelet, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk  Started container redis-master\n"
Apr  9 07:00:07.365: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe rc redis-master --namespace=kubectl-9284'
Apr  9 07:00:07.581: INFO: stderr: ""
Apr  9 07:00:07.581: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9284\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-mnbm2\n"
Apr  9 07:00:07.581: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe service redis-master --namespace=kubectl-9284'
Apr  9 07:00:07.835: INFO: stderr: ""
Apr  9 07:00:07.835: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9284\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.71.2.21\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.0.81:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr  9 07:00:07.857: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl'
Apr  9 07:00:08.096: INFO: stderr: ""
Apr  9 07:00:08.096: INFO: stdout: "Name:               shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=n1-standard-4\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=europe-west1\n                    failure-domain.beta.kubernetes.io/zone=europe-west1-d\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl\n                    kubernetes.io/os=linux\n                    kubernetes.io/role=node\n                    node-role.kubernetes.io/node=\n                    worker.garden.sapcloud.io/group=cpu-worker\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.3/32\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 09 Apr 2019 06:24:06 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 09 Apr 2019 06:24:25 +0000   Tue, 09 Apr 2019 06:24:25 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Tue, 09 Apr 2019 07:00:00 +0000   Tue, 09 Apr 2019 06:24:06 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 09 Apr 2019 07:00:00 +0000   Tue, 09 Apr 2019 06:24:06 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 09 Apr 2019 07:00:00 +0000   Tue, 09 Apr 2019 06:24:06 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 09 Apr 2019 07:00:00 +0000   Tue, 09 Apr 2019 06:24:16 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.250.0.3\n  ExternalIP:   34.76.205.27\n  InternalDNS:  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl.c.sap-se-gcp-scp-k8s-dev.internal\n  Hostname:     shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl.c.sap-se-gcp-scp-k8s-dev.internal\nCapacity:\n attachable-volumes-gce-pd:  64\n cpu:                        4\n ephemeral-storage:          17897500Ki\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     15395148Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  64\n cpu:                        3920m\n ephemeral-storage:          17410687987\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     13297996Ki\n pods:                       110\nSystem Info:\n Machine ID:                 c68fecedbe509bf900e36deff8736d06\n System UUID:                c68feced-be50-9bf9-00e3-6deff8736d06\n Boot ID:                    bb73a14b-fcd5-4501-9d46-9f5c7378f91b\n Kernel Version:             4.19.25-coreos\n OS Image:                   Container Linux by CoreOS 2023.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.14.0\n Kube-Proxy Version:         v1.14.0\nPodCIDR:                     100.96.1.0/24\nProviderID:                  gce://sap-se-gcp-scp-k8s-dev/europe-west1-d/shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                               ------------  ----------  ---------------  -------------\n  kube-system                addons-nginx-ingress-controller-d4f8c9cc5-fznw4                    100m (2%)     2 (51%)     100Mi (0%)       800Mi (6%)\n  kube-system                addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-fxn5k    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-dfwwr                                                  100m (2%)     500m (12%)  100Mi (0%)       700Mi (5%)\n  kube-system                coredns-7f7f7978c8-hdctx                                           50m (1%)      100m (2%)   15Mi (0%)        100Mi (0%)\n  kube-system                kube-proxy-f7xbd                                                   20m (0%)      0 (0%)      64Mi (0%)        0 (0%)\n  kube-system                node-exporter-8f864                                                5m (0%)       15m (0%)    10Mi (0%)        100Mi (0%)\n  kube-system                vpn-shoot-b9464f486-vkb96                                          50m (1%)      100m (2%)   50Mi (0%)        100Mi (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        325m (8%)   2715m (69%)\n  memory                     339Mi (2%)  1800Mi (13%)\n  attachable-volumes-gce-pd  0           0\nEvents:\n  Type    Reason                   Age                From                                                                 Message\n  ----    ------                   ----               ----                                                                 -------\n  Normal  Starting                 36m                kubelet, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl     Starting kubelet.\n  Normal  NodeHasSufficientMemory  36m (x2 over 36m)  kubelet, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl     Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    36m (x2 over 36m)  kubelet, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl     Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     36m (x2 over 36m)  kubelet, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl     Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  36m                kubelet, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl     Updated Node Allocatable limit across pods\n  Normal  Starting                 36m                kube-proxy, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Starting kube-proxy.\n  Normal  NodeReady                35m                kubelet, shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl     Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl status is now: NodeReady\n"
Apr  9 07:00:08.097: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config describe namespace kubectl-9284'
Apr  9 07:00:08.339: INFO: stderr: ""
Apr  9 07:00:08.340: INFO: stdout: "Name:         kubectl-9284\nLabels:       e2e-framework=kubectl\n              e2e-run=d00a4a67-5a90-11e9-8d38-4647074cf119\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:00:08.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9284" for this suite.
Apr  9 07:00:32.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:00:33.240: INFO: namespace kubectl-9284 deletion completed in 24.87848773s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:00:33.240: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2631
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Apr  9 07:00:33.524: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2631" to be "success or failure"
Apr  9 07:00:33.546: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 21.460596ms
Apr  9 07:00:35.568: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044032768s
STEP: Saw pod success
Apr  9 07:00:35.568: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr  9 07:00:35.590: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr  9 07:00:35.648: INFO: Waiting for pod pod-host-path-test to disappear
Apr  9 07:00:35.670: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:00:35.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2631" for this suite.
Apr  9 07:00:41.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:00:42.548: INFO: namespace hostpath-2631 deletion completed in 6.855010431s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:00:42.548: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5461
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-30dd9082-5a95-11e9-8d38-4647074cf119
STEP: Creating secret with name secret-projected-all-test-volume-30dd906f-5a95-11e9-8d38-4647074cf119
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr  9 07:00:42.867: INFO: Waiting up to 5m0s for pod "projected-volume-30dd903b-5a95-11e9-8d38-4647074cf119" in namespace "projected-5461" to be "success or failure"
Apr  9 07:00:42.887: INFO: Pod "projected-volume-30dd903b-5a95-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.743019ms
Apr  9 07:00:44.910: INFO: Pod "projected-volume-30dd903b-5a95-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043082103s
STEP: Saw pod success
Apr  9 07:00:44.910: INFO: Pod "projected-volume-30dd903b-5a95-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:00:44.932: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod projected-volume-30dd903b-5a95-11e9-8d38-4647074cf119 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr  9 07:00:44.994: INFO: Waiting for pod projected-volume-30dd903b-5a95-11e9-8d38-4647074cf119 to disappear
Apr  9 07:00:45.015: INFO: Pod projected-volume-30dd903b-5a95-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:00:45.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5461" for this suite.
Apr  9 07:00:51.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:00:51.893: INFO: namespace projected-5461 deletion completed in 6.855746641s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:00:51.893: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6692
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Apr  9 07:00:52.313: INFO: Waiting up to 5m0s for pod "var-expansion-3685c041-5a95-11e9-8d38-4647074cf119" in namespace "var-expansion-6692" to be "success or failure"
Apr  9 07:00:52.334: INFO: Pod "var-expansion-3685c041-5a95-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.87119ms
Apr  9 07:00:54.357: INFO: Pod "var-expansion-3685c041-5a95-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044198591s
STEP: Saw pod success
Apr  9 07:00:54.357: INFO: Pod "var-expansion-3685c041-5a95-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:00:54.379: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod var-expansion-3685c041-5a95-11e9-8d38-4647074cf119 container dapi-container: <nil>
STEP: delete the pod
Apr  9 07:00:54.477: INFO: Waiting for pod var-expansion-3685c041-5a95-11e9-8d38-4647074cf119 to disappear
Apr  9 07:00:54.499: INFO: Pod var-expansion-3685c041-5a95-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:00:54.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6692" for this suite.
Apr  9 07:01:00.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:01:01.417: INFO: namespace var-expansion-6692 deletion completed in 6.896737837s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:01:01.418: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-qckd
STEP: Creating a pod to test atomic-volume-subpath
Apr  9 07:01:01.765: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-qckd" in namespace "subpath-7885" to be "success or failure"
Apr  9 07:01:01.787: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Pending", Reason="", readiness=false. Elapsed: 21.273082ms
Apr  9 07:01:03.815: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 2.049629884s
Apr  9 07:01:05.838: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 4.073094365s
Apr  9 07:01:07.862: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 6.096214478s
Apr  9 07:01:09.884: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 8.119141813s
Apr  9 07:01:11.907: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 10.141312012s
Apr  9 07:01:13.928: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 12.163031906s
Apr  9 07:01:15.951: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 14.185913643s
Apr  9 07:01:17.974: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 16.209049687s
Apr  9 07:01:19.996: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 18.231179497s
Apr  9 07:01:22.019: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Running", Reason="", readiness=true. Elapsed: 20.253800279s
Apr  9 07:01:24.041: INFO: Pod "pod-subpath-test-projected-qckd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.275743108s
STEP: Saw pod success
Apr  9 07:01:24.041: INFO: Pod "pod-subpath-test-projected-qckd" satisfied condition "success or failure"
Apr  9 07:01:24.065: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-subpath-test-projected-qckd container test-container-subpath-projected-qckd: <nil>
STEP: delete the pod
Apr  9 07:01:24.120: INFO: Waiting for pod pod-subpath-test-projected-qckd to disappear
Apr  9 07:01:24.142: INFO: Pod pod-subpath-test-projected-qckd no longer exists
STEP: Deleting pod pod-subpath-test-projected-qckd
Apr  9 07:01:24.142: INFO: Deleting pod "pod-subpath-test-projected-qckd" in namespace "subpath-7885"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:01:24.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7885" for this suite.
Apr  9 07:01:30.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:01:31.051: INFO: namespace subpath-7885 deletion completed in 6.862242318s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:01:31.052: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2897
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  9 07:01:34.074: INFO: Successfully updated pod "annotationupdate4dd3f376-5a95-11e9-8d38-4647074cf119"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:01:38.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2897" for this suite.
Apr  9 07:02:00.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:02:01.034: INFO: namespace projected-2897 deletion completed in 22.850343634s
•SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:02:01.034: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  9 07:02:01.408: INFO: Waiting up to 5m0s for pod "pod-5fb4b4c1-5a95-11e9-8d38-4647074cf119" in namespace "emptydir-8742" to be "success or failure"
Apr  9 07:02:01.429: INFO: Pod "pod-5fb4b4c1-5a95-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.796538ms
Apr  9 07:02:03.451: INFO: Pod "pod-5fb4b4c1-5a95-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042141273s
STEP: Saw pod success
Apr  9 07:02:03.451: INFO: Pod "pod-5fb4b4c1-5a95-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:02:03.471: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-5fb4b4c1-5a95-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:02:03.526: INFO: Waiting for pod pod-5fb4b4c1-5a95-11e9-8d38-4647074cf119 to disappear
Apr  9 07:02:03.548: INFO: Pod pod-5fb4b4c1-5a95-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:02:03.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8742" for this suite.
Apr  9 07:02:09.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:02:10.468: INFO: namespace emptydir-8742 deletion completed in 6.899271s
•
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:02:10.469: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1774
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:02:12.944: INFO: Waiting up to 5m0s for pod "client-envvars-66956733-5a95-11e9-8d38-4647074cf119" in namespace "pods-1774" to be "success or failure"
Apr  9 07:02:12.966: INFO: Pod "client-envvars-66956733-5a95-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.114514ms
Apr  9 07:02:14.989: INFO: Pod "client-envvars-66956733-5a95-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045032716s
STEP: Saw pod success
Apr  9 07:02:14.989: INFO: Pod "client-envvars-66956733-5a95-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:02:15.011: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl pod client-envvars-66956733-5a95-11e9-8d38-4647074cf119 container env3cont: <nil>
STEP: delete the pod
Apr  9 07:02:15.066: INFO: Waiting for pod client-envvars-66956733-5a95-11e9-8d38-4647074cf119 to disappear
Apr  9 07:02:15.088: INFO: Pod client-envvars-66956733-5a95-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:02:15.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1774" for this suite.
Apr  9 07:02:55.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:02:55.993: INFO: namespace pods-1774 deletion completed in 40.882929704s
•SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:02:55.993: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2014
Apr  9 07:02:58.365: INFO: Started pod liveness-exec in namespace container-probe-2014
STEP: checking the pod's current state and verifying that restartCount is present
Apr  9 07:02:58.388: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:06:59.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2014" for this suite.
Apr  9 07:07:05.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:07:06.034: INFO: namespace container-probe-2014 deletion completed in 6.852761728s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:07:06.034: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4470
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4470
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  9 07:07:06.292: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  9 07:07:26.695: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.36:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4470 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 07:07:26.695: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 07:07:27.318: INFO: Found all expected endpoints: [netserver-0]
Apr  9 07:07:27.341: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.0.90:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4470 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 07:07:27.341: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 07:07:27.904: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:07:27.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4470" for this suite.
Apr  9 07:07:49.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:07:50.783: INFO: namespace pod-network-test-4470 deletion completed in 22.856344341s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:07:50.783: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4973
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  9 07:07:51.185: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4973'
Apr  9 07:07:51.364: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Apr  9 07:07:51.364: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Apr  9 07:07:51.385: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-4973'
Apr  9 07:07:51.560: INFO: stderr: ""
Apr  9 07:07:51.560: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:07:51.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4973" for this suite.
Apr  9 07:07:57.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:07:58.445: INFO: namespace kubectl-4973 deletion completed in 6.862900515s
•SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:07:58.446: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2126
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-34ae643d-5a96-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:07:58.759: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-34b3edce-5a96-11e9-8d38-4647074cf119" in namespace "projected-2126" to be "success or failure"
Apr  9 07:07:58.780: INFO: Pod "pod-projected-configmaps-34b3edce-5a96-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.119649ms
Apr  9 07:08:00.803: INFO: Pod "pod-projected-configmaps-34b3edce-5a96-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044590301s
STEP: Saw pod success
Apr  9 07:08:00.803: INFO: Pod "pod-projected-configmaps-34b3edce-5a96-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:08:00.825: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-configmaps-34b3edce-5a96-11e9-8d38-4647074cf119 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 07:08:00.886: INFO: Waiting for pod pod-projected-configmaps-34b3edce-5a96-11e9-8d38-4647074cf119 to disappear
Apr  9 07:08:00.908: INFO: Pod pod-projected-configmaps-34b3edce-5a96-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:08:00.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2126" for this suite.
Apr  9 07:08:08.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:08:09.822: INFO: namespace projected-2126 deletion completed in 8.892075345s
•SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:08:09.822: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:08:10.211: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b879a87-5a96-11e9-8d38-4647074cf119" in namespace "downward-api-644" to be "success or failure"
Apr  9 07:08:10.233: INFO: Pod "downwardapi-volume-3b879a87-5a96-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.219211ms
Apr  9 07:08:12.255: INFO: Pod "downwardapi-volume-3b879a87-5a96-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043133492s
STEP: Saw pod success
Apr  9 07:08:12.255: INFO: Pod "downwardapi-volume-3b879a87-5a96-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:08:12.276: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-3b879a87-5a96-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:08:12.333: INFO: Waiting for pod downwardapi-volume-3b879a87-5a96-11e9-8d38-4647074cf119 to disappear
Apr  9 07:08:12.355: INFO: Pod downwardapi-volume-3b879a87-5a96-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:08:12.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-644" for this suite.
Apr  9 07:08:20.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:08:21.234: INFO: namespace downward-api-644 deletion completed in 8.856983705s
•
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:08:21.234: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8897
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Apr  9 07:08:22.109: INFO: created pod pod-service-account-defaultsa
Apr  9 07:08:22.109: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr  9 07:08:22.131: INFO: created pod pod-service-account-mountsa
Apr  9 07:08:22.131: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr  9 07:08:22.154: INFO: created pod pod-service-account-nomountsa
Apr  9 07:08:22.154: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr  9 07:08:22.176: INFO: created pod pod-service-account-defaultsa-mountspec
Apr  9 07:08:22.176: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr  9 07:08:22.199: INFO: created pod pod-service-account-mountsa-mountspec
Apr  9 07:08:22.199: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr  9 07:08:22.222: INFO: created pod pod-service-account-nomountsa-mountspec
Apr  9 07:08:22.222: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr  9 07:08:22.244: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr  9 07:08:22.244: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr  9 07:08:22.267: INFO: created pod pod-service-account-mountsa-nomountspec
Apr  9 07:08:22.267: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr  9 07:08:22.296: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr  9 07:08:22.296: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:08:22.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8897" for this suite.
Apr  9 07:08:28.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:08:29.188: INFO: namespace svcaccounts-8897 deletion completed in 6.868894136s
•SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:08:29.189: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2449
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:08:29.605: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr  9 07:08:29.672: INFO: Number of nodes with available pods: 0
Apr  9 07:08:29.672: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:08:30.717: INFO: Number of nodes with available pods: 0
Apr  9 07:08:30.718: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:08:31.718: INFO: Number of nodes with available pods: 2
Apr  9 07:08:31.718: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr  9 07:08:31.877: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:31.877: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:32.922: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:32.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:33.921: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:33.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:34.922: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:34.922: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:34.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:35.923: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:35.923: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:35.923: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:36.922: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:36.922: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:36.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:37.921: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:37.921: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:37.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:38.921: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:38.921: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:38.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:39.922: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:39.922: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:39.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:40.921: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:40.921: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:40.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:41.921: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:41.921: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:41.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:42.921: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:42.921: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:42.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:43.921: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:43.921: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:43.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:44.921: INFO: Wrong image for pod: daemon-set-8k2dg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:44.922: INFO: Pod daemon-set-8k2dg is not available
Apr  9 07:08:44.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:45.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:45.921: INFO: Pod daemon-set-vmwsg is not available
Apr  9 07:08:46.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:46.921: INFO: Pod daemon-set-vmwsg is not available
Apr  9 07:08:47.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:48.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:48.921: INFO: Pod daemon-set-t9hpj is not available
Apr  9 07:08:49.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:49.922: INFO: Pod daemon-set-t9hpj is not available
Apr  9 07:08:50.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:50.921: INFO: Pod daemon-set-t9hpj is not available
Apr  9 07:08:51.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:51.921: INFO: Pod daemon-set-t9hpj is not available
Apr  9 07:08:52.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:52.922: INFO: Pod daemon-set-t9hpj is not available
Apr  9 07:08:53.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:53.922: INFO: Pod daemon-set-t9hpj is not available
Apr  9 07:08:54.922: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:54.922: INFO: Pod daemon-set-t9hpj is not available
Apr  9 07:08:55.921: INFO: Wrong image for pod: daemon-set-t9hpj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Apr  9 07:08:55.921: INFO: Pod daemon-set-t9hpj is not available
Apr  9 07:08:56.921: INFO: Pod daemon-set-4cvk8 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr  9 07:08:57.005: INFO: Number of nodes with available pods: 1
Apr  9 07:08:57.005: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:08:58.069: INFO: Number of nodes with available pods: 1
Apr  9 07:08:58.069: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:08:59.075: INFO: Number of nodes with available pods: 2
Apr  9 07:08:59.076: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2449, will wait for the garbage collector to delete the pods
Apr  9 07:08:59.283: INFO: Deleting DaemonSet.extensions daemon-set took: 24.996181ms
Apr  9 07:08:59.383: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.239158ms
Apr  9 07:09:02.704: INFO: Number of nodes with available pods: 0
Apr  9 07:09:02.704: INFO: Number of running nodes: 0, number of available pods: 0
Apr  9 07:09:02.726: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2449/daemonsets","resourceVersion":"10553"},"items":null}

Apr  9 07:09:02.747: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2449/pods","resourceVersion":"10553"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:09:02.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2449" for this suite.
Apr  9 07:09:10.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:09:11.709: INFO: namespace daemonsets-2449 deletion completed in 8.854752097s
•SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:09:11.709: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9619
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Apr  9 07:09:12.080: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config api-versions'
Apr  9 07:09:12.317: INFO: stderr: ""
Apr  9 07:09:12.317: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:09:12.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9619" for this suite.
Apr  9 07:09:18.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:09:19.213: INFO: namespace kubectl-9619 deletion completed in 6.873765631s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:09:19.213: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6452
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-64e5b501-5a96-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:09:19.636: INFO: Waiting up to 5m0s for pod "pod-configmaps-64e91e91-5a96-11e9-8d38-4647074cf119" in namespace "configmap-6452" to be "success or failure"
Apr  9 07:09:19.657: INFO: Pod "pod-configmaps-64e91e91-5a96-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.921195ms
Apr  9 07:09:21.679: INFO: Pod "pod-configmaps-64e91e91-5a96-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042990265s
STEP: Saw pod success
Apr  9 07:09:21.679: INFO: Pod "pod-configmaps-64e91e91-5a96-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:09:21.701: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-64e91e91-5a96-11e9-8d38-4647074cf119 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 07:09:21.758: INFO: Waiting for pod pod-configmaps-64e91e91-5a96-11e9-8d38-4647074cf119 to disappear
Apr  9 07:09:21.780: INFO: Pod pod-configmaps-64e91e91-5a96-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:09:21.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6452" for this suite.
Apr  9 07:09:27.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:09:28.675: INFO: namespace configmap-6452 deletion completed in 6.855301504s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:09:28.676: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6457
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:09:29.023: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a8135d4-5a96-11e9-8d38-4647074cf119" in namespace "projected-6457" to be "success or failure"
Apr  9 07:09:29.044: INFO: Pod "downwardapi-volume-6a8135d4-5a96-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.315922ms
Apr  9 07:09:31.066: INFO: Pod "downwardapi-volume-6a8135d4-5a96-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043404408s
STEP: Saw pod success
Apr  9 07:09:31.066: INFO: Pod "downwardapi-volume-6a8135d4-5a96-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:09:31.088: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-6a8135d4-5a96-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:09:31.156: INFO: Waiting for pod downwardapi-volume-6a8135d4-5a96-11e9-8d38-4647074cf119 to disappear
Apr  9 07:09:31.177: INFO: Pod downwardapi-volume-6a8135d4-5a96-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:09:31.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6457" for this suite.
Apr  9 07:09:37.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:09:38.101: INFO: namespace projected-6457 deletion completed in 6.88385421s
•SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:09:38.101: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:09:38.426: INFO: Waiting up to 5m0s for pod "downwardapi-volume-701c3c54-5a96-11e9-8d38-4647074cf119" in namespace "projected-912" to be "success or failure"
Apr  9 07:09:38.448: INFO: Pod "downwardapi-volume-701c3c54-5a96-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.628096ms
Apr  9 07:09:40.470: INFO: Pod "downwardapi-volume-701c3c54-5a96-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043664812s
STEP: Saw pod success
Apr  9 07:09:40.470: INFO: Pod "downwardapi-volume-701c3c54-5a96-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:09:40.491: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-701c3c54-5a96-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:09:40.550: INFO: Waiting for pod downwardapi-volume-701c3c54-5a96-11e9-8d38-4647074cf119 to disappear
Apr  9 07:09:40.571: INFO: Pod downwardapi-volume-701c3c54-5a96-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:09:40.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-912" for this suite.
Apr  9 07:09:46.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:09:47.466: INFO: namespace projected-912 deletion completed in 6.854939751s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:09:47.467: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-314
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  9 07:09:52.253: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:09:52.275: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:09:54.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:09:54.297: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:09:56.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:09:56.297: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:09:58.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:09:58.297: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:00.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:00.297: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:02.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:02.296: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:04.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:04.297: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:06.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:06.297: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:08.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:08.297: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:10.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:10.298: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:12.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:12.297: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:14.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:14.298: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:16.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:16.298: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  9 07:10:18.275: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  9 07:10:18.297: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:10:18.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-314" for this suite.
Apr  9 07:10:42.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:10:43.240: INFO: namespace container-lifecycle-hook-314 deletion completed in 24.871495062s
•SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:10:43.240: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2896
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-2896/configmap-test-96e8eff3-5a96-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:10:43.543: INFO: Waiting up to 5m0s for pod "pod-configmaps-96ec5755-5a96-11e9-8d38-4647074cf119" in namespace "configmap-2896" to be "success or failure"
Apr  9 07:10:43.564: INFO: Pod "pod-configmaps-96ec5755-5a96-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.651449ms
Apr  9 07:10:45.586: INFO: Pod "pod-configmaps-96ec5755-5a96-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042566309s
STEP: Saw pod success
Apr  9 07:10:45.586: INFO: Pod "pod-configmaps-96ec5755-5a96-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:10:45.608: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-96ec5755-5a96-11e9-8d38-4647074cf119 container env-test: <nil>
STEP: delete the pod
Apr  9 07:10:45.663: INFO: Waiting for pod pod-configmaps-96ec5755-5a96-11e9-8d38-4647074cf119 to disappear
Apr  9 07:10:45.684: INFO: Pod pod-configmaps-96ec5755-5a96-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:10:45.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2896" for this suite.
Apr  9 07:10:51.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:10:52.762: INFO: namespace configmap-2896 deletion completed in 7.037820748s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:10:52.762: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1829
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-9cb33e3c-5a96-11e9-8d38-4647074cf119
STEP: Creating configMap with name cm-test-opt-upd-9cb33e76-5a96-11e9-8d38-4647074cf119
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9cb33e3c-5a96-11e9-8d38-4647074cf119
STEP: Updating configmap cm-test-opt-upd-9cb33e76-5a96-11e9-8d38-4647074cf119
STEP: Creating configMap with name cm-test-opt-create-9cb33e8c-5a96-11e9-8d38-4647074cf119
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:10:57.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1829" for this suite.
Apr  9 07:11:21.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:11:22.660: INFO: namespace projected-1829 deletion completed in 24.855051523s
•SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:11:22.660: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3477
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
W0409 07:11:23.179426    5079 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  9 07:11:23.179: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:11:23.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3477" for this suite.
Apr  9 07:11:29.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:11:30.051: INFO: namespace gc-3477 deletion completed in 6.850132742s
•SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:11:30.051: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-941
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:11:32.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-941" for this suite.
Apr  9 07:12:12.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:12:13.323: INFO: namespace kubelet-test-941 deletion completed in 40.862579257s
•SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:12:13.323: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:12:13.708: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ccaa529e-5a96-11e9-8d38-4647074cf119" in namespace "projected-6922" to be "success or failure"
Apr  9 07:12:13.731: INFO: Pod "downwardapi-volume-ccaa529e-5a96-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.9085ms
Apr  9 07:12:15.753: INFO: Pod "downwardapi-volume-ccaa529e-5a96-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044484055s
Apr  9 07:12:17.775: INFO: Pod "downwardapi-volume-ccaa529e-5a96-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066708588s
STEP: Saw pod success
Apr  9 07:12:17.775: INFO: Pod "downwardapi-volume-ccaa529e-5a96-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:12:17.797: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-ccaa529e-5a96-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:12:17.856: INFO: Waiting for pod downwardapi-volume-ccaa529e-5a96-11e9-8d38-4647074cf119 to disappear
Apr  9 07:12:17.877: INFO: Pod downwardapi-volume-ccaa529e-5a96-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:12:17.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6922" for this suite.
Apr  9 07:12:23.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:12:24.766: INFO: namespace projected-6922 deletion completed in 6.849433026s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:12:24.767: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4653
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-d379eba5-5a96-11e9-8d38-4647074cf119
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-d379eba5-5a96-11e9-8d38-4647074cf119
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:12:29.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4653" for this suite.
Apr  9 07:12:51.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:12:52.217: INFO: namespace projected-4653 deletion completed in 22.842785128s
•SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:12:52.217: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4100
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  9 07:12:52.668: INFO: Number of nodes with available pods: 0
Apr  9 07:12:52.668: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:12:53.731: INFO: Number of nodes with available pods: 0
Apr  9 07:12:53.731: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:12:54.731: INFO: Number of nodes with available pods: 2
Apr  9 07:12:54.731: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr  9 07:12:54.843: INFO: Number of nodes with available pods: 1
Apr  9 07:12:54.843: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:12:55.906: INFO: Number of nodes with available pods: 1
Apr  9 07:12:55.906: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:12:56.905: INFO: Number of nodes with available pods: 1
Apr  9 07:12:56.905: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:12:57.906: INFO: Number of nodes with available pods: 1
Apr  9 07:12:57.906: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:12:58.905: INFO: Number of nodes with available pods: 1
Apr  9 07:12:58.905: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:12:59.906: INFO: Number of nodes with available pods: 1
Apr  9 07:12:59.906: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:13:00.905: INFO: Number of nodes with available pods: 1
Apr  9 07:13:00.905: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:13:01.905: INFO: Number of nodes with available pods: 1
Apr  9 07:13:01.905: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:13:02.905: INFO: Number of nodes with available pods: 1
Apr  9 07:13:02.905: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:13:03.904: INFO: Number of nodes with available pods: 1
Apr  9 07:13:03.904: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:13:04.904: INFO: Number of nodes with available pods: 1
Apr  9 07:13:04.904: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:13:05.905: INFO: Number of nodes with available pods: 1
Apr  9 07:13:05.905: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk is running more than one daemon pod
Apr  9 07:13:06.905: INFO: Number of nodes with available pods: 2
Apr  9 07:13:06.905: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4100, will wait for the garbage collector to delete the pods
Apr  9 07:13:07.024: INFO: Deleting DaemonSet.extensions daemon-set took: 25.379002ms
Apr  9 07:13:07.124: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.27144ms
Apr  9 07:13:15.348: INFO: Number of nodes with available pods: 0
Apr  9 07:13:15.348: INFO: Number of running nodes: 0, number of available pods: 0
Apr  9 07:13:15.369: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4100/daemonsets","resourceVersion":"11385"},"items":null}

Apr  9 07:13:15.392: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4100/pods","resourceVersion":"11385"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:13:15.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4100" for this suite.
Apr  9 07:13:21.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:13:22.355: INFO: namespace daemonsets-4100 deletion completed in 6.855568613s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:13:22.355: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-581
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-581
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-581
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-581
Apr  9 07:13:22.868: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Apr  9 07:13:32.891: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr  9 07:13:32.912: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-581 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:13:33.619: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:13:33.619: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:13:33.619: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  9 07:13:33.641: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  9 07:13:43.665: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  9 07:13:43.665: INFO: Waiting for statefulset status.replicas updated to 0
Apr  9 07:13:43.753: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999497s
Apr  9 07:13:44.777: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.978570084s
Apr  9 07:13:45.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.955118092s
Apr  9 07:13:46.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.932253595s
Apr  9 07:13:47.847: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.909560535s
Apr  9 07:13:48.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.885401484s
Apr  9 07:13:49.891: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.863535973s
Apr  9 07:13:50.915: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.840807116s
Apr  9 07:13:51.939: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.81619597s
Apr  9 07:13:52.961: INFO: Verifying statefulset ss doesn't scale past 3 for another 793.513618ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-581
Apr  9 07:13:53.984: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-581 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  9 07:13:54.668: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  9 07:13:54.668: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  9 07:13:54.668: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  9 07:13:54.668: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-581 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  9 07:13:55.350: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  9 07:13:55.350: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  9 07:13:55.350: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  9 07:13:55.350: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-581 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  9 07:13:56.077: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  9 07:13:56.077: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  9 07:13:56.077: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  9 07:13:56.099: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:13:56.099: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:13:56.100: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr  9 07:13:56.122: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-581 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:13:56.854: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:13:56.854: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:13:56.854: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  9 07:13:56.854: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-581 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:13:57.487: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:13:57.487: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:13:57.487: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  9 07:13:57.487: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-581 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:13:58.139: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:13:58.139: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:13:58.139: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  9 07:13:58.139: INFO: Waiting for statefulset status.replicas updated to 0
Apr  9 07:13:58.160: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr  9 07:14:08.207: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  9 07:14:08.207: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  9 07:14:08.207: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  9 07:14:08.273: INFO: POD   NODE                                                     PHASE    GRACE  CONDITIONS
Apr  9 07:14:08.273: INFO: ss-0  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:22 +0000 UTC  }]
Apr  9 07:14:08.273: INFO: ss-1  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:08.273: INFO: ss-2  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:08.273: INFO: 
Apr  9 07:14:08.273: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  9 07:14:09.296: INFO: POD   NODE                                                     PHASE    GRACE  CONDITIONS
Apr  9 07:14:09.296: INFO: ss-0  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:22 +0000 UTC  }]
Apr  9 07:14:09.296: INFO: ss-1  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:09.296: INFO: ss-2  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:09.296: INFO: 
Apr  9 07:14:09.296: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  9 07:14:10.319: INFO: POD   NODE                                                     PHASE    GRACE  CONDITIONS
Apr  9 07:14:10.319: INFO: ss-1  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:10.319: INFO: ss-2  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:10.319: INFO: 
Apr  9 07:14:10.319: INFO: StatefulSet ss has not reached scale 0, at 2
Apr  9 07:14:11.342: INFO: POD   NODE                                                     PHASE    GRACE  CONDITIONS
Apr  9 07:14:11.342: INFO: ss-1  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:11.342: INFO: 
Apr  9 07:14:11.342: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  9 07:14:12.365: INFO: POD   NODE                                                     PHASE    GRACE  CONDITIONS
Apr  9 07:14:12.365: INFO: ss-1  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:12.365: INFO: 
Apr  9 07:14:12.365: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  9 07:14:13.388: INFO: POD   NODE                                                     PHASE    GRACE  CONDITIONS
Apr  9 07:14:13.388: INFO: ss-1  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:13.388: INFO: 
Apr  9 07:14:13.388: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  9 07:14:14.411: INFO: POD   NODE                                                     PHASE    GRACE  CONDITIONS
Apr  9 07:14:14.411: INFO: ss-1  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:14.411: INFO: 
Apr  9 07:14:14.411: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  9 07:14:15.434: INFO: POD   NODE                                                     PHASE    GRACE  CONDITIONS
Apr  9 07:14:15.434: INFO: ss-1  shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:13:43 +0000 UTC  }]
Apr  9 07:14:15.434: INFO: 
Apr  9 07:14:15.434: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  9 07:14:16.456: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.817734828s
Apr  9 07:14:17.478: INFO: Verifying statefulset ss doesn't scale past 0 for another 795.353841ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-581
Apr  9 07:14:18.500: INFO: Scaling statefulset ss to 0
Apr  9 07:14:18.565: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  9 07:14:18.587: INFO: Deleting all statefulset in ns statefulset-581
Apr  9 07:14:18.610: INFO: Scaling statefulset ss to 0
Apr  9 07:14:18.676: INFO: Waiting for statefulset status.replicas updated to 0
Apr  9 07:14:18.697: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:14:18.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-581" for this suite.
Apr  9 07:14:24.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:14:25.666: INFO: namespace statefulset-581 deletion completed in 6.860400532s
•S
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:14:25.667: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4336
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4336.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4336.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4336.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4336.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4336.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4336.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  9 07:14:38.748: INFO: DNS probes using dns-4336/dns-test-1b94f12e-5a97-11e9-8d38-4647074cf119 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:14:38.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4336" for this suite.
Apr  9 07:14:44.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:14:45.674: INFO: namespace dns-4336 deletion completed in 6.856313848s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:14:45.674: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4883
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:14:45.993: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:14:48.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4883" for this suite.
Apr  9 07:15:28.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:15:29.125: INFO: namespace pods-4883 deletion completed in 40.875731196s
•SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:15:29.125: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7642
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-7642
Apr  9 07:15:31.469: INFO: Started pod liveness-exec in namespace container-probe-7642
STEP: checking the pod's current state and verifying that restartCount is present
Apr  9 07:15:31.490: INFO: Initial restart count of pod liveness-exec is 0
Apr  9 07:16:18.033: INFO: Restart count of pod container-probe-7642/liveness-exec is now 1 (46.54261681s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:16:18.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7642" for this suite.
Apr  9 07:16:24.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:16:24.960: INFO: namespace container-probe-7642 deletion completed in 6.851897086s
•SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:16:24.960: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:16:25.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7453" for this suite.
Apr  9 07:16:31.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:16:32.183: INFO: namespace services-7453 deletion completed in 6.849301306s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:16:32.184: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1199
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-66f14819-5a97-11e9-8d38-4647074cf119
STEP: Creating secret with name s-test-opt-upd-66f1489c-5a97-11e9-8d38-4647074cf119
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-66f14819-5a97-11e9-8d38-4647074cf119
STEP: Updating secret s-test-opt-upd-66f1489c-5a97-11e9-8d38-4647074cf119
STEP: Creating secret with name s-test-opt-create-66f1494a-5a97-11e9-8d38-4647074cf119
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:16:37.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1199" for this suite.
Apr  9 07:17:01.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:17:01.951: INFO: namespace projected-1199 deletion completed in 24.842618855s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:17:01.951: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9457
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-78af0398-5a97-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 07:17:02.329: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-78b26a5c-5a97-11e9-8d38-4647074cf119" in namespace "projected-9457" to be "success or failure"
Apr  9 07:17:02.351: INFO: Pod "pod-projected-secrets-78b26a5c-5a97-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.821573ms
Apr  9 07:17:04.395: INFO: Pod "pod-projected-secrets-78b26a5c-5a97-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.066814214s
STEP: Saw pod success
Apr  9 07:17:04.396: INFO: Pod "pod-projected-secrets-78b26a5c-5a97-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:17:04.417: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-secrets-78b26a5c-5a97-11e9-8d38-4647074cf119 container secret-volume-test: <nil>
STEP: delete the pod
Apr  9 07:17:04.499: INFO: Waiting for pod pod-projected-secrets-78b26a5c-5a97-11e9-8d38-4647074cf119 to disappear
Apr  9 07:17:04.520: INFO: Pod pod-projected-secrets-78b26a5c-5a97-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:17:04.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9457" for this suite.
Apr  9 07:17:10.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:17:11.498: INFO: namespace projected-9457 deletion completed in 6.938371405s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:17:11.498: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Apr  9 07:17:13.995: INFO: Pod pod-hostip-7e67c360-5a97-11e9-8d38-4647074cf119 has hostIP: 10.250.0.2
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:17:13.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-379" for this suite.
Apr  9 07:17:36.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:17:36.887: INFO: namespace pods-379 deletion completed in 22.851829061s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:17:36.888: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  9 07:17:41.651: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:41.694: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:17:43.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:43.716: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:17:45.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:45.716: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:17:47.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:47.717: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:17:49.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:49.716: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:17:51.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:51.717: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:17:53.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:53.716: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:17:55.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:55.717: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:17:57.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:57.717: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:17:59.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:17:59.716: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:18:01.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:18:01.717: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:18:03.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:18:03.717: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:18:05.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:18:05.716: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  9 07:18:07.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  9 07:18:07.716: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:18:07.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5592" for this suite.
Apr  9 07:18:31.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:18:32.634: INFO: namespace container-lifecycle-hook-5592 deletion completed in 24.876869287s
•SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:18:32.634: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7378
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr  9 07:18:32.942: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:18:33.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7378" for this suite.
Apr  9 07:18:39.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:18:39.886: INFO: namespace replication-controller-7378 deletion completed in 6.855957977s
•SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:18:39.887: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3733
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:18:40.241: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  9 07:18:42.286: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr  9 07:18:44.309: INFO: Creating deployment "test-rollover-deployment"
Apr  9 07:18:44.354: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr  9 07:18:46.398: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr  9 07:18:46.442: INFO: Ensure that both replica sets have 1 created replica
Apr  9 07:18:46.485: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr  9 07:18:46.529: INFO: Updating deployment test-rollover-deployment
Apr  9 07:18:46.529: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr  9 07:18:48.572: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr  9 07:18:48.615: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr  9 07:18:48.658: INFO: all replica sets need to contain the pod-template-hash label
Apr  9 07:18:48.659: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391128, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 07:18:50.703: INFO: all replica sets need to contain the pod-template-hash label
Apr  9 07:18:50.703: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391128, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 07:18:52.702: INFO: all replica sets need to contain the pod-template-hash label
Apr  9 07:18:52.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391128, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 07:18:54.704: INFO: all replica sets need to contain the pod-template-hash label
Apr  9 07:18:54.704: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391128, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 07:18:56.703: INFO: all replica sets need to contain the pod-template-hash label
Apr  9 07:18:56.703: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391128, loc:(*time.Location)(0x89f10e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63690391124, loc:(*time.Location)(0x89f10e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  9 07:18:58.718: INFO: 
Apr  9 07:18:58.718: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  9 07:18:58.784: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3733,SelfLink:/apis/apps/v1/namespaces/deployment-3733/deployments/test-rollover-deployment,UID:b580f3ca-5a97-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:12477,Generation:2,CreationTimestamp:2019-04-09 07:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-09 07:18:44 +0000 UTC 2019-04-09 07:18:44 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-09 07:18:58 +0000 UTC 2019-04-09 07:18:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  9 07:18:58.807: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-3733,SelfLink:/apis/apps/v1/namespaces/deployment-3733/replicasets/test-rollover-deployment-766b4d6c9d,UID:b6d0f8a2-5a97-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:12470,Generation:2,CreationTimestamp:2019-04-09 07:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b580f3ca-5a97-11e9-8ec1-5e80bdd8d9d6 0xc002adac67 0xc002adac68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  9 07:18:58.807: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr  9 07:18:58.807: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3733,SelfLink:/apis/apps/v1/namespaces/deployment-3733/replicasets/test-rollover-controller,UID:b30d7cce-5a97-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:12476,Generation:2,CreationTimestamp:2019-04-09 07:18:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b580f3ca-5a97-11e9-8ec1-5e80bdd8d9d6 0xc002adaab7 0xc002adaab8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  9 07:18:58.807: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-3733,SelfLink:/apis/apps/v1/namespaces/deployment-3733/replicasets/test-rollover-deployment-6455657675,UID:b582e87b-5a97-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:12437,Generation:2,CreationTimestamp:2019-04-09 07:18:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b580f3ca-5a97-11e9-8ec1-5e80bdd8d9d6 0xc002adab87 0xc002adab88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  9 07:18:58.829: INFO: Pod "test-rollover-deployment-766b4d6c9d-gb8wp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-gb8wp,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-3733,SelfLink:/api/v1/namespaces/deployment-3733/pods/test-rollover-deployment-766b4d6c9d-gb8wp,UID:b6d3db5b-5a97-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:12446,Generation:0,CreationTimestamp:2019-04-09 07:18:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.121/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d b6d0f8a2-5a97-11e9-8ec1-5e80bdd8d9d6 0xc0021b8047 0xc0021b8048}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqk2r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqk2r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-bqk2r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021b80b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021b80d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:18:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:18:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:18:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:18:46 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.121,StartTime:2019-04-09 07:18:46 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-09 07:18:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://4cde89ebfc69d40b9ee48b1a3f439a6756bdda217a0d08ad5a34be8a77514f84}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:18:58.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3733" for this suite.
Apr  9 07:19:06.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:19:07.730: INFO: namespace deployment-3733 deletion completed in 8.860521307s
•SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:19:07.731: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7938
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Apr  9 07:19:07.991: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr  9 07:19:07.991: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-7938'
Apr  9 07:19:09.735: INFO: stderr: ""
Apr  9 07:19:09.735: INFO: stdout: "service/redis-slave created\n"
Apr  9 07:19:09.735: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr  9 07:19:09.735: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-7938'
Apr  9 07:19:10.024: INFO: stderr: ""
Apr  9 07:19:10.024: INFO: stdout: "service/redis-master created\n"
Apr  9 07:19:10.024: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr  9 07:19:10.024: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-7938'
Apr  9 07:19:10.302: INFO: stderr: ""
Apr  9 07:19:10.302: INFO: stdout: "service/frontend created\n"
Apr  9 07:19:10.303: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr  9 07:19:10.303: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-7938'
Apr  9 07:19:10.574: INFO: stderr: ""
Apr  9 07:19:10.574: INFO: stdout: "deployment.apps/frontend created\n"
Apr  9 07:19:10.575: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr  9 07:19:10.575: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-7938'
Apr  9 07:19:10.875: INFO: stderr: ""
Apr  9 07:19:10.875: INFO: stdout: "deployment.apps/redis-master created\n"
Apr  9 07:19:10.875: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr  9 07:19:10.875: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-7938'
Apr  9 07:19:11.174: INFO: stderr: ""
Apr  9 07:19:11.174: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr  9 07:19:11.174: INFO: Waiting for all frontend pods to be Running.
Apr  9 07:19:31.226: INFO: Waiting for frontend to serve content.
Apr  9 07:19:31.335: INFO: Trying to add a new entry to the guestbook.
Apr  9 07:19:31.462: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr  9 07:19:31.512: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7938'
Apr  9 07:19:31.774: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 07:19:31.774: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr  9 07:19:31.774: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7938'
Apr  9 07:19:31.947: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 07:19:31.947: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  9 07:19:31.947: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7938'
Apr  9 07:19:32.182: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 07:19:32.182: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  9 07:19:32.183: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7938'
Apr  9 07:19:32.350: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 07:19:32.350: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  9 07:19:32.350: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7938'
Apr  9 07:19:32.552: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 07:19:32.552: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  9 07:19:32.552: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7938'
Apr  9 07:19:32.750: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 07:19:32.750: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:19:32.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7938" for this suite.
Apr  9 07:20:17.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:20:17.921: INFO: namespace kubectl-7938 deletion completed in 45.008293373s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:20:17.921: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9899
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  9 07:20:18.326: INFO: Waiting up to 5m0s for pod "downward-api-ed851adc-5a97-11e9-8d38-4647074cf119" in namespace "downward-api-9899" to be "success or failure"
Apr  9 07:20:18.347: INFO: Pod "downward-api-ed851adc-5a97-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.138523ms
Apr  9 07:20:20.370: INFO: Pod "downward-api-ed851adc-5a97-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044188819s
STEP: Saw pod success
Apr  9 07:20:20.370: INFO: Pod "downward-api-ed851adc-5a97-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:20:20.393: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downward-api-ed851adc-5a97-11e9-8d38-4647074cf119 container dapi-container: <nil>
STEP: delete the pod
Apr  9 07:20:20.453: INFO: Waiting for pod downward-api-ed851adc-5a97-11e9-8d38-4647074cf119 to disappear
Apr  9 07:20:20.475: INFO: Pod downward-api-ed851adc-5a97-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:20:20.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9899" for this suite.
Apr  9 07:20:26.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:20:27.594: INFO: namespace downward-api-9899 deletion completed in 7.078611108s
•
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:20:27.594: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1344
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1344
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1344
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1344
Apr  9 07:20:27.983: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Apr  9 07:20:38.007: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr  9 07:20:38.029: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1344 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:20:38.764: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:20:38.764: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:20:38.764: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  9 07:20:38.786: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  9 07:20:48.809: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  9 07:20:48.809: INFO: Waiting for statefulset status.replicas updated to 0
Apr  9 07:20:48.896: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999731s
Apr  9 07:20:49.919: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.978347961s
Apr  9 07:20:50.941: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.955797854s
Apr  9 07:20:51.963: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.933583833s
Apr  9 07:20:52.986: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.911290195s
Apr  9 07:20:54.007: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.888767846s
Apr  9 07:20:55.029: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.866999186s
Apr  9 07:20:56.052: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.844984763s
Apr  9 07:20:57.074: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.822651263s
Apr  9 07:20:58.097: INFO: Verifying statefulset ss doesn't scale past 1 for another 799.836432ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1344
Apr  9 07:20:59.120: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1344 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  9 07:20:59.741: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  9 07:20:59.741: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  9 07:20:59.741: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  9 07:20:59.763: INFO: Found 1 stateful pods, waiting for 3
Apr  9 07:21:09.786: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:21:09.786: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:21:09.786: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr  9 07:21:09.829: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1344 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:21:10.562: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:21:10.562: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:21:10.562: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  9 07:21:10.563: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1344 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:21:11.287: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:21:11.287: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:21:11.287: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  9 07:21:11.287: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1344 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:21:11.833: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:21:11.833: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:21:11.833: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  9 07:21:11.833: INFO: Waiting for statefulset status.replicas updated to 0
Apr  9 07:21:11.854: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr  9 07:21:21.900: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  9 07:21:21.900: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  9 07:21:21.900: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  9 07:21:21.967: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999549s
Apr  9 07:21:22.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.977729249s
Apr  9 07:21:24.012: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.955364621s
Apr  9 07:21:25.035: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.932738239s
Apr  9 07:21:26.059: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.909696534s
Apr  9 07:21:27.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.885388188s
Apr  9 07:21:28.105: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.861760234s
Apr  9 07:21:29.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.839226416s
Apr  9 07:21:30.150: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.816507031s
Apr  9 07:21:31.173: INFO: Verifying statefulset ss doesn't scale past 3 for another 793.88741ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1344
Apr  9 07:21:32.196: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1344 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  9 07:21:32.883: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  9 07:21:32.883: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  9 07:21:32.883: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  9 07:21:32.883: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1344 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  9 07:21:33.535: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  9 07:21:33.535: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  9 07:21:33.535: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  9 07:21:33.535: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1344 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  9 07:21:34.176: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  9 07:21:34.176: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  9 07:21:34.176: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  9 07:21:34.176: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  9 07:22:14.266: INFO: Deleting all statefulset in ns statefulset-1344
Apr  9 07:22:14.288: INFO: Scaling statefulset ss to 0
Apr  9 07:22:14.352: INFO: Waiting for statefulset status.replicas updated to 0
Apr  9 07:22:14.374: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:22:14.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1344" for this suite.
Apr  9 07:22:20.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:22:21.348: INFO: namespace statefulset-1344 deletion completed in 6.866612164s
•
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:22:21.348: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  9 07:22:21.725: INFO: Waiting up to 5m0s for pod "downward-api-3712551a-5a98-11e9-8d38-4647074cf119" in namespace "downward-api-3500" to be "success or failure"
Apr  9 07:22:21.747: INFO: Pod "downward-api-3712551a-5a98-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.684156ms
Apr  9 07:22:23.769: INFO: Pod "downward-api-3712551a-5a98-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043724288s
STEP: Saw pod success
Apr  9 07:22:23.769: INFO: Pod "downward-api-3712551a-5a98-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:22:23.791: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downward-api-3712551a-5a98-11e9-8d38-4647074cf119 container dapi-container: <nil>
STEP: delete the pod
Apr  9 07:22:23.851: INFO: Waiting for pod downward-api-3712551a-5a98-11e9-8d38-4647074cf119 to disappear
Apr  9 07:22:23.872: INFO: Pod downward-api-3712551a-5a98-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:22:23.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3500" for this suite.
Apr  9 07:22:29.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:22:30.762: INFO: namespace downward-api-3500 deletion completed in 6.850102981s
•SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:22:30.762: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5159
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:22:31.332: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:22:31.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5159" for this suite.
Apr  9 07:22:37.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:22:38.520: INFO: namespace custom-resource-definition-5159 deletion completed in 6.901165113s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:22:38.521: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-41425347-5a98-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 07:22:38.841: INFO: Waiting up to 5m0s for pod "pod-secrets-4145bb63-5a98-11e9-8d38-4647074cf119" in namespace "secrets-541" to be "success or failure"
Apr  9 07:22:38.861: INFO: Pod "pod-secrets-4145bb63-5a98-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.813218ms
Apr  9 07:22:40.884: INFO: Pod "pod-secrets-4145bb63-5a98-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042984312s
STEP: Saw pod success
Apr  9 07:22:40.884: INFO: Pod "pod-secrets-4145bb63-5a98-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:22:40.906: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-secrets-4145bb63-5a98-11e9-8d38-4647074cf119 container secret-volume-test: <nil>
STEP: delete the pod
Apr  9 07:22:40.964: INFO: Waiting for pod pod-secrets-4145bb63-5a98-11e9-8d38-4647074cf119 to disappear
Apr  9 07:22:40.985: INFO: Pod pod-secrets-4145bb63-5a98-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:22:40.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-541" for this suite.
Apr  9 07:22:47.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:22:47.875: INFO: namespace secrets-541 deletion completed in 6.847992038s
•SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:22:47.875: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6879
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  9 07:22:48.221: INFO: Waiting up to 5m0s for pod "pod-46dd6283-5a98-11e9-8d38-4647074cf119" in namespace "emptydir-6879" to be "success or failure"
Apr  9 07:22:48.247: INFO: Pod "pod-46dd6283-5a98-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 26.542511ms
Apr  9 07:22:50.270: INFO: Pod "pod-46dd6283-5a98-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.049113821s
STEP: Saw pod success
Apr  9 07:22:50.270: INFO: Pod "pod-46dd6283-5a98-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:22:50.292: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-46dd6283-5a98-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:22:50.355: INFO: Waiting for pod pod-46dd6283-5a98-11e9-8d38-4647074cf119 to disappear
Apr  9 07:22:50.376: INFO: Pod pod-46dd6283-5a98-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:22:50.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6879" for this suite.
Apr  9 07:22:56.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:22:57.271: INFO: namespace emptydir-6879 deletion completed in 6.854803515s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:22:57.271: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1908
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-4c862806-5a98-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:22:57.737: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4c898f9e-5a98-11e9-8d38-4647074cf119" in namespace "projected-1908" to be "success or failure"
Apr  9 07:22:57.759: INFO: Pod "pod-projected-configmaps-4c898f9e-5a98-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.498188ms
Apr  9 07:22:59.781: INFO: Pod "pod-projected-configmaps-4c898f9e-5a98-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044207882s
STEP: Saw pod success
Apr  9 07:22:59.781: INFO: Pod "pod-projected-configmaps-4c898f9e-5a98-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:22:59.803: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-configmaps-4c898f9e-5a98-11e9-8d38-4647074cf119 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 07:22:59.860: INFO: Waiting for pod pod-projected-configmaps-4c898f9e-5a98-11e9-8d38-4647074cf119 to disappear
Apr  9 07:22:59.881: INFO: Pod pod-projected-configmaps-4c898f9e-5a98-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:22:59.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1908" for this suite.
Apr  9 07:23:05.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:23:06.770: INFO: namespace projected-1908 deletion completed in 6.848670539s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:23:06.771: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3933
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Apr  9 07:23:07.188: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-3933'
Apr  9 07:23:07.509: INFO: stderr: ""
Apr  9 07:23:07.509: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  9 07:23:07.509: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3933'
Apr  9 07:23:07.723: INFO: stderr: ""
Apr  9 07:23:07.723: INFO: stdout: "update-demo-nautilus-64qzp update-demo-nautilus-s4dq8 "
Apr  9 07:23:07.724: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-64qzp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3933'
Apr  9 07:23:07.876: INFO: stderr: ""
Apr  9 07:23:07.876: INFO: stdout: ""
Apr  9 07:23:07.876: INFO: update-demo-nautilus-64qzp is created but not running
Apr  9 07:23:12.876: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3933'
Apr  9 07:23:13.075: INFO: stderr: ""
Apr  9 07:23:13.075: INFO: stdout: "update-demo-nautilus-64qzp update-demo-nautilus-s4dq8 "
Apr  9 07:23:13.075: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-64qzp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3933'
Apr  9 07:23:13.248: INFO: stderr: ""
Apr  9 07:23:13.248: INFO: stdout: "true"
Apr  9 07:23:13.248: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-64qzp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3933'
Apr  9 07:23:13.400: INFO: stderr: ""
Apr  9 07:23:13.400: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 07:23:13.400: INFO: validating pod update-demo-nautilus-64qzp
Apr  9 07:23:13.508: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 07:23:13.508: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 07:23:13.508: INFO: update-demo-nautilus-64qzp is verified up and running
Apr  9 07:23:13.508: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-s4dq8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3933'
Apr  9 07:23:13.658: INFO: stderr: ""
Apr  9 07:23:13.658: INFO: stdout: "true"
Apr  9 07:23:13.658: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-s4dq8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3933'
Apr  9 07:23:13.836: INFO: stderr: ""
Apr  9 07:23:13.836: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 07:23:13.836: INFO: validating pod update-demo-nautilus-s4dq8
Apr  9 07:23:13.942: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 07:23:13.942: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 07:23:13.942: INFO: update-demo-nautilus-s4dq8 is verified up and running
STEP: using delete to clean up resources
Apr  9 07:23:13.942: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-3933'
Apr  9 07:23:14.135: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 07:23:14.136: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  9 07:23:14.136: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3933'
Apr  9 07:23:14.310: INFO: stderr: "No resources found.\n"
Apr  9 07:23:14.310: INFO: stdout: ""
Apr  9 07:23:14.310: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -l name=update-demo --namespace=kubectl-3933 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  9 07:23:14.463: INFO: stderr: ""
Apr  9 07:23:14.463: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:23:14.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3933" for this suite.
Apr  9 07:23:38.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:23:39.360: INFO: namespace kubectl-3933 deletion completed in 24.856344029s
•S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:23:39.360: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:24:04.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1506" for this suite.
Apr  9 07:24:11.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:24:11.798: INFO: namespace container-runtime-1506 deletion completed in 6.888899548s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:24:11.799: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-78ec8373-5a98-11e9-8d38-4647074cf119
Apr  9 07:24:12.224: INFO: Pod name my-hostname-basic-78ec8373-5a98-11e9-8d38-4647074cf119: Found 1 pods out of 1
Apr  9 07:24:12.224: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-78ec8373-5a98-11e9-8d38-4647074cf119" are running
Apr  9 07:24:14.270: INFO: Pod "my-hostname-basic-78ec8373-5a98-11e9-8d38-4647074cf119-hn9fq" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-09 07:24:12 +0000 UTC Reason: Message:}])
Apr  9 07:24:14.270: INFO: Trying to dial the pod
Apr  9 07:24:19.423: INFO: Controller my-hostname-basic-78ec8373-5a98-11e9-8d38-4647074cf119: Got expected result from replica 1 [my-hostname-basic-78ec8373-5a98-11e9-8d38-4647074cf119-hn9fq]: "my-hostname-basic-78ec8373-5a98-11e9-8d38-4647074cf119-hn9fq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:24:19.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4770" for this suite.
Apr  9 07:24:27.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:24:28.325: INFO: namespace replication-controller-4770 deletion completed in 8.861526483s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:24:28.325: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1793
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:24:28.617: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82b49f94-5a98-11e9-8d38-4647074cf119" in namespace "projected-1793" to be "success or failure"
Apr  9 07:24:28.638: INFO: Pod "downwardapi-volume-82b49f94-5a98-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.691219ms
Apr  9 07:24:30.661: INFO: Pod "downwardapi-volume-82b49f94-5a98-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043401166s
STEP: Saw pod success
Apr  9 07:24:30.661: INFO: Pod "downwardapi-volume-82b49f94-5a98-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:24:30.682: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-82b49f94-5a98-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:24:30.740: INFO: Waiting for pod downwardapi-volume-82b49f94-5a98-11e9-8d38-4647074cf119 to disappear
Apr  9 07:24:30.761: INFO: Pod downwardapi-volume-82b49f94-5a98-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:24:30.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1793" for this suite.
Apr  9 07:24:38.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:24:39.655: INFO: namespace projected-1793 deletion completed in 8.854016197s
•SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:24:39.655: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6070
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-89803005-5a98-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 07:24:40.040: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8983897a-5a98-11e9-8d38-4647074cf119" in namespace "projected-6070" to be "success or failure"
Apr  9 07:24:40.061: INFO: Pod "pod-projected-secrets-8983897a-5a98-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.733113ms
Apr  9 07:24:42.084: INFO: Pod "pod-projected-secrets-8983897a-5a98-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044600573s
STEP: Saw pod success
Apr  9 07:24:42.084: INFO: Pod "pod-projected-secrets-8983897a-5a98-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:24:42.106: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-secrets-8983897a-5a98-11e9-8d38-4647074cf119 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  9 07:24:42.163: INFO: Waiting for pod pod-projected-secrets-8983897a-5a98-11e9-8d38-4647074cf119 to disappear
Apr  9 07:24:42.184: INFO: Pod pod-projected-secrets-8983897a-5a98-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:24:42.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6070" for this suite.
Apr  9 07:24:48.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:24:49.091: INFO: namespace projected-6070 deletion completed in 6.868209405s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:24:49.092: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5358
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Apr  9 07:24:49.421: INFO: Waiting up to 5m0s for pod "client-containers-8f1b152d-5a98-11e9-8d38-4647074cf119" in namespace "containers-5358" to be "success or failure"
Apr  9 07:24:49.443: INFO: Pod "client-containers-8f1b152d-5a98-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.944468ms
Apr  9 07:24:51.466: INFO: Pod "client-containers-8f1b152d-5a98-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044891467s
STEP: Saw pod success
Apr  9 07:24:51.466: INFO: Pod "client-containers-8f1b152d-5a98-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:24:51.488: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod client-containers-8f1b152d-5a98-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:24:51.545: INFO: Waiting for pod client-containers-8f1b152d-5a98-11e9-8d38-4647074cf119 to disappear
Apr  9 07:24:51.566: INFO: Pod client-containers-8f1b152d-5a98-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:24:51.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5358" for this suite.
Apr  9 07:24:57.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:24:58.468: INFO: namespace containers-5358 deletion completed in 6.860599192s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:24:58.468: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9639
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-94c2596a-5a98-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:24:58.928: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-94c5a858-5a98-11e9-8d38-4647074cf119" in namespace "projected-9639" to be "success or failure"
Apr  9 07:24:58.950: INFO: Pod "pod-projected-configmaps-94c5a858-5a98-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.326344ms
Apr  9 07:25:00.971: INFO: Pod "pod-projected-configmaps-94c5a858-5a98-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042676867s
STEP: Saw pod success
Apr  9 07:25:00.971: INFO: Pod "pod-projected-configmaps-94c5a858-5a98-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:25:00.993: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-configmaps-94c5a858-5a98-11e9-8d38-4647074cf119 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 07:25:01.050: INFO: Waiting for pod pod-projected-configmaps-94c5a858-5a98-11e9-8d38-4647074cf119 to disappear
Apr  9 07:25:01.072: INFO: Pod pod-projected-configmaps-94c5a858-5a98-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:25:01.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9639" for this suite.
Apr  9 07:25:09.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:25:09.996: INFO: namespace projected-9639 deletion completed in 8.882348595s
•SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:25:09.996: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5494
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:25:10.344: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  9 07:25:12.388: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  9 07:25:16.565: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5494,SelfLink:/apis/apps/v1/namespaces/deployment-5494/deployments/test-cleanup-deployment,UID:9cd77aed-5a98-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:13857,Generation:1,CreationTimestamp:2019-04-09 07:25:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-09 07:25:12 +0000 UTC 2019-04-09 07:25:12 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-09 07:25:14 +0000 UTC 2019-04-09 07:25:12 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55cbfbc8f5" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr  9 07:25:16.588: INFO: New ReplicaSet "test-cleanup-deployment-55cbfbc8f5" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5,GenerateName:,Namespace:deployment-5494,SelfLink:/apis/apps/v1/namespaces/deployment-5494/replicasets/test-cleanup-deployment-55cbfbc8f5,UID:9cd984c6-5a98-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:13849,Generation:1,CreationTimestamp:2019-04-09 07:25:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 9cd77aed-5a98-11e9-8ec1-5e80bdd8d9d6 0xc002cbb677 0xc002cbb678}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr  9 07:25:16.610: INFO: Pod "test-cleanup-deployment-55cbfbc8f5-6znvc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55cbfbc8f5-6znvc,GenerateName:test-cleanup-deployment-55cbfbc8f5-,Namespace:deployment-5494,SelfLink:/api/v1/namespaces/deployment-5494/pods/test-cleanup-deployment-55cbfbc8f5-6znvc,UID:9cda2e10-5a98-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:13848,Generation:0,CreationTimestamp:2019-04-09 07:25:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55cbfbc8f5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.143/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55cbfbc8f5 9cd984c6-5a98-11e9-8ec1-5e80bdd8d9d6 0xc002dfb0e7 0xc002dfb0e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2zhvr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2zhvr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2zhvr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002dfb150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002dfb170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:25:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:25:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:25:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:25:12 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.143,StartTime:2019-04-09 07:25:12 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-09 07:25:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://0a0cec7e5b7d056e2d859cf31503055c7e5dd7d563bec49f25f5fff6bea93139}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:25:16.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5494" for this suite.
Apr  9 07:25:24.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:25:25.560: INFO: namespace deployment-5494 deletion completed in 8.910020922s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:25:25.561: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1796
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-a4ea6dcb-5a98-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:25:26.034: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a4edcba8-5a98-11e9-8d38-4647074cf119" in namespace "projected-1796" to be "success or failure"
Apr  9 07:25:26.056: INFO: Pod "pod-projected-configmaps-a4edcba8-5a98-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.584124ms
Apr  9 07:25:28.079: INFO: Pod "pod-projected-configmaps-a4edcba8-5a98-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04410764s
STEP: Saw pod success
Apr  9 07:25:28.079: INFO: Pod "pod-projected-configmaps-a4edcba8-5a98-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:25:28.101: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-configmaps-a4edcba8-5a98-11e9-8d38-4647074cf119 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 07:25:28.163: INFO: Waiting for pod pod-projected-configmaps-a4edcba8-5a98-11e9-8d38-4647074cf119 to disappear
Apr  9 07:25:28.185: INFO: Pod pod-projected-configmaps-a4edcba8-5a98-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:25:28.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1796" for this suite.
Apr  9 07:25:34.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:25:35.108: INFO: namespace projected-1796 deletion completed in 6.882918868s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:25:35.109: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7359
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Apr  9 07:25:35.393: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-7359'
Apr  9 07:25:35.725: INFO: stderr: ""
Apr  9 07:25:35.725: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  9 07:25:35.725: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7359'
Apr  9 07:25:35.887: INFO: stderr: ""
Apr  9 07:25:35.887: INFO: stdout: "update-demo-nautilus-t7nw7 update-demo-nautilus-w8cp8 "
Apr  9 07:25:35.887: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-t7nw7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7359'
Apr  9 07:25:36.095: INFO: stderr: ""
Apr  9 07:25:36.095: INFO: stdout: ""
Apr  9 07:25:36.095: INFO: update-demo-nautilus-t7nw7 is created but not running
Apr  9 07:25:41.095: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7359'
Apr  9 07:25:41.250: INFO: stderr: ""
Apr  9 07:25:41.250: INFO: stdout: "update-demo-nautilus-t7nw7 update-demo-nautilus-w8cp8 "
Apr  9 07:25:41.250: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-t7nw7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7359'
Apr  9 07:25:41.426: INFO: stderr: ""
Apr  9 07:25:41.426: INFO: stdout: "true"
Apr  9 07:25:41.426: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-t7nw7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7359'
Apr  9 07:25:41.598: INFO: stderr: ""
Apr  9 07:25:41.598: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 07:25:41.598: INFO: validating pod update-demo-nautilus-t7nw7
Apr  9 07:25:41.706: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 07:25:41.706: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 07:25:41.706: INFO: update-demo-nautilus-t7nw7 is verified up and running
Apr  9 07:25:41.706: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-w8cp8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7359'
Apr  9 07:25:41.878: INFO: stderr: ""
Apr  9 07:25:41.878: INFO: stdout: "true"
Apr  9 07:25:41.878: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-nautilus-w8cp8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7359'
Apr  9 07:25:42.050: INFO: stderr: ""
Apr  9 07:25:42.051: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  9 07:25:42.051: INFO: validating pod update-demo-nautilus-w8cp8
Apr  9 07:25:42.157: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  9 07:25:42.157: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  9 07:25:42.157: INFO: update-demo-nautilus-w8cp8 is verified up and running
STEP: rolling-update to new replication controller
Apr  9 07:25:42.162: INFO: scanned /root for discovery docs: <nil>
Apr  9 07:25:42.162: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-7359'
Apr  9 07:25:57.181: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  9 07:25:57.181: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  9 07:25:57.181: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7359'
Apr  9 07:25:57.359: INFO: stderr: ""
Apr  9 07:25:57.359: INFO: stdout: "update-demo-kitten-5rp2c update-demo-kitten-q6bnv "
Apr  9 07:25:57.359: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-kitten-5rp2c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7359'
Apr  9 07:25:57.502: INFO: stderr: ""
Apr  9 07:25:57.503: INFO: stdout: "true"
Apr  9 07:25:57.503: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-kitten-5rp2c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7359'
Apr  9 07:25:57.654: INFO: stderr: ""
Apr  9 07:25:57.654: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  9 07:25:57.654: INFO: validating pod update-demo-kitten-5rp2c
Apr  9 07:25:57.763: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  9 07:25:57.763: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  9 07:25:57.763: INFO: update-demo-kitten-5rp2c is verified up and running
Apr  9 07:25:57.763: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-kitten-q6bnv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7359'
Apr  9 07:25:57.939: INFO: stderr: ""
Apr  9 07:25:57.939: INFO: stdout: "true"
Apr  9 07:25:57.939: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods update-demo-kitten-q6bnv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7359'
Apr  9 07:25:58.114: INFO: stderr: ""
Apr  9 07:25:58.114: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  9 07:25:58.114: INFO: validating pod update-demo-kitten-q6bnv
Apr  9 07:25:58.220: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  9 07:25:58.220: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  9 07:25:58.220: INFO: update-demo-kitten-q6bnv is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:25:58.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7359" for this suite.
Apr  9 07:26:22.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:26:23.112: INFO: namespace kubectl-7359 deletion completed in 24.851853288s
•S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:26:23.112: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6093
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr  9 07:26:23.546: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6093,SelfLink:/api/v1/namespaces/watch-6093/configmaps/e2e-watch-test-resource-version,UID:c7237346-5a98-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:14136,Generation:0,CreationTimestamp:2019-04-09 07:26:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  9 07:26:23.546: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6093,SelfLink:/api/v1/namespaces/watch-6093/configmaps/e2e-watch-test-resource-version,UID:c7237346-5a98-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:14137,Generation:0,CreationTimestamp:2019-04-09 07:26:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:26:23.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6093" for this suite.
Apr  9 07:26:29.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:26:30.419: INFO: namespace watch-6093 deletion completed in 6.849621368s
•SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:26:30.419: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:26:32.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-920" for this suite.
Apr  9 07:27:13.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:27:13.794: INFO: namespace kubelet-test-920 deletion completed in 40.85239451s
•
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:27:13.794: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8410
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr  9 07:27:14.200: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8410'
Apr  9 07:27:14.391: INFO: stderr: ""
Apr  9 07:27:14.391: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Apr  9 07:27:14.413: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-8410'
Apr  9 07:27:25.264: INFO: stderr: ""
Apr  9 07:27:25.264: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:27:25.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8410" for this suite.
Apr  9 07:27:31.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:27:32.160: INFO: namespace kubectl-8410 deletion completed in 6.854992701s
•SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:27:32.160: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  9 07:27:35.162: INFO: Successfully updated pod "pod-update-activedeadlineseconds-f0537128-5a98-11e9-8d38-4647074cf119"
Apr  9 07:27:35.162: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f0537128-5a98-11e9-8d38-4647074cf119" in namespace "pods-5517" to be "terminated due to deadline exceeded"
Apr  9 07:27:35.184: INFO: Pod "pod-update-activedeadlineseconds-f0537128-5a98-11e9-8d38-4647074cf119": Phase="Running", Reason="", readiness=true. Elapsed: 21.841881ms
Apr  9 07:27:37.206: INFO: Pod "pod-update-activedeadlineseconds-f0537128-5a98-11e9-8d38-4647074cf119": Phase="Running", Reason="", readiness=true. Elapsed: 2.043622816s
Apr  9 07:27:39.228: INFO: Pod "pod-update-activedeadlineseconds-f0537128-5a98-11e9-8d38-4647074cf119": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.065687577s
Apr  9 07:27:39.228: INFO: Pod "pod-update-activedeadlineseconds-f0537128-5a98-11e9-8d38-4647074cf119" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:27:39.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5517" for this suite.
Apr  9 07:27:45.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:27:46.113: INFO: namespace pods-5517 deletion completed in 6.845571926s
•SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:27:46.113: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-763
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:27:46.397: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config version'
Apr  9 07:27:46.609: INFO: stderr: ""
Apr  9 07:27:46.609: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:57:14Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.0\", GitCommit:\"641856db18352033a0d96dbc99153fa3b27298e5\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:45:25Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:27:46.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-763" for this suite.
Apr  9 07:27:52.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:27:53.483: INFO: namespace kubectl-763 deletion completed in 6.85006947s
•
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:27:53.483: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3864
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  9 07:27:56.487: INFO: Successfully updated pod "annotationupdatefd04015e-5a98-11e9-8d38-4647074cf119"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:27:58.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3864" for this suite.
Apr  9 07:28:22.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:28:23.482: INFO: namespace downward-api-3864 deletion completed in 24.89568884s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:28:23.482: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7545
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-0ee5ff4c-5a99-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:28:23.845: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0ee9646e-5a99-11e9-8d38-4647074cf119" in namespace "projected-7545" to be "success or failure"
Apr  9 07:28:23.866: INFO: Pod "pod-projected-configmaps-0ee9646e-5a99-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.832554ms
Apr  9 07:28:25.888: INFO: Pod "pod-projected-configmaps-0ee9646e-5a99-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043133319s
STEP: Saw pod success
Apr  9 07:28:25.888: INFO: Pod "pod-projected-configmaps-0ee9646e-5a99-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:28:25.910: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-configmaps-0ee9646e-5a99-11e9-8d38-4647074cf119 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 07:28:25.967: INFO: Waiting for pod pod-projected-configmaps-0ee9646e-5a99-11e9-8d38-4647074cf119 to disappear
Apr  9 07:28:25.988: INFO: Pod pod-projected-configmaps-0ee9646e-5a99-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:28:25.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7545" for this suite.
Apr  9 07:28:32.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:28:32.891: INFO: namespace projected-7545 deletion completed in 6.862439825s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:28:32.891: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4649
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:28:33.219: INFO: Waiting up to 5m0s for pod "downwardapi-volume-147fdf99-5a99-11e9-8d38-4647074cf119" in namespace "downward-api-4649" to be "success or failure"
Apr  9 07:28:33.241: INFO: Pod "downwardapi-volume-147fdf99-5a99-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.245992ms
Apr  9 07:28:35.263: INFO: Pod "downwardapi-volume-147fdf99-5a99-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043669342s
STEP: Saw pod success
Apr  9 07:28:35.263: INFO: Pod "downwardapi-volume-147fdf99-5a99-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:28:35.285: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-147fdf99-5a99-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:28:35.343: INFO: Waiting for pod downwardapi-volume-147fdf99-5a99-11e9-8d38-4647074cf119 to disappear
Apr  9 07:28:35.364: INFO: Pod downwardapi-volume-147fdf99-5a99-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:28:35.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4649" for this suite.
Apr  9 07:28:41.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:28:42.275: INFO: namespace downward-api-4649 deletion completed in 6.870672541s
•SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:28:42.275: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8258
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  9 07:28:42.706: INFO: Waiting up to 5m0s for pod "pod-1a277856-5a99-11e9-8d38-4647074cf119" in namespace "emptydir-8258" to be "success or failure"
Apr  9 07:28:42.728: INFO: Pod "pod-1a277856-5a99-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.284729ms
Apr  9 07:28:44.751: INFO: Pod "pod-1a277856-5a99-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044927869s
STEP: Saw pod success
Apr  9 07:28:44.751: INFO: Pod "pod-1a277856-5a99-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:28:44.773: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-1a277856-5a99-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:28:44.833: INFO: Waiting for pod pod-1a277856-5a99-11e9-8d38-4647074cf119 to disappear
Apr  9 07:28:44.855: INFO: Pod pod-1a277856-5a99-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:28:44.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8258" for this suite.
Apr  9 07:28:50.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:28:51.780: INFO: namespace emptydir-8258 deletion completed in 6.884490497s
•SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:28:51.780: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  9 07:28:54.846: INFO: Successfully updated pod "pod-update-1fd211a3-5a99-11e9-8d38-4647074cf119"
STEP: verifying the updated pod is in kubernetes
Apr  9 07:28:54.889: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:28:54.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6363" for this suite.
Apr  9 07:29:18.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:29:19.786: INFO: namespace pods-6363 deletion completed in 24.857551602s
•SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:29:19.787: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4426
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  9 07:29:20.211: INFO: Waiting up to 5m0s for pod "downward-api-3082263f-5a99-11e9-8d38-4647074cf119" in namespace "downward-api-4426" to be "success or failure"
Apr  9 07:29:20.232: INFO: Pod "downward-api-3082263f-5a99-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.997267ms
Apr  9 07:29:22.255: INFO: Pod "downward-api-3082263f-5a99-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044071249s
STEP: Saw pod success
Apr  9 07:29:22.255: INFO: Pod "downward-api-3082263f-5a99-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:29:22.277: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downward-api-3082263f-5a99-11e9-8d38-4647074cf119 container dapi-container: <nil>
STEP: delete the pod
Apr  9 07:29:22.339: INFO: Waiting for pod downward-api-3082263f-5a99-11e9-8d38-4647074cf119 to disappear
Apr  9 07:29:22.360: INFO: Pod downward-api-3082263f-5a99-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:29:22.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4426" for this suite.
Apr  9 07:29:28.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:29:29.251: INFO: namespace downward-api-4426 deletion completed in 6.850458686s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:29:29.252: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4552
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Apr  9 07:29:29.523: INFO: Waiting up to 5m0s for pod "client-containers-360f0a71-5a99-11e9-8d38-4647074cf119" in namespace "containers-4552" to be "success or failure"
Apr  9 07:29:29.545: INFO: Pod "client-containers-360f0a71-5a99-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.393264ms
Apr  9 07:29:31.567: INFO: Pod "client-containers-360f0a71-5a99-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044112507s
STEP: Saw pod success
Apr  9 07:29:31.567: INFO: Pod "client-containers-360f0a71-5a99-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:29:31.589: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod client-containers-360f0a71-5a99-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:29:31.647: INFO: Waiting for pod client-containers-360f0a71-5a99-11e9-8d38-4647074cf119 to disappear
Apr  9 07:29:31.668: INFO: Pod client-containers-360f0a71-5a99-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:29:31.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4552" for this suite.
Apr  9 07:29:37.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:29:38.564: INFO: namespace containers-4552 deletion completed in 6.854924528s
•SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:29:38.564: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-9222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9222 to expose endpoints map[]
Apr  9 07:29:38.942: INFO: successfully validated that service endpoint-test2 in namespace services-9222 exposes endpoints map[] (21.434713ms elapsed)
STEP: Creating pod pod1 in namespace services-9222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9222 to expose endpoints map[pod1:[80]]
Apr  9 07:29:41.098: INFO: successfully validated that service endpoint-test2 in namespace services-9222 exposes endpoints map[pod1:[80]] (2.130370631s elapsed)
STEP: Creating pod pod2 in namespace services-9222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9222 to expose endpoints map[pod1:[80] pod2:[80]]
Apr  9 07:29:43.326: INFO: successfully validated that service endpoint-test2 in namespace services-9222 exposes endpoints map[pod1:[80] pod2:[80]] (2.204504488s elapsed)
STEP: Deleting pod pod1 in namespace services-9222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9222 to expose endpoints map[pod2:[80]]
Apr  9 07:29:43.394: INFO: successfully validated that service endpoint-test2 in namespace services-9222 exposes endpoints map[pod2:[80]] (43.21428ms elapsed)
STEP: Deleting pod pod2 in namespace services-9222
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9222 to expose endpoints map[]
Apr  9 07:29:43.439: INFO: successfully validated that service endpoint-test2 in namespace services-9222 exposes endpoints map[] (21.541865ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:29:43.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9222" for this suite.
Apr  9 07:30:05.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:30:06.415: INFO: namespace services-9222 deletion completed in 22.902381922s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
•SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:30:06.416: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  9 07:30:06.694: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:30:10.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3592" for this suite.
Apr  9 07:30:16.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:30:16.980: INFO: namespace init-container-3592 deletion completed in 6.864886342s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:30:16.980: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6590
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-528f4a3e-5a99-11e9-8d38-4647074cf119
STEP: Creating configMap with name cm-test-opt-upd-528f4a9c-5a99-11e9-8d38-4647074cf119
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-528f4a3e-5a99-11e9-8d38-4647074cf119
STEP: Updating configmap cm-test-opt-upd-528f4a9c-5a99-11e9-8d38-4647074cf119
STEP: Creating configMap with name cm-test-opt-create-528f4ab0-5a99-11e9-8d38-4647074cf119
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:30:21.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6590" for this suite.
Apr  9 07:30:46.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:30:46.799: INFO: namespace configmap-6590 deletion completed in 24.843783088s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:30:46.799: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3011
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:30:47.091: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:30:49.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3011" for this suite.
Apr  9 07:31:39.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:31:40.388: INFO: namespace pods-3011 deletion completed in 50.852528359s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:31:40.388: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  9 07:31:40.780: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  9 07:31:40.823: INFO: Waiting for terminating namespaces to be deleted...
Apr  9 07:31:40.844: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl before test
Apr  9 07:31:40.873: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-fxn5k from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.873: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr  9 07:31:40.873: INFO: calico-node-dfwwr from kube-system started at 2019-04-09 06:24:06 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.873: INFO: 	Container calico-node ready: true, restart count 0
Apr  9 07:31:40.873: INFO: kube-proxy-f7xbd from kube-system started at 2019-04-09 06:24:06 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.873: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  9 07:31:40.873: INFO: node-exporter-8f864 from kube-system started at 2019-04-09 06:24:06 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.873: INFO: 	Container node-exporter ready: true, restart count 0
Apr  9 07:31:40.873: INFO: addons-nginx-ingress-controller-d4f8c9cc5-fznw4 from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.873: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr  9 07:31:40.873: INFO: vpn-shoot-b9464f486-vkb96 from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.873: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr  9 07:31:40.873: INFO: coredns-7f7f7978c8-hdctx from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.873: INFO: 	Container coredns ready: true, restart count 0
Apr  9 07:31:40.873: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk before test
Apr  9 07:31:40.932: INFO: calico-node-nwjm4 from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.932: INFO: 	Container calico-node ready: true, restart count 0
Apr  9 07:31:40.932: INFO: metrics-server-59f948f45b-7sxlv from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.932: INFO: 	Container metrics-server ready: true, restart count 0
Apr  9 07:31:40.932: INFO: kube-proxy-j2p5w from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.932: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  9 07:31:40.932: INFO: node-exporter-gjlww from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.932: INFO: 	Container node-exporter ready: true, restart count 0
Apr  9 07:31:40.932: INFO: coredns-7f7f7978c8-86gmt from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.932: INFO: 	Container coredns ready: true, restart count 0
Apr  9 07:31:40.932: INFO: addons-kubernetes-dashboard-665df4b66d-2826t from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.932: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr  9 07:31:40.932: INFO: blackbox-exporter-6dc58dcffc-jdb7f from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:31:40.932: INFO: 	Container blackbox-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-85aa1c25-5a99-11e9-8d38-4647074cf119 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-85aa1c25-5a99-11e9-8d38-4647074cf119 off the node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
STEP: verifying the node doesn't have the label kubernetes.io/e2e-85aa1c25-5a99-11e9-8d38-4647074cf119
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:31:45.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8903" for this suite.
Apr  9 07:31:57.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:31:58.135: INFO: namespace sched-pred-8903 deletion completed in 12.853727681s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:31:58.136: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:32:58.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6694" for this suite.
Apr  9 07:33:20.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:33:21.342: INFO: namespace container-probe-6694 deletion completed in 22.859049075s
•SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:33:21.342: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-296
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Apr  9 07:33:24.355: INFO: Successfully updated pod "labelsupdatec0746034-5a99-11e9-8d38-4647074cf119"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:33:28.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-296" for this suite.
Apr  9 07:33:52.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:33:53.377: INFO: namespace downward-api-296 deletion completed in 24.893669311s
•SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:33:53.377: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6502
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-d39577e4-5a99-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 07:33:53.828: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d398d890-5a99-11e9-8d38-4647074cf119" in namespace "projected-6502" to be "success or failure"
Apr  9 07:33:53.849: INFO: Pod "pod-projected-secrets-d398d890-5a99-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.971445ms
Apr  9 07:33:55.873: INFO: Pod "pod-projected-secrets-d398d890-5a99-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04455238s
STEP: Saw pod success
Apr  9 07:33:55.873: INFO: Pod "pod-projected-secrets-d398d890-5a99-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:33:55.895: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-secrets-d398d890-5a99-11e9-8d38-4647074cf119 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  9 07:33:55.955: INFO: Waiting for pod pod-projected-secrets-d398d890-5a99-11e9-8d38-4647074cf119 to disappear
Apr  9 07:33:55.979: INFO: Pod pod-projected-secrets-d398d890-5a99-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:33:55.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6502" for this suite.
Apr  9 07:34:02.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:34:02.939: INFO: namespace projected-6502 deletion completed in 6.91988717s
•SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:34:02.939: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  9 07:34:07.408: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  9 07:34:07.429: INFO: Pod pod-with-prestop-http-hook still exists
Apr  9 07:34:09.429: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  9 07:34:09.451: INFO: Pod pod-with-prestop-http-hook still exists
Apr  9 07:34:11.430: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  9 07:34:11.452: INFO: Pod pod-with-prestop-http-hook still exists
Apr  9 07:34:13.430: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  9 07:34:13.452: INFO: Pod pod-with-prestop-http-hook still exists
Apr  9 07:34:15.430: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  9 07:34:15.452: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:34:15.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8017" for this suite.
Apr  9 07:34:39.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:34:40.418: INFO: namespace container-lifecycle-hook-8017 deletion completed in 24.885452005s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:34:40.418: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3731
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3731
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3731
STEP: Creating statefulset with conflicting port in namespace statefulset-3731
STEP: Waiting until pod test-pod will start running in namespace statefulset-3731
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3731
Apr  9 07:34:42.893: INFO: Observed stateful pod in namespace: statefulset-3731, name: ss-0, uid: f0d9dc13-5a99-11e9-8ec1-5e80bdd8d9d6, status phase: Pending. Waiting for statefulset controller to delete.
Apr  9 07:34:42.906: INFO: Observed stateful pod in namespace: statefulset-3731, name: ss-0, uid: f0d9dc13-5a99-11e9-8ec1-5e80bdd8d9d6, status phase: Failed. Waiting for statefulset controller to delete.
Apr  9 07:34:42.942: INFO: Observed stateful pod in namespace: statefulset-3731, name: ss-0, uid: f0d9dc13-5a99-11e9-8ec1-5e80bdd8d9d6, status phase: Failed. Waiting for statefulset controller to delete.
Apr  9 07:34:42.945: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3731
STEP: Removing pod with conflicting port in namespace statefulset-3731
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3731 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  9 07:34:45.016: INFO: Deleting all statefulset in ns statefulset-3731
Apr  9 07:34:45.038: INFO: Scaling statefulset ss to 0
Apr  9 07:34:55.129: INFO: Waiting for statefulset status.replicas updated to 0
Apr  9 07:34:55.152: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:34:55.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3731" for this suite.
Apr  9 07:35:01.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:35:02.148: INFO: namespace statefulset-3731 deletion completed in 6.864034354s
•SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:35:02.148: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5462
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr  9 07:35:02.418: INFO: Waiting up to 5m0s for pod "pod-fc7aeb79-5a99-11e9-8d38-4647074cf119" in namespace "emptydir-5462" to be "success or failure"
Apr  9 07:35:02.440: INFO: Pod "pod-fc7aeb79-5a99-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.719855ms
Apr  9 07:35:04.462: INFO: Pod "pod-fc7aeb79-5a99-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043962866s
STEP: Saw pod success
Apr  9 07:35:04.462: INFO: Pod "pod-fc7aeb79-5a99-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:35:04.492: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-fc7aeb79-5a99-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:35:04.550: INFO: Waiting for pod pod-fc7aeb79-5a99-11e9-8d38-4647074cf119 to disappear
Apr  9 07:35:04.593: INFO: Pod pod-fc7aeb79-5a99-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:35:04.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5462" for this suite.
Apr  9 07:35:10.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:35:11.534: INFO: namespace emptydir-5462 deletion completed in 6.900306453s
•S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:35:11.535: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2689
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2689.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2689.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2689.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2689.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2689.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2689.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2689.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2689.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2689.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2689.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2689.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 40.225.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.225.40_udp@PTR;check="$$(dig +tcp +noall +answer +search 40.225.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.225.40_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2689.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2689.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2689.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2689.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2689.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2689.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2689.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2689.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2689.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2689.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2689.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 40.225.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.225.40_udp@PTR;check="$$(dig +tcp +noall +answer +search 40.225.66.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.66.225.40_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  9 07:35:14.049: INFO: Unable to read wheezy_udp@dns-test-service.dns-2689.svc.cluster.local from pod dns-2689/dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119: the server could not find the requested resource (get pods dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119)
Apr  9 07:35:14.092: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2689.svc.cluster.local from pod dns-2689/dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119: the server could not find the requested resource (get pods dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119)
Apr  9 07:35:14.117: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local from pod dns-2689/dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119: the server could not find the requested resource (get pods dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119)
Apr  9 07:35:14.160: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local from pod dns-2689/dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119: the server could not find the requested resource (get pods dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119)
Apr  9 07:35:14.695: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local from pod dns-2689/dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119: the server could not find the requested resource (get pods dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119)
Apr  9 07:35:14.720: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local from pod dns-2689/dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119: the server could not find the requested resource (get pods dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119)
Apr  9 07:35:15.086: INFO: Lookups using dns-2689/dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119 failed for: [wheezy_udp@dns-test-service.dns-2689.svc.cluster.local wheezy_tcp@dns-test-service.dns-2689.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2689.svc.cluster.local]

Apr  9 07:35:21.577: INFO: DNS probes using dns-2689/dns-test-021d38fa-5a9a-11e9-8d38-4647074cf119 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:35:21.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2689" for this suite.
Apr  9 07:35:27.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:35:28.557: INFO: namespace dns-2689 deletion completed in 6.868985677s
•SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:35:28.558: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8560
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Apr  9 07:35:29.005: INFO: Waiting up to 5m0s for pod "downward-api-0c53ceff-5a9a-11e9-8d38-4647074cf119" in namespace "downward-api-8560" to be "success or failure"
Apr  9 07:35:29.027: INFO: Pod "downward-api-0c53ceff-5a9a-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.635819ms
Apr  9 07:35:31.049: INFO: Pod "downward-api-0c53ceff-5a9a-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043857417s
STEP: Saw pod success
Apr  9 07:35:31.049: INFO: Pod "downward-api-0c53ceff-5a9a-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:35:31.073: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downward-api-0c53ceff-5a9a-11e9-8d38-4647074cf119 container dapi-container: <nil>
STEP: delete the pod
Apr  9 07:35:31.132: INFO: Waiting for pod downward-api-0c53ceff-5a9a-11e9-8d38-4647074cf119 to disappear
Apr  9 07:35:31.153: INFO: Pod downward-api-0c53ceff-5a9a-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:35:31.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8560" for this suite.
Apr  9 07:35:37.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:35:38.339: INFO: namespace downward-api-8560 deletion completed in 7.14476864s
•S
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:35:38.339: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:35:38.619: INFO: Waiting up to 5m0s for pod "downwardapi-volume-120ec6ca-5a9a-11e9-8d38-4647074cf119" in namespace "projected-9017" to be "success or failure"
Apr  9 07:35:38.640: INFO: Pod "downwardapi-volume-120ec6ca-5a9a-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.960708ms
Apr  9 07:35:40.662: INFO: Pod "downwardapi-volume-120ec6ca-5a9a-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043476316s
STEP: Saw pod success
Apr  9 07:35:40.662: INFO: Pod "downwardapi-volume-120ec6ca-5a9a-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:35:40.685: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-120ec6ca-5a9a-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:35:40.743: INFO: Waiting for pod downwardapi-volume-120ec6ca-5a9a-11e9-8d38-4647074cf119 to disappear
Apr  9 07:35:40.765: INFO: Pod downwardapi-volume-120ec6ca-5a9a-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:35:40.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9017" for this suite.
Apr  9 07:35:46.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:35:47.649: INFO: namespace projected-9017 deletion completed in 6.843796753s
•SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:35:47.649: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-87cp
STEP: Creating a pod to test atomic-volume-subpath
Apr  9 07:35:48.049: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-87cp" in namespace "subpath-3539" to be "success or failure"
Apr  9 07:35:48.070: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Pending", Reason="", readiness=false. Elapsed: 21.049546ms
Apr  9 07:35:50.093: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 2.043808411s
Apr  9 07:35:52.116: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 4.066686881s
Apr  9 07:35:54.139: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 6.089864329s
Apr  9 07:35:56.162: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 8.112704349s
Apr  9 07:35:58.185: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 10.135297533s
Apr  9 07:36:00.207: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 12.157923982s
Apr  9 07:36:02.230: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 14.180571509s
Apr  9 07:36:04.252: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 16.202871497s
Apr  9 07:36:06.274: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 18.225032331s
Apr  9 07:36:08.297: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Running", Reason="", readiness=true. Elapsed: 20.247408307s
Apr  9 07:36:10.319: INFO: Pod "pod-subpath-test-secret-87cp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.269213914s
STEP: Saw pod success
Apr  9 07:36:10.319: INFO: Pod "pod-subpath-test-secret-87cp" satisfied condition "success or failure"
Apr  9 07:36:10.350: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-subpath-test-secret-87cp container test-container-subpath-secret-87cp: <nil>
STEP: delete the pod
Apr  9 07:36:10.411: INFO: Waiting for pod pod-subpath-test-secret-87cp to disappear
Apr  9 07:36:10.433: INFO: Pod pod-subpath-test-secret-87cp no longer exists
STEP: Deleting pod pod-subpath-test-secret-87cp
Apr  9 07:36:10.433: INFO: Deleting pod "pod-subpath-test-secret-87cp" in namespace "subpath-3539"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:36:10.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3539" for this suite.
Apr  9 07:36:18.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:36:19.348: INFO: namespace subpath-3539 deletion completed in 8.853091484s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:36:19.349: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-2666/secret-test-2a8cf5f4-5a9a-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 07:36:19.734: INFO: Waiting up to 5m0s for pod "pod-configmaps-2a9059ea-5a9a-11e9-8d38-4647074cf119" in namespace "secrets-2666" to be "success or failure"
Apr  9 07:36:19.755: INFO: Pod "pod-configmaps-2a9059ea-5a9a-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.676091ms
Apr  9 07:36:21.777: INFO: Pod "pod-configmaps-2a9059ea-5a9a-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043088466s
STEP: Saw pod success
Apr  9 07:36:21.777: INFO: Pod "pod-configmaps-2a9059ea-5a9a-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:36:21.804: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-2a9059ea-5a9a-11e9-8d38-4647074cf119 container env-test: <nil>
STEP: delete the pod
Apr  9 07:36:21.859: INFO: Waiting for pod pod-configmaps-2a9059ea-5a9a-11e9-8d38-4647074cf119 to disappear
Apr  9 07:36:21.880: INFO: Pod pod-configmaps-2a9059ea-5a9a-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:36:21.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2666" for this suite.
Apr  9 07:36:27.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:36:28.772: INFO: namespace secrets-2666 deletion completed in 6.851744936s
•SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:36:28.772: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7880
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  9 07:36:29.091: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  9 07:36:29.135: INFO: Waiting for terminating namespaces to be deleted...
Apr  9 07:36:29.156: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl before test
Apr  9 07:36:29.203: INFO: calico-node-dfwwr from kube-system started at 2019-04-09 06:24:06 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.203: INFO: 	Container calico-node ready: true, restart count 0
Apr  9 07:36:29.203: INFO: kube-proxy-f7xbd from kube-system started at 2019-04-09 06:24:06 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.203: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  9 07:36:29.203: INFO: node-exporter-8f864 from kube-system started at 2019-04-09 06:24:06 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.203: INFO: 	Container node-exporter ready: true, restart count 0
Apr  9 07:36:29.203: INFO: addons-nginx-ingress-controller-d4f8c9cc5-fznw4 from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.203: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr  9 07:36:29.203: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-fxn5k from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.203: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr  9 07:36:29.203: INFO: vpn-shoot-b9464f486-vkb96 from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.203: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr  9 07:36:29.203: INFO: coredns-7f7f7978c8-hdctx from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.203: INFO: 	Container coredns ready: true, restart count 0
Apr  9 07:36:29.203: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk before test
Apr  9 07:36:29.236: INFO: calico-node-nwjm4 from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.236: INFO: 	Container calico-node ready: true, restart count 0
Apr  9 07:36:29.236: INFO: metrics-server-59f948f45b-7sxlv from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.236: INFO: 	Container metrics-server ready: true, restart count 0
Apr  9 07:36:29.236: INFO: kube-proxy-j2p5w from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.236: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  9 07:36:29.236: INFO: node-exporter-gjlww from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.236: INFO: 	Container node-exporter ready: true, restart count 0
Apr  9 07:36:29.236: INFO: coredns-7f7f7978c8-86gmt from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.236: INFO: 	Container coredns ready: true, restart count 0
Apr  9 07:36:29.236: INFO: addons-kubernetes-dashboard-665df4b66d-2826t from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.236: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr  9 07:36:29.236: INFO: blackbox-exporter-6dc58dcffc-jdb7f from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:36:29.236: INFO: 	Container blackbox-exporter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl
STEP: verifying the node has the label node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
Apr  9 07:36:29.376: INFO: Pod addons-kubernetes-dashboard-665df4b66d-2826t requesting resource cpu=50m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
Apr  9 07:36:29.376: INFO: Pod addons-nginx-ingress-controller-d4f8c9cc5-fznw4 requesting resource cpu=100m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl
Apr  9 07:36:29.376: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-fxn5k requesting resource cpu=0m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl
Apr  9 07:36:29.376: INFO: Pod blackbox-exporter-6dc58dcffc-jdb7f requesting resource cpu=5m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
Apr  9 07:36:29.376: INFO: Pod calico-node-dfwwr requesting resource cpu=100m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl
Apr  9 07:36:29.376: INFO: Pod calico-node-nwjm4 requesting resource cpu=100m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
Apr  9 07:36:29.376: INFO: Pod coredns-7f7f7978c8-86gmt requesting resource cpu=50m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
Apr  9 07:36:29.376: INFO: Pod coredns-7f7f7978c8-hdctx requesting resource cpu=50m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl
Apr  9 07:36:29.376: INFO: Pod kube-proxy-f7xbd requesting resource cpu=20m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl
Apr  9 07:36:29.376: INFO: Pod kube-proxy-j2p5w requesting resource cpu=20m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
Apr  9 07:36:29.376: INFO: Pod metrics-server-59f948f45b-7sxlv requesting resource cpu=20m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
Apr  9 07:36:29.376: INFO: Pod node-exporter-8f864 requesting resource cpu=5m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl
Apr  9 07:36:29.376: INFO: Pod node-exporter-gjlww requesting resource cpu=5m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
Apr  9 07:36:29.376: INFO: Pod vpn-shoot-b9464f486-vkb96 requesting resource cpu=50m on Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3053bb66-5a9a-11e9-8d38-4647074cf119.1593be2b43992ebf], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7880/filler-pod-3053bb66-5a9a-11e9-8d38-4647074cf119 to shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3053bb66-5a9a-11e9-8d38-4647074cf119.1593be2b69d2124f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3053bb66-5a9a-11e9-8d38-4647074cf119.1593be2b6d66b28e], Reason = [Created], Message = [Created container filler-pod-3053bb66-5a9a-11e9-8d38-4647074cf119]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3053bb66-5a9a-11e9-8d38-4647074cf119.1593be2b75f21a59], Reason = [Started], Message = [Started container filler-pod-3053bb66-5a9a-11e9-8d38-4647074cf119]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3057cdca-5a9a-11e9-8d38-4647074cf119.1593be2b44f3ab0b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7880/filler-pod-3057cdca-5a9a-11e9-8d38-4647074cf119 to shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3057cdca-5a9a-11e9-8d38-4647074cf119.1593be2b70624b5f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3057cdca-5a9a-11e9-8d38-4647074cf119.1593be2b740593ae], Reason = [Created], Message = [Created container filler-pod-3057cdca-5a9a-11e9-8d38-4647074cf119]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3057cdca-5a9a-11e9-8d38-4647074cf119.1593be2b7c76a5a0], Reason = [Started], Message = [Started container filler-pod-3057cdca-5a9a-11e9-8d38-4647074cf119]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1593be2bc3dc59c0], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:36:32.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7880" for this suite.
Apr  9 07:36:38.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:36:39.599: INFO: namespace sched-pred-7880 deletion completed in 6.85149101s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:36:39.599: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2229
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2229.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2229.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  9 07:36:54.536: INFO: DNS probes using dns-2229/dns-test-3698bb85-5a9a-11e9-8d38-4647074cf119 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:36:54.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2229" for this suite.
Apr  9 07:37:00.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:37:01.452: INFO: namespace dns-2229 deletion completed in 6.848615346s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:37:01.453: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1993
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1993
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  9 07:37:01.855: INFO: Found 1 stateful pods, waiting for 3
Apr  9 07:37:11.878: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:37:11.878: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:37:11.878: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:37:11.946: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1993 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:37:12.660: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:37:12.660: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:37:12.660: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  9 07:37:12.760: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr  9 07:37:12.827: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1993 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  9 07:37:13.480: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  9 07:37:13.480: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  9 07:37:13.480: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  9 07:37:23.614: INFO: Waiting for StatefulSet statefulset-1993/ss2 to complete update
Apr  9 07:37:23.614: INFO: Waiting for Pod statefulset-1993/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  9 07:37:23.614: INFO: Waiting for Pod statefulset-1993/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  9 07:37:23.614: INFO: Waiting for Pod statefulset-1993/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  9 07:37:33.659: INFO: Waiting for StatefulSet statefulset-1993/ss2 to complete update
Apr  9 07:37:33.659: INFO: Waiting for Pod statefulset-1993/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  9 07:37:33.659: INFO: Waiting for Pod statefulset-1993/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  9 07:37:43.660: INFO: Waiting for StatefulSet statefulset-1993/ss2 to complete update
STEP: Rolling back to a previous revision
Apr  9 07:37:53.660: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1993 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr  9 07:37:54.324: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Apr  9 07:37:54.324: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr  9 07:37:54.325: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr  9 07:38:04.491: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr  9 07:38:04.560: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config exec --namespace=statefulset-1993 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr  9 07:38:05.273: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Apr  9 07:38:05.273: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr  9 07:38:05.273: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr  9 07:38:15.407: INFO: Waiting for StatefulSet statefulset-1993/ss2 to complete update
Apr  9 07:38:15.407: INFO: Waiting for Pod statefulset-1993/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr  9 07:38:15.407: INFO: Waiting for Pod statefulset-1993/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Apr  9 07:38:15.407: INFO: Waiting for Pod statefulset-1993/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  9 07:38:25.451: INFO: Deleting all statefulset in ns statefulset-1993
Apr  9 07:38:25.473: INFO: Scaling statefulset ss2 to 0
Apr  9 07:38:45.562: INFO: Waiting for statefulset status.replicas updated to 0
Apr  9 07:38:45.584: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:38:45.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1993" for this suite.
Apr  9 07:38:51.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:38:52.607: INFO: namespace statefulset-1993 deletion completed in 6.915932637s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:38:52.608: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-85ded3a4-5a9a-11e9-8d38-4647074cf119
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:38:52.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3124" for this suite.
Apr  9 07:38:59.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:38:59.788: INFO: namespace configmap-3124 deletion completed in 6.851795105s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:38:59.788: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6243
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  9 07:39:00.115: INFO: Waiting up to 5m0s for pod "pod-8a28df7a-5a9a-11e9-8d38-4647074cf119" in namespace "emptydir-6243" to be "success or failure"
Apr  9 07:39:00.137: INFO: Pod "pod-8a28df7a-5a9a-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.101909ms
Apr  9 07:39:02.159: INFO: Pod "pod-8a28df7a-5a9a-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043237838s
STEP: Saw pod success
Apr  9 07:39:02.159: INFO: Pod "pod-8a28df7a-5a9a-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:39:02.181: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-8a28df7a-5a9a-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:39:02.240: INFO: Waiting for pod pod-8a28df7a-5a9a-11e9-8d38-4647074cf119 to disappear
Apr  9 07:39:02.262: INFO: Pod pod-8a28df7a-5a9a-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:39:02.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6243" for this suite.
Apr  9 07:39:08.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:39:09.160: INFO: namespace emptydir-6243 deletion completed in 6.857985921s
•SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:39:09.160: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2304
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2304
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  9 07:39:09.490: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  9 07:39:31.896: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.0.181:8080/dial?request=hostName&protocol=http&host=100.96.1.68&port=8080&tries=1'] Namespace:pod-network-test-2304 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 07:39:31.896: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 07:39:32.489: INFO: Waiting for endpoints: map[]
Apr  9 07:39:32.511: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.0.181:8080/dial?request=hostName&protocol=http&host=100.96.0.180&port=8080&tries=1'] Namespace:pod-network-test-2304 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 07:39:32.511: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 07:39:32.966: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:39:32.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2304" for this suite.
Apr  9 07:39:55.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:39:55.859: INFO: namespace pod-network-test-2304 deletion completed in 22.852887104s
•SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:39:55.860: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5189
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-aba88e56-5a9a-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:39:56.342: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-abac1077-5a9a-11e9-8d38-4647074cf119" in namespace "projected-5189" to be "success or failure"
Apr  9 07:39:56.365: INFO: Pod "pod-projected-configmaps-abac1077-5a9a-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 23.264021ms
Apr  9 07:39:58.388: INFO: Pod "pod-projected-configmaps-abac1077-5a9a-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046110932s
STEP: Saw pod success
Apr  9 07:39:58.388: INFO: Pod "pod-projected-configmaps-abac1077-5a9a-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:39:58.411: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-configmaps-abac1077-5a9a-11e9-8d38-4647074cf119 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 07:39:58.468: INFO: Waiting for pod pod-projected-configmaps-abac1077-5a9a-11e9-8d38-4647074cf119 to disappear
Apr  9 07:39:58.489: INFO: Pod pod-projected-configmaps-abac1077-5a9a-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:39:58.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5189" for this suite.
Apr  9 07:40:06.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:40:07.386: INFO: namespace projected-5189 deletion completed in 8.855881449s
•SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:40:07.386: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:40:07.805: INFO: Create a RollingUpdate DaemonSet
Apr  9 07:40:07.828: INFO: Check that daemon pods launch on every node of the cluster
Apr  9 07:40:07.871: INFO: Number of nodes with available pods: 0
Apr  9 07:40:07.871: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:40:08.934: INFO: Number of nodes with available pods: 0
Apr  9 07:40:08.934: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:40:09.934: INFO: Number of nodes with available pods: 2
Apr  9 07:40:09.934: INFO: Number of running nodes: 2, number of available pods: 2
Apr  9 07:40:09.934: INFO: Update the DaemonSet to trigger a rollout
Apr  9 07:40:09.978: INFO: Updating DaemonSet daemon-set
Apr  9 07:40:14.045: INFO: Roll back the DaemonSet before rollout is complete
Apr  9 07:40:14.090: INFO: Updating DaemonSet daemon-set
Apr  9 07:40:14.090: INFO: Make sure DaemonSet rollback is complete
Apr  9 07:40:14.111: INFO: Wrong image for pod: daemon-set-xdpsl. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Apr  9 07:40:14.111: INFO: Pod daemon-set-xdpsl is not available
Apr  9 07:40:16.173: INFO: Pod daemon-set-lm45t is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3800, will wait for the garbage collector to delete the pods
Apr  9 07:40:16.355: INFO: Deleting DaemonSet.extensions daemon-set took: 25.168872ms
Apr  9 07:40:16.756: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.464847ms
Apr  9 07:40:26.377: INFO: Number of nodes with available pods: 0
Apr  9 07:40:26.377: INFO: Number of running nodes: 0, number of available pods: 0
Apr  9 07:40:26.398: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3800/daemonsets","resourceVersion":"17064"},"items":null}

Apr  9 07:40:26.421: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3800/pods","resourceVersion":"17064"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:40:26.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3800" for this suite.
Apr  9 07:40:32.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:40:33.398: INFO: namespace daemonsets-3800 deletion completed in 6.870693173s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:40:33.399: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:40:37.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9724" for this suite.
Apr  9 07:40:43.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:40:44.758: INFO: namespace kubelet-test-9724 deletion completed in 6.862648371s
•SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:40:44.758: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1684
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Apr  9 07:40:45.114: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-1684'
Apr  9 07:40:46.817: INFO: stderr: ""
Apr  9 07:40:46.817: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  9 07:40:47.839: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 07:40:47.839: INFO: Found 0 / 1
Apr  9 07:40:48.839: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 07:40:48.839: INFO: Found 1 / 1
Apr  9 07:40:48.839: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr  9 07:40:48.861: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 07:40:48.861: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  9 07:40:48.861: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config patch pod redis-master-84r2g --namespace=kubectl-1684 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr  9 07:40:49.081: INFO: stderr: ""
Apr  9 07:40:49.081: INFO: stdout: "pod/redis-master-84r2g patched\n"
STEP: checking annotations
Apr  9 07:40:49.102: INFO: Selector matched 1 pods for map[app:redis]
Apr  9 07:40:49.102: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:40:49.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1684" for this suite.
Apr  9 07:41:13.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:41:13.990: INFO: namespace kubectl-1684 deletion completed in 24.84832908s
•SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:41:13.991: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4642
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Apr  9 07:41:14.286: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:41:18.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4642" for this suite.
Apr  9 07:41:40.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:41:41.135: INFO: namespace init-container-4642 deletion completed in 22.87702643s
•SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:41:41.135: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7841
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  9 07:41:41.420: INFO: Waiting up to 5m0s for pod "pod-ea4dcb04-5a9a-11e9-8d38-4647074cf119" in namespace "emptydir-7841" to be "success or failure"
Apr  9 07:41:41.440: INFO: Pod "pod-ea4dcb04-5a9a-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.626757ms
Apr  9 07:41:43.462: INFO: Pod "pod-ea4dcb04-5a9a-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042691196s
STEP: Saw pod success
Apr  9 07:41:43.462: INFO: Pod "pod-ea4dcb04-5a9a-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:41:43.484: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-ea4dcb04-5a9a-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:41:43.544: INFO: Waiting for pod pod-ea4dcb04-5a9a-11e9-8d38-4647074cf119 to disappear
Apr  9 07:41:43.566: INFO: Pod pod-ea4dcb04-5a9a-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:41:43.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7841" for this suite.
Apr  9 07:41:51.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:41:52.458: INFO: namespace emptydir-7841 deletion completed in 8.851710064s
•S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:41:52.458: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3529
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-f11c2376-5a9a-11e9-8d38-4647074cf119
STEP: Creating secret with name s-test-opt-upd-f11c2436-5a9a-11e9-8d38-4647074cf119
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f11c2376-5a9a-11e9-8d38-4647074cf119
STEP: Updating secret s-test-opt-upd-f11c2436-5a9a-11e9-8d38-4647074cf119
STEP: Creating secret with name s-test-opt-create-f11c2464-5a9a-11e9-8d38-4647074cf119
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:43:18.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3529" for this suite.
Apr  9 07:43:42.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:43:43.648: INFO: namespace secrets-3529 deletion completed in 24.858108364s
•SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:43:43.648: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6672
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  9 07:43:48.430: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  9 07:43:48.453: INFO: Pod pod-with-poststart-http-hook still exists
Apr  9 07:43:50.454: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  9 07:43:50.475: INFO: Pod pod-with-poststart-http-hook still exists
Apr  9 07:43:52.454: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  9 07:43:52.475: INFO: Pod pod-with-poststart-http-hook still exists
Apr  9 07:43:54.454: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  9 07:43:54.476: INFO: Pod pod-with-poststart-http-hook still exists
Apr  9 07:43:56.454: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  9 07:43:56.481: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:43:56.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6672" for this suite.
Apr  9 07:44:18.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:44:19.403: INFO: namespace container-lifecycle-hook-6672 deletion completed in 22.864947772s
•SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:44:19.403: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7925
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr  9 07:44:19.694: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  9 07:44:19.739: INFO: Waiting for terminating namespaces to be deleted...
Apr  9 07:44:19.760: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl before test
Apr  9 07:44:19.788: INFO: node-exporter-8f864 from kube-system started at 2019-04-09 06:24:06 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.788: INFO: 	Container node-exporter ready: true, restart count 0
Apr  9 07:44:19.788: INFO: addons-nginx-ingress-controller-d4f8c9cc5-fznw4 from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.788: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Apr  9 07:44:19.788: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-754f8f5dcb-fxn5k from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.788: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Apr  9 07:44:19.788: INFO: calico-node-dfwwr from kube-system started at 2019-04-09 06:24:06 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.788: INFO: 	Container calico-node ready: true, restart count 0
Apr  9 07:44:19.788: INFO: kube-proxy-f7xbd from kube-system started at 2019-04-09 06:24:06 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.788: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  9 07:44:19.788: INFO: vpn-shoot-b9464f486-vkb96 from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.788: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr  9 07:44:19.788: INFO: coredns-7f7f7978c8-hdctx from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.788: INFO: 	Container coredns ready: true, restart count 0
Apr  9 07:44:19.788: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk before test
Apr  9 07:44:19.833: INFO: kube-proxy-j2p5w from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.833: INFO: 	Container kube-proxy ready: true, restart count 0
Apr  9 07:44:19.833: INFO: calico-node-nwjm4 from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.833: INFO: 	Container calico-node ready: true, restart count 0
Apr  9 07:44:19.833: INFO: metrics-server-59f948f45b-7sxlv from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.833: INFO: 	Container metrics-server ready: true, restart count 0
Apr  9 07:44:19.833: INFO: blackbox-exporter-6dc58dcffc-jdb7f from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.833: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr  9 07:44:19.833: INFO: node-exporter-gjlww from kube-system started at 2019-04-09 06:24:05 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.833: INFO: 	Container node-exporter ready: true, restart count 0
Apr  9 07:44:19.833: INFO: coredns-7f7f7978c8-86gmt from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.833: INFO: 	Container coredns ready: true, restart count 0
Apr  9 07:44:19.833: INFO: addons-kubernetes-dashboard-665df4b66d-2826t from kube-system started at 2019-04-09 06:24:28 +0000 UTC (1 container statuses recorded)
Apr  9 07:44:19.833: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1593be98d0c539ed], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:44:20.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7925" for this suite.
Apr  9 07:44:29.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:44:29.890: INFO: namespace sched-pred-7925 deletion completed in 8.900097994s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:44:29.891: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0409 07:45:10.459669    5079 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  9 07:45:10.459: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:45:10.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7750" for this suite.
Apr  9 07:45:18.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:45:19.333: INFO: namespace gc-7750 deletion completed in 8.852052229s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:45:19.334: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3735
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-6c5c93b1-5a9b-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 07:45:19.643: INFO: Waiting up to 5m0s for pod "pod-secrets-6c5ffd88-5a9b-11e9-8d38-4647074cf119" in namespace "secrets-3735" to be "success or failure"
Apr  9 07:45:19.665: INFO: Pod "pod-secrets-6c5ffd88-5a9b-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.098333ms
Apr  9 07:45:21.687: INFO: Pod "pod-secrets-6c5ffd88-5a9b-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043537742s
STEP: Saw pod success
Apr  9 07:45:21.687: INFO: Pod "pod-secrets-6c5ffd88-5a9b-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:45:21.709: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-secrets-6c5ffd88-5a9b-11e9-8d38-4647074cf119 container secret-volume-test: <nil>
STEP: delete the pod
Apr  9 07:45:21.766: INFO: Waiting for pod pod-secrets-6c5ffd88-5a9b-11e9-8d38-4647074cf119 to disappear
Apr  9 07:45:21.787: INFO: Pod pod-secrets-6c5ffd88-5a9b-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:45:21.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3735" for this suite.
Apr  9 07:45:27.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:45:28.731: INFO: namespace secrets-3735 deletion completed in 6.903752027s
•SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:45:28.731: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8005
Apr  9 07:45:31.066: INFO: Started pod liveness-http in namespace container-probe-8005
STEP: checking the pod's current state and verifying that restartCount is present
Apr  9 07:45:31.088: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:49:32.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8005" for this suite.
Apr  9 07:49:38.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:49:38.988: INFO: namespace container-probe-8005 deletion completed in 6.869366671s
•SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:49:38.989: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7529
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:49:41.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7529" for this suite.
Apr  9 07:50:27.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:50:28.314: INFO: namespace kubelet-test-7529 deletion completed in 46.852671892s
•SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:50:28.314: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1537
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0409 07:50:38.934677    5079 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  9 07:50:38.934: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:50:38.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1537" for this suite.
Apr  9 07:50:45.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:50:45.847: INFO: namespace gc-1537 deletion completed in 6.890819427s
•SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:50:45.847: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5677
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-2f074931-5a9c-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:50:46.243: INFO: Waiting up to 5m0s for pod "pod-configmaps-2f0ab09b-5a9c-11e9-8d38-4647074cf119" in namespace "configmap-5677" to be "success or failure"
Apr  9 07:50:46.264: INFO: Pod "pod-configmaps-2f0ab09b-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.04648ms
Apr  9 07:50:48.287: INFO: Pod "pod-configmaps-2f0ab09b-5a9c-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043705579s
STEP: Saw pod success
Apr  9 07:50:48.287: INFO: Pod "pod-configmaps-2f0ab09b-5a9c-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:50:48.309: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-2f0ab09b-5a9c-11e9-8d38-4647074cf119 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 07:50:48.369: INFO: Waiting for pod pod-configmaps-2f0ab09b-5a9c-11e9-8d38-4647074cf119 to disappear
Apr  9 07:50:48.390: INFO: Pod pod-configmaps-2f0ab09b-5a9c-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:50:48.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5677" for this suite.
Apr  9 07:50:54.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:50:55.281: INFO: namespace configmap-5677 deletion completed in 6.850152709s
•SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:50:55.281: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1130
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  9 07:50:55.707: INFO: Waiting up to 5m0s for pod "pod-34af402f-5a9c-11e9-8d38-4647074cf119" in namespace "emptydir-1130" to be "success or failure"
Apr  9 07:50:55.727: INFO: Pod "pod-34af402f-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 20.712592ms
Apr  9 07:50:57.750: INFO: Pod "pod-34af402f-5a9c-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043243283s
STEP: Saw pod success
Apr  9 07:50:57.750: INFO: Pod "pod-34af402f-5a9c-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:50:57.771: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-34af402f-5a9c-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:50:57.830: INFO: Waiting for pod pod-34af402f-5a9c-11e9-8d38-4647074cf119 to disappear
Apr  9 07:50:57.851: INFO: Pod pod-34af402f-5a9c-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:50:57.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1130" for this suite.
Apr  9 07:51:03.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:51:05.271: INFO: namespace emptydir-1130 deletion completed in 7.380116865s
•SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:51:05.271: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6120
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:51:05.616: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a973d16-5a9c-11e9-8d38-4647074cf119" in namespace "downward-api-6120" to be "success or failure"
Apr  9 07:51:05.638: INFO: Pod "downwardapi-volume-3a973d16-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.327954ms
Apr  9 07:51:07.659: INFO: Pod "downwardapi-volume-3a973d16-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043506873s
Apr  9 07:51:09.682: INFO: Pod "downwardapi-volume-3a973d16-5a9c-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06606701s
STEP: Saw pod success
Apr  9 07:51:09.682: INFO: Pod "downwardapi-volume-3a973d16-5a9c-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:51:09.704: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-3a973d16-5a9c-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:51:09.762: INFO: Waiting for pod downwardapi-volume-3a973d16-5a9c-11e9-8d38-4647074cf119 to disappear
Apr  9 07:51:09.784: INFO: Pod downwardapi-volume-3a973d16-5a9c-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:51:09.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6120" for this suite.
Apr  9 07:51:15.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:51:16.747: INFO: namespace downward-api-6120 deletion completed in 6.922719602s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:51:16.747: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5406
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:51:16.996: INFO: Creating ReplicaSet my-hostname-basic-4163b935-5a9c-11e9-8d38-4647074cf119
Apr  9 07:51:17.042: INFO: Pod name my-hostname-basic-4163b935-5a9c-11e9-8d38-4647074cf119: Found 1 pods out of 1
Apr  9 07:51:17.042: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-4163b935-5a9c-11e9-8d38-4647074cf119" is running
Apr  9 07:51:19.087: INFO: Pod "my-hostname-basic-4163b935-5a9c-11e9-8d38-4647074cf119-9d8hn" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-09 07:51:17 +0000 UTC Reason: Message:}])
Apr  9 07:51:19.087: INFO: Trying to dial the pod
Apr  9 07:51:24.238: INFO: Controller my-hostname-basic-4163b935-5a9c-11e9-8d38-4647074cf119: Got expected result from replica 1 [my-hostname-basic-4163b935-5a9c-11e9-8d38-4647074cf119-9d8hn]: "my-hostname-basic-4163b935-5a9c-11e9-8d38-4647074cf119-9d8hn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:51:24.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5406" for this suite.
Apr  9 07:51:30.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:51:31.135: INFO: namespace replicaset-5406 deletion completed in 6.85659972s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:51:31.135: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2345
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:51:31.418: INFO: Waiting up to 5m0s for pod "downwardapi-volume-49f85f9e-5a9c-11e9-8d38-4647074cf119" in namespace "downward-api-2345" to be "success or failure"
Apr  9 07:51:31.440: INFO: Pod "downwardapi-volume-49f85f9e-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.73062ms
Apr  9 07:51:33.462: INFO: Pod "downwardapi-volume-49f85f9e-5a9c-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044039464s
STEP: Saw pod success
Apr  9 07:51:33.462: INFO: Pod "downwardapi-volume-49f85f9e-5a9c-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:51:33.484: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-49f85f9e-5a9c-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:51:33.541: INFO: Waiting for pod downwardapi-volume-49f85f9e-5a9c-11e9-8d38-4647074cf119 to disappear
Apr  9 07:51:33.562: INFO: Pod downwardapi-volume-49f85f9e-5a9c-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:51:33.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2345" for this suite.
Apr  9 07:51:39.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:51:40.759: INFO: namespace downward-api-2345 deletion completed in 7.156652626s
•SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:51:40.760: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4061
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr  9 07:51:41.232: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4061,SelfLink:/api/v1/namespaces/watch-4061/configmaps/e2e-watch-test-watch-closed,UID:4fcbedfd-5a9c-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:19074,Generation:0,CreationTimestamp:2019-04-09 07:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  9 07:51:41.232: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4061,SelfLink:/api/v1/namespaces/watch-4061/configmaps/e2e-watch-test-watch-closed,UID:4fcbedfd-5a9c-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:19075,Generation:0,CreationTimestamp:2019-04-09 07:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr  9 07:51:41.333: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4061,SelfLink:/api/v1/namespaces/watch-4061/configmaps/e2e-watch-test-watch-closed,UID:4fcbedfd-5a9c-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:19077,Generation:0,CreationTimestamp:2019-04-09 07:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  9 07:51:41.333: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-4061,SelfLink:/api/v1/namespaces/watch-4061/configmaps/e2e-watch-test-watch-closed,UID:4fcbedfd-5a9c-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:19078,Generation:0,CreationTimestamp:2019-04-09 07:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:51:41.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4061" for this suite.
Apr  9 07:51:47.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:51:48.269: INFO: namespace watch-4061 deletion completed in 6.913820659s
•S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:51:48.269: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3692
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-54524cd0-5a9c-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume configMaps
Apr  9 07:51:48.813: INFO: Waiting up to 5m0s for pod "pod-configmaps-5455e063-5a9c-11e9-8d38-4647074cf119" in namespace "configmap-3692" to be "success or failure"
Apr  9 07:51:48.834: INFO: Pod "pod-configmaps-5455e063-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.105241ms
Apr  9 07:51:50.856: INFO: Pod "pod-configmaps-5455e063-5a9c-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043005962s
STEP: Saw pod success
Apr  9 07:51:50.856: INFO: Pod "pod-configmaps-5455e063-5a9c-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:51:50.878: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-configmaps-5455e063-5a9c-11e9-8d38-4647074cf119 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  9 07:51:50.935: INFO: Waiting for pod pod-configmaps-5455e063-5a9c-11e9-8d38-4647074cf119 to disappear
Apr  9 07:51:50.957: INFO: Pod pod-configmaps-5455e063-5a9c-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:51:50.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3692" for this suite.
Apr  9 07:51:57.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:51:57.868: INFO: namespace configmap-3692 deletion completed in 6.87095846s
•SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:51:57.868: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:51:58.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9665" for this suite.
Apr  9 07:52:20.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:52:21.244: INFO: namespace kubelet-test-9665 deletion completed in 22.876657134s
•SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:52:21.244: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5947
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr  9 07:52:23.740: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:52:23.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5947" for this suite.
Apr  9 07:52:47.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:52:48.923: INFO: namespace replicaset-5947 deletion completed in 25.076079368s
•S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:52:48.923: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:52:49.258: INFO: Waiting up to 5m0s for pod "downwardapi-volume-785cc46d-5a9c-11e9-8d38-4647074cf119" in namespace "projected-8726" to be "success or failure"
Apr  9 07:52:49.286: INFO: Pod "downwardapi-volume-785cc46d-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 27.998106ms
Apr  9 07:52:51.308: INFO: Pod "downwardapi-volume-785cc46d-5a9c-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050137709s
STEP: Saw pod success
Apr  9 07:52:51.308: INFO: Pod "downwardapi-volume-785cc46d-5a9c-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:52:51.330: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-785cc46d-5a9c-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:52:51.387: INFO: Waiting for pod downwardapi-volume-785cc46d-5a9c-11e9-8d38-4647074cf119 to disappear
Apr  9 07:52:51.408: INFO: Pod downwardapi-volume-785cc46d-5a9c-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:52:51.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8726" for this suite.
Apr  9 07:52:57.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:52:58.319: INFO: namespace projected-8726 deletion completed in 6.870714924s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:52:58.319: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2504
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  9 07:52:58.710: INFO: Waiting up to 5m0s for pod "pod-7e00176b-5a9c-11e9-8d38-4647074cf119" in namespace "emptydir-2504" to be "success or failure"
Apr  9 07:52:58.732: INFO: Pod "pod-7e00176b-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.023186ms
Apr  9 07:53:00.754: INFO: Pod "pod-7e00176b-5a9c-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044147108s
STEP: Saw pod success
Apr  9 07:53:00.754: INFO: Pod "pod-7e00176b-5a9c-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:53:00.775: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-7e00176b-5a9c-11e9-8d38-4647074cf119 container test-container: <nil>
STEP: delete the pod
Apr  9 07:53:00.830: INFO: Waiting for pod pod-7e00176b-5a9c-11e9-8d38-4647074cf119 to disappear
Apr  9 07:53:00.852: INFO: Pod pod-7e00176b-5a9c-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:53:00.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2504" for this suite.
Apr  9 07:53:06.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:53:07.988: INFO: namespace emptydir-2504 deletion completed in 7.096253093s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:53:07.988: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr  9 07:53:08.420: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Apr  9 07:53:15.601: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:53:15.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4217" for this suite.
Apr  9 07:53:21.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:53:22.499: INFO: namespace pods-4217 deletion completed in 6.852968153s
•SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:53:22.499: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Apr  9 07:53:22.819: INFO: Waiting up to 5m0s for pod "var-expansion-8c5ed22d-5a9c-11e9-8d38-4647074cf119" in namespace "var-expansion-1012" to be "success or failure"
Apr  9 07:53:22.841: INFO: Pod "var-expansion-8c5ed22d-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 22.491604ms
Apr  9 07:53:24.863: INFO: Pod "var-expansion-8c5ed22d-5a9c-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043964423s
STEP: Saw pod success
Apr  9 07:53:24.863: INFO: Pod "var-expansion-8c5ed22d-5a9c-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:53:24.884: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod var-expansion-8c5ed22d-5a9c-11e9-8d38-4647074cf119 container dapi-container: <nil>
STEP: delete the pod
Apr  9 07:53:24.939: INFO: Waiting for pod var-expansion-8c5ed22d-5a9c-11e9-8d38-4647074cf119 to disappear
Apr  9 07:53:24.960: INFO: Pod var-expansion-8c5ed22d-5a9c-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:53:24.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1012" for this suite.
Apr  9 07:53:31.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:53:31.855: INFO: namespace var-expansion-1012 deletion completed in 6.854727825s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:53:31.855: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2817
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-2817
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Apr  9 07:53:32.258: INFO: Found 1 stateful pods, waiting for 3
Apr  9 07:53:42.288: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:53:42.288: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:53:42.288: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr  9 07:53:42.412: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr  9 07:53:42.511: INFO: Updating stateful set ss2
Apr  9 07:53:42.554: INFO: Waiting for Pod statefulset-2817/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  9 07:53:52.599: INFO: Waiting for Pod statefulset-2817/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr  9 07:54:02.673: INFO: Found 2 stateful pods, waiting for 3
Apr  9 07:54:12.696: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:54:12.696: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  9 07:54:12.696: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr  9 07:54:12.795: INFO: Updating stateful set ss2
Apr  9 07:54:12.838: INFO: Waiting for Pod statefulset-2817/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  9 07:54:22.939: INFO: Updating stateful set ss2
Apr  9 07:54:22.982: INFO: Waiting for StatefulSet statefulset-2817/ss2 to complete update
Apr  9 07:54:22.983: INFO: Waiting for Pod statefulset-2817/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr  9 07:54:33.028: INFO: Waiting for StatefulSet statefulset-2817/ss2 to complete update
Apr  9 07:54:33.028: INFO: Waiting for Pod statefulset-2817/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr  9 07:54:43.028: INFO: Deleting all statefulset in ns statefulset-2817
Apr  9 07:54:43.050: INFO: Scaling statefulset ss2 to 0
Apr  9 07:55:23.144: INFO: Waiting for statefulset status.replicas updated to 0
Apr  9 07:55:23.166: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:55:23.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2817" for this suite.
Apr  9 07:55:31.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:55:32.126: INFO: namespace statefulset-2817 deletion completed in 8.852196077s
•SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:55:32.127: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8978
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-d9ab3cc8-5a9c-11e9-8d38-4647074cf119
STEP: Creating a pod to test consume secrets
Apr  9 07:55:32.527: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d9aeb199-5a9c-11e9-8d38-4647074cf119" in namespace "projected-8978" to be "success or failure"
Apr  9 07:55:32.549: INFO: Pod "pod-projected-secrets-d9aeb199-5a9c-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.61684ms
Apr  9 07:55:34.591: INFO: Pod "pod-projected-secrets-d9aeb199-5a9c-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.063499191s
STEP: Saw pod success
Apr  9 07:55:34.591: INFO: Pod "pod-projected-secrets-d9aeb199-5a9c-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:55:34.613: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod pod-projected-secrets-d9aeb199-5a9c-11e9-8d38-4647074cf119 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  9 07:55:34.693: INFO: Waiting for pod pod-projected-secrets-d9aeb199-5a9c-11e9-8d38-4647074cf119 to disappear
Apr  9 07:55:34.714: INFO: Pod pod-projected-secrets-d9aeb199-5a9c-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:55:34.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8978" for this suite.
Apr  9 07:55:42.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:55:43.629: INFO: namespace projected-8978 deletion completed in 8.874596918s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:55:43.629: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Apr  9 07:55:43.897: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config create -f - --namespace=kubectl-4488'
Apr  9 07:55:45.999: INFO: stderr: ""
Apr  9 07:55:45.999: INFO: stdout: "pod/pause created\n"
Apr  9 07:55:45.999: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr  9 07:55:45.999: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4488" to be "running and ready"
Apr  9 07:55:46.021: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 21.679642ms
Apr  9 07:55:48.043: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.043913765s
Apr  9 07:55:48.043: INFO: Pod "pause" satisfied condition "running and ready"
Apr  9 07:55:48.043: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Apr  9 07:55:48.043: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-4488'
Apr  9 07:55:48.330: INFO: stderr: ""
Apr  9 07:55:48.330: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr  9 07:55:48.330: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pod pause -L testing-label --namespace=kubectl-4488'
Apr  9 07:55:48.562: INFO: stderr: ""
Apr  9 07:55:48.562: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr  9 07:55:48.562: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config label pods pause testing-label- --namespace=kubectl-4488'
Apr  9 07:55:48.813: INFO: stderr: ""
Apr  9 07:55:48.813: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr  9 07:55:48.813: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pod pause -L testing-label --namespace=kubectl-4488'
Apr  9 07:55:49.044: INFO: stderr: ""
Apr  9 07:55:49.045: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Apr  9 07:55:49.045: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-4488'
Apr  9 07:55:49.286: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  9 07:55:49.287: INFO: stdout: "pod \"pause\" force deleted\n"
Apr  9 07:55:49.287: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-4488'
Apr  9 07:55:49.604: INFO: stderr: "No resources found.\n"
Apr  9 07:55:49.604: INFO: stdout: ""
Apr  9 07:55:49.604: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config get pods -l name=pause --namespace=kubectl-4488 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  9 07:55:49.853: INFO: stderr: ""
Apr  9 07:55:49.853: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:55:49.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4488" for this suite.
Apr  9 07:55:55.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:55:56.754: INFO: namespace kubectl-4488 deletion completed in 6.861384783s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:55:56.755: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6325
Apr  9 07:55:59.253: INFO: Started pod liveness-http in namespace container-probe-6325
STEP: checking the pod's current state and verifying that restartCount is present
Apr  9 07:55:59.275: INFO: Initial restart count of pod liveness-http is 0
Apr  9 07:56:17.496: INFO: Restart count of pod container-probe-6325/liveness-http is now 1 (18.220986228s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:56:17.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6325" for this suite.
Apr  9 07:56:23.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:56:24.423: INFO: namespace container-probe-6325 deletion completed in 6.85839461s
•SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:56:24.424: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8721
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  9 07:56:24.692: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  9 07:56:43.070: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.88:8080/dial?request=hostName&protocol=udp&host=100.96.0.222&port=8081&tries=1'] Namespace:pod-network-test-8721 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 07:56:43.070: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 07:56:43.651: INFO: Waiting for endpoints: map[]
Apr  9 07:56:43.673: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.88:8080/dial?request=hostName&protocol=udp&host=100.96.1.87&port=8081&tries=1'] Namespace:pod-network-test-8721 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  9 07:56:43.673: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
Apr  9 07:56:44.155: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:56:44.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8721" for this suite.
Apr  9 07:57:08.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:57:09.051: INFO: namespace pod-network-test-8721 deletion completed in 24.855122626s
•SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:57:09.051: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9934
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Apr  9 07:57:09.410: INFO: Waiting up to 5m0s for pod "var-expansion-136ddbad-5a9d-11e9-8d38-4647074cf119" in namespace "var-expansion-9934" to be "success or failure"
Apr  9 07:57:09.431: INFO: Pod "var-expansion-136ddbad-5a9d-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.22641ms
Apr  9 07:57:11.454: INFO: Pod "var-expansion-136ddbad-5a9d-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044150276s
STEP: Saw pod success
Apr  9 07:57:11.454: INFO: Pod "var-expansion-136ddbad-5a9d-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:57:11.476: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod var-expansion-136ddbad-5a9d-11e9-8d38-4647074cf119 container dapi-container: <nil>
STEP: delete the pod
Apr  9 07:57:11.536: INFO: Waiting for pod var-expansion-136ddbad-5a9d-11e9-8d38-4647074cf119 to disappear
Apr  9 07:57:11.557: INFO: Pod var-expansion-136ddbad-5a9d-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:57:11.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9934" for this suite.
Apr  9 07:57:17.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:57:18.477: INFO: namespace var-expansion-9934 deletion completed in 6.879136727s
•SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:57:18.477: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Apr  9 07:57:18.800: INFO: Asynchronously running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl kubectl --server=https://api.pub-gcp-8or3z.it.internal.dev.k8s.ondemand.com --kubeconfig=/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix605597407/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:57:18.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2327" for this suite.
Apr  9 07:57:25.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:57:25.859: INFO: namespace kubectl-2327 deletion completed in 6.866196857s
•SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:57:25.860: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:57:26.191: INFO: Creating deployment "nginx-deployment"
Apr  9 07:57:26.213: INFO: Waiting for observed generation 1
Apr  9 07:57:28.257: INFO: Waiting for all required pods to come up
Apr  9 07:57:28.302: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr  9 07:57:30.366: INFO: Waiting for deployment "nginx-deployment" to complete
Apr  9 07:57:30.409: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr  9 07:57:30.454: INFO: Updating deployment nginx-deployment
Apr  9 07:57:30.454: INFO: Waiting for observed generation 2
Apr  9 07:57:32.499: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr  9 07:57:32.520: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr  9 07:57:32.541: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  9 07:57:32.607: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr  9 07:57:32.607: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr  9 07:57:32.630: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr  9 07:57:32.673: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr  9 07:57:32.673: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr  9 07:57:32.720: INFO: Updating deployment nginx-deployment
Apr  9 07:57:32.720: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr  9 07:57:32.791: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr  9 07:57:34.891: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr  9 07:57:34.934: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-9439,SelfLink:/apis/apps/v1/namespaces/deployment-9439/deployments/nginx-deployment,UID:1d743dea-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20503,Generation:3,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:10,UnavailableReplicas:23,Conditions:[{Available False 2019-04-09 07:57:32 +0000 UTC 2019-04-09 07:57:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-09 07:57:34 +0000 UTC 2019-04-09 07:57:26 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:10,CollisionCount:nil,},}

Apr  9 07:57:34.993: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-9439,SelfLink:/apis/apps/v1/namespaces/deployment-9439/replicasets/nginx-deployment-5f9595f595,UID:1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20477,Generation:3,CreationTimestamp:2019-04-09 07:57:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 1d743dea-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002d2a627 0xc002d2a628}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr  9 07:57:34.993: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr  9 07:57:34.993: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-9439,SelfLink:/apis/apps/v1/namespaces/deployment-9439/replicasets/nginx-deployment-6f478d8d8,UID:1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20501,Generation:3,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 1d743dea-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002d2a8b7 0xc002d2a8b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:10,AvailableReplicas:10,Conditions:[],},}
Apr  9 07:57:35.054: INFO: Pod "nginx-deployment-5f9595f595-5l629" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5l629,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-5l629,UID:21575879-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20489,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.97/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002704557 0xc002704558}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027045c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027045e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.054: INFO: Pod "nginx-deployment-5f9595f595-5q24l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5q24l,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-5q24l,UID:218411ca-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20511,Generation:0,CreationTimestamp:2019-04-09 07:57:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.241/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc0027046c0 0xc0027046c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002704730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002704750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.055: INFO: Pod "nginx-deployment-5f9595f595-5skbd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-5skbd,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-5skbd,UID:217307d9-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20494,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.101/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002704830 0xc002704831}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027048a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027048c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.055: INFO: Pod "nginx-deployment-5f9595f595-d8xxh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-d8xxh,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-d8xxh,UID:2163b27c-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20490,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.98/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc0027049a0 0xc0027049a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002704a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002704a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.055: INFO: Pod "nginx-deployment-5f9595f595-f6hzn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-f6hzn,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-f6hzn,UID:1ffd7de4-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20402,Generation:0,CreationTimestamp:2019-04-09 07:57:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.231/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002704c90 0xc002704c91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002704d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002704d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.055: INFO: Pod "nginx-deployment-5f9595f595-hgvv4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-hgvv4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-hgvv4,UID:2172f4aa-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20507,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.104/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002704f50 0xc002704f51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002705010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002705030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.055: INFO: Pod "nginx-deployment-5f9595f595-hmgbx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-hmgbx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-hmgbx,UID:21731bbc-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20508,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.238/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc0027051f0 0xc0027051f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027052b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002705350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.055: INFO: Pod "nginx-deployment-5f9595f595-j5dzs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-j5dzs,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-j5dzs,UID:200686bb-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20502,Generation:0,CreationTimestamp:2019-04-09 07:57:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.94/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002705530 0xc002705531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027055f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002705610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.94,StartTime:2019-04-09 07:57:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.055: INFO: Pod "nginx-deployment-5f9595f595-lklhk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-lklhk,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-lklhk,UID:2165d9d5-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20488,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.234/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc0027057a0 0xc0027057a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002705950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027059f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.055: INFO: Pod "nginx-deployment-5f9595f595-lp2ml" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-lp2ml,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-lp2ml,UID:217318b2-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20510,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.240/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002705b00 0xc002705b01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002705b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002705b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.055: INFO: Pod "nginx-deployment-5f9595f595-njt9b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-njt9b,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-njt9b,UID:1ffcc523-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20474,Generation:0,CreationTimestamp:2019-04-09 07:57:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.230/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002705e80 0xc002705e81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002705ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002705f10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.230,StartTime:2019-04-09 07:57:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.056: INFO: Pod "nginx-deployment-5f9595f595-nsvtb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-nsvtb,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-nsvtb,UID:20074089-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20499,Generation:0,CreationTimestamp:2019-04-09 07:57:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.232/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a380f0 0xc002a380f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a38160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a38180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.232,StartTime:2019-04-09 07:57:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.056: INFO: Pod "nginx-deployment-5f9595f595-xhrlc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xhrlc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-5f9595f595-xhrlc,UID:1ffd7f2f-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20408,Generation:0,CreationTimestamp:2019-04-09 07:57:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.93/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 1ffc1026-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a38280 0xc002a38281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a38300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a38320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:30 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.93,StartTime:2019-04-09 07:57:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.056: INFO: Pod "nginx-deployment-6f478d8d8-2t8p6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-2t8p6,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-2t8p6,UID:1da290fa-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20347,Generation:0,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.227/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a38420 0xc002a38421}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a38480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a384a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.227,StartTime:2019-04-09 07:57:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://783b7fa0be511dd38217a07bff8730cf5c40bae6c872881125273eb3accd9579}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.056: INFO: Pod "nginx-deployment-6f478d8d8-4jxsf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-4jxsf,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-4jxsf,UID:2165da8d-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20493,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.235/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a38580 0xc002a38581}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a385e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a38600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.056: INFO: Pod "nginx-deployment-6f478d8d8-54pgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-54pgl,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-54pgl,UID:2165e06b-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20491,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.99/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a386e0 0xc002a386e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a38740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a38760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.056: INFO: Pod "nginx-deployment-6f478d8d8-676rj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-676rj,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-676rj,UID:2165e260-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20498,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.236/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a38830 0xc002a38831}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a38890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a388b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.056: INFO: Pod "nginx-deployment-6f478d8d8-8ldck" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-8ldck,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-8ldck,UID:1da288b9-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20359,Generation:0,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.228/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a38980 0xc002a38981}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a389f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a38a10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.228,StartTime:2019-04-09 07:57:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://1e395e9d29e66363f2758a80074997818c7d5eab7fe306e95cf774359d5d89f0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.056: INFO: Pod "nginx-deployment-6f478d8d8-9vbgn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-9vbgn,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-9vbgn,UID:21731d4e-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20509,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.242/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a38af0 0xc002a38af1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a38b50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a38b70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.057: INFO: Pod "nginx-deployment-6f478d8d8-c8hlw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-c8hlw,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-c8hlw,UID:2165da60-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20492,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.100/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a38c40 0xc002a38c41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a38ca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a38cc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.057: INFO: Pod "nginx-deployment-6f478d8d8-fsxzx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-fsxzx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-fsxzx,UID:21574fd3-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20487,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.96/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a38d90 0xc002a38d91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a38df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a38e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.057: INFO: Pod "nginx-deployment-6f478d8d8-gqh6v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-gqh6v,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-gqh6v,UID:1da28670-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20334,Generation:0,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.91/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a38ef0 0xc002a38ef1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a38f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a38f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.91,StartTime:2019-04-09 07:57:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://28d12b8603a7d88a8323d55bedaf1a0a2640a8c034460405511d2357c4790f00}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.057: INFO: Pod "nginx-deployment-6f478d8d8-kmntb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-kmntb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-kmntb,UID:1d94cd67-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20353,Generation:0,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.224/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a39050 0xc002a39051}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a390b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a390d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.224,StartTime:2019-04-09 07:57:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://7cf0647d224460f8cf32d381e2f19fac8535b237750f3d45a1f66986498565b0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.057: INFO: Pod "nginx-deployment-6f478d8d8-ln8x4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ln8x4,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-ln8x4,UID:1da4d971-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20356,Generation:0,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.229/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a391b0 0xc002a391b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a39210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a39230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.229,StartTime:2019-04-09 07:57:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://ab7ed237e1711e8a964b9304db8a49f143cfd4d7b0be7b07e338e4a2ded37294}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.057: INFO: Pod "nginx-deployment-6f478d8d8-ltx4q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-ltx4q,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-ltx4q,UID:21732dec-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20505,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.103/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a39320 0xc002a39321}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a39380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a393a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.057: INFO: Pod "nginx-deployment-6f478d8d8-m6929" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-m6929,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-m6929,UID:1d93f2e1-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20350,Generation:0,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.225/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a39470 0xc002a39471}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a394d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a394f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.225,StartTime:2019-04-09 07:57:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://425719f2935550be094bb2cc9c0b74a6f9abb031f6aaa8b2e9a79cb065d13f6c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.057: INFO: Pod "nginx-deployment-6f478d8d8-qgg49" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qgg49,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-qgg49,UID:21735cde-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20504,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.102/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a395f0 0xc002a395f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a39650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a39670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.057: INFO: Pod "nginx-deployment-6f478d8d8-s26js" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-s26js,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-s26js,UID:21567c1d-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20500,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.95/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a39750 0xc002a39751}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a397b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a397d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.95,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://7cdca3d1cfb5e5f0d4e45e4ffe368090ba45a9902ef939aef5b633694797be6b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.058: INFO: Pod "nginx-deployment-6f478d8d8-tkmrg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-tkmrg,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-tkmrg,UID:1d94bbaa-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20331,Generation:0,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.89/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a398b0 0xc002a398b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a39910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a39930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.89,StartTime:2019-04-09 07:57:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://1a9045b6ecd72797f16efc6bedb4a6e14685d0bc8571f724ae91f04b4a2cac4a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.058: INFO: Pod "nginx-deployment-6f478d8d8-v29g5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-v29g5,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-v29g5,UID:2157547a-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20495,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.233/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a39a10 0xc002a39a11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a39a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a39a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.233,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://7d21dbc16dd4c7dba1e2a61dca8fbd769e632d3241f3ec4276f2b75c8325b240}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.058: INFO: Pod "nginx-deployment-6f478d8d8-x7g6l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-x7g6l,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-x7g6l,UID:21735466-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20512,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.239/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a39b70 0xc002a39b71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a39bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a39bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:33 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.058: INFO: Pod "nginx-deployment-6f478d8d8-xpdgq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-xpdgq,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-xpdgq,UID:1da2886e-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20337,Generation:0,CreationTimestamp:2019-04-09 07:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.90/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a39cc0 0xc002a39cc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a39d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a39d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:26 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.90,StartTime:2019-04-09 07:57:26 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-09 07:57:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://473eac36339ffc5a02f5a30a96ba1a248df75d8f9da895ad1d43269d3f89f6d4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr  9 07:57:35.058: INFO: Pod "nginx-deployment-6f478d8d8-zxzf2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-zxzf2,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-9439,SelfLink:/api/v1/namespaces/deployment-9439/pods/nginx-deployment-6f478d8d8-zxzf2,UID:21732883-5a9d-11e9-8ec1-5e80bdd8d9d6,ResourceVersion:20506,Generation:0,CreationTimestamp:2019-04-09 07:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.237/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 1d76b986-5a9d-11e9-8ec1-5e80bdd8d9d6 0xc002a39e20 0xc002a39e21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-j987p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j987p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j987p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002a39e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002a39ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-09 07:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-04-09 07:57:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:57:35.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9439" for this suite.
Apr  9 07:57:43.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:57:43.952: INFO: namespace deployment-9439 deletion completed in 8.857396038s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:57:43.952: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6253
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Apr  9 07:57:44.310: INFO: Waiting up to 5m0s for pod "downwardapi-volume-283b1dd6-5a9d-11e9-8d38-4647074cf119" in namespace "projected-6253" to be "success or failure"
Apr  9 07:57:44.331: INFO: Pod "downwardapi-volume-283b1dd6-5a9d-11e9-8d38-4647074cf119": Phase="Pending", Reason="", readiness=false. Elapsed: 21.173838ms
Apr  9 07:57:46.353: INFO: Pod "downwardapi-volume-283b1dd6-5a9d-11e9-8d38-4647074cf119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043248756s
STEP: Saw pod success
Apr  9 07:57:46.353: INFO: Pod "downwardapi-volume-283b1dd6-5a9d-11e9-8d38-4647074cf119" satisfied condition "success or failure"
Apr  9 07:57:46.375: INFO: Trying to get logs from node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-wxxpk pod downwardapi-volume-283b1dd6-5a9d-11e9-8d38-4647074cf119 container client-container: <nil>
STEP: delete the pod
Apr  9 07:57:46.431: INFO: Waiting for pod downwardapi-volume-283b1dd6-5a9d-11e9-8d38-4647074cf119 to disappear
Apr  9 07:57:46.453: INFO: Pod downwardapi-volume-283b1dd6-5a9d-11e9-8d38-4647074cf119 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:57:46.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6253" for this suite.
Apr  9 07:57:54.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:57:55.349: INFO: namespace projected-6253 deletion completed in 8.856398194s
•SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:57:55.350: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7729
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr  9 07:57:58.325: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl exec --namespace=svcaccounts-7729 pod-service-account-2f5dbd40-5a9d-11e9-8d38-4647074cf119 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr  9 07:57:59.094: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl exec --namespace=svcaccounts-7729 pod-service-account-2f5dbd40-5a9d-11e9-8d38-4647074cf119 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr  9 07:57:59.830: INFO: Running '/tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/setup/scripts/kubectl exec --namespace=svcaccounts-7729 pod-service-account-2f5dbd40-5a9d-11e9-8d38-4647074cf119 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:58:00.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7729" for this suite.
Apr  9 07:58:06.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:58:07.445: INFO: namespace svcaccounts-7729 deletion completed in 6.859732226s
•SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Apr  9 07:58:07.445: INFO: >>> kubeConfig: /tmp/build/03b5f99b/git-kubernetes-dev_landscape-dev-garden-master_master/../tm/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7735
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Apr  9 07:58:07.804: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr  9 07:58:07.850: INFO: Number of nodes with available pods: 0
Apr  9 07:58:07.850: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr  9 07:58:07.942: INFO: Number of nodes with available pods: 0
Apr  9 07:58:07.942: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:58:08.965: INFO: Number of nodes with available pods: 0
Apr  9 07:58:08.965: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:58:09.964: INFO: Number of nodes with available pods: 1
Apr  9 07:58:09.964: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr  9 07:58:10.054: INFO: Number of nodes with available pods: 0
Apr  9 07:58:10.054: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr  9 07:58:10.099: INFO: Number of nodes with available pods: 0
Apr  9 07:58:10.099: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:58:11.122: INFO: Number of nodes with available pods: 0
Apr  9 07:58:11.122: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:58:12.120: INFO: Number of nodes with available pods: 0
Apr  9 07:58:12.120: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:58:13.121: INFO: Number of nodes with available pods: 0
Apr  9 07:58:13.121: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:58:14.121: INFO: Number of nodes with available pods: 0
Apr  9 07:58:14.121: INFO: Node shoot--it--pub-gcp-8or3z-cpu-worker-z1-5579c477b7-nldzl is running more than one daemon pod
Apr  9 07:58:15.121: INFO: Number of nodes with available pods: 1
Apr  9 07:58:15.121: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7735, will wait for the garbage collector to delete the pods
Apr  9 07:58:15.610: INFO: Deleting DaemonSet.extensions daemon-set took: 25.419376ms
Apr  9 07:58:15.710: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.213033ms
Apr  9 07:58:18.433: INFO: Number of nodes with available pods: 0
Apr  9 07:58:18.433: INFO: Number of running nodes: 0, number of available pods: 0
Apr  9 07:58:18.454: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7735/daemonsets","resourceVersion":"20804"},"items":null}

Apr  9 07:58:18.475: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7735/pods","resourceVersion":"20804"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.0-rc.1.5+641856db183520/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Apr  9 07:58:18.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7735" for this suite.
Apr  9 07:58:24.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  9 07:58:25.454: INFO: namespace daemonsets-7735 deletion completed in 6.846311508s
•SSSSSSSSSSApr  9 07:58:25.454: INFO: Running AfterSuite actions on all nodes
Apr  9 07:58:25.464: INFO: Running AfterSuite actions on node 1
Apr  9 07:58:25.476: INFO: Skipping dumping logs from cluster

Ran 204 of 3584 Specs in 5341.883 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Flaked | 0 Pending | 3380 Skipped PASS

Ginkgo ran 1 suite in 1h29m3.215672219s
Test Suite Passed

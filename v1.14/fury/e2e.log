I0218 12:09:54.538951      16 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-639612178
I0218 12:09:54.539043      16 e2e.go:242] Starting e2e run "92355115-5247-11ea-bd69-fac0b7afc6af" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1582027793 - Will randomize all specs
Will run 204 of 3585 specs

Feb 18 12:09:54.599: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 12:09:54.601: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 18 12:09:54.610: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 18 12:09:54.629: INFO: The status of Pod minio-setup-b9gv4 is Succeeded, skipping waiting
Feb 18 12:09:54.629: INFO: 17 / 18 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 18 12:09:54.629: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Feb 18 12:09:54.629: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 18 12:09:54.634: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 18 12:09:54.634: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 18 12:09:54.634: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'velero-restic' (0 seconds elapsed)
Feb 18 12:09:54.634: INFO: e2e test version: v1.14.10
Feb 18 12:09:54.635: INFO: kube-apiserver version: v1.14.10
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:09:54.635: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
Feb 18 12:09:54.655: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:09:54.660: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92c20ba0-5247-11ea-bd69-fac0b7afc6af" in namespace "downward-api-6351" to be "success or failure"
Feb 18 12:09:54.663: INFO: Pod "downwardapi-volume-92c20ba0-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.437866ms
Feb 18 12:09:56.665: INFO: Pod "downwardapi-volume-92c20ba0-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005695236s
Feb 18 12:09:58.668: INFO: Pod "downwardapi-volume-92c20ba0-5247-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008090626s
STEP: Saw pod success
Feb 18 12:09:58.668: INFO: Pod "downwardapi-volume-92c20ba0-5247-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:09:58.670: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-92c20ba0-5247-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:09:58.693: INFO: Waiting for pod downwardapi-volume-92c20ba0-5247-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:09:58.695: INFO: Pod downwardapi-volume-92c20ba0-5247-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:09:58.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6351" for this suite.
Feb 18 12:10:04.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:10:04.865: INFO: namespace downward-api-6351 deletion completed in 6.167568243s

• [SLOW TEST:10.230 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:10:04.865: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0218 12:10:10.899866      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 12:10:10.899: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:10:10.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3141" for this suite.
Feb 18 12:10:16.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:10:17.070: INFO: namespace gc-3141 deletion completed in 6.168757229s

• [SLOW TEST:12.205 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:10:17.070: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 18 12:10:25.129: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:25.132: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:27.132: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:27.135: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:29.132: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:29.134: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:31.132: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:31.134: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:33.133: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:33.135: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:35.132: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:35.135: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:37.132: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:37.134: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:39.132: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:39.135: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:41.132: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:41.135: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:43.132: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:43.135: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 18 12:10:45.132: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 18 12:10:45.135: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:10:45.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4955" for this suite.
Feb 18 12:11:07.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:11:07.317: INFO: namespace container-lifecycle-hook-4955 deletion completed in 22.170020172s

• [SLOW TEST:50.247 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:11:07.318: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:11:07.349: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be14d6e2-5247-11ea-bd69-fac0b7afc6af" in namespace "downward-api-4560" to be "success or failure"
Feb 18 12:11:07.357: INFO: Pod "downwardapi-volume-be14d6e2-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.903699ms
Feb 18 12:11:09.359: INFO: Pod "downwardapi-volume-be14d6e2-5247-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009858972s
STEP: Saw pod success
Feb 18 12:11:09.359: INFO: Pod "downwardapi-volume-be14d6e2-5247-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:11:09.361: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-be14d6e2-5247-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:11:09.377: INFO: Waiting for pod downwardapi-volume-be14d6e2-5247-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:11:09.379: INFO: Pod downwardapi-volume-be14d6e2-5247-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:11:09.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4560" for this suite.
Feb 18 12:11:15.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:11:15.549: INFO: namespace downward-api-4560 deletion completed in 6.168145966s

• [SLOW TEST:8.232 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:11:15.549: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 18 12:11:15.574: INFO: Waiting up to 5m0s for pod "pod-c2fc8f1b-5247-11ea-bd69-fac0b7afc6af" in namespace "emptydir-796" to be "success or failure"
Feb 18 12:11:15.587: INFO: Pod "pod-c2fc8f1b-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 12.796102ms
Feb 18 12:11:17.618: INFO: Pod "pod-c2fc8f1b-5247-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044124398s
STEP: Saw pod success
Feb 18 12:11:17.618: INFO: Pod "pod-c2fc8f1b-5247-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:11:17.620: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-c2fc8f1b-5247-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:11:17.638: INFO: Waiting for pod pod-c2fc8f1b-5247-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:11:17.640: INFO: Pod pod-c2fc8f1b-5247-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:11:17.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-796" for this suite.
Feb 18 12:11:23.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:11:23.813: INFO: namespace emptydir-796 deletion completed in 6.170222476s

• [SLOW TEST:8.264 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:11:23.813: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-c7e97a11-5247-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 12:11:23.844: INFO: Waiting up to 5m0s for pod "pod-secrets-c7ea7e6e-5247-11ea-bd69-fac0b7afc6af" in namespace "secrets-5589" to be "success or failure"
Feb 18 12:11:23.856: INFO: Pod "pod-secrets-c7ea7e6e-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 11.249913ms
Feb 18 12:11:25.858: INFO: Pod "pod-secrets-c7ea7e6e-5247-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013484121s
STEP: Saw pod success
Feb 18 12:11:25.858: INFO: Pod "pod-secrets-c7ea7e6e-5247-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:11:25.860: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-secrets-c7ea7e6e-5247-11ea-bd69-fac0b7afc6af container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 12:11:25.878: INFO: Waiting for pod pod-secrets-c7ea7e6e-5247-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:11:25.880: INFO: Pod pod-secrets-c7ea7e6e-5247-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:11:25.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5589" for this suite.
Feb 18 12:11:31.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:11:32.049: INFO: namespace secrets-5589 deletion completed in 6.16644003s

• [SLOW TEST:8.235 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:11:32.049: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:11:32.068: INFO: Creating ReplicaSet my-hostname-basic-ccd1f621-5247-11ea-bd69-fac0b7afc6af
Feb 18 12:11:32.086: INFO: Pod name my-hostname-basic-ccd1f621-5247-11ea-bd69-fac0b7afc6af: Found 1 pods out of 1
Feb 18 12:11:32.086: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-ccd1f621-5247-11ea-bd69-fac0b7afc6af" is running
Feb 18 12:11:36.097: INFO: Pod "my-hostname-basic-ccd1f621-5247-11ea-bd69-fac0b7afc6af-b2vp2" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-18 12:11:32 +0000 UTC Reason: Message:}])
Feb 18 12:11:36.097: INFO: Trying to dial the pod
Feb 18 12:11:41.103: INFO: Controller my-hostname-basic-ccd1f621-5247-11ea-bd69-fac0b7afc6af: Got expected result from replica 1 [my-hostname-basic-ccd1f621-5247-11ea-bd69-fac0b7afc6af-b2vp2]: "my-hostname-basic-ccd1f621-5247-11ea-bd69-fac0b7afc6af-b2vp2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:11:41.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4230" for this suite.
Feb 18 12:11:47.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:11:47.275: INFO: namespace replicaset-4230 deletion completed in 6.170226861s

• [SLOW TEST:15.226 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:11:47.275: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:11:47.300: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5e588f3-5247-11ea-bd69-fac0b7afc6af" in namespace "projected-8989" to be "success or failure"
Feb 18 12:11:47.309: INFO: Pod "downwardapi-volume-d5e588f3-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 9.298191ms
Feb 18 12:11:49.312: INFO: Pod "downwardapi-volume-d5e588f3-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011632467s
Feb 18 12:11:51.314: INFO: Pod "downwardapi-volume-d5e588f3-5247-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013882026s
STEP: Saw pod success
Feb 18 12:11:51.314: INFO: Pod "downwardapi-volume-d5e588f3-5247-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:11:51.316: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-d5e588f3-5247-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:11:51.334: INFO: Waiting for pod downwardapi-volume-d5e588f3-5247-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:11:51.336: INFO: Pod downwardapi-volume-d5e588f3-5247-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:11:51.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8989" for this suite.
Feb 18 12:11:57.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:11:57.507: INFO: namespace projected-8989 deletion completed in 6.166801942s

• [SLOW TEST:10.231 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:11:57.507: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-dbff2807-5247-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:11:57.564: INFO: Waiting up to 5m0s for pod "pod-configmaps-dbfff2e0-5247-11ea-bd69-fac0b7afc6af" in namespace "configmap-9112" to be "success or failure"
Feb 18 12:11:57.572: INFO: Pod "pod-configmaps-dbfff2e0-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.985739ms
Feb 18 12:11:59.574: INFO: Pod "pod-configmaps-dbfff2e0-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010206336s
Feb 18 12:12:01.576: INFO: Pod "pod-configmaps-dbfff2e0-5247-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012636993s
STEP: Saw pod success
Feb 18 12:12:01.576: INFO: Pod "pod-configmaps-dbfff2e0-5247-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:12:01.578: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-dbfff2e0-5247-11ea-bd69-fac0b7afc6af container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:12:01.593: INFO: Waiting for pod pod-configmaps-dbfff2e0-5247-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:12:01.595: INFO: Pod pod-configmaps-dbfff2e0-5247-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:12:01.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9112" for this suite.
Feb 18 12:12:07.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:12:07.765: INFO: namespace configmap-9112 deletion completed in 6.16773552s

• [SLOW TEST:10.259 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:12:07.765: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 18 12:12:07.793: INFO: Waiting up to 5m0s for pod "pod-e21c1e9b-5247-11ea-bd69-fac0b7afc6af" in namespace "emptydir-6223" to be "success or failure"
Feb 18 12:12:07.799: INFO: Pod "pod-e21c1e9b-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 5.186312ms
Feb 18 12:12:09.801: INFO: Pod "pod-e21c1e9b-5247-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00770208s
Feb 18 12:12:11.803: INFO: Pod "pod-e21c1e9b-5247-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009921431s
STEP: Saw pod success
Feb 18 12:12:11.803: INFO: Pod "pod-e21c1e9b-5247-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:12:11.805: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-e21c1e9b-5247-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:12:11.817: INFO: Waiting for pod pod-e21c1e9b-5247-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:12:11.823: INFO: Pod pod-e21c1e9b-5247-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:12:11.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6223" for this suite.
Feb 18 12:12:17.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:12:17.995: INFO: namespace emptydir-6223 deletion completed in 6.169595812s

• [SLOW TEST:10.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:12:17.995: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:12:18.015: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:12:24.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2484" for this suite.
Feb 18 12:13:02.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:13:02.356: INFO: namespace pods-2484 deletion completed in 38.168334896s

• [SLOW TEST:44.360 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:13:02.356: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-02afc7bd-5248-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 12:13:02.454: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-02b05b1e-5248-11ea-bd69-fac0b7afc6af" in namespace "projected-3500" to be "success or failure"
Feb 18 12:13:02.464: INFO: Pod "pod-projected-secrets-02b05b1e-5248-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 9.384948ms
Feb 18 12:13:04.466: INFO: Pod "pod-projected-secrets-02b05b1e-5248-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011688035s
STEP: Saw pod success
Feb 18 12:13:04.466: INFO: Pod "pod-projected-secrets-02b05b1e-5248-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:13:04.468: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-secrets-02b05b1e-5248-11ea-bd69-fac0b7afc6af container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 12:13:04.487: INFO: Waiting for pod pod-projected-secrets-02b05b1e-5248-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:13:04.489: INFO: Pod pod-projected-secrets-02b05b1e-5248-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:13:04.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3500" for this suite.
Feb 18 12:13:10.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:13:10.659: INFO: namespace projected-3500 deletion completed in 6.167335776s

• [SLOW TEST:8.303 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:13:10.659: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 18 12:13:10.690: INFO: Waiting up to 5m0s for pod "pod-07996a57-5248-11ea-bd69-fac0b7afc6af" in namespace "emptydir-2366" to be "success or failure"
Feb 18 12:13:10.708: INFO: Pod "pod-07996a57-5248-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 18.048057ms
Feb 18 12:13:12.710: INFO: Pod "pod-07996a57-5248-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020198401s
STEP: Saw pod success
Feb 18 12:13:12.711: INFO: Pod "pod-07996a57-5248-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:13:12.712: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-07996a57-5248-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:13:12.729: INFO: Waiting for pod pod-07996a57-5248-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:13:12.733: INFO: Pod pod-07996a57-5248-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:13:12.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2366" for this suite.
Feb 18 12:13:18.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:13:18.902: INFO: namespace emptydir-2366 deletion completed in 6.166606295s

• [SLOW TEST:8.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:13:18.902: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-rmll
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 12:13:18.934: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rmll" in namespace "subpath-4641" to be "success or failure"
Feb 18 12:13:18.937: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Pending", Reason="", readiness=false. Elapsed: 2.899884ms
Feb 18 12:13:20.939: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005257636s
Feb 18 12:13:22.942: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 4.007394319s
Feb 18 12:13:24.944: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 6.009628739s
Feb 18 12:13:26.946: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 8.012105775s
Feb 18 12:13:28.949: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 10.014510223s
Feb 18 12:13:30.951: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 12.016669138s
Feb 18 12:13:32.953: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 14.018928113s
Feb 18 12:13:34.955: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 16.021112899s
Feb 18 12:13:36.958: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 18.023495272s
Feb 18 12:13:38.960: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 20.025583353s
Feb 18 12:13:40.962: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Running", Reason="", readiness=true. Elapsed: 22.027859376s
Feb 18 12:13:42.964: INFO: Pod "pod-subpath-test-configmap-rmll": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.030202905s
STEP: Saw pod success
Feb 18 12:13:42.964: INFO: Pod "pod-subpath-test-configmap-rmll" satisfied condition "success or failure"
Feb 18 12:13:42.966: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-subpath-test-configmap-rmll container test-container-subpath-configmap-rmll: <nil>
STEP: delete the pod
Feb 18 12:13:42.981: INFO: Waiting for pod pod-subpath-test-configmap-rmll to disappear
Feb 18 12:13:42.983: INFO: Pod pod-subpath-test-configmap-rmll no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rmll
Feb 18 12:13:42.983: INFO: Deleting pod "pod-subpath-test-configmap-rmll" in namespace "subpath-4641"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:13:42.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4641" for this suite.
Feb 18 12:13:48.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:13:49.154: INFO: namespace subpath-4641 deletion completed in 6.166659649s

• [SLOW TEST:30.252 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:13:49.154: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Feb 18 12:13:49.181: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4077" to be "success or failure"
Feb 18 12:13:49.195: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 14.322052ms
Feb 18 12:13:51.197: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016716865s
Feb 18 12:13:53.200: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018811128s
STEP: Saw pod success
Feb 18 12:13:53.200: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 18 12:13:53.201: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 18 12:13:53.222: INFO: Waiting for pod pod-host-path-test to disappear
Feb 18 12:13:53.224: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:13:53.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4077" for this suite.
Feb 18 12:13:59.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:13:59.393: INFO: namespace hostpath-4077 deletion completed in 6.166901657s

• [SLOW TEST:10.238 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:13:59.393: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Feb 18 12:13:59.464: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:14:03.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4499" for this suite.
Feb 18 12:14:25.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:14:26.140: INFO: namespace init-container-4499 deletion completed in 22.171423727s

• [SLOW TEST:26.747 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:14:26.140: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Feb 18 12:14:30.735: INFO: Successfully updated pod "annotationupdate349dfcca-5248-11ea-bd69-fac0b7afc6af"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:14:32.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4367" for this suite.
Feb 18 12:14:54.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:14:54.927: INFO: namespace projected-4367 deletion completed in 22.171690337s

• [SLOW TEST:28.787 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:14:54.928: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:14:54.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8369" for this suite.
Feb 18 12:15:00.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:15:01.141: INFO: namespace kubelet-test-8369 deletion completed in 6.168949011s

• [SLOW TEST:6.213 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:15:01.141: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Feb 18 12:15:01.176: INFO: namespace kubectl-6812
Feb 18 12:15:01.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-6812'
Feb 18 12:15:01.545: INFO: stderr: ""
Feb 18 12:15:01.545: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 18 12:15:02.548: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 12:15:02.548: INFO: Found 0 / 1
Feb 18 12:15:03.547: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 12:15:03.547: INFO: Found 0 / 1
Feb 18 12:15:04.547: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 12:15:04.547: INFO: Found 0 / 1
Feb 18 12:15:05.547: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 12:15:05.547: INFO: Found 1 / 1
Feb 18 12:15:05.547: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 18 12:15:05.549: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 12:15:05.549: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 18 12:15:05.549: INFO: wait on redis-master startup in kubectl-6812 
Feb 18 12:15:05.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 logs redis-master-sp9ck redis-master --namespace=kubectl-6812'
Feb 18 12:15:05.618: INFO: stderr: ""
Feb 18 12:15:05.618: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Feb 12:15:04.250 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Feb 12:15:04.250 # Server started, Redis version 3.2.12\n1:M 18 Feb 12:15:04.250 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Feb 12:15:04.250 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 18 12:15:05.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6812'
Feb 18 12:15:05.692: INFO: stderr: ""
Feb 18 12:15:05.692: INFO: stdout: "service/rm2 exposed\n"
Feb 18 12:15:05.699: INFO: Service rm2 in namespace kubectl-6812 found.
STEP: exposing service
Feb 18 12:15:07.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6812'
Feb 18 12:15:07.772: INFO: stderr: ""
Feb 18 12:15:07.772: INFO: stdout: "service/rm3 exposed\n"
Feb 18 12:15:07.774: INFO: Service rm3 in namespace kubectl-6812 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:15:09.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6812" for this suite.
Feb 18 12:15:31.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:15:31.948: INFO: namespace kubectl-6812 deletion completed in 22.167700278s

• [SLOW TEST:30.806 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:15:31.948: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Feb 18 12:15:32.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 --namespace=kubectl-7247 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 18 12:15:35.145: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 18 12:15:35.145: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:15:37.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7247" for this suite.
Feb 18 12:15:45.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:15:45.321: INFO: namespace kubectl-7247 deletion completed in 8.170465896s

• [SLOW TEST:13.373 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:15:45.321: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:16:09.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-867" for this suite.
Feb 18 12:16:15.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:16:15.578: INFO: namespace namespaces-867 deletion completed in 6.166741778s
STEP: Destroying namespace "nsdeletetest-5440" for this suite.
Feb 18 12:16:15.580: INFO: Namespace nsdeletetest-5440 was already deleted
STEP: Destroying namespace "nsdeletetest-2805" for this suite.
Feb 18 12:16:21.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:16:21.747: INFO: namespace nsdeletetest-2805 deletion completed in 6.166890852s

• [SLOW TEST:36.426 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:16:21.747: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-t47f
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 12:16:21.784: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-t47f" in namespace "subpath-8521" to be "success or failure"
Feb 18 12:16:21.790: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.170379ms
Feb 18 12:16:23.793: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008740841s
Feb 18 12:16:25.795: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 4.010838945s
Feb 18 12:16:27.797: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 6.013344949s
Feb 18 12:16:29.799: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 8.015620991s
Feb 18 12:16:31.802: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 10.01795571s
Feb 18 12:16:33.804: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 12.020178777s
Feb 18 12:16:35.806: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 14.022511851s
Feb 18 12:16:37.809: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 16.02477156s
Feb 18 12:16:39.811: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 18.027140604s
Feb 18 12:16:41.813: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 20.02960556s
Feb 18 12:16:43.816: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Running", Reason="", readiness=true. Elapsed: 22.031868123s
Feb 18 12:16:45.818: INFO: Pod "pod-subpath-test-downwardapi-t47f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.034146921s
STEP: Saw pod success
Feb 18 12:16:45.818: INFO: Pod "pod-subpath-test-downwardapi-t47f" satisfied condition "success or failure"
Feb 18 12:16:45.820: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-subpath-test-downwardapi-t47f container test-container-subpath-downwardapi-t47f: <nil>
STEP: delete the pod
Feb 18 12:16:45.832: INFO: Waiting for pod pod-subpath-test-downwardapi-t47f to disappear
Feb 18 12:16:45.837: INFO: Pod pod-subpath-test-downwardapi-t47f no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-t47f
Feb 18 12:16:45.837: INFO: Deleting pod "pod-subpath-test-downwardapi-t47f" in namespace "subpath-8521"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:16:45.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8521" for this suite.
Feb 18 12:16:51.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:16:52.007: INFO: namespace subpath-8521 deletion completed in 6.166016071s

• [SLOW TEST:30.260 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:16:52.008: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:16:52.038: INFO: (0) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.450034ms)
Feb 18 12:16:52.041: INFO: (1) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.316826ms)
Feb 18 12:16:52.043: INFO: (2) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.325159ms)
Feb 18 12:16:52.047: INFO: (3) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.180297ms)
Feb 18 12:16:52.054: INFO: (4) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.220857ms)
Feb 18 12:16:52.056: INFO: (5) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.345718ms)
Feb 18 12:16:52.058: INFO: (6) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.118229ms)
Feb 18 12:16:52.060: INFO: (7) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.969147ms)
Feb 18 12:16:52.062: INFO: (8) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.824892ms)
Feb 18 12:16:52.064: INFO: (9) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.068041ms)
Feb 18 12:16:52.068: INFO: (10) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.06628ms)
Feb 18 12:16:52.070: INFO: (11) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.317236ms)
Feb 18 12:16:52.072: INFO: (12) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.013554ms)
Feb 18 12:16:52.075: INFO: (13) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.066122ms)
Feb 18 12:16:52.077: INFO: (14) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.066077ms)
Feb 18 12:16:52.079: INFO: (15) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.316808ms)
Feb 18 12:16:52.081: INFO: (16) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.108479ms)
Feb 18 12:16:52.083: INFO: (17) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.936149ms)
Feb 18 12:16:52.085: INFO: (18) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.010956ms)
Feb 18 12:16:52.087: INFO: (19) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.374735ms)
[AfterEach] version v1
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:16:52.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7728" for this suite.
Feb 18 12:16:58.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:16:58.172: INFO: namespace proxy-7728 deletion completed in 6.082914576s

• [SLOW TEST:6.165 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:16:58.172: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-218.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-218.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-218.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-218.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-218.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-218.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-218.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-218.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-218.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-218.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-218.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-218.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-218.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 88.46.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.46.88_udp@PTR;check="$$(dig +tcp +noall +answer +search 88.46.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.46.88_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-218.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-218.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-218.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-218.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-218.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-218.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-218.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-218.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-218.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-218.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-218.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-218.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-218.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 88.46.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.46.88_udp@PTR;check="$$(dig +tcp +noall +answer +search 88.46.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.46.88_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 18 12:17:12.241: INFO: Unable to read wheezy_udp@dns-test-service.dns-218.svc.cluster.local from pod dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af: the server could not find the requested resource (get pods dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af)
Feb 18 12:17:12.243: INFO: Unable to read wheezy_tcp@dns-test-service.dns-218.svc.cluster.local from pod dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af: the server could not find the requested resource (get pods dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af)
Feb 18 12:17:12.245: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-218.svc.cluster.local from pod dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af: the server could not find the requested resource (get pods dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af)
Feb 18 12:17:12.248: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-218.svc.cluster.local from pod dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af: the server could not find the requested resource (get pods dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af)
Feb 18 12:17:12.274: INFO: Unable to read jessie_udp@dns-test-service.dns-218.svc.cluster.local from pod dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af: the server could not find the requested resource (get pods dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af)
Feb 18 12:17:12.276: INFO: Unable to read jessie_tcp@dns-test-service.dns-218.svc.cluster.local from pod dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af: the server could not find the requested resource (get pods dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af)
Feb 18 12:17:12.279: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-218.svc.cluster.local from pod dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af: the server could not find the requested resource (get pods dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af)
Feb 18 12:17:12.282: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-218.svc.cluster.local from pod dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af: the server could not find the requested resource (get pods dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af)
Feb 18 12:17:12.293: INFO: Lookups using dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af failed for: [wheezy_udp@dns-test-service.dns-218.svc.cluster.local wheezy_tcp@dns-test-service.dns-218.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-218.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-218.svc.cluster.local jessie_udp@dns-test-service.dns-218.svc.cluster.local jessie_tcp@dns-test-service.dns-218.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-218.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-218.svc.cluster.local]

Feb 18 12:17:17.330: INFO: DNS probes using dns-218/dns-test-8f36b221-5248-11ea-bd69-fac0b7afc6af succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:17:17.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-218" for this suite.
Feb 18 12:17:23.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:17:23.587: INFO: namespace dns-218 deletion completed in 6.169665029s

• [SLOW TEST:25.415 seconds]
[sig-network] DNS
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:17:23.587: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Feb 18 12:17:25.631: INFO: Pod pod-hostip-9e5bbcc8-5248-11ea-bd69-fac0b7afc6af has hostIP: 10.100.10.235
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:17:25.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2768" for this suite.
Feb 18 12:17:47.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:17:47.807: INFO: namespace pods-2768 deletion completed in 22.172799409s

• [SLOW TEST:24.220 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:17:47.807: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-6833
Feb 18 12:17:49.846: INFO: Started pod liveness-exec in namespace container-probe-6833
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 12:17:49.848: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:21:50.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6833" for this suite.
Feb 18 12:21:56.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:21:56.336: INFO: namespace container-probe-6833 deletion completed in 6.16986302s

• [SLOW TEST:248.529 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:21:56.337: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Feb 18 12:21:56.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-4894'
Feb 18 12:21:56.526: INFO: stderr: ""
Feb 18 12:21:56.526: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 12:21:56.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4894'
Feb 18 12:21:56.603: INFO: stderr: ""
Feb 18 12:21:56.603: INFO: stdout: "update-demo-nautilus-mnnkc update-demo-nautilus-nwznv "
Feb 18 12:21:56.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-mnnkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:21:56.660: INFO: stderr: ""
Feb 18 12:21:56.660: INFO: stdout: ""
Feb 18 12:21:56.660: INFO: update-demo-nautilus-mnnkc is created but not running
Feb 18 12:22:01.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4894'
Feb 18 12:22:01.719: INFO: stderr: ""
Feb 18 12:22:01.719: INFO: stdout: "update-demo-nautilus-mnnkc update-demo-nautilus-nwznv "
Feb 18 12:22:01.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-mnnkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:01.778: INFO: stderr: ""
Feb 18 12:22:01.778: INFO: stdout: "true"
Feb 18 12:22:01.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-mnnkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:01.837: INFO: stderr: ""
Feb 18 12:22:01.837: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 12:22:01.837: INFO: validating pod update-demo-nautilus-mnnkc
Feb 18 12:22:01.840: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 12:22:01.840: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 12:22:01.840: INFO: update-demo-nautilus-mnnkc is verified up and running
Feb 18 12:22:01.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-nwznv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:01.898: INFO: stderr: ""
Feb 18 12:22:01.898: INFO: stdout: "true"
Feb 18 12:22:01.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-nwznv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:01.956: INFO: stderr: ""
Feb 18 12:22:01.956: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 12:22:01.956: INFO: validating pod update-demo-nautilus-nwznv
Feb 18 12:22:01.959: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 12:22:01.959: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 12:22:01.959: INFO: update-demo-nautilus-nwznv is verified up and running
STEP: scaling down the replication controller
Feb 18 12:22:01.961: INFO: scanned /root for discovery docs: <nil>
Feb 18 12:22:01.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4894'
Feb 18 12:22:03.052: INFO: stderr: ""
Feb 18 12:22:03.052: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 12:22:03.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4894'
Feb 18 12:22:03.131: INFO: stderr: ""
Feb 18 12:22:03.131: INFO: stdout: "update-demo-nautilus-mnnkc update-demo-nautilus-nwznv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 18 12:22:08.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4894'
Feb 18 12:22:08.192: INFO: stderr: ""
Feb 18 12:22:08.192: INFO: stdout: "update-demo-nautilus-mnnkc "
Feb 18 12:22:08.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-mnnkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:08.251: INFO: stderr: ""
Feb 18 12:22:08.251: INFO: stdout: "true"
Feb 18 12:22:08.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-mnnkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:08.322: INFO: stderr: ""
Feb 18 12:22:08.322: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 12:22:08.322: INFO: validating pod update-demo-nautilus-mnnkc
Feb 18 12:22:08.325: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 12:22:08.325: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 12:22:08.325: INFO: update-demo-nautilus-mnnkc is verified up and running
STEP: scaling up the replication controller
Feb 18 12:22:08.326: INFO: scanned /root for discovery docs: <nil>
Feb 18 12:22:08.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4894'
Feb 18 12:22:09.415: INFO: stderr: ""
Feb 18 12:22:09.416: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 12:22:09.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4894'
Feb 18 12:22:09.501: INFO: stderr: ""
Feb 18 12:22:09.501: INFO: stdout: "update-demo-nautilus-mnnkc update-demo-nautilus-vhmpv "
Feb 18 12:22:09.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-mnnkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:09.574: INFO: stderr: ""
Feb 18 12:22:09.574: INFO: stdout: "true"
Feb 18 12:22:09.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-mnnkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:09.650: INFO: stderr: ""
Feb 18 12:22:09.650: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 12:22:09.650: INFO: validating pod update-demo-nautilus-mnnkc
Feb 18 12:22:09.654: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 12:22:09.654: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 12:22:09.654: INFO: update-demo-nautilus-mnnkc is verified up and running
Feb 18 12:22:09.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-vhmpv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:09.723: INFO: stderr: ""
Feb 18 12:22:09.723: INFO: stdout: ""
Feb 18 12:22:09.723: INFO: update-demo-nautilus-vhmpv is created but not running
Feb 18 12:22:14.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4894'
Feb 18 12:22:14.783: INFO: stderr: ""
Feb 18 12:22:14.783: INFO: stdout: "update-demo-nautilus-mnnkc update-demo-nautilus-vhmpv "
Feb 18 12:22:14.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-mnnkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:14.841: INFO: stderr: ""
Feb 18 12:22:14.841: INFO: stdout: "true"
Feb 18 12:22:14.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-mnnkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:14.903: INFO: stderr: ""
Feb 18 12:22:14.903: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 12:22:14.903: INFO: validating pod update-demo-nautilus-mnnkc
Feb 18 12:22:14.905: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 12:22:14.905: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 12:22:14.905: INFO: update-demo-nautilus-mnnkc is verified up and running
Feb 18 12:22:14.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-vhmpv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:14.963: INFO: stderr: ""
Feb 18 12:22:14.963: INFO: stdout: "true"
Feb 18 12:22:14.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-vhmpv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4894'
Feb 18 12:22:15.022: INFO: stderr: ""
Feb 18 12:22:15.022: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 12:22:15.022: INFO: validating pod update-demo-nautilus-vhmpv
Feb 18 12:22:15.024: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 12:22:15.025: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 12:22:15.025: INFO: update-demo-nautilus-vhmpv is verified up and running
STEP: using delete to clean up resources
Feb 18 12:22:15.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-4894'
Feb 18 12:22:15.091: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:22:15.091: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 18 12:22:15.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4894'
Feb 18 12:22:15.154: INFO: stderr: "No resources found.\n"
Feb 18 12:22:15.154: INFO: stdout: ""
Feb 18 12:22:15.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -l name=update-demo --namespace=kubectl-4894 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 12:22:15.217: INFO: stderr: ""
Feb 18 12:22:15.217: INFO: stdout: "update-demo-nautilus-mnnkc\nupdate-demo-nautilus-vhmpv\n"
Feb 18 12:22:15.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4894'
Feb 18 12:22:15.794: INFO: stderr: "No resources found.\n"
Feb 18 12:22:15.794: INFO: stdout: ""
Feb 18 12:22:15.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -l name=update-demo --namespace=kubectl-4894 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 12:22:15.871: INFO: stderr: ""
Feb 18 12:22:15.871: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:22:15.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4894" for this suite.
Feb 18 12:22:37.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:22:38.047: INFO: namespace kubectl-4894 deletion completed in 22.169316234s

• [SLOW TEST:41.710 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:22:38.047: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 12:22:38.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-648'
Feb 18 12:22:38.139: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 12:22:38.140: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 18 12:22:38.149: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 18 12:22:38.153: INFO: scanned /root for discovery docs: <nil>
Feb 18 12:22:38.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-648'
Feb 18 12:22:53.884: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 18 12:22:53.884: INFO: stdout: "Created e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6\nScaling up e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 18 12:22:53.884: INFO: stdout: "Created e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6\nScaling up e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 18 12:22:53.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-648'
Feb 18 12:22:53.945: INFO: stderr: ""
Feb 18 12:22:53.945: INFO: stdout: "e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6-2k6ng "
Feb 18 12:22:53.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6-2k6ng -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-648'
Feb 18 12:22:54.004: INFO: stderr: ""
Feb 18 12:22:54.004: INFO: stdout: "true"
Feb 18 12:22:54.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6-2k6ng -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-648'
Feb 18 12:22:54.063: INFO: stderr: ""
Feb 18 12:22:54.063: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 18 12:22:54.063: INFO: e2e-test-nginx-rc-1ca5ed36406d943bdf4edc7d979d46a6-2k6ng is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1486
Feb 18 12:22:54.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete rc e2e-test-nginx-rc --namespace=kubectl-648'
Feb 18 12:22:54.135: INFO: stderr: ""
Feb 18 12:22:54.135: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:22:54.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-648" for this suite.
Feb 18 12:23:16.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:23:16.317: INFO: namespace kubectl-648 deletion completed in 22.174827665s

• [SLOW TEST:38.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:23:16.317: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 18 12:23:16.345: INFO: Waiting up to 5m0s for pod "pod-7099824a-5249-11ea-bd69-fac0b7afc6af" in namespace "emptydir-9787" to be "success or failure"
Feb 18 12:23:16.349: INFO: Pod "pod-7099824a-5249-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.255456ms
Feb 18 12:23:18.351: INFO: Pod "pod-7099824a-5249-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006450945s
Feb 18 12:23:20.354: INFO: Pod "pod-7099824a-5249-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008827755s
STEP: Saw pod success
Feb 18 12:23:20.354: INFO: Pod "pod-7099824a-5249-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:23:20.356: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-7099824a-5249-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:23:20.380: INFO: Waiting for pod pod-7099824a-5249-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:23:20.382: INFO: Pod pod-7099824a-5249-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:23:20.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9787" for this suite.
Feb 18 12:23:26.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:23:26.553: INFO: namespace emptydir-9787 deletion completed in 6.167602757s

• [SLOW TEST:10.235 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:23:26.553: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-873
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Feb 18 12:23:26.594: INFO: Found 0 stateful pods, waiting for 3
Feb 18 12:23:36.596: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 12:23:36.596: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 12:23:36.596: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 18 12:23:36.616: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 18 12:23:46.653: INFO: Updating stateful set ss2
Feb 18 12:23:46.658: INFO: Waiting for Pod statefulset-873/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Feb 18 12:23:56.747: INFO: Found 2 stateful pods, waiting for 3
Feb 18 12:24:06.749: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 12:24:06.749: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 12:24:06.749: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 18 12:24:06.768: INFO: Updating stateful set ss2
Feb 18 12:24:06.782: INFO: Waiting for Pod statefulset-873/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 18 12:24:16.801: INFO: Updating stateful set ss2
Feb 18 12:24:16.808: INFO: Waiting for StatefulSet statefulset-873/ss2 to complete update
Feb 18 12:24:16.808: INFO: Waiting for Pod statefulset-873/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 12:24:26.812: INFO: Deleting all statefulset in ns statefulset-873
Feb 18 12:24:26.813: INFO: Scaling statefulset ss2 to 0
Feb 18 12:24:46.823: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 12:24:46.824: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:24:46.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-873" for this suite.
Feb 18 12:24:52.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:24:53.005: INFO: namespace statefulset-873 deletion completed in 6.1697558s

• [SLOW TEST:86.452 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:24:53.006: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-hv4n
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 12:24:53.050: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-hv4n" in namespace "subpath-2962" to be "success or failure"
Feb 18 12:24:53.057: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Pending", Reason="", readiness=false. Elapsed: 7.332353ms
Feb 18 12:24:55.059: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009742344s
Feb 18 12:24:57.062: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 4.012360075s
Feb 18 12:24:59.064: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 6.014673489s
Feb 18 12:25:01.067: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 8.016911203s
Feb 18 12:25:03.069: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 10.019128187s
Feb 18 12:25:05.071: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 12.021583268s
Feb 18 12:25:07.074: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 14.023772786s
Feb 18 12:25:09.076: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 16.026063021s
Feb 18 12:25:11.078: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 18.02842839s
Feb 18 12:25:13.081: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 20.030877913s
Feb 18 12:25:15.083: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Running", Reason="", readiness=true. Elapsed: 22.033143948s
Feb 18 12:25:17.085: INFO: Pod "pod-subpath-test-projected-hv4n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.035360411s
STEP: Saw pod success
Feb 18 12:25:17.085: INFO: Pod "pod-subpath-test-projected-hv4n" satisfied condition "success or failure"
Feb 18 12:25:17.087: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-subpath-test-projected-hv4n container test-container-subpath-projected-hv4n: <nil>
STEP: delete the pod
Feb 18 12:25:17.111: INFO: Waiting for pod pod-subpath-test-projected-hv4n to disappear
Feb 18 12:25:17.113: INFO: Pod pod-subpath-test-projected-hv4n no longer exists
STEP: Deleting pod pod-subpath-test-projected-hv4n
Feb 18 12:25:17.113: INFO: Deleting pod "pod-subpath-test-projected-hv4n" in namespace "subpath-2962"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:25:17.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2962" for this suite.
Feb 18 12:25:23.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:25:23.293: INFO: namespace subpath-2962 deletion completed in 6.176402442s

• [SLOW TEST:30.287 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:25:23.293: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-bc47ebff-5249-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:25:23.326: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bc489b27-5249-11ea-bd69-fac0b7afc6af" in namespace "projected-2092" to be "success or failure"
Feb 18 12:25:23.333: INFO: Pod "pod-projected-configmaps-bc489b27-5249-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.037978ms
Feb 18 12:25:25.335: INFO: Pod "pod-projected-configmaps-bc489b27-5249-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009330525s
Feb 18 12:25:27.338: INFO: Pod "pod-projected-configmaps-bc489b27-5249-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011533052s
STEP: Saw pod success
Feb 18 12:25:27.338: INFO: Pod "pod-projected-configmaps-bc489b27-5249-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:25:27.340: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-configmaps-bc489b27-5249-11ea-bd69-fac0b7afc6af container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:25:27.355: INFO: Waiting for pod pod-projected-configmaps-bc489b27-5249-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:25:27.357: INFO: Pod pod-projected-configmaps-bc489b27-5249-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:25:27.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2092" for this suite.
Feb 18 12:25:33.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:25:33.528: INFO: namespace projected-2092 deletion completed in 6.168596589s

• [SLOW TEST:10.234 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:25:33.528: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-c2625e93-5249-11ea-bd69-fac0b7afc6af
STEP: Creating secret with name s-test-opt-upd-c2625eda-5249-11ea-bd69-fac0b7afc6af
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c2625e93-5249-11ea-bd69-fac0b7afc6af
STEP: Updating secret s-test-opt-upd-c2625eda-5249-11ea-bd69-fac0b7afc6af
STEP: Creating secret with name s-test-opt-create-c2625ef5-5249-11ea-bd69-fac0b7afc6af
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:27:01.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8917" for this suite.
Feb 18 12:27:23.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:27:24.042: INFO: namespace projected-8917 deletion completed in 22.168841836s

• [SLOW TEST:110.514 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:27:24.042: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:27:24.140: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0449e08d-524a-11ea-bd69-fac0b7afc6af" in namespace "downward-api-5097" to be "success or failure"
Feb 18 12:27:24.147: INFO: Pod "downwardapi-volume-0449e08d-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.23989ms
Feb 18 12:27:26.149: INFO: Pod "downwardapi-volume-0449e08d-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009592113s
STEP: Saw pod success
Feb 18 12:27:26.149: INFO: Pod "downwardapi-volume-0449e08d-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:27:26.151: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-0449e08d-524a-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:27:26.164: INFO: Waiting for pod downwardapi-volume-0449e08d-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:27:26.168: INFO: Pod downwardapi-volume-0449e08d-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:27:26.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5097" for this suite.
Feb 18 12:27:32.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:27:32.338: INFO: namespace downward-api-5097 deletion completed in 6.167739232s

• [SLOW TEST:8.296 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:27:32.339: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 18 12:27:32.417: INFO: Waiting up to 5m0s for pod "pod-093abc32-524a-11ea-bd69-fac0b7afc6af" in namespace "emptydir-9991" to be "success or failure"
Feb 18 12:27:32.425: INFO: Pod "pod-093abc32-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.100517ms
Feb 18 12:27:34.427: INFO: Pod "pod-093abc32-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009306805s
Feb 18 12:27:36.429: INFO: Pod "pod-093abc32-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01158929s
STEP: Saw pod success
Feb 18 12:27:36.429: INFO: Pod "pod-093abc32-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:27:36.431: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-093abc32-524a-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:27:36.446: INFO: Waiting for pod pod-093abc32-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:27:36.447: INFO: Pod pod-093abc32-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:27:36.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9991" for this suite.
Feb 18 12:27:42.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:27:42.618: INFO: namespace emptydir-9991 deletion completed in 6.168136732s

• [SLOW TEST:10.279 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:27:42.618: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 18 12:27:42.661: INFO: Waiting up to 5m0s for pod "pod-0f548571-524a-11ea-bd69-fac0b7afc6af" in namespace "emptydir-2637" to be "success or failure"
Feb 18 12:27:42.670: INFO: Pod "pod-0f548571-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 8.499191ms
Feb 18 12:27:44.672: INFO: Pod "pod-0f548571-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011119958s
Feb 18 12:27:46.674: INFO: Pod "pod-0f548571-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01333239s
STEP: Saw pod success
Feb 18 12:27:46.674: INFO: Pod "pod-0f548571-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:27:46.676: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-0f548571-524a-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:27:46.692: INFO: Waiting for pod pod-0f548571-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:27:46.695: INFO: Pod pod-0f548571-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:27:46.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2637" for this suite.
Feb 18 12:27:52.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:27:52.864: INFO: namespace emptydir-2637 deletion completed in 6.166975165s

• [SLOW TEST:10.247 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:27:52.864: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Feb 18 12:27:52.942: INFO: Waiting up to 5m0s for pod "client-containers-1576b6dc-524a-11ea-bd69-fac0b7afc6af" in namespace "containers-1284" to be "success or failure"
Feb 18 12:27:52.950: INFO: Pod "client-containers-1576b6dc-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.878886ms
Feb 18 12:27:54.952: INFO: Pod "client-containers-1576b6dc-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010106434s
Feb 18 12:27:56.954: INFO: Pod "client-containers-1576b6dc-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012027578s
STEP: Saw pod success
Feb 18 12:27:56.954: INFO: Pod "client-containers-1576b6dc-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:27:56.956: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod client-containers-1576b6dc-524a-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:27:56.972: INFO: Waiting for pod client-containers-1576b6dc-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:27:56.978: INFO: Pod client-containers-1576b6dc-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:27:56.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1284" for this suite.
Feb 18 12:28:02.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:28:03.154: INFO: namespace containers-1284 deletion completed in 6.169557481s

• [SLOW TEST:10.290 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:28:03.154: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:28:03.190: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 18 12:28:03.198: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:03.205: INFO: Number of nodes with available pods: 0
Feb 18 12:28:03.205: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:28:04.208: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:04.210: INFO: Number of nodes with available pods: 0
Feb 18 12:28:04.210: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:28:05.208: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:05.209: INFO: Number of nodes with available pods: 0
Feb 18 12:28:05.209: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:28:06.207: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:06.209: INFO: Number of nodes with available pods: 2
Feb 18 12:28:06.209: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 18 12:28:06.232: INFO: Wrong image for pod: daemon-set-968rl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:06.233: INFO: Wrong image for pod: daemon-set-bc845. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:06.238: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:07.241: INFO: Wrong image for pod: daemon-set-968rl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:07.241: INFO: Wrong image for pod: daemon-set-bc845. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:07.243: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:08.241: INFO: Wrong image for pod: daemon-set-968rl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:08.241: INFO: Wrong image for pod: daemon-set-bc845. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:08.243: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:09.241: INFO: Wrong image for pod: daemon-set-968rl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:09.241: INFO: Pod daemon-set-968rl is not available
Feb 18 12:28:09.241: INFO: Wrong image for pod: daemon-set-bc845. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:09.243: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:10.241: INFO: Wrong image for pod: daemon-set-bc845. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:10.241: INFO: Pod daemon-set-df5cv is not available
Feb 18 12:28:10.243: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:11.241: INFO: Wrong image for pod: daemon-set-bc845. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:11.241: INFO: Pod daemon-set-df5cv is not available
Feb 18 12:28:11.243: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:12.241: INFO: Wrong image for pod: daemon-set-bc845. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:12.243: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:13.241: INFO: Wrong image for pod: daemon-set-bc845. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Feb 18 12:28:13.241: INFO: Pod daemon-set-bc845 is not available
Feb 18 12:28:13.243: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:14.241: INFO: Pod daemon-set-rfh5j is not available
Feb 18 12:28:14.243: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 18 12:28:14.245: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:14.247: INFO: Number of nodes with available pods: 1
Feb 18 12:28:14.247: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:28:15.249: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:15.251: INFO: Number of nodes with available pods: 1
Feb 18 12:28:15.251: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:28:16.249: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:16.251: INFO: Number of nodes with available pods: 1
Feb 18 12:28:16.251: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:28:17.249: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:28:17.251: INFO: Number of nodes with available pods: 2
Feb 18 12:28:17.251: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7295, will wait for the garbage collector to delete the pods
Feb 18 12:28:17.319: INFO: Deleting DaemonSet.extensions daemon-set took: 8.447546ms
Feb 18 12:28:17.819: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.160775ms
Feb 18 12:28:23.125: INFO: Number of nodes with available pods: 0
Feb 18 12:28:23.125: INFO: Number of running nodes: 0, number of available pods: 0
Feb 18 12:28:23.127: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7295/daemonsets","resourceVersion":"8507"},"items":null}

Feb 18 12:28:23.129: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7295/pods","resourceVersion":"8507"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:28:23.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7295" for this suite.
Feb 18 12:28:29.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:28:29.305: INFO: namespace daemonsets-7295 deletion completed in 6.167734055s

• [SLOW TEST:26.151 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:28:29.305: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-2b273265-524a-11ea-bd69-fac0b7afc6af
Feb 18 12:28:29.332: INFO: Pod name my-hostname-basic-2b273265-524a-11ea-bd69-fac0b7afc6af: Found 0 pods out of 1
Feb 18 12:28:34.335: INFO: Pod name my-hostname-basic-2b273265-524a-11ea-bd69-fac0b7afc6af: Found 1 pods out of 1
Feb 18 12:28:34.335: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2b273265-524a-11ea-bd69-fac0b7afc6af" are running
Feb 18 12:28:34.336: INFO: Pod "my-hostname-basic-2b273265-524a-11ea-bd69-fac0b7afc6af-57f44" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-18 12:28:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-18 12:28:31 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-18 12:28:31 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-18 12:28:29 +0000 UTC Reason: Message:}])
Feb 18 12:28:34.336: INFO: Trying to dial the pod
Feb 18 12:28:39.342: INFO: Controller my-hostname-basic-2b273265-524a-11ea-bd69-fac0b7afc6af: Got expected result from replica 1 [my-hostname-basic-2b273265-524a-11ea-bd69-fac0b7afc6af-57f44]: "my-hostname-basic-2b273265-524a-11ea-bd69-fac0b7afc6af-57f44", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:28:39.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3399" for this suite.
Feb 18 12:28:45.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:28:45.516: INFO: namespace replication-controller-3399 deletion completed in 6.16825322s

• [SLOW TEST:16.211 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:28:45.516: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 18 12:28:45.547: INFO: Waiting up to 5m0s for pod "pod-34d132cb-524a-11ea-bd69-fac0b7afc6af" in namespace "emptydir-2585" to be "success or failure"
Feb 18 12:28:45.552: INFO: Pod "pod-34d132cb-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 5.572459ms
Feb 18 12:28:47.555: INFO: Pod "pod-34d132cb-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007851014s
STEP: Saw pod success
Feb 18 12:28:47.555: INFO: Pod "pod-34d132cb-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:28:47.557: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-34d132cb-524a-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:28:47.578: INFO: Waiting for pod pod-34d132cb-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:28:47.582: INFO: Pod pod-34d132cb-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:28:47.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2585" for this suite.
Feb 18 12:28:53.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:28:53.763: INFO: namespace emptydir-2585 deletion completed in 6.177000712s

• [SLOW TEST:8.246 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:28:53.763: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 18 12:28:57.824: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 18 12:28:57.828: INFO: Pod pod-with-poststart-http-hook still exists
Feb 18 12:28:59.828: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 18 12:28:59.831: INFO: Pod pod-with-poststart-http-hook still exists
Feb 18 12:29:01.828: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 18 12:29:01.830: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:29:01.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-616" for this suite.
Feb 18 12:29:23.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:29:24.007: INFO: namespace container-lifecycle-hook-616 deletion completed in 22.174120347s

• [SLOW TEST:30.244 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:29:24.007: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:29:24.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5218" for this suite.
Feb 18 12:29:46.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:29:46.254: INFO: namespace pods-5218 deletion completed in 22.17560489s

• [SLOW TEST:22.247 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:29:46.254: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:29:46.287: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5904f4a8-524a-11ea-bd69-fac0b7afc6af" in namespace "downward-api-565" to be "success or failure"
Feb 18 12:29:46.294: INFO: Pod "downwardapi-volume-5904f4a8-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 6.639849ms
Feb 18 12:29:48.296: INFO: Pod "downwardapi-volume-5904f4a8-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008999282s
Feb 18 12:29:50.298: INFO: Pod "downwardapi-volume-5904f4a8-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011309604s
STEP: Saw pod success
Feb 18 12:29:50.299: INFO: Pod "downwardapi-volume-5904f4a8-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:29:50.300: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-5904f4a8-524a-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:29:50.316: INFO: Waiting for pod downwardapi-volume-5904f4a8-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:29:50.318: INFO: Pod downwardapi-volume-5904f4a8-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:29:50.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-565" for this suite.
Feb 18 12:29:56.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:29:56.488: INFO: namespace downward-api-565 deletion completed in 6.167450426s

• [SLOW TEST:10.234 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:29:56.488: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Feb 18 12:29:56.513: INFO: Waiting up to 5m0s for pod "downward-api-5f1e1d5c-524a-11ea-bd69-fac0b7afc6af" in namespace "downward-api-6480" to be "success or failure"
Feb 18 12:29:56.517: INFO: Pod "downward-api-5f1e1d5c-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.947826ms
Feb 18 12:29:58.519: INFO: Pod "downward-api-5f1e1d5c-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006307232s
Feb 18 12:30:00.521: INFO: Pod "downward-api-5f1e1d5c-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008591882s
STEP: Saw pod success
Feb 18 12:30:00.521: INFO: Pod "downward-api-5f1e1d5c-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:30:00.523: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downward-api-5f1e1d5c-524a-11ea-bd69-fac0b7afc6af container dapi-container: <nil>
STEP: delete the pod
Feb 18 12:30:00.538: INFO: Waiting for pod downward-api-5f1e1d5c-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:30:00.544: INFO: Pod downward-api-5f1e1d5c-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:30:00.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6480" for this suite.
Feb 18 12:30:06.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:30:06.722: INFO: namespace downward-api-6480 deletion completed in 6.175026596s

• [SLOW TEST:10.233 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:30:06.722: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 18 12:30:06.750: INFO: Waiting up to 5m0s for pod "pod-653822bf-524a-11ea-bd69-fac0b7afc6af" in namespace "emptydir-6965" to be "success or failure"
Feb 18 12:30:06.752: INFO: Pod "pod-653822bf-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.340396ms
Feb 18 12:30:08.755: INFO: Pod "pod-653822bf-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004817673s
Feb 18 12:30:10.757: INFO: Pod "pod-653822bf-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007012502s
STEP: Saw pod success
Feb 18 12:30:10.757: INFO: Pod "pod-653822bf-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:30:10.759: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-653822bf-524a-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:30:10.773: INFO: Waiting for pod pod-653822bf-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:30:10.776: INFO: Pod pod-653822bf-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:30:10.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6965" for this suite.
Feb 18 12:30:16.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:30:16.949: INFO: namespace emptydir-6965 deletion completed in 6.170991969s

• [SLOW TEST:10.228 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:30:16.950: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6399
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6399
STEP: Creating statefulset with conflicting port in namespace statefulset-6399
STEP: Waiting until pod test-pod will start running in namespace statefulset-6399
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6399
Feb 18 12:30:21.022: INFO: Observed stateful pod in namespace: statefulset-6399, name: ss-0, uid: 6d82e598-524a-11ea-b701-0ae3ad6fc27e, status phase: Pending. Waiting for statefulset controller to delete.
Feb 18 12:30:21.200: INFO: Observed stateful pod in namespace: statefulset-6399, name: ss-0, uid: 6d82e598-524a-11ea-b701-0ae3ad6fc27e, status phase: Failed. Waiting for statefulset controller to delete.
Feb 18 12:30:21.204: INFO: Observed stateful pod in namespace: statefulset-6399, name: ss-0, uid: 6d82e598-524a-11ea-b701-0ae3ad6fc27e, status phase: Failed. Waiting for statefulset controller to delete.
Feb 18 12:30:21.208: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6399
STEP: Removing pod with conflicting port in namespace statefulset-6399
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6399 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 12:30:25.238: INFO: Deleting all statefulset in ns statefulset-6399
Feb 18 12:30:25.241: INFO: Scaling statefulset ss to 0
Feb 18 12:30:35.251: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 12:30:35.253: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:30:35.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6399" for this suite.
Feb 18 12:30:41.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:30:41.437: INFO: namespace statefulset-6399 deletion completed in 6.173056991s

• [SLOW TEST:24.487 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:30:41.437: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 18 12:30:41.512: INFO: Waiting up to 5m0s for pod "pod-79f08823-524a-11ea-bd69-fac0b7afc6af" in namespace "emptydir-8695" to be "success or failure"
Feb 18 12:30:41.517: INFO: Pod "pod-79f08823-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.456595ms
Feb 18 12:30:43.521: INFO: Pod "pod-79f08823-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009133524s
Feb 18 12:30:45.524: INFO: Pod "pod-79f08823-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012086917s
STEP: Saw pod success
Feb 18 12:30:45.524: INFO: Pod "pod-79f08823-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:30:45.526: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-79f08823-524a-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:30:45.547: INFO: Waiting for pod pod-79f08823-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:30:45.549: INFO: Pod pod-79f08823-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:30:45.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8695" for this suite.
Feb 18 12:30:51.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:30:51.729: INFO: namespace emptydir-8695 deletion completed in 6.175640449s

• [SLOW TEST:10.292 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:30:51.729: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:30:51.754: INFO: Waiting up to 5m0s for pod "downwardapi-volume-800b611a-524a-11ea-bd69-fac0b7afc6af" in namespace "downward-api-3328" to be "success or failure"
Feb 18 12:30:51.766: INFO: Pod "downwardapi-volume-800b611a-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 11.955888ms
Feb 18 12:30:53.769: INFO: Pod "downwardapi-volume-800b611a-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01434954s
STEP: Saw pod success
Feb 18 12:30:53.769: INFO: Pod "downwardapi-volume-800b611a-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:30:53.770: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-800b611a-524a-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:30:53.790: INFO: Waiting for pod downwardapi-volume-800b611a-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:30:53.792: INFO: Pod downwardapi-volume-800b611a-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:30:53.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3328" for this suite.
Feb 18 12:30:59.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:30:59.961: INFO: namespace downward-api-3328 deletion completed in 6.167623075s

• [SLOW TEST:8.233 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:30:59.961: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-84f3bc36-524a-11ea-bd69-fac0b7afc6af
STEP: Creating configMap with name cm-test-opt-upd-84f3bc75-524a-11ea-bd69-fac0b7afc6af
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-84f3bc36-524a-11ea-bd69-fac0b7afc6af
STEP: Updating configmap cm-test-opt-upd-84f3bc75-524a-11ea-bd69-fac0b7afc6af
STEP: Creating configMap with name cm-test-opt-create-84f3bcb9-524a-11ea-bd69-fac0b7afc6af
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:31:04.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9474" for this suite.
Feb 18 12:31:26.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:31:26.214: INFO: namespace configmap-9474 deletion completed in 22.170392934s

• [SLOW TEST:26.253 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:31:26.214: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:31:26.240: INFO: Waiting up to 5m0s for pod "downwardapi-volume-949938a6-524a-11ea-bd69-fac0b7afc6af" in namespace "projected-8527" to be "success or failure"
Feb 18 12:31:26.247: INFO: Pod "downwardapi-volume-949938a6-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.472855ms
Feb 18 12:31:28.250: INFO: Pod "downwardapi-volume-949938a6-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009693382s
Feb 18 12:31:30.252: INFO: Pod "downwardapi-volume-949938a6-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011818603s
STEP: Saw pod success
Feb 18 12:31:30.252: INFO: Pod "downwardapi-volume-949938a6-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:31:30.253: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-949938a6-524a-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:31:30.270: INFO: Waiting for pod downwardapi-volume-949938a6-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:31:30.271: INFO: Pod downwardapi-volume-949938a6-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:31:30.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8527" for this suite.
Feb 18 12:31:36.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:31:36.440: INFO: namespace projected-8527 deletion completed in 6.166804877s

• [SLOW TEST:10.225 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:31:36.440: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-8425
Feb 18 12:31:40.471: INFO: Started pod liveness-exec in namespace container-probe-8425
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 12:31:40.473: INFO: Initial restart count of pod liveness-exec is 0
Feb 18 12:32:32.537: INFO: Restart count of pod container-probe-8425/liveness-exec is now 1 (52.063955737s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:32:32.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8425" for this suite.
Feb 18 12:32:38.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:32:38.720: INFO: namespace container-probe-8425 deletion completed in 6.170084274s

• [SLOW TEST:62.280 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:32:38.720: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-9039/secret-test-bfd87327-524a-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 12:32:38.807: INFO: Waiting up to 5m0s for pod "pod-configmaps-bfd8c876-524a-11ea-bd69-fac0b7afc6af" in namespace "secrets-9039" to be "success or failure"
Feb 18 12:32:38.814: INFO: Pod "pod-configmaps-bfd8c876-524a-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.238631ms
Feb 18 12:32:40.817: INFO: Pod "pod-configmaps-bfd8c876-524a-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009608602s
STEP: Saw pod success
Feb 18 12:32:40.817: INFO: Pod "pod-configmaps-bfd8c876-524a-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:32:40.818: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-bfd8c876-524a-11ea-bd69-fac0b7afc6af container env-test: <nil>
STEP: delete the pod
Feb 18 12:32:40.839: INFO: Waiting for pod pod-configmaps-bfd8c876-524a-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:32:40.841: INFO: Pod pod-configmaps-bfd8c876-524a-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:32:40.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9039" for this suite.
Feb 18 12:32:46.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:32:47.019: INFO: namespace secrets-9039 deletion completed in 6.17516107s

• [SLOW TEST:8.299 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:32:47.019: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 18 12:32:47.039: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 18 12:32:47.043: INFO: Waiting for terminating namespaces to be deleted...
Feb 18 12:32:47.047: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-116.eu-west-1.compute.internal before test
Feb 18 12:32:47.054: INFO: coredns-6dcc67dcbc-kzd86 from kube-system started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container coredns ready: true, restart count 0
Feb 18 12:32:47.054: INFO: minio-setup-b9gv4 from kube-system started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container mc ready: false, restart count 4
Feb 18 12:32:47.054: INFO: elasticsearch-0 from logging started at 2020-02-18 12:05:24 +0000 UTC (2 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container elasticsearch ready: true, restart count 0
Feb 18 12:32:47.054: INFO: 	Container exporter ready: true, restart count 0
Feb 18 12:32:47.054: INFO: prometheus-k8s-0 from monitoring started at 2020-02-18 12:06:25 +0000 UTC (3 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container prometheus ready: true, restart count 1
Feb 18 12:32:47.054: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb 18 12:32:47.054: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb 18 12:32:47.054: INFO: fluentd-cfbcp from logging started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container fluentd ready: true, restart count 0
Feb 18 12:32:47.054: INFO: goldpinger-mpmjx from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container goldpinger ready: true, restart count 0
Feb 18 12:32:47.054: INFO: nginx-ingress-controller-bzkzv from ingress-nginx started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 18 12:32:47.054: INFO: calico-node-5nng8 from kube-system started at 2020-02-18 12:04:31 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container calico-node ready: true, restart count 0
Feb 18 12:32:47.054: INFO: node-exporter-phhnx from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container node-exporter ready: true, restart count 0
Feb 18 12:32:47.054: INFO: velero-restic-76fnt from kube-system started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container restic ready: true, restart count 0
Feb 18 12:32:47.054: INFO: sonobuoy-systemd-logs-daemon-set-31cf4124bed54e00-jh6ql from sonobuoy started at 2020-02-18 12:09:27 +0000 UTC (2 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 12:32:47.054: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 18 12:32:47.054: INFO: kube-proxy-spwpp from kube-system started at 2020-02-18 11:58:33 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.054: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 18 12:32:47.054: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-235.eu-west-1.compute.internal before test
Feb 18 12:32:47.061: INFO: velero-restic-bq46s from kube-system started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container restic ready: true, restart count 0
Feb 18 12:32:47.061: INFO: kibana-6f49c4b465-vql5n from logging started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container kibana ready: true, restart count 0
Feb 18 12:32:47.061: INFO: minio-0 from kube-system started at 2020-02-18 12:06:16 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container minio ready: true, restart count 0
Feb 18 12:32:47.061: INFO: sonobuoy-systemd-logs-daemon-set-31cf4124bed54e00-qvtk7 from sonobuoy started at 2020-02-18 12:09:27 +0000 UTC (2 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 12:32:47.061: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 18 12:32:47.061: INFO: grafana-68f989d655-kcwx2 from monitoring started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container grafana ready: true, restart count 0
Feb 18 12:32:47.061: INFO: cert-manager-cainjector-78dcdf7fd7-fpcfb from cert-manager started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container cainjector ready: true, restart count 0
Feb 18 12:32:47.061: INFO: cerebro-7b55c4d445-2zks6 from logging started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container cerebro ready: true, restart count 0
Feb 18 12:32:47.061: INFO: kube-state-metrics-5c9968c7dd-q9xj7 from monitoring started at 2020-02-18 12:06:32 +0000 UTC (2 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 18 12:32:47.061: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 18 12:32:47.061: INFO: kube-proxy-gwwx8 from kube-system started at 2020-02-18 11:58:33 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 18 12:32:47.061: INFO: coredns-6dcc67dcbc-w68cb from kube-system started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container coredns ready: true, restart count 0
Feb 18 12:32:47.061: INFO: cert-manager-6c8d45976-vwf68 from cert-manager started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container cert-manager ready: true, restart count 0
Feb 18 12:32:47.061: INFO: calico-node-2clft from kube-system started at 2020-02-18 12:04:31 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container calico-node ready: true, restart count 0
Feb 18 12:32:47.061: INFO: node-exporter-8wxrs from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container node-exporter ready: true, restart count 0
Feb 18 12:32:47.061: INFO: velero-5b65f87655-pngzh from kube-system started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container velero ready: true, restart count 0
Feb 18 12:32:47.061: INFO: fluentd-wcktw from logging started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container fluentd ready: true, restart count 0
Feb 18 12:32:47.061: INFO: prometheus-operator-85d4fd776c-zc59s from monitoring started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb 18 12:32:47.061: INFO: sonobuoy from sonobuoy started at 2020-02-18 12:09:21 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 18 12:32:47.061: INFO: forecastle-788c565ff4-4k25g from ingress-nginx started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container forecastle ready: true, restart count 0
Feb 18 12:32:47.061: INFO: nginx-ingress-controller-v98c7 from ingress-nginx started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 18 12:32:47.061: INFO: local-path-provisioner-74c64c9987-kxrk8 from local-path-storage started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container local-path-provisioner ready: true, restart count 0
Feb 18 12:32:47.061: INFO: calico-kube-controllers-784774949-2b5pl from kube-system started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 18 12:32:47.061: INFO: goldpinger-wm8hn from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container goldpinger ready: true, restart count 0
Feb 18 12:32:47.061: INFO: cert-manager-webhook-bf467d894-vxrds from cert-manager started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container webhook ready: true, restart count 0
Feb 18 12:32:47.061: INFO: sonobuoy-e2e-job-044c93865a804752 from sonobuoy started at 2020-02-18 12:09:27 +0000 UTC (2 container statuses recorded)
Feb 18 12:32:47.061: INFO: 	Container e2e ready: true, restart count 0
Feb 18 12:32:47.061: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f47f2541d07b0a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:32:48.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5966" for this suite.
Feb 18 12:32:54.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:32:54.256: INFO: namespace sched-pred-5966 deletion completed in 6.174128218s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.237 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:32:54.256: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:32:56.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1750" for this suite.
Feb 18 12:33:02.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:33:02.540: INFO: namespace emptydir-wrapper-1750 deletion completed in 6.167690889s

• [SLOW TEST:8.284 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:33:02.540: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:33:06.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6741" for this suite.
Feb 18 12:34:00.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:34:00.805: INFO: namespace kubelet-test-6741 deletion completed in 54.175772201s

• [SLOW TEST:58.265 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:34:00.806: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-f0c41cd5-524a-11ea-bd69-fac0b7afc6af
STEP: Creating configMap with name cm-test-opt-upd-f0c41d12-524a-11ea-bd69-fac0b7afc6af
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f0c41cd5-524a-11ea-bd69-fac0b7afc6af
STEP: Updating configmap cm-test-opt-upd-f0c41d12-524a-11ea-bd69-fac0b7afc6af
STEP: Creating configMap with name cm-test-opt-create-f0c41d2d-524a-11ea-bd69-fac0b7afc6af
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:34:04.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-725" for this suite.
Feb 18 12:34:26.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:34:27.110: INFO: namespace projected-725 deletion completed in 22.175080185s

• [SLOW TEST:26.304 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:34:27.110: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-0076376e-524b-11ea-bd69-fac0b7afc6af
STEP: Creating secret with name secret-projected-all-test-volume-0076375e-524b-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 18 12:34:27.211: INFO: Waiting up to 5m0s for pod "projected-volume-00763737-524b-11ea-bd69-fac0b7afc6af" in namespace "projected-2318" to be "success or failure"
Feb 18 12:34:27.220: INFO: Pod "projected-volume-00763737-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 8.602436ms
Feb 18 12:34:29.222: INFO: Pod "projected-volume-00763737-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010788931s
Feb 18 12:34:31.224: INFO: Pod "projected-volume-00763737-524b-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013096968s
STEP: Saw pod success
Feb 18 12:34:31.224: INFO: Pod "projected-volume-00763737-524b-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:34:31.226: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod projected-volume-00763737-524b-11ea-bd69-fac0b7afc6af container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 18 12:34:31.242: INFO: Waiting for pod projected-volume-00763737-524b-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:34:31.245: INFO: Pod projected-volume-00763737-524b-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:34:31.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2318" for this suite.
Feb 18 12:34:37.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:34:37.417: INFO: namespace projected-2318 deletion completed in 6.16940338s

• [SLOW TEST:10.307 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:34:37.417: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:34:37.442: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0690617a-524b-11ea-bd69-fac0b7afc6af" in namespace "projected-295" to be "success or failure"
Feb 18 12:34:37.449: INFO: Pod "downwardapi-volume-0690617a-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 6.820269ms
Feb 18 12:34:39.451: INFO: Pod "downwardapi-volume-0690617a-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009112478s
Feb 18 12:34:41.453: INFO: Pod "downwardapi-volume-0690617a-524b-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011343724s
STEP: Saw pod success
Feb 18 12:34:41.453: INFO: Pod "downwardapi-volume-0690617a-524b-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:34:41.455: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-0690617a-524b-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:34:41.470: INFO: Waiting for pod downwardapi-volume-0690617a-524b-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:34:41.472: INFO: Pod downwardapi-volume-0690617a-524b-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:34:41.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-295" for this suite.
Feb 18 12:34:47.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:34:47.642: INFO: namespace projected-295 deletion completed in 6.168382531s

• [SLOW TEST:10.225 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:34:47.642: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-6454
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 18 12:34:47.673: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 18 12:35:11.776: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.26.150 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6454 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 12:35:11.776: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 12:35:12.902: INFO: Found all expected endpoints: [netserver-0]
Feb 18 12:35:12.905: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.102.245 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6454 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 12:35:12.905: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 12:35:14.043: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:35:14.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6454" for this suite.
Feb 18 12:35:36.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:35:36.217: INFO: namespace pod-network-test-6454 deletion completed in 22.172109643s

• [SLOW TEST:48.575 seconds]
[sig-network] Networking
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:35:36.217: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 18 12:35:36.242: INFO: Waiting up to 5m0s for pod "pod-299ca747-524b-11ea-bd69-fac0b7afc6af" in namespace "emptydir-9624" to be "success or failure"
Feb 18 12:35:36.250: INFO: Pod "pod-299ca747-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 8.765651ms
Feb 18 12:35:38.253: INFO: Pod "pod-299ca747-524b-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01098313s
STEP: Saw pod success
Feb 18 12:35:38.253: INFO: Pod "pod-299ca747-524b-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:35:38.254: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-299ca747-524b-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:35:38.269: INFO: Waiting for pod pod-299ca747-524b-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:35:38.270: INFO: Pod pod-299ca747-524b-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:35:38.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9624" for this suite.
Feb 18 12:35:44.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:35:44.437: INFO: namespace emptydir-9624 deletion completed in 6.165531369s

• [SLOW TEST:8.220 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:35:44.438: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-2e8b4c34-524b-11ea-bd69-fac0b7afc6af
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:35:46.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-468" for this suite.
Feb 18 12:36:08.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:36:08.720: INFO: namespace configmap-468 deletion completed in 22.166590419s

• [SLOW TEST:24.282 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:36:08.720: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 18 12:36:08.741: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 18 12:36:08.745: INFO: Waiting for terminating namespaces to be deleted...
Feb 18 12:36:08.746: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-116.eu-west-1.compute.internal before test
Feb 18 12:36:08.751: INFO: velero-restic-76fnt from kube-system started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container restic ready: true, restart count 0
Feb 18 12:36:08.751: INFO: sonobuoy-systemd-logs-daemon-set-31cf4124bed54e00-jh6ql from sonobuoy started at 2020-02-18 12:09:27 +0000 UTC (2 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 12:36:08.751: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 18 12:36:08.751: INFO: kube-proxy-spwpp from kube-system started at 2020-02-18 11:58:33 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 18 12:36:08.751: INFO: coredns-6dcc67dcbc-kzd86 from kube-system started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container coredns ready: true, restart count 0
Feb 18 12:36:08.751: INFO: minio-setup-b9gv4 from kube-system started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container mc ready: false, restart count 4
Feb 18 12:36:08.751: INFO: elasticsearch-0 from logging started at 2020-02-18 12:05:24 +0000 UTC (2 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container elasticsearch ready: true, restart count 0
Feb 18 12:36:08.751: INFO: 	Container exporter ready: true, restart count 0
Feb 18 12:36:08.751: INFO: prometheus-k8s-0 from monitoring started at 2020-02-18 12:06:25 +0000 UTC (3 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container prometheus ready: true, restart count 1
Feb 18 12:36:08.751: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb 18 12:36:08.751: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb 18 12:36:08.751: INFO: fluentd-cfbcp from logging started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container fluentd ready: true, restart count 0
Feb 18 12:36:08.751: INFO: goldpinger-mpmjx from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container goldpinger ready: true, restart count 0
Feb 18 12:36:08.751: INFO: nginx-ingress-controller-bzkzv from ingress-nginx started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 18 12:36:08.751: INFO: calico-node-5nng8 from kube-system started at 2020-02-18 12:04:31 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container calico-node ready: true, restart count 0
Feb 18 12:36:08.751: INFO: node-exporter-phhnx from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.751: INFO: 	Container node-exporter ready: true, restart count 0
Feb 18 12:36:08.751: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-235.eu-west-1.compute.internal before test
Feb 18 12:36:08.759: INFO: kube-state-metrics-5c9968c7dd-q9xj7 from monitoring started at 2020-02-18 12:06:32 +0000 UTC (2 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 18 12:36:08.759: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 18 12:36:08.759: INFO: kube-proxy-gwwx8 from kube-system started at 2020-02-18 11:58:33 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 18 12:36:08.759: INFO: coredns-6dcc67dcbc-w68cb from kube-system started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container coredns ready: true, restart count 0
Feb 18 12:36:08.759: INFO: calico-node-2clft from kube-system started at 2020-02-18 12:04:31 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container calico-node ready: true, restart count 0
Feb 18 12:36:08.759: INFO: node-exporter-8wxrs from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container node-exporter ready: true, restart count 0
Feb 18 12:36:08.759: INFO: velero-5b65f87655-pngzh from kube-system started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container velero ready: true, restart count 0
Feb 18 12:36:08.759: INFO: cert-manager-6c8d45976-vwf68 from cert-manager started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container cert-manager ready: true, restart count 0
Feb 18 12:36:08.759: INFO: fluentd-wcktw from logging started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container fluentd ready: true, restart count 0
Feb 18 12:36:08.759: INFO: prometheus-operator-85d4fd776c-zc59s from monitoring started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb 18 12:36:08.759: INFO: sonobuoy from sonobuoy started at 2020-02-18 12:09:21 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 18 12:36:08.759: INFO: nginx-ingress-controller-v98c7 from ingress-nginx started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 18 12:36:08.759: INFO: local-path-provisioner-74c64c9987-kxrk8 from local-path-storage started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container local-path-provisioner ready: true, restart count 0
Feb 18 12:36:08.759: INFO: calico-kube-controllers-784774949-2b5pl from kube-system started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 18 12:36:08.759: INFO: forecastle-788c565ff4-4k25g from ingress-nginx started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container forecastle ready: true, restart count 0
Feb 18 12:36:08.759: INFO: goldpinger-wm8hn from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container goldpinger ready: true, restart count 0
Feb 18 12:36:08.759: INFO: cert-manager-webhook-bf467d894-vxrds from cert-manager started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container webhook ready: true, restart count 0
Feb 18 12:36:08.759: INFO: sonobuoy-e2e-job-044c93865a804752 from sonobuoy started at 2020-02-18 12:09:27 +0000 UTC (2 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container e2e ready: true, restart count 0
Feb 18 12:36:08.759: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 12:36:08.759: INFO: velero-restic-bq46s from kube-system started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container restic ready: true, restart count 0
Feb 18 12:36:08.759: INFO: kibana-6f49c4b465-vql5n from logging started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container kibana ready: true, restart count 0
Feb 18 12:36:08.759: INFO: grafana-68f989d655-kcwx2 from monitoring started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container grafana ready: true, restart count 0
Feb 18 12:36:08.759: INFO: cert-manager-cainjector-78dcdf7fd7-fpcfb from cert-manager started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container cainjector ready: true, restart count 0
Feb 18 12:36:08.759: INFO: cerebro-7b55c4d445-2zks6 from logging started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container cerebro ready: true, restart count 0
Feb 18 12:36:08.759: INFO: minio-0 from kube-system started at 2020-02-18 12:06:16 +0000 UTC (1 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container minio ready: true, restart count 0
Feb 18 12:36:08.759: INFO: sonobuoy-systemd-logs-daemon-set-31cf4124bed54e00-qvtk7 from sonobuoy started at 2020-02-18 12:09:27 +0000 UTC (2 container statuses recorded)
Feb 18 12:36:08.759: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 12:36:08.759: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node ip-10-100-10-116.eu-west-1.compute.internal
STEP: verifying the node has the label node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod cert-manager-6c8d45976-vwf68 requesting resource cpu=50m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod cert-manager-cainjector-78dcdf7fd7-fpcfb requesting resource cpu=50m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod cert-manager-webhook-bf467d894-vxrds requesting resource cpu=50m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod forecastle-788c565ff4-4k25g requesting resource cpu=50m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod nginx-ingress-controller-bzkzv requesting resource cpu=0m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod nginx-ingress-controller-v98c7 requesting resource cpu=0m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod calico-kube-controllers-784774949-2b5pl requesting resource cpu=0m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod calico-node-2clft requesting resource cpu=250m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod calico-node-5nng8 requesting resource cpu=250m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod coredns-6dcc67dcbc-kzd86 requesting resource cpu=100m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod coredns-6dcc67dcbc-w68cb requesting resource cpu=100m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod kube-proxy-gwwx8 requesting resource cpu=0m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod kube-proxy-spwpp requesting resource cpu=0m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod minio-0 requesting resource cpu=0m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod velero-5b65f87655-pngzh requesting resource cpu=100m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod velero-restic-76fnt requesting resource cpu=100m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod velero-restic-bq46s requesting resource cpu=100m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod local-path-provisioner-74c64c9987-kxrk8 requesting resource cpu=0m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod cerebro-7b55c4d445-2zks6 requesting resource cpu=500m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod elasticsearch-0 requesting resource cpu=1600m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod fluentd-cfbcp requesting resource cpu=300m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod fluentd-wcktw requesting resource cpu=300m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod kibana-6f49c4b465-vql5n requesting resource cpu=100m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod goldpinger-mpmjx requesting resource cpu=1m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod goldpinger-wm8hn requesting resource cpu=1m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod grafana-68f989d655-kcwx2 requesting resource cpu=100m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod kube-state-metrics-5c9968c7dd-q9xj7 requesting resource cpu=116m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod node-exporter-8wxrs requesting resource cpu=102m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod node-exporter-phhnx requesting resource cpu=102m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod prometheus-k8s-0 requesting resource cpu=700m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod prometheus-operator-85d4fd776c-zc59s requesting resource cpu=100m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod sonobuoy-e2e-job-044c93865a804752 requesting resource cpu=0m on Node ip-10-100-10-235.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod sonobuoy-systemd-logs-daemon-set-31cf4124bed54e00-jh6ql requesting resource cpu=0m on Node ip-10-100-10-116.eu-west-1.compute.internal
Feb 18 12:36:08.791: INFO: Pod sonobuoy-systemd-logs-daemon-set-31cf4124bed54e00-qvtk7 requesting resource cpu=0m on Node ip-10-100-10-235.eu-west-1.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d03f0fc-524b-11ea-bd69-fac0b7afc6af.15f47f5438ff541d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3491/filler-pod-3d03f0fc-524b-11ea-bd69-fac0b7afc6af to ip-10-100-10-116.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d03f0fc-524b-11ea-bd69-fac0b7afc6af.15f47f5477dcb938], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d03f0fc-524b-11ea-bd69-fac0b7afc6af.15f47f547dab97ff], Reason = [Created], Message = [Created container filler-pod-3d03f0fc-524b-11ea-bd69-fac0b7afc6af]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d03f0fc-524b-11ea-bd69-fac0b7afc6af.15f47f54895c659a], Reason = [Started], Message = [Started container filler-pod-3d03f0fc-524b-11ea-bd69-fac0b7afc6af]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d04aeaf-524b-11ea-bd69-fac0b7afc6af.15f47f5439c6757a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3491/filler-pod-3d04aeaf-524b-11ea-bd69-fac0b7afc6af to ip-10-100-10-235.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d04aeaf-524b-11ea-bd69-fac0b7afc6af.15f47f54758599b7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d04aeaf-524b-11ea-bd69-fac0b7afc6af.15f47f547b020a2a], Reason = [Created], Message = [Created container filler-pod-3d04aeaf-524b-11ea-bd69-fac0b7afc6af]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d04aeaf-524b-11ea-bd69-fac0b7afc6af.15f47f5485af4da9], Reason = [Started], Message = [Started container filler-pod-3d04aeaf-524b-11ea-bd69-fac0b7afc6af]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f47f55290533ca], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node ip-10-100-10-116.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-100-10-235.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:36:13.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3491" for this suite.
Feb 18 12:36:19.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:36:20.043: INFO: namespace sched-pred-3491 deletion completed in 6.182349868s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.323 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:36:20.043: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Feb 18 12:36:20.124: INFO: Waiting up to 5m0s for pod "client-containers-43c41ae3-524b-11ea-bd69-fac0b7afc6af" in namespace "containers-6454" to be "success or failure"
Feb 18 12:36:20.129: INFO: Pod "client-containers-43c41ae3-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.271135ms
Feb 18 12:36:22.131: INFO: Pod "client-containers-43c41ae3-524b-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0065038s
STEP: Saw pod success
Feb 18 12:36:22.131: INFO: Pod "client-containers-43c41ae3-524b-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:36:22.134: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod client-containers-43c41ae3-524b-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:36:22.160: INFO: Waiting for pod client-containers-43c41ae3-524b-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:36:22.162: INFO: Pod client-containers-43c41ae3-524b-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:36:22.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6454" for this suite.
Feb 18 12:36:28.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:36:28.330: INFO: namespace containers-6454 deletion completed in 6.166389107s

• [SLOW TEST:8.287 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:36:28.330: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Feb 18 12:36:28.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 cluster-info'
Feb 18 12:36:28.644: INFO: stderr: ""
Feb 18 12:36:28.644: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:36:28.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-279" for this suite.
Feb 18 12:36:34.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:36:34.812: INFO: namespace kubectl-279 deletion completed in 6.166078742s

• [SLOW TEST:6.482 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:36:34.812: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0218 12:36:44.986926      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 12:36:44.986: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:36:44.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8634" for this suite.
Feb 18 12:36:50.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:36:51.158: INFO: namespace gc-8634 deletion completed in 6.170034664s

• [SLOW TEST:16.346 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:36:51.158: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-5647ef15-524b-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:36:51.188: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-56484b39-524b-11ea-bd69-fac0b7afc6af" in namespace "projected-7749" to be "success or failure"
Feb 18 12:36:51.195: INFO: Pod "pod-projected-configmaps-56484b39-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.296858ms
Feb 18 12:36:53.198: INFO: Pod "pod-projected-configmaps-56484b39-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010021855s
Feb 18 12:36:55.200: INFO: Pod "pod-projected-configmaps-56484b39-524b-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012561583s
STEP: Saw pod success
Feb 18 12:36:55.200: INFO: Pod "pod-projected-configmaps-56484b39-524b-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:36:55.202: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-configmaps-56484b39-524b-11ea-bd69-fac0b7afc6af container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:36:55.218: INFO: Waiting for pod pod-projected-configmaps-56484b39-524b-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:36:55.219: INFO: Pod pod-projected-configmaps-56484b39-524b-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:36:55.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7749" for this suite.
Feb 18 12:37:01.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:37:01.390: INFO: namespace projected-7749 deletion completed in 6.168871714s

• [SLOW TEST:10.232 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:37:01.390: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Feb 18 12:37:01.415: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-639612178 proxy --unix-socket=/tmp/kubectl-proxy-unix096255305/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:37:01.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9972" for this suite.
Feb 18 12:37:07.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:37:07.635: INFO: namespace kubectl-9972 deletion completed in 6.165904242s

• [SLOW TEST:6.245 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:37:07.636: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:37:07.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-601a4742-524b-11ea-bd69-fac0b7afc6af" in namespace "downward-api-5956" to be "success or failure"
Feb 18 12:37:07.666: INFO: Pod "downwardapi-volume-601a4742-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.866291ms
Feb 18 12:37:09.668: INFO: Pod "downwardapi-volume-601a4742-524b-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005785952s
STEP: Saw pod success
Feb 18 12:37:09.668: INFO: Pod "downwardapi-volume-601a4742-524b-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:37:09.669: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-601a4742-524b-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:37:09.685: INFO: Waiting for pod downwardapi-volume-601a4742-524b-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:37:09.687: INFO: Pod downwardapi-volume-601a4742-524b-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:37:09.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5956" for this suite.
Feb 18 12:37:15.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:37:15.858: INFO: namespace downward-api-5956 deletion completed in 6.168813523s

• [SLOW TEST:8.222 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:37:15.858: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Feb 18 12:37:15.884: INFO: Waiting up to 5m0s for pod "downward-api-65008423-524b-11ea-bd69-fac0b7afc6af" in namespace "downward-api-2007" to be "success or failure"
Feb 18 12:37:15.892: INFO: Pod "downward-api-65008423-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.946566ms
Feb 18 12:37:17.896: INFO: Pod "downward-api-65008423-524b-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01128458s
STEP: Saw pod success
Feb 18 12:37:17.896: INFO: Pod "downward-api-65008423-524b-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:37:17.897: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downward-api-65008423-524b-11ea-bd69-fac0b7afc6af container dapi-container: <nil>
STEP: delete the pod
Feb 18 12:37:17.913: INFO: Waiting for pod downward-api-65008423-524b-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:37:17.916: INFO: Pod downward-api-65008423-524b-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:37:17.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2007" for this suite.
Feb 18 12:37:23.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:37:24.085: INFO: namespace downward-api-2007 deletion completed in 6.167288869s

• [SLOW TEST:8.227 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:37:24.085: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-69e94b48-524b-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:37:24.128: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-69e9c907-524b-11ea-bd69-fac0b7afc6af" in namespace "projected-8526" to be "success or failure"
Feb 18 12:37:24.131: INFO: Pod "pod-projected-configmaps-69e9c907-524b-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.447957ms
Feb 18 12:37:26.134: INFO: Pod "pod-projected-configmaps-69e9c907-524b-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005698165s
STEP: Saw pod success
Feb 18 12:37:26.134: INFO: Pod "pod-projected-configmaps-69e9c907-524b-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:37:26.135: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-configmaps-69e9c907-524b-11ea-bd69-fac0b7afc6af container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:37:26.152: INFO: Waiting for pod pod-projected-configmaps-69e9c907-524b-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:37:26.154: INFO: Pod pod-projected-configmaps-69e9c907-524b-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:37:26.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8526" for this suite.
Feb 18 12:37:32.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:37:32.325: INFO: namespace projected-8526 deletion completed in 6.169308854s

• [SLOW TEST:8.240 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:37:32.326: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1174
STEP: creating the pod
Feb 18 12:37:32.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-3436'
Feb 18 12:37:32.489: INFO: stderr: ""
Feb 18 12:37:32.489: INFO: stdout: "pod/pause created\n"
Feb 18 12:37:32.489: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 18 12:37:32.489: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3436" to be "running and ready"
Feb 18 12:37:32.492: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.40642ms
Feb 18 12:37:34.494: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005300953s
Feb 18 12:37:34.494: INFO: Pod "pause" satisfied condition "running and ready"
Feb 18 12:37:34.494: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 18 12:37:34.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 label pods pause testing-label=testing-label-value --namespace=kubectl-3436'
Feb 18 12:37:34.558: INFO: stderr: ""
Feb 18 12:37:34.558: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 18 12:37:34.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pod pause -L testing-label --namespace=kubectl-3436'
Feb 18 12:37:34.619: INFO: stderr: ""
Feb 18 12:37:34.619: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 18 12:37:34.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 label pods pause testing-label- --namespace=kubectl-3436'
Feb 18 12:37:34.681: INFO: stderr: ""
Feb 18 12:37:34.681: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 18 12:37:34.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pod pause -L testing-label --namespace=kubectl-3436'
Feb 18 12:37:34.751: INFO: stderr: ""
Feb 18 12:37:34.751: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1181
STEP: using delete to clean up resources
Feb 18 12:37:34.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-3436'
Feb 18 12:37:34.817: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:37:34.817: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 18 12:37:34.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get rc,svc -l name=pause --no-headers --namespace=kubectl-3436'
Feb 18 12:37:34.884: INFO: stderr: "No resources found.\n"
Feb 18 12:37:34.884: INFO: stdout: ""
Feb 18 12:37:34.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -l name=pause --namespace=kubectl-3436 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 12:37:34.940: INFO: stderr: ""
Feb 18 12:37:34.940: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:37:34.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3436" for this suite.
Feb 18 12:37:40.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:37:41.115: INFO: namespace kubectl-3436 deletion completed in 6.171391217s

• [SLOW TEST:8.789 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:37:41.115: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:37:41.137: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 18 12:37:41.142: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 18 12:37:46.145: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 18 12:37:46.145: INFO: Creating deployment "test-rolling-update-deployment"
Feb 18 12:37:46.148: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 18 12:37:46.153: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 18 12:37:48.157: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 18 12:37:48.158: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717626266, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717626266, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717626266, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717626266, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-57b6b5bb54\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 12:37:50.161: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 12:37:50.165: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5828,SelfLink:/apis/apps/v1/namespaces/deployment-5828/deployments/test-rolling-update-deployment,UID:770def51-524b-11ea-b701-0ae3ad6fc27e,ResourceVersion:11597,Generation:1,CreationTimestamp:2020-02-18 12:37:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-18 12:37:46 +0000 UTC 2020-02-18 12:37:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-18 12:37:48 +0000 UTC 2020-02-18 12:37:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-57b6b5bb54" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 18 12:37:50.167: INFO: New ReplicaSet "test-rolling-update-deployment-57b6b5bb54" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54,GenerateName:,Namespace:deployment-5828,SelfLink:/apis/apps/v1/namespaces/deployment-5828/replicasets/test-rolling-update-deployment-57b6b5bb54,UID:770fd886-524b-11ea-b701-0ae3ad6fc27e,ResourceVersion:11586,Generation:1,CreationTimestamp:2020-02-18 12:37:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 770def51-524b-11ea-b701-0ae3ad6fc27e 0xc0014dcc57 0xc0014dcc58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 18 12:37:50.167: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 18 12:37:50.167: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5828,SelfLink:/apis/apps/v1/namespaces/deployment-5828/replicasets/test-rolling-update-controller,UID:7411c317-524b-11ea-b701-0ae3ad6fc27e,ResourceVersion:11595,Generation:2,CreationTimestamp:2020-02-18 12:37:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 770def51-524b-11ea-b701-0ae3ad6fc27e 0xc0014dcb87 0xc0014dcb88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 12:37:50.169: INFO: Pod "test-rolling-update-deployment-57b6b5bb54-w5bff" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-57b6b5bb54-w5bff,GenerateName:test-rolling-update-deployment-57b6b5bb54-,Namespace:deployment-5828,SelfLink:/api/v1/namespaces/deployment-5828/pods/test-rolling-update-deployment-57b6b5bb54-w5bff,UID:771024f9-524b-11ea-b701-0ae3ad6fc27e,ResourceVersion:11585,Generation:0,CreationTimestamp:2020-02-18 12:37:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 57b6b5bb54,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.224/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-57b6b5bb54 770fd886-524b-11ea-b701-0ae3ad6fc27e 0xc0025c0437 0xc0025c0438}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qlz5p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qlz5p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qlz5p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025c04a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025c04c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:37:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:37:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:37:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:37:46 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:172.16.102.224,StartTime:2020-02-18 12:37:46 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-18 12:37:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://286697e709023249857bf4595b00c5ce9252168069b41539ef9d20e5ede1f646}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:37:50.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5828" for this suite.
Feb 18 12:37:56.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:37:56.337: INFO: namespace deployment-5828 deletion completed in 6.166699108s

• [SLOW TEST:15.222 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:37:56.337: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 18 12:38:02.450: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 12:38:02.458: INFO: Pod pod-with-prestop-http-hook still exists
Feb 18 12:38:04.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 12:38:04.461: INFO: Pod pod-with-prestop-http-hook still exists
Feb 18 12:38:06.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 12:38:06.461: INFO: Pod pod-with-prestop-http-hook still exists
Feb 18 12:38:08.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 12:38:08.461: INFO: Pod pod-with-prestop-http-hook still exists
Feb 18 12:38:10.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 12:38:10.460: INFO: Pod pod-with-prestop-http-hook still exists
Feb 18 12:38:12.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 12:38:12.461: INFO: Pod pod-with-prestop-http-hook still exists
Feb 18 12:38:14.458: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 18 12:38:14.461: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:38:14.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9531" for this suite.
Feb 18 12:38:36.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:38:36.635: INFO: namespace container-lifecycle-hook-9531 deletion completed in 22.167207206s

• [SLOW TEST:40.297 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:38:36.635: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Feb 18 12:38:36.657: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 18 12:38:36.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-5746'
Feb 18 12:38:36.810: INFO: stderr: ""
Feb 18 12:38:36.810: INFO: stdout: "service/redis-slave created\n"
Feb 18 12:38:36.810: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 18 12:38:36.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-5746'
Feb 18 12:38:36.998: INFO: stderr: ""
Feb 18 12:38:36.998: INFO: stdout: "service/redis-master created\n"
Feb 18 12:38:36.998: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 18 12:38:36.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-5746'
Feb 18 12:38:37.163: INFO: stderr: ""
Feb 18 12:38:37.163: INFO: stdout: "service/frontend created\n"
Feb 18 12:38:37.163: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 18 12:38:37.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-5746'
Feb 18 12:38:37.313: INFO: stderr: ""
Feb 18 12:38:37.313: INFO: stdout: "deployment.apps/frontend created\n"
Feb 18 12:38:37.313: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 18 12:38:37.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-5746'
Feb 18 12:38:37.468: INFO: stderr: ""
Feb 18 12:38:37.468: INFO: stdout: "deployment.apps/redis-master created\n"
Feb 18 12:38:37.468: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 18 12:38:37.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-5746'
Feb 18 12:38:37.622: INFO: stderr: ""
Feb 18 12:38:37.622: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb 18 12:38:37.622: INFO: Waiting for all frontend pods to be Running.
Feb 18 12:38:52.673: INFO: Waiting for frontend to serve content.
Feb 18 12:38:57.688: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 18 12:39:02.696: INFO: Trying to add a new entry to the guestbook.
Feb 18 12:39:02.702: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 18 12:39:02.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-5746'
Feb 18 12:39:02.791: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:39:02.791: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 12:39:02.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-5746'
Feb 18 12:39:02.877: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:39:02.877: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 12:39:02.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-5746'
Feb 18 12:39:02.960: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:39:02.960: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 12:39:02.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-5746'
Feb 18 12:39:03.027: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:39:03.027: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 12:39:03.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-5746'
Feb 18 12:39:03.106: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:39:03.106: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 18 12:39:03.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-5746'
Feb 18 12:39:03.167: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:39:03.167: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:39:03.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5746" for this suite.
Feb 18 12:39:45.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:39:45.336: INFO: namespace kubectl-5746 deletion completed in 42.167160937s

• [SLOW TEST:68.701 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:39:45.336: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-be2190c1-524b-11ea-bd69-fac0b7afc6af
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-be2190c1-524b-11ea-bd69-fac0b7afc6af
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:41:21.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4623" for this suite.
Feb 18 12:41:43.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:41:43.943: INFO: namespace configmap-4623 deletion completed in 22.167999075s

• [SLOW TEST:118.606 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:41:43.943: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-8322
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 18 12:41:43.978: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 18 12:42:02.066: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.102.228:8080/dial?request=hostName&protocol=http&host=172.16.26.158&port=8080&tries=1'] Namespace:pod-network-test-8322 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 12:42:02.066: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 12:42:02.212: INFO: Waiting for endpoints: map[]
Feb 18 12:42:02.216: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.102.228:8080/dial?request=hostName&protocol=http&host=172.16.102.229&port=8080&tries=1'] Namespace:pod-network-test-8322 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 12:42:02.216: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 12:42:02.363: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:42:02.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8322" for this suite.
Feb 18 12:42:24.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:42:24.533: INFO: namespace pod-network-test-8322 deletion completed in 22.167235875s

• [SLOW TEST:40.590 seconds]
[sig-network] Networking
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:42:24.533: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-592
I0218 12:42:24.613884      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-592, replica count: 1
I0218 12:42:25.664177      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0218 12:42:26.664313      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 18 12:42:26.778: INFO: Created: latency-svc-9xn44
Feb 18 12:42:26.778: INFO: Got endpoints: latency-svc-9xn44 [13.783191ms]
Feb 18 12:42:26.795: INFO: Created: latency-svc-85lzw
Feb 18 12:42:26.798: INFO: Got endpoints: latency-svc-85lzw [20.252044ms]
Feb 18 12:42:26.805: INFO: Created: latency-svc-zhjlq
Feb 18 12:42:26.812: INFO: Got endpoints: latency-svc-zhjlq [33.96724ms]
Feb 18 12:42:26.815: INFO: Created: latency-svc-szlpd
Feb 18 12:42:26.819: INFO: Got endpoints: latency-svc-szlpd [39.599588ms]
Feb 18 12:42:26.832: INFO: Created: latency-svc-p4ltn
Feb 18 12:42:26.841: INFO: Got endpoints: latency-svc-p4ltn [63.125214ms]
Feb 18 12:42:26.856: INFO: Created: latency-svc-xthrb
Feb 18 12:42:26.856: INFO: Got endpoints: latency-svc-xthrb [77.52115ms]
Feb 18 12:42:26.866: INFO: Created: latency-svc-6jqp9
Feb 18 12:42:26.870: INFO: Got endpoints: latency-svc-6jqp9 [92.010027ms]
Feb 18 12:42:26.875: INFO: Created: latency-svc-l4bkt
Feb 18 12:42:26.881: INFO: Got endpoints: latency-svc-l4bkt [102.467333ms]
Feb 18 12:42:26.914: INFO: Created: latency-svc-wdf8d
Feb 18 12:42:26.918: INFO: Got endpoints: latency-svc-wdf8d [138.940284ms]
Feb 18 12:42:26.930: INFO: Created: latency-svc-rplws
Feb 18 12:42:26.935: INFO: Got endpoints: latency-svc-rplws [156.492047ms]
Feb 18 12:42:26.947: INFO: Created: latency-svc-szrln
Feb 18 12:42:26.952: INFO: Got endpoints: latency-svc-szrln [173.535277ms]
Feb 18 12:42:26.962: INFO: Created: latency-svc-wbslw
Feb 18 12:42:26.965: INFO: Got endpoints: latency-svc-wbslw [185.901473ms]
Feb 18 12:42:26.974: INFO: Created: latency-svc-zlwdv
Feb 18 12:42:26.979: INFO: Got endpoints: latency-svc-zlwdv [200.954052ms]
Feb 18 12:42:26.990: INFO: Created: latency-svc-zwjq9
Feb 18 12:42:26.997: INFO: Got endpoints: latency-svc-zwjq9 [217.941305ms]
Feb 18 12:42:27.004: INFO: Created: latency-svc-k2h59
Feb 18 12:42:27.007: INFO: Got endpoints: latency-svc-k2h59 [228.520404ms]
Feb 18 12:42:27.019: INFO: Created: latency-svc-8f958
Feb 18 12:42:27.023: INFO: Got endpoints: latency-svc-8f958 [243.76439ms]
Feb 18 12:42:27.032: INFO: Created: latency-svc-7vlrw
Feb 18 12:42:27.039: INFO: Got endpoints: latency-svc-7vlrw [240.632904ms]
Feb 18 12:42:27.045: INFO: Created: latency-svc-x869j
Feb 18 12:42:27.050: INFO: Got endpoints: latency-svc-x869j [238.131116ms]
Feb 18 12:42:27.056: INFO: Created: latency-svc-lf4cw
Feb 18 12:42:27.059: INFO: Got endpoints: latency-svc-lf4cw [239.776559ms]
Feb 18 12:42:27.072: INFO: Created: latency-svc-pdgpd
Feb 18 12:42:27.074: INFO: Got endpoints: latency-svc-pdgpd [232.150638ms]
Feb 18 12:42:27.089: INFO: Created: latency-svc-t8bbd
Feb 18 12:42:27.091: INFO: Got endpoints: latency-svc-t8bbd [235.276124ms]
Feb 18 12:42:27.106: INFO: Created: latency-svc-5fs2j
Feb 18 12:42:27.112: INFO: Got endpoints: latency-svc-5fs2j [241.614403ms]
Feb 18 12:42:27.117: INFO: Created: latency-svc-mhrsf
Feb 18 12:42:27.120: INFO: Got endpoints: latency-svc-mhrsf [238.521559ms]
Feb 18 12:42:27.129: INFO: Created: latency-svc-r944v
Feb 18 12:42:27.131: INFO: Got endpoints: latency-svc-r944v [213.434948ms]
Feb 18 12:42:27.143: INFO: Created: latency-svc-2cj24
Feb 18 12:42:27.156: INFO: Got endpoints: latency-svc-2cj24 [220.66404ms]
Feb 18 12:42:27.158: INFO: Created: latency-svc-vnlv9
Feb 18 12:42:27.159: INFO: Got endpoints: latency-svc-vnlv9 [207.298499ms]
Feb 18 12:42:27.185: INFO: Created: latency-svc-8wp5z
Feb 18 12:42:27.199: INFO: Got endpoints: latency-svc-8wp5z [234.415876ms]
Feb 18 12:42:27.212: INFO: Created: latency-svc-hw5qp
Feb 18 12:42:27.219: INFO: Got endpoints: latency-svc-hw5qp [239.514437ms]
Feb 18 12:42:27.239: INFO: Created: latency-svc-qd5sk
Feb 18 12:42:27.245: INFO: Got endpoints: latency-svc-qd5sk [248.647343ms]
Feb 18 12:42:27.257: INFO: Created: latency-svc-6vhxk
Feb 18 12:42:27.258: INFO: Got endpoints: latency-svc-6vhxk [250.363288ms]
Feb 18 12:42:27.267: INFO: Created: latency-svc-qgb2t
Feb 18 12:42:27.284: INFO: Got endpoints: latency-svc-qgb2t [261.682262ms]
Feb 18 12:42:27.295: INFO: Created: latency-svc-q4wkz
Feb 18 12:42:27.296: INFO: Got endpoints: latency-svc-q4wkz [257.26186ms]
Feb 18 12:42:27.306: INFO: Created: latency-svc-mg755
Feb 18 12:42:27.309: INFO: Got endpoints: latency-svc-mg755 [258.519662ms]
Feb 18 12:42:27.319: INFO: Created: latency-svc-ctwnn
Feb 18 12:42:27.322: INFO: Got endpoints: latency-svc-ctwnn [263.200002ms]
Feb 18 12:42:27.340: INFO: Created: latency-svc-8kft9
Feb 18 12:42:27.346: INFO: Got endpoints: latency-svc-8kft9 [271.842766ms]
Feb 18 12:42:27.349: INFO: Created: latency-svc-n5nrx
Feb 18 12:42:27.354: INFO: Got endpoints: latency-svc-n5nrx [262.879108ms]
Feb 18 12:42:27.361: INFO: Created: latency-svc-vtnll
Feb 18 12:42:27.370: INFO: Got endpoints: latency-svc-vtnll [257.555487ms]
Feb 18 12:42:27.375: INFO: Created: latency-svc-d2gpw
Feb 18 12:42:27.385: INFO: Got endpoints: latency-svc-d2gpw [264.882197ms]
Feb 18 12:42:27.393: INFO: Created: latency-svc-rdsp2
Feb 18 12:42:27.395: INFO: Got endpoints: latency-svc-rdsp2 [263.907839ms]
Feb 18 12:42:27.409: INFO: Created: latency-svc-snc6p
Feb 18 12:42:27.409: INFO: Got endpoints: latency-svc-snc6p [253.108859ms]
Feb 18 12:42:27.414: INFO: Created: latency-svc-k5gbn
Feb 18 12:42:27.416: INFO: Got endpoints: latency-svc-k5gbn [256.878732ms]
Feb 18 12:42:27.432: INFO: Created: latency-svc-qxhlf
Feb 18 12:42:27.441: INFO: Got endpoints: latency-svc-qxhlf [241.532728ms]
Feb 18 12:42:27.446: INFO: Created: latency-svc-fwt2c
Feb 18 12:42:27.451: INFO: Got endpoints: latency-svc-fwt2c [232.156911ms]
Feb 18 12:42:27.460: INFO: Created: latency-svc-nzpqc
Feb 18 12:42:27.467: INFO: Created: latency-svc-2np2l
Feb 18 12:42:27.480: INFO: Created: latency-svc-kvq52
Feb 18 12:42:27.481: INFO: Got endpoints: latency-svc-nzpqc [235.524767ms]
Feb 18 12:42:27.497: INFO: Created: latency-svc-vxcr4
Feb 18 12:42:27.516: INFO: Created: latency-svc-tvn6d
Feb 18 12:42:27.528: INFO: Got endpoints: latency-svc-2np2l [270.243056ms]
Feb 18 12:42:27.549: INFO: Created: latency-svc-c7lck
Feb 18 12:42:27.563: INFO: Created: latency-svc-lfvgz
Feb 18 12:42:27.581: INFO: Created: latency-svc-dwbfq
Feb 18 12:42:27.582: INFO: Got endpoints: latency-svc-kvq52 [298.167391ms]
Feb 18 12:42:27.590: INFO: Created: latency-svc-mltlx
Feb 18 12:42:27.606: INFO: Created: latency-svc-snkpw
Feb 18 12:42:27.610: INFO: Created: latency-svc-wzpvm
Feb 18 12:42:27.620: INFO: Created: latency-svc-74j4h
Feb 18 12:42:27.629: INFO: Got endpoints: latency-svc-vxcr4 [332.857974ms]
Feb 18 12:42:27.631: INFO: Created: latency-svc-dpqx7
Feb 18 12:42:27.642: INFO: Created: latency-svc-nhdcs
Feb 18 12:42:27.652: INFO: Created: latency-svc-d9p9l
Feb 18 12:42:27.671: INFO: Created: latency-svc-wg44v
Feb 18 12:42:27.675: INFO: Got endpoints: latency-svc-tvn6d [366.404287ms]
Feb 18 12:42:27.689: INFO: Created: latency-svc-8q9gg
Feb 18 12:42:27.705: INFO: Created: latency-svc-5vgk2
Feb 18 12:42:27.713: INFO: Created: latency-svc-dgl6p
Feb 18 12:42:27.720: INFO: Created: latency-svc-w6gdn
Feb 18 12:42:27.724: INFO: Got endpoints: latency-svc-c7lck [402.188955ms]
Feb 18 12:42:27.737: INFO: Created: latency-svc-6crm9
Feb 18 12:42:27.777: INFO: Got endpoints: latency-svc-lfvgz [431.466339ms]
Feb 18 12:42:27.794: INFO: Created: latency-svc-4nd7k
Feb 18 12:42:27.826: INFO: Got endpoints: latency-svc-dwbfq [471.82896ms]
Feb 18 12:42:27.843: INFO: Created: latency-svc-h5f4h
Feb 18 12:42:27.876: INFO: Got endpoints: latency-svc-mltlx [505.855666ms]
Feb 18 12:42:27.896: INFO: Created: latency-svc-fjnz8
Feb 18 12:42:27.926: INFO: Got endpoints: latency-svc-snkpw [540.450499ms]
Feb 18 12:42:27.965: INFO: Created: latency-svc-2wrpz
Feb 18 12:42:27.977: INFO: Got endpoints: latency-svc-wzpvm [581.788261ms]
Feb 18 12:42:27.991: INFO: Created: latency-svc-pznzh
Feb 18 12:42:28.026: INFO: Got endpoints: latency-svc-74j4h [617.243396ms]
Feb 18 12:42:28.040: INFO: Created: latency-svc-zppqj
Feb 18 12:42:28.075: INFO: Got endpoints: latency-svc-dpqx7 [658.504432ms]
Feb 18 12:42:28.087: INFO: Created: latency-svc-llkqx
Feb 18 12:42:28.125: INFO: Got endpoints: latency-svc-nhdcs [684.65904ms]
Feb 18 12:42:28.140: INFO: Created: latency-svc-xmk5r
Feb 18 12:42:28.175: INFO: Got endpoints: latency-svc-d9p9l [724.096574ms]
Feb 18 12:42:28.189: INFO: Created: latency-svc-xr29x
Feb 18 12:42:28.226: INFO: Got endpoints: latency-svc-wg44v [745.192341ms]
Feb 18 12:42:28.241: INFO: Created: latency-svc-qzw4c
Feb 18 12:42:28.276: INFO: Got endpoints: latency-svc-8q9gg [748.213712ms]
Feb 18 12:42:28.292: INFO: Created: latency-svc-lfn8s
Feb 18 12:42:28.326: INFO: Got endpoints: latency-svc-5vgk2 [743.675943ms]
Feb 18 12:42:28.336: INFO: Created: latency-svc-r8kp4
Feb 18 12:42:28.376: INFO: Got endpoints: latency-svc-dgl6p [747.387545ms]
Feb 18 12:42:28.392: INFO: Created: latency-svc-dxrqv
Feb 18 12:42:28.425: INFO: Got endpoints: latency-svc-w6gdn [749.7193ms]
Feb 18 12:42:28.441: INFO: Created: latency-svc-hshjb
Feb 18 12:42:28.476: INFO: Got endpoints: latency-svc-6crm9 [751.450232ms]
Feb 18 12:42:28.494: INFO: Created: latency-svc-5sdm7
Feb 18 12:42:28.526: INFO: Got endpoints: latency-svc-4nd7k [748.526548ms]
Feb 18 12:42:28.538: INFO: Created: latency-svc-8d8wx
Feb 18 12:42:28.575: INFO: Got endpoints: latency-svc-h5f4h [748.67248ms]
Feb 18 12:42:28.587: INFO: Created: latency-svc-glngt
Feb 18 12:42:28.627: INFO: Got endpoints: latency-svc-fjnz8 [751.396459ms]
Feb 18 12:42:28.642: INFO: Created: latency-svc-fdrvm
Feb 18 12:42:28.676: INFO: Got endpoints: latency-svc-2wrpz [750.528581ms]
Feb 18 12:42:28.691: INFO: Created: latency-svc-h4dcq
Feb 18 12:42:28.727: INFO: Got endpoints: latency-svc-pznzh [749.903594ms]
Feb 18 12:42:28.743: INFO: Created: latency-svc-ddmgk
Feb 18 12:42:28.775: INFO: Got endpoints: latency-svc-zppqj [749.263475ms]
Feb 18 12:42:28.789: INFO: Created: latency-svc-sm8f2
Feb 18 12:42:28.826: INFO: Got endpoints: latency-svc-llkqx [751.460084ms]
Feb 18 12:42:28.846: INFO: Created: latency-svc-69gqb
Feb 18 12:42:28.876: INFO: Got endpoints: latency-svc-xmk5r [750.874468ms]
Feb 18 12:42:29.032: INFO: Got endpoints: latency-svc-lfn8s [755.687556ms]
Feb 18 12:42:29.033: INFO: Got endpoints: latency-svc-xr29x [857.405775ms]
Feb 18 12:42:29.033: INFO: Got endpoints: latency-svc-qzw4c [806.784831ms]
Feb 18 12:42:29.069: INFO: Created: latency-svc-qnddz
Feb 18 12:42:29.078: INFO: Got endpoints: latency-svc-r8kp4 [751.963999ms]
Feb 18 12:42:29.082: INFO: Created: latency-svc-9kpxd
Feb 18 12:42:29.091: INFO: Created: latency-svc-rsg9f
Feb 18 12:42:29.098: INFO: Created: latency-svc-qsgsm
Feb 18 12:42:29.116: INFO: Created: latency-svc-x9f56
Feb 18 12:42:29.126: INFO: Got endpoints: latency-svc-dxrqv [749.724404ms]
Feb 18 12:42:29.143: INFO: Created: latency-svc-7wknr
Feb 18 12:42:29.176: INFO: Got endpoints: latency-svc-hshjb [751.236098ms]
Feb 18 12:42:29.187: INFO: Created: latency-svc-2tgc2
Feb 18 12:42:29.226: INFO: Got endpoints: latency-svc-5sdm7 [750.228622ms]
Feb 18 12:42:29.244: INFO: Created: latency-svc-pvz72
Feb 18 12:42:29.275: INFO: Got endpoints: latency-svc-8d8wx [749.495086ms]
Feb 18 12:42:29.289: INFO: Created: latency-svc-4k65x
Feb 18 12:42:29.325: INFO: Got endpoints: latency-svc-glngt [749.644865ms]
Feb 18 12:42:29.337: INFO: Created: latency-svc-h7hsv
Feb 18 12:42:29.376: INFO: Got endpoints: latency-svc-fdrvm [749.009551ms]
Feb 18 12:42:29.391: INFO: Created: latency-svc-gxnbl
Feb 18 12:42:29.426: INFO: Got endpoints: latency-svc-h4dcq [749.455896ms]
Feb 18 12:42:29.441: INFO: Created: latency-svc-xtklf
Feb 18 12:42:29.477: INFO: Got endpoints: latency-svc-ddmgk [749.678834ms]
Feb 18 12:42:29.493: INFO: Created: latency-svc-vj2j2
Feb 18 12:42:29.527: INFO: Got endpoints: latency-svc-sm8f2 [750.991051ms]
Feb 18 12:42:29.539: INFO: Created: latency-svc-ll9n5
Feb 18 12:42:29.576: INFO: Got endpoints: latency-svc-69gqb [749.143016ms]
Feb 18 12:42:29.586: INFO: Created: latency-svc-f6z64
Feb 18 12:42:29.625: INFO: Got endpoints: latency-svc-qnddz [749.15774ms]
Feb 18 12:42:29.637: INFO: Created: latency-svc-twpsp
Feb 18 12:42:29.676: INFO: Got endpoints: latency-svc-9kpxd [643.095777ms]
Feb 18 12:42:29.688: INFO: Created: latency-svc-qz7f2
Feb 18 12:42:29.726: INFO: Got endpoints: latency-svc-rsg9f [692.606746ms]
Feb 18 12:42:29.743: INFO: Created: latency-svc-9745n
Feb 18 12:42:29.781: INFO: Got endpoints: latency-svc-qsgsm [748.094727ms]
Feb 18 12:42:29.808: INFO: Created: latency-svc-b2zwc
Feb 18 12:42:29.825: INFO: Got endpoints: latency-svc-x9f56 [746.794616ms]
Feb 18 12:42:29.842: INFO: Created: latency-svc-8v24j
Feb 18 12:42:29.881: INFO: Got endpoints: latency-svc-7wknr [754.838952ms]
Feb 18 12:42:29.894: INFO: Created: latency-svc-775z5
Feb 18 12:42:29.926: INFO: Got endpoints: latency-svc-2tgc2 [749.755234ms]
Feb 18 12:42:29.970: INFO: Created: latency-svc-mdsd7
Feb 18 12:42:29.977: INFO: Got endpoints: latency-svc-pvz72 [750.596235ms]
Feb 18 12:42:29.992: INFO: Created: latency-svc-7f4pz
Feb 18 12:42:30.025: INFO: Got endpoints: latency-svc-4k65x [749.97375ms]
Feb 18 12:42:30.037: INFO: Created: latency-svc-vjg9k
Feb 18 12:42:30.075: INFO: Got endpoints: latency-svc-h7hsv [750.641712ms]
Feb 18 12:42:30.089: INFO: Created: latency-svc-rgth7
Feb 18 12:42:30.125: INFO: Got endpoints: latency-svc-gxnbl [749.272143ms]
Feb 18 12:42:30.138: INFO: Created: latency-svc-lqmmc
Feb 18 12:42:30.177: INFO: Got endpoints: latency-svc-xtklf [751.328131ms]
Feb 18 12:42:30.190: INFO: Created: latency-svc-78xlz
Feb 18 12:42:30.230: INFO: Got endpoints: latency-svc-vj2j2 [752.888236ms]
Feb 18 12:42:30.242: INFO: Created: latency-svc-png9q
Feb 18 12:42:30.276: INFO: Got endpoints: latency-svc-ll9n5 [749.529417ms]
Feb 18 12:42:30.288: INFO: Created: latency-svc-b98sz
Feb 18 12:42:30.326: INFO: Got endpoints: latency-svc-f6z64 [750.447409ms]
Feb 18 12:42:30.338: INFO: Created: latency-svc-4rs6n
Feb 18 12:42:30.376: INFO: Got endpoints: latency-svc-twpsp [750.845176ms]
Feb 18 12:42:30.391: INFO: Created: latency-svc-vsn6h
Feb 18 12:42:30.426: INFO: Got endpoints: latency-svc-qz7f2 [749.987291ms]
Feb 18 12:42:30.437: INFO: Created: latency-svc-vp2fg
Feb 18 12:42:30.476: INFO: Got endpoints: latency-svc-9745n [750.775993ms]
Feb 18 12:42:30.494: INFO: Created: latency-svc-h2gth
Feb 18 12:42:30.526: INFO: Got endpoints: latency-svc-b2zwc [745.388009ms]
Feb 18 12:42:30.542: INFO: Created: latency-svc-wv58g
Feb 18 12:42:30.575: INFO: Got endpoints: latency-svc-8v24j [749.846916ms]
Feb 18 12:42:30.594: INFO: Created: latency-svc-5pgf2
Feb 18 12:42:30.627: INFO: Got endpoints: latency-svc-775z5 [745.506844ms]
Feb 18 12:42:30.647: INFO: Created: latency-svc-rcwmn
Feb 18 12:42:30.677: INFO: Got endpoints: latency-svc-mdsd7 [750.947212ms]
Feb 18 12:42:30.692: INFO: Created: latency-svc-mn222
Feb 18 12:42:30.729: INFO: Got endpoints: latency-svc-7f4pz [752.773534ms]
Feb 18 12:42:30.749: INFO: Created: latency-svc-d9mzs
Feb 18 12:42:30.781: INFO: Got endpoints: latency-svc-vjg9k [755.272573ms]
Feb 18 12:42:30.804: INFO: Created: latency-svc-kp2fc
Feb 18 12:42:30.826: INFO: Got endpoints: latency-svc-rgth7 [750.025535ms]
Feb 18 12:42:30.844: INFO: Created: latency-svc-jr9mf
Feb 18 12:42:30.876: INFO: Got endpoints: latency-svc-lqmmc [750.809312ms]
Feb 18 12:42:30.892: INFO: Created: latency-svc-6s2bg
Feb 18 12:42:30.925: INFO: Got endpoints: latency-svc-78xlz [747.945067ms]
Feb 18 12:42:30.941: INFO: Created: latency-svc-hdwkr
Feb 18 12:42:30.976: INFO: Got endpoints: latency-svc-png9q [746.067146ms]
Feb 18 12:42:30.988: INFO: Created: latency-svc-9dr5t
Feb 18 12:42:31.026: INFO: Got endpoints: latency-svc-b98sz [749.399887ms]
Feb 18 12:42:31.068: INFO: Created: latency-svc-r8bbf
Feb 18 12:42:31.077: INFO: Got endpoints: latency-svc-4rs6n [750.790722ms]
Feb 18 12:42:31.090: INFO: Created: latency-svc-4fz9f
Feb 18 12:42:31.125: INFO: Got endpoints: latency-svc-vsn6h [748.91878ms]
Feb 18 12:42:31.139: INFO: Created: latency-svc-mt8xd
Feb 18 12:42:31.176: INFO: Got endpoints: latency-svc-vp2fg [750.698272ms]
Feb 18 12:42:31.191: INFO: Created: latency-svc-d82st
Feb 18 12:42:31.225: INFO: Got endpoints: latency-svc-h2gth [749.002774ms]
Feb 18 12:42:31.240: INFO: Created: latency-svc-jdg9t
Feb 18 12:42:31.277: INFO: Got endpoints: latency-svc-wv58g [750.418613ms]
Feb 18 12:42:31.290: INFO: Created: latency-svc-tpnrt
Feb 18 12:42:31.325: INFO: Got endpoints: latency-svc-5pgf2 [749.514447ms]
Feb 18 12:42:31.337: INFO: Created: latency-svc-knvqj
Feb 18 12:42:31.376: INFO: Got endpoints: latency-svc-rcwmn [749.597347ms]
Feb 18 12:42:31.391: INFO: Created: latency-svc-gskvr
Feb 18 12:42:31.426: INFO: Got endpoints: latency-svc-mn222 [748.938346ms]
Feb 18 12:42:31.438: INFO: Created: latency-svc-jbc7j
Feb 18 12:42:31.476: INFO: Got endpoints: latency-svc-d9mzs [746.717106ms]
Feb 18 12:42:31.495: INFO: Created: latency-svc-scp86
Feb 18 12:42:31.525: INFO: Got endpoints: latency-svc-kp2fc [744.64666ms]
Feb 18 12:42:31.545: INFO: Created: latency-svc-ljmqz
Feb 18 12:42:31.575: INFO: Got endpoints: latency-svc-jr9mf [749.312154ms]
Feb 18 12:42:31.594: INFO: Created: latency-svc-kg49r
Feb 18 12:42:31.625: INFO: Got endpoints: latency-svc-6s2bg [748.922178ms]
Feb 18 12:42:31.642: INFO: Created: latency-svc-8swgw
Feb 18 12:42:31.676: INFO: Got endpoints: latency-svc-hdwkr [750.070667ms]
Feb 18 12:42:31.687: INFO: Created: latency-svc-nww9q
Feb 18 12:42:31.728: INFO: Got endpoints: latency-svc-9dr5t [751.904247ms]
Feb 18 12:42:31.739: INFO: Created: latency-svc-h6dpk
Feb 18 12:42:31.775: INFO: Got endpoints: latency-svc-r8bbf [749.279155ms]
Feb 18 12:42:31.790: INFO: Created: latency-svc-7zfmv
Feb 18 12:42:31.826: INFO: Got endpoints: latency-svc-4fz9f [748.714298ms]
Feb 18 12:42:31.842: INFO: Created: latency-svc-djvdn
Feb 18 12:42:31.877: INFO: Got endpoints: latency-svc-mt8xd [752.244395ms]
Feb 18 12:42:31.887: INFO: Created: latency-svc-8ws4x
Feb 18 12:42:31.926: INFO: Got endpoints: latency-svc-d82st [749.120513ms]
Feb 18 12:42:31.941: INFO: Created: latency-svc-tszz4
Feb 18 12:42:31.977: INFO: Got endpoints: latency-svc-jdg9t [751.521631ms]
Feb 18 12:42:31.990: INFO: Created: latency-svc-wsqtd
Feb 18 12:42:32.026: INFO: Got endpoints: latency-svc-tpnrt [748.303569ms]
Feb 18 12:42:32.038: INFO: Created: latency-svc-8stq6
Feb 18 12:42:32.075: INFO: Got endpoints: latency-svc-knvqj [750.733104ms]
Feb 18 12:42:32.088: INFO: Created: latency-svc-d9bgw
Feb 18 12:42:32.128: INFO: Got endpoints: latency-svc-gskvr [751.582161ms]
Feb 18 12:42:32.144: INFO: Created: latency-svc-xcfq5
Feb 18 12:42:32.175: INFO: Got endpoints: latency-svc-jbc7j [749.004182ms]
Feb 18 12:42:32.195: INFO: Created: latency-svc-wxwsw
Feb 18 12:42:32.226: INFO: Got endpoints: latency-svc-scp86 [749.861289ms]
Feb 18 12:42:32.266: INFO: Created: latency-svc-5c25z
Feb 18 12:42:32.275: INFO: Got endpoints: latency-svc-ljmqz [749.867564ms]
Feb 18 12:42:32.292: INFO: Created: latency-svc-qrp8x
Feb 18 12:42:32.327: INFO: Got endpoints: latency-svc-kg49r [751.750242ms]
Feb 18 12:42:32.342: INFO: Created: latency-svc-bpq8g
Feb 18 12:42:32.375: INFO: Got endpoints: latency-svc-8swgw [750.10965ms]
Feb 18 12:42:32.393: INFO: Created: latency-svc-n8lqc
Feb 18 12:42:32.434: INFO: Got endpoints: latency-svc-nww9q [758.292469ms]
Feb 18 12:42:32.447: INFO: Created: latency-svc-pdmqb
Feb 18 12:42:32.477: INFO: Got endpoints: latency-svc-h6dpk [749.049451ms]
Feb 18 12:42:32.490: INFO: Created: latency-svc-lmkb8
Feb 18 12:42:32.526: INFO: Got endpoints: latency-svc-7zfmv [750.930803ms]
Feb 18 12:42:32.541: INFO: Created: latency-svc-6f27z
Feb 18 12:42:32.576: INFO: Got endpoints: latency-svc-djvdn [750.207106ms]
Feb 18 12:42:32.591: INFO: Created: latency-svc-v4bh7
Feb 18 12:42:32.626: INFO: Got endpoints: latency-svc-8ws4x [748.487569ms]
Feb 18 12:42:32.640: INFO: Created: latency-svc-d27wh
Feb 18 12:42:32.677: INFO: Got endpoints: latency-svc-tszz4 [750.788407ms]
Feb 18 12:42:32.688: INFO: Created: latency-svc-tk2fz
Feb 18 12:42:32.726: INFO: Got endpoints: latency-svc-wsqtd [748.272376ms]
Feb 18 12:42:32.742: INFO: Created: latency-svc-p6sf7
Feb 18 12:42:32.776: INFO: Got endpoints: latency-svc-8stq6 [750.223717ms]
Feb 18 12:42:32.795: INFO: Created: latency-svc-lc6vw
Feb 18 12:42:32.828: INFO: Got endpoints: latency-svc-d9bgw [752.630467ms]
Feb 18 12:42:32.848: INFO: Created: latency-svc-jblkz
Feb 18 12:42:32.876: INFO: Got endpoints: latency-svc-xcfq5 [747.546023ms]
Feb 18 12:42:32.888: INFO: Created: latency-svc-dv62g
Feb 18 12:42:32.925: INFO: Got endpoints: latency-svc-wxwsw [750.080422ms]
Feb 18 12:42:32.940: INFO: Created: latency-svc-c7ncx
Feb 18 12:42:32.976: INFO: Got endpoints: latency-svc-5c25z [750.101733ms]
Feb 18 12:42:33.046: INFO: Got endpoints: latency-svc-qrp8x [770.2827ms]
Feb 18 12:42:33.059: INFO: Created: latency-svc-l76xd
Feb 18 12:42:33.079: INFO: Created: latency-svc-ml6cr
Feb 18 12:42:33.080: INFO: Got endpoints: latency-svc-bpq8g [752.812856ms]
Feb 18 12:42:33.092: INFO: Created: latency-svc-7ppmg
Feb 18 12:42:33.126: INFO: Got endpoints: latency-svc-n8lqc [750.920207ms]
Feb 18 12:42:33.139: INFO: Created: latency-svc-862ht
Feb 18 12:42:33.176: INFO: Got endpoints: latency-svc-pdmqb [742.033752ms]
Feb 18 12:42:33.192: INFO: Created: latency-svc-x4rxx
Feb 18 12:42:33.226: INFO: Got endpoints: latency-svc-lmkb8 [749.587078ms]
Feb 18 12:42:33.323: INFO: Created: latency-svc-8mpsm
Feb 18 12:42:33.340: INFO: Got endpoints: latency-svc-v4bh7 [763.545195ms]
Feb 18 12:42:33.340: INFO: Got endpoints: latency-svc-6f27z [814.224708ms]
Feb 18 12:42:33.354: INFO: Created: latency-svc-tv9z6
Feb 18 12:42:33.486: INFO: Got endpoints: latency-svc-d27wh [860.282756ms]
Feb 18 12:42:33.490: INFO: Created: latency-svc-w754f
Feb 18 12:42:33.490: INFO: Got endpoints: latency-svc-p6sf7 [764.254061ms]
Feb 18 12:42:33.490: INFO: Got endpoints: latency-svc-tk2fz [813.640298ms]
Feb 18 12:42:33.525: INFO: Created: latency-svc-98lbb
Feb 18 12:42:33.528: INFO: Got endpoints: latency-svc-lc6vw [751.675486ms]
Feb 18 12:42:33.535: INFO: Created: latency-svc-b6m7q
Feb 18 12:42:33.563: INFO: Created: latency-svc-z767v
Feb 18 12:42:33.563: INFO: Created: latency-svc-kbxm4
Feb 18 12:42:33.575: INFO: Got endpoints: latency-svc-jblkz [746.97524ms]
Feb 18 12:42:33.614: INFO: Created: latency-svc-lmhtv
Feb 18 12:42:33.627: INFO: Got endpoints: latency-svc-c7ncx [701.081333ms]
Feb 18 12:42:33.643: INFO: Created: latency-svc-7gjql
Feb 18 12:42:33.675: INFO: Got endpoints: latency-svc-l76xd [698.886212ms]
Feb 18 12:42:33.684: INFO: Created: latency-svc-fgpfs
Feb 18 12:42:33.726: INFO: Got endpoints: latency-svc-dv62g [850.100281ms]
Feb 18 12:42:33.737: INFO: Created: latency-svc-8qg69
Feb 18 12:42:33.777: INFO: Got endpoints: latency-svc-ml6cr [731.127159ms]
Feb 18 12:42:33.792: INFO: Created: latency-svc-b6b9d
Feb 18 12:42:33.825: INFO: Got endpoints: latency-svc-7ppmg [745.294944ms]
Feb 18 12:42:33.840: INFO: Created: latency-svc-x26gz
Feb 18 12:42:33.877: INFO: Got endpoints: latency-svc-862ht [750.331482ms]
Feb 18 12:42:33.888: INFO: Created: latency-svc-46wfg
Feb 18 12:42:33.925: INFO: Got endpoints: latency-svc-x4rxx [749.428052ms]
Feb 18 12:42:33.944: INFO: Created: latency-svc-wrjv2
Feb 18 12:42:33.976: INFO: Got endpoints: latency-svc-8mpsm [749.433589ms]
Feb 18 12:42:34.002: INFO: Created: latency-svc-mtdxg
Feb 18 12:42:34.038: INFO: Got endpoints: latency-svc-tv9z6 [698.205261ms]
Feb 18 12:42:34.083: INFO: Got endpoints: latency-svc-w754f [742.153077ms]
Feb 18 12:42:34.091: INFO: Created: latency-svc-nc2g2
Feb 18 12:42:34.106: INFO: Created: latency-svc-rm75q
Feb 18 12:42:34.128: INFO: Got endpoints: latency-svc-98lbb [641.054058ms]
Feb 18 12:42:34.151: INFO: Created: latency-svc-d7cgd
Feb 18 12:42:34.176: INFO: Got endpoints: latency-svc-b6m7q [685.594858ms]
Feb 18 12:42:34.189: INFO: Created: latency-svc-jzr2x
Feb 18 12:42:34.225: INFO: Got endpoints: latency-svc-kbxm4 [734.883535ms]
Feb 18 12:42:34.243: INFO: Created: latency-svc-nrzg4
Feb 18 12:42:34.279: INFO: Got endpoints: latency-svc-z767v [751.26281ms]
Feb 18 12:42:34.293: INFO: Created: latency-svc-xztf8
Feb 18 12:42:34.326: INFO: Got endpoints: latency-svc-lmhtv [751.041571ms]
Feb 18 12:42:34.342: INFO: Created: latency-svc-kbs97
Feb 18 12:42:34.375: INFO: Got endpoints: latency-svc-7gjql [748.836271ms]
Feb 18 12:42:34.387: INFO: Created: latency-svc-q67gj
Feb 18 12:42:34.426: INFO: Got endpoints: latency-svc-fgpfs [750.623518ms]
Feb 18 12:42:34.443: INFO: Created: latency-svc-qmc96
Feb 18 12:42:34.475: INFO: Got endpoints: latency-svc-8qg69 [749.296349ms]
Feb 18 12:42:34.492: INFO: Created: latency-svc-27w4n
Feb 18 12:42:34.525: INFO: Got endpoints: latency-svc-b6b9d [748.255656ms]
Feb 18 12:42:34.541: INFO: Created: latency-svc-cslm2
Feb 18 12:42:34.576: INFO: Got endpoints: latency-svc-x26gz [750.44252ms]
Feb 18 12:42:34.591: INFO: Created: latency-svc-xj76d
Feb 18 12:42:34.626: INFO: Got endpoints: latency-svc-46wfg [748.672499ms]
Feb 18 12:42:34.677: INFO: Got endpoints: latency-svc-wrjv2 [751.076822ms]
Feb 18 12:42:34.726: INFO: Got endpoints: latency-svc-mtdxg [749.765212ms]
Feb 18 12:42:34.777: INFO: Got endpoints: latency-svc-nc2g2 [738.306927ms]
Feb 18 12:42:34.825: INFO: Got endpoints: latency-svc-rm75q [742.737392ms]
Feb 18 12:42:34.876: INFO: Got endpoints: latency-svc-d7cgd [748.118771ms]
Feb 18 12:42:34.929: INFO: Got endpoints: latency-svc-jzr2x [753.709717ms]
Feb 18 12:42:34.975: INFO: Got endpoints: latency-svc-nrzg4 [750.134938ms]
Feb 18 12:42:35.026: INFO: Got endpoints: latency-svc-xztf8 [747.370551ms]
Feb 18 12:42:35.075: INFO: Got endpoints: latency-svc-kbs97 [748.684525ms]
Feb 18 12:42:35.128: INFO: Got endpoints: latency-svc-q67gj [752.581226ms]
Feb 18 12:42:35.176: INFO: Got endpoints: latency-svc-qmc96 [749.74619ms]
Feb 18 12:42:35.226: INFO: Got endpoints: latency-svc-27w4n [750.643082ms]
Feb 18 12:42:35.276: INFO: Got endpoints: latency-svc-cslm2 [750.441606ms]
Feb 18 12:42:35.326: INFO: Got endpoints: latency-svc-xj76d [750.019336ms]
Feb 18 12:42:35.326: INFO: Latencies: [20.252044ms 33.96724ms 39.599588ms 63.125214ms 77.52115ms 92.010027ms 102.467333ms 138.940284ms 156.492047ms 173.535277ms 185.901473ms 200.954052ms 207.298499ms 213.434948ms 217.941305ms 220.66404ms 228.520404ms 232.150638ms 232.156911ms 234.415876ms 235.276124ms 235.524767ms 238.131116ms 238.521559ms 239.514437ms 239.776559ms 240.632904ms 241.532728ms 241.614403ms 243.76439ms 248.647343ms 250.363288ms 253.108859ms 256.878732ms 257.26186ms 257.555487ms 258.519662ms 261.682262ms 262.879108ms 263.200002ms 263.907839ms 264.882197ms 270.243056ms 271.842766ms 298.167391ms 332.857974ms 366.404287ms 402.188955ms 431.466339ms 471.82896ms 505.855666ms 540.450499ms 581.788261ms 617.243396ms 641.054058ms 643.095777ms 658.504432ms 684.65904ms 685.594858ms 692.606746ms 698.205261ms 698.886212ms 701.081333ms 724.096574ms 731.127159ms 734.883535ms 738.306927ms 742.033752ms 742.153077ms 742.737392ms 743.675943ms 744.64666ms 745.192341ms 745.294944ms 745.388009ms 745.506844ms 746.067146ms 746.717106ms 746.794616ms 746.97524ms 747.370551ms 747.387545ms 747.546023ms 747.945067ms 748.094727ms 748.118771ms 748.213712ms 748.255656ms 748.272376ms 748.303569ms 748.487569ms 748.526548ms 748.67248ms 748.672499ms 748.684525ms 748.714298ms 748.836271ms 748.91878ms 748.922178ms 748.938346ms 749.002774ms 749.004182ms 749.009551ms 749.049451ms 749.120513ms 749.143016ms 749.15774ms 749.263475ms 749.272143ms 749.279155ms 749.296349ms 749.312154ms 749.399887ms 749.428052ms 749.433589ms 749.455896ms 749.495086ms 749.514447ms 749.529417ms 749.587078ms 749.597347ms 749.644865ms 749.678834ms 749.7193ms 749.724404ms 749.74619ms 749.755234ms 749.765212ms 749.846916ms 749.861289ms 749.867564ms 749.903594ms 749.97375ms 749.987291ms 750.019336ms 750.025535ms 750.070667ms 750.080422ms 750.101733ms 750.10965ms 750.134938ms 750.207106ms 750.223717ms 750.228622ms 750.331482ms 750.418613ms 750.441606ms 750.44252ms 750.447409ms 750.528581ms 750.596235ms 750.623518ms 750.641712ms 750.643082ms 750.698272ms 750.733104ms 750.775993ms 750.788407ms 750.790722ms 750.809312ms 750.845176ms 750.874468ms 750.920207ms 750.930803ms 750.947212ms 750.991051ms 751.041571ms 751.076822ms 751.236098ms 751.26281ms 751.328131ms 751.396459ms 751.450232ms 751.460084ms 751.521631ms 751.582161ms 751.675486ms 751.750242ms 751.904247ms 751.963999ms 752.244395ms 752.581226ms 752.630467ms 752.773534ms 752.812856ms 752.888236ms 753.709717ms 754.838952ms 755.272573ms 755.687556ms 758.292469ms 763.545195ms 764.254061ms 770.2827ms 806.784831ms 813.640298ms 814.224708ms 850.100281ms 857.405775ms 860.282756ms]
Feb 18 12:42:35.326: INFO: 50 %ile: 749.002774ms
Feb 18 12:42:35.326: INFO: 90 %ile: 752.244395ms
Feb 18 12:42:35.326: INFO: 99 %ile: 857.405775ms
Feb 18 12:42:35.326: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:42:35.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-592" for this suite.
Feb 18 12:42:59.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:42:59.500: INFO: namespace svc-latency-592 deletion completed in 24.169722909s

• [SLOW TEST:34.967 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:42:59.500: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8285
Feb 18 12:43:03.534: INFO: Started pod liveness-http in namespace container-probe-8285
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 12:43:03.536: INFO: Initial restart count of pod liveness-http is 0
Feb 18 12:43:27.572: INFO: Restart count of pod container-probe-8285/liveness-http is now 1 (24.035967445s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:43:27.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8285" for this suite.
Feb 18 12:43:33.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:43:33.754: INFO: namespace container-probe-8285 deletion completed in 6.168715979s

• [SLOW TEST:34.254 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:43:33.754: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:43:33.778: INFO: Creating deployment "test-recreate-deployment"
Feb 18 12:43:33.780: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 18 12:43:33.787: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 18 12:43:35.792: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 18 12:43:35.793: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 18 12:43:35.797: INFO: Updating deployment test-recreate-deployment
Feb 18 12:43:35.797: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 12:43:35.847: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-724,SelfLink:/apis/apps/v1/namespaces/deployment-724/deployments/test-recreate-deployment,UID:464209f7-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:14373,Generation:2,CreationTimestamp:2020-02-18 12:43:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2020-02-18 12:43:35 +0000 UTC 2020-02-18 12:43:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2020-02-18 12:43:35 +0000 UTC 2020-02-18 12:43:33 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-745fb9c84c" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 18 12:43:35.851: INFO: New ReplicaSet "test-recreate-deployment-745fb9c84c" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c,GenerateName:,Namespace:deployment-724,SelfLink:/apis/apps/v1/namespaces/deployment-724/replicasets/test-recreate-deployment-745fb9c84c,UID:47798b88-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:14370,Generation:1,CreationTimestamp:2020-02-18 12:43:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 464209f7-524c-11ea-b701-0ae3ad6fc27e 0xc002b381f7 0xc002b381f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 12:43:35.852: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 18 12:43:35.852: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6566d46b4b,GenerateName:,Namespace:deployment-724,SelfLink:/apis/apps/v1/namespaces/deployment-724/replicasets/test-recreate-deployment-6566d46b4b,UID:464287a6-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:14362,Generation:2,CreationTimestamp:2020-02-18 12:43:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 464209f7-524c-11ea-b701-0ae3ad6fc27e 0xc002b38127 0xc002b38128}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6566d46b4b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 12:43:35.854: INFO: Pod "test-recreate-deployment-745fb9c84c-l9zwz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-745fb9c84c-l9zwz,GenerateName:test-recreate-deployment-745fb9c84c-,Namespace:deployment-724,SelfLink:/api/v1/namespaces/deployment-724/pods/test-recreate-deployment-745fb9c84c-l9zwz,UID:4779f454-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:14374,Generation:0,CreationTimestamp:2020-02-18 12:43:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 745fb9c84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-745fb9c84c 47798b88-524c-11ea-b701-0ae3ad6fc27e 0xc002e3e117 0xc002e3e118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ppq5s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ppq5s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ppq5s true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3e180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3e1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:43:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:43:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:43:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:43:35 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:,StartTime:2020-02-18 12:43:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:43:35.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-724" for this suite.
Feb 18 12:43:41.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:43:42.022: INFO: namespace deployment-724 deletion completed in 6.166771736s

• [SLOW TEST:8.268 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:43:42.023: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-4b2c884b-524c-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:43:42.056: INFO: Waiting up to 5m0s for pod "pod-configmaps-4b2dd57b-524c-11ea-bd69-fac0b7afc6af" in namespace "configmap-9800" to be "success or failure"
Feb 18 12:43:42.060: INFO: Pod "pod-configmaps-4b2dd57b-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.393747ms
Feb 18 12:43:44.063: INFO: Pod "pod-configmaps-4b2dd57b-524c-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007332693s
STEP: Saw pod success
Feb 18 12:43:44.063: INFO: Pod "pod-configmaps-4b2dd57b-524c-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:43:44.069: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-4b2dd57b-524c-11ea-bd69-fac0b7afc6af container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:43:44.108: INFO: Waiting for pod pod-configmaps-4b2dd57b-524c-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:43:44.120: INFO: Pod pod-configmaps-4b2dd57b-524c-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:43:44.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9800" for this suite.
Feb 18 12:43:50.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:43:50.289: INFO: namespace configmap-9800 deletion completed in 6.166955002s

• [SLOW TEST:8.266 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:43:50.289: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-5019f780-524c-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:43:50.433: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-501a8bb8-524c-11ea-bd69-fac0b7afc6af" in namespace "projected-1005" to be "success or failure"
Feb 18 12:43:50.499: INFO: Pod "pod-projected-configmaps-501a8bb8-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 66.455534ms
Feb 18 12:43:52.502: INFO: Pod "pod-projected-configmaps-501a8bb8-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06882011s
Feb 18 12:43:54.504: INFO: Pod "pod-projected-configmaps-501a8bb8-524c-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071040659s
STEP: Saw pod success
Feb 18 12:43:54.504: INFO: Pod "pod-projected-configmaps-501a8bb8-524c-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:43:54.506: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-configmaps-501a8bb8-524c-11ea-bd69-fac0b7afc6af container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:43:54.519: INFO: Waiting for pod pod-projected-configmaps-501a8bb8-524c-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:43:54.522: INFO: Pod pod-projected-configmaps-501a8bb8-524c-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:43:54.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1005" for this suite.
Feb 18 12:44:00.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:44:00.691: INFO: namespace projected-1005 deletion completed in 6.166644173s

• [SLOW TEST:10.402 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:44:00.691: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-zx6hz in namespace proxy-961
I0218 12:44:00.784738      16 runners.go:184] Created replication controller with name: proxy-service-zx6hz, namespace: proxy-961, replica count: 1
I0218 12:44:01.835365      16 runners.go:184] proxy-service-zx6hz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0218 12:44:02.835508      16 runners.go:184] proxy-service-zx6hz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0218 12:44:03.835654      16 runners.go:184] proxy-service-zx6hz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0218 12:44:04.835788      16 runners.go:184] proxy-service-zx6hz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0218 12:44:05.835932      16 runners.go:184] proxy-service-zx6hz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0218 12:44:06.836079      16 runners.go:184] proxy-service-zx6hz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0218 12:44:07.836194      16 runners.go:184] proxy-service-zx6hz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0218 12:44:08.836362      16 runners.go:184] proxy-service-zx6hz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 18 12:44:08.838: INFO: setup took 8.067996457s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 18 12:44:08.846: INFO: (0) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 7.891353ms)
Feb 18 12:44:08.849: INFO: (0) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 11.57552ms)
Feb 18 12:44:08.851: INFO: (0) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 12.596316ms)
Feb 18 12:44:08.851: INFO: (0) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 13.102264ms)
Feb 18 12:44:08.852: INFO: (0) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 13.550789ms)
Feb 18 12:44:08.852: INFO: (0) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 13.623642ms)
Feb 18 12:44:08.852: INFO: (0) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 13.696268ms)
Feb 18 12:44:08.852: INFO: (0) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 13.6975ms)
Feb 18 12:44:08.852: INFO: (0) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 13.953078ms)
Feb 18 12:44:08.852: INFO: (0) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 14.048927ms)
Feb 18 12:44:08.852: INFO: (0) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 14.449931ms)
Feb 18 12:44:08.857: INFO: (0) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 18.781227ms)
Feb 18 12:44:08.857: INFO: (0) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 19.461961ms)
Feb 18 12:44:08.859: INFO: (0) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 20.930646ms)
Feb 18 12:44:08.859: INFO: (0) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 21.378065ms)
Feb 18 12:44:08.860: INFO: (0) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 21.673286ms)
Feb 18 12:44:08.865: INFO: (1) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 5.327904ms)
Feb 18 12:44:08.868: INFO: (1) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.155561ms)
Feb 18 12:44:08.868: INFO: (1) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 8.134614ms)
Feb 18 12:44:08.868: INFO: (1) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 8.356948ms)
Feb 18 12:44:08.868: INFO: (1) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.492692ms)
Feb 18 12:44:08.869: INFO: (1) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 8.550057ms)
Feb 18 12:44:08.870: INFO: (1) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 9.695195ms)
Feb 18 12:44:08.870: INFO: (1) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 10.282785ms)
Feb 18 12:44:08.870: INFO: (1) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 10.074572ms)
Feb 18 12:44:08.870: INFO: (1) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 9.884192ms)
Feb 18 12:44:08.870: INFO: (1) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.566916ms)
Feb 18 12:44:08.870: INFO: (1) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 10.359213ms)
Feb 18 12:44:08.870: INFO: (1) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 10.553912ms)
Feb 18 12:44:08.870: INFO: (1) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.485263ms)
Feb 18 12:44:08.870: INFO: (1) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 10.252741ms)
Feb 18 12:44:08.871: INFO: (1) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.45259ms)
Feb 18 12:44:08.878: INFO: (2) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 6.878872ms)
Feb 18 12:44:08.878: INFO: (2) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 7.322093ms)
Feb 18 12:44:08.878: INFO: (2) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 7.504299ms)
Feb 18 12:44:08.879: INFO: (2) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 8.211702ms)
Feb 18 12:44:08.879: INFO: (2) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 8.715295ms)
Feb 18 12:44:08.880: INFO: (2) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 8.959823ms)
Feb 18 12:44:08.880: INFO: (2) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.91891ms)
Feb 18 12:44:08.880: INFO: (2) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 9.58392ms)
Feb 18 12:44:08.880: INFO: (2) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 9.726716ms)
Feb 18 12:44:08.881: INFO: (2) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.100917ms)
Feb 18 12:44:08.881: INFO: (2) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 10.102574ms)
Feb 18 12:44:08.881: INFO: (2) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 10.392418ms)
Feb 18 12:44:08.881: INFO: (2) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 10.524664ms)
Feb 18 12:44:08.881: INFO: (2) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 10.768194ms)
Feb 18 12:44:08.882: INFO: (2) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 10.764769ms)
Feb 18 12:44:08.882: INFO: (2) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 11.019061ms)
Feb 18 12:44:08.889: INFO: (3) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 7.313621ms)
Feb 18 12:44:08.889: INFO: (3) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 7.636754ms)
Feb 18 12:44:08.891: INFO: (3) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 9.221498ms)
Feb 18 12:44:08.891: INFO: (3) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 9.637144ms)
Feb 18 12:44:08.892: INFO: (3) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 9.824893ms)
Feb 18 12:44:08.892: INFO: (3) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 9.989527ms)
Feb 18 12:44:08.892: INFO: (3) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.833286ms)
Feb 18 12:44:08.892: INFO: (3) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 9.874891ms)
Feb 18 12:44:08.892: INFO: (3) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.668415ms)
Feb 18 12:44:08.893: INFO: (3) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.823542ms)
Feb 18 12:44:08.893: INFO: (3) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 11.054469ms)
Feb 18 12:44:08.893: INFO: (3) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 11.21929ms)
Feb 18 12:44:08.893: INFO: (3) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 11.246267ms)
Feb 18 12:44:08.893: INFO: (3) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 11.497827ms)
Feb 18 12:44:08.893: INFO: (3) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 11.480089ms)
Feb 18 12:44:08.894: INFO: (3) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 12.531632ms)
Feb 18 12:44:08.901: INFO: (4) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 6.937075ms)
Feb 18 12:44:08.902: INFO: (4) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 7.330475ms)
Feb 18 12:44:08.902: INFO: (4) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 7.20857ms)
Feb 18 12:44:08.902: INFO: (4) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 7.567312ms)
Feb 18 12:44:08.902: INFO: (4) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 7.984188ms)
Feb 18 12:44:08.903: INFO: (4) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 8.269903ms)
Feb 18 12:44:08.903: INFO: (4) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 8.321218ms)
Feb 18 12:44:08.903: INFO: (4) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.360643ms)
Feb 18 12:44:08.903: INFO: (4) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 8.39827ms)
Feb 18 12:44:08.904: INFO: (4) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 9.441569ms)
Feb 18 12:44:08.904: INFO: (4) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 9.424265ms)
Feb 18 12:44:08.905: INFO: (4) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 10.6785ms)
Feb 18 12:44:08.905: INFO: (4) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 10.897995ms)
Feb 18 12:44:08.905: INFO: (4) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 10.849225ms)
Feb 18 12:44:08.905: INFO: (4) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.904703ms)
Feb 18 12:44:08.906: INFO: (4) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 11.587763ms)
Feb 18 12:44:08.913: INFO: (5) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 6.573433ms)
Feb 18 12:44:08.914: INFO: (5) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 7.264639ms)
Feb 18 12:44:08.914: INFO: (5) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 7.578023ms)
Feb 18 12:44:08.914: INFO: (5) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 7.988566ms)
Feb 18 12:44:08.915: INFO: (5) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.674881ms)
Feb 18 12:44:08.915: INFO: (5) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 8.840517ms)
Feb 18 12:44:08.916: INFO: (5) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 9.461862ms)
Feb 18 12:44:08.916: INFO: (5) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 9.73521ms)
Feb 18 12:44:08.916: INFO: (5) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 10.0164ms)
Feb 18 12:44:08.917: INFO: (5) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 10.677705ms)
Feb 18 12:44:08.917: INFO: (5) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.656505ms)
Feb 18 12:44:08.917: INFO: (5) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 10.897719ms)
Feb 18 12:44:08.917: INFO: (5) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.910231ms)
Feb 18 12:44:08.917: INFO: (5) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 10.967675ms)
Feb 18 12:44:08.917: INFO: (5) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 11.150996ms)
Feb 18 12:44:08.918: INFO: (5) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 11.957874ms)
Feb 18 12:44:08.927: INFO: (6) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 8.406743ms)
Feb 18 12:44:08.927: INFO: (6) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 8.680717ms)
Feb 18 12:44:08.927: INFO: (6) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 8.96188ms)
Feb 18 12:44:08.927: INFO: (6) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 8.999345ms)
Feb 18 12:44:08.927: INFO: (6) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 8.948553ms)
Feb 18 12:44:08.927: INFO: (6) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 9.072657ms)
Feb 18 12:44:08.928: INFO: (6) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 9.339257ms)
Feb 18 12:44:08.929: INFO: (6) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.356858ms)
Feb 18 12:44:08.929: INFO: (6) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 10.510552ms)
Feb 18 12:44:08.929: INFO: (6) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 10.370731ms)
Feb 18 12:44:08.929: INFO: (6) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 10.503649ms)
Feb 18 12:44:08.929: INFO: (6) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 10.747803ms)
Feb 18 12:44:08.929: INFO: (6) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 10.75663ms)
Feb 18 12:44:08.929: INFO: (6) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.791839ms)
Feb 18 12:44:08.929: INFO: (6) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 11.138218ms)
Feb 18 12:44:08.930: INFO: (6) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 11.880818ms)
Feb 18 12:44:08.941: INFO: (7) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 10.647395ms)
Feb 18 12:44:08.942: INFO: (7) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 11.454721ms)
Feb 18 12:44:08.943: INFO: (7) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 12.290899ms)
Feb 18 12:44:08.943: INFO: (7) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 12.520662ms)
Feb 18 12:44:08.943: INFO: (7) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 12.652331ms)
Feb 18 12:44:08.943: INFO: (7) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 12.945122ms)
Feb 18 12:44:08.943: INFO: (7) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 12.897306ms)
Feb 18 12:44:08.944: INFO: (7) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 13.209026ms)
Feb 18 12:44:08.944: INFO: (7) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 13.684055ms)
Feb 18 12:44:08.944: INFO: (7) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 13.705767ms)
Feb 18 12:44:08.946: INFO: (7) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 15.332259ms)
Feb 18 12:44:08.946: INFO: (7) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 15.590719ms)
Feb 18 12:44:08.946: INFO: (7) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 15.699993ms)
Feb 18 12:44:08.946: INFO: (7) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 15.907797ms)
Feb 18 12:44:08.946: INFO: (7) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 15.846026ms)
Feb 18 12:44:08.946: INFO: (7) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 15.955044ms)
Feb 18 12:44:08.954: INFO: (8) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 7.09389ms)
Feb 18 12:44:08.954: INFO: (8) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 7.208215ms)
Feb 18 12:44:08.954: INFO: (8) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 7.462118ms)
Feb 18 12:44:08.954: INFO: (8) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 7.833441ms)
Feb 18 12:44:08.955: INFO: (8) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 8.62494ms)
Feb 18 12:44:08.955: INFO: (8) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 8.778435ms)
Feb 18 12:44:08.955: INFO: (8) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 8.996801ms)
Feb 18 12:44:08.956: INFO: (8) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.909234ms)
Feb 18 12:44:08.956: INFO: (8) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 9.120077ms)
Feb 18 12:44:08.956: INFO: (8) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 9.171894ms)
Feb 18 12:44:08.956: INFO: (8) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 9.479594ms)
Feb 18 12:44:08.957: INFO: (8) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.149623ms)
Feb 18 12:44:08.957: INFO: (8) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 10.06881ms)
Feb 18 12:44:08.957: INFO: (8) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 10.577986ms)
Feb 18 12:44:08.957: INFO: (8) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 10.615756ms)
Feb 18 12:44:08.957: INFO: (8) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.672733ms)
Feb 18 12:44:08.964: INFO: (9) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 6.062531ms)
Feb 18 12:44:08.964: INFO: (9) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 6.105809ms)
Feb 18 12:44:08.964: INFO: (9) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 6.533253ms)
Feb 18 12:44:08.964: INFO: (9) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 6.679377ms)
Feb 18 12:44:08.965: INFO: (9) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 7.378287ms)
Feb 18 12:44:08.965: INFO: (9) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 7.754544ms)
Feb 18 12:44:08.965: INFO: (9) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 7.837105ms)
Feb 18 12:44:08.966: INFO: (9) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 8.164158ms)
Feb 18 12:44:08.966: INFO: (9) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 8.378083ms)
Feb 18 12:44:08.966: INFO: (9) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.506255ms)
Feb 18 12:44:08.968: INFO: (9) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.6016ms)
Feb 18 12:44:08.968: INFO: (9) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 10.621154ms)
Feb 18 12:44:08.968: INFO: (9) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.703194ms)
Feb 18 12:44:08.968: INFO: (9) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 10.792864ms)
Feb 18 12:44:08.969: INFO: (9) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 10.951268ms)
Feb 18 12:44:08.969: INFO: (9) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 11.31448ms)
Feb 18 12:44:08.974: INFO: (10) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 5.51836ms)
Feb 18 12:44:08.976: INFO: (10) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 6.720485ms)
Feb 18 12:44:08.976: INFO: (10) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 7.369399ms)
Feb 18 12:44:08.976: INFO: (10) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 7.426072ms)
Feb 18 12:44:08.976: INFO: (10) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 7.526934ms)
Feb 18 12:44:08.976: INFO: (10) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 7.532616ms)
Feb 18 12:44:08.978: INFO: (10) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 9.085767ms)
Feb 18 12:44:08.978: INFO: (10) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 9.208894ms)
Feb 18 12:44:08.978: INFO: (10) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.288347ms)
Feb 18 12:44:08.978: INFO: (10) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 9.318157ms)
Feb 18 12:44:08.978: INFO: (10) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 9.46776ms)
Feb 18 12:44:08.978: INFO: (10) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 9.477281ms)
Feb 18 12:44:08.979: INFO: (10) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 9.743273ms)
Feb 18 12:44:08.979: INFO: (10) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.352461ms)
Feb 18 12:44:08.979: INFO: (10) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 10.653323ms)
Feb 18 12:44:08.980: INFO: (10) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 11.459194ms)
Feb 18 12:44:08.984: INFO: (11) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 3.869743ms)
Feb 18 12:44:08.989: INFO: (11) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.943108ms)
Feb 18 12:44:08.989: INFO: (11) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 9.11511ms)
Feb 18 12:44:08.991: INFO: (11) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 10.83099ms)
Feb 18 12:44:08.991: INFO: (11) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.656905ms)
Feb 18 12:44:08.991: INFO: (11) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 10.869556ms)
Feb 18 12:44:08.991: INFO: (11) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 11.016523ms)
Feb 18 12:44:08.992: INFO: (11) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 11.821548ms)
Feb 18 12:44:08.993: INFO: (11) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 12.024848ms)
Feb 18 12:44:08.993: INFO: (11) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 12.336758ms)
Feb 18 12:44:08.993: INFO: (11) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 12.226595ms)
Feb 18 12:44:08.993: INFO: (11) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 12.228954ms)
Feb 18 12:44:08.993: INFO: (11) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 12.315189ms)
Feb 18 12:44:08.993: INFO: (11) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 12.372896ms)
Feb 18 12:44:08.993: INFO: (11) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 12.63817ms)
Feb 18 12:44:08.993: INFO: (11) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 12.595541ms)
Feb 18 12:44:08.999: INFO: (12) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 6.254032ms)
Feb 18 12:44:09.000: INFO: (12) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 6.440492ms)
Feb 18 12:44:09.001: INFO: (12) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 7.466272ms)
Feb 18 12:44:09.001: INFO: (12) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 7.592254ms)
Feb 18 12:44:09.001: INFO: (12) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 8.312817ms)
Feb 18 12:44:09.002: INFO: (12) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.329133ms)
Feb 18 12:44:09.002: INFO: (12) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 8.63582ms)
Feb 18 12:44:09.002: INFO: (12) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 8.832233ms)
Feb 18 12:44:09.002: INFO: (12) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 8.77558ms)
Feb 18 12:44:09.002: INFO: (12) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 8.953308ms)
Feb 18 12:44:09.002: INFO: (12) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 8.979327ms)
Feb 18 12:44:09.002: INFO: (12) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 9.213566ms)
Feb 18 12:44:09.002: INFO: (12) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 9.260049ms)
Feb 18 12:44:09.004: INFO: (12) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 11.040565ms)
Feb 18 12:44:09.004: INFO: (12) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 11.157903ms)
Feb 18 12:44:09.005: INFO: (12) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 11.431334ms)
Feb 18 12:44:09.011: INFO: (13) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 6.066389ms)
Feb 18 12:44:09.012: INFO: (13) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 6.938183ms)
Feb 18 12:44:09.013: INFO: (13) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 7.845528ms)
Feb 18 12:44:09.014: INFO: (13) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 9.41164ms)
Feb 18 12:44:09.014: INFO: (13) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 9.390267ms)
Feb 18 12:44:09.014: INFO: (13) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 9.582124ms)
Feb 18 12:44:09.015: INFO: (13) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.661262ms)
Feb 18 12:44:09.015: INFO: (13) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 10.127951ms)
Feb 18 12:44:09.015: INFO: (13) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 10.282862ms)
Feb 18 12:44:09.015: INFO: (13) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.434498ms)
Feb 18 12:44:09.015: INFO: (13) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 10.521077ms)
Feb 18 12:44:09.015: INFO: (13) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 10.639876ms)
Feb 18 12:44:09.016: INFO: (13) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.67675ms)
Feb 18 12:44:09.016: INFO: (13) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 10.765753ms)
Feb 18 12:44:09.016: INFO: (13) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 11.105751ms)
Feb 18 12:44:09.016: INFO: (13) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 11.212764ms)
Feb 18 12:44:09.025: INFO: (14) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 8.420015ms)
Feb 18 12:44:09.025: INFO: (14) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 9.272598ms)
Feb 18 12:44:09.025: INFO: (14) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 9.317913ms)
Feb 18 12:44:09.026: INFO: (14) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 9.441435ms)
Feb 18 12:44:09.026: INFO: (14) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 9.506888ms)
Feb 18 12:44:09.026: INFO: (14) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 9.328178ms)
Feb 18 12:44:09.026: INFO: (14) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 9.961531ms)
Feb 18 12:44:09.026: INFO: (14) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.141362ms)
Feb 18 12:44:09.026: INFO: (14) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.353473ms)
Feb 18 12:44:09.026: INFO: (14) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.929843ms)
Feb 18 12:44:09.026: INFO: (14) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 10.150322ms)
Feb 18 12:44:09.027: INFO: (14) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 10.387672ms)
Feb 18 12:44:09.027: INFO: (14) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.735033ms)
Feb 18 12:44:09.027: INFO: (14) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 10.397399ms)
Feb 18 12:44:09.027: INFO: (14) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 10.816777ms)
Feb 18 12:44:09.027: INFO: (14) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 11.297517ms)
Feb 18 12:44:09.035: INFO: (15) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 7.439057ms)
Feb 18 12:44:09.035: INFO: (15) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 7.743098ms)
Feb 18 12:44:09.036: INFO: (15) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 8.034946ms)
Feb 18 12:44:09.036: INFO: (15) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 7.996781ms)
Feb 18 12:44:09.036: INFO: (15) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 8.679528ms)
Feb 18 12:44:09.037: INFO: (15) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 9.392795ms)
Feb 18 12:44:09.037: INFO: (15) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.234599ms)
Feb 18 12:44:09.037: INFO: (15) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.469307ms)
Feb 18 12:44:09.037: INFO: (15) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 9.511384ms)
Feb 18 12:44:09.038: INFO: (15) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 9.93082ms)
Feb 18 12:44:09.038: INFO: (15) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.381552ms)
Feb 18 12:44:09.038: INFO: (15) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.673999ms)
Feb 18 12:44:09.039: INFO: (15) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 10.990591ms)
Feb 18 12:44:09.039: INFO: (15) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 11.125444ms)
Feb 18 12:44:09.039: INFO: (15) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 11.381794ms)
Feb 18 12:44:09.039: INFO: (15) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 11.319743ms)
Feb 18 12:44:09.047: INFO: (16) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 7.560279ms)
Feb 18 12:44:09.047: INFO: (16) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 7.487603ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 14.693456ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 14.512697ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 14.403807ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 14.087874ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 14.171506ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 14.36235ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 15.18701ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 14.545284ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 15.063506ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 14.279008ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 14.997646ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 14.541692ms)
Feb 18 12:44:09.054: INFO: (16) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 14.369407ms)
Feb 18 12:44:09.059: INFO: (16) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 19.549502ms)
Feb 18 12:44:09.063: INFO: (17) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 3.147443ms)
Feb 18 12:44:09.063: INFO: (17) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 3.20593ms)
Feb 18 12:44:09.068: INFO: (17) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 7.811712ms)
Feb 18 12:44:09.068: INFO: (17) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 8.050438ms)
Feb 18 12:44:09.068: INFO: (17) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 8.265927ms)
Feb 18 12:44:09.068: INFO: (17) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 8.686721ms)
Feb 18 12:44:09.069: INFO: (17) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 9.195047ms)
Feb 18 12:44:09.070: INFO: (17) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.691795ms)
Feb 18 12:44:09.070: INFO: (17) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 10.043944ms)
Feb 18 12:44:09.070: INFO: (17) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.787234ms)
Feb 18 12:44:09.070: INFO: (17) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.051988ms)
Feb 18 12:44:09.070: INFO: (17) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.070128ms)
Feb 18 12:44:09.070: INFO: (17) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 10.320035ms)
Feb 18 12:44:09.072: INFO: (17) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 11.756742ms)
Feb 18 12:44:09.072: INFO: (17) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 12.234977ms)
Feb 18 12:44:09.072: INFO: (17) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 12.309539ms)
Feb 18 12:44:09.081: INFO: (18) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 8.699555ms)
Feb 18 12:44:09.081: INFO: (18) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 8.786297ms)
Feb 18 12:44:09.082: INFO: (18) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.068885ms)
Feb 18 12:44:09.082: INFO: (18) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 9.256234ms)
Feb 18 12:44:09.082: INFO: (18) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 9.310964ms)
Feb 18 12:44:09.082: INFO: (18) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 9.215822ms)
Feb 18 12:44:09.082: INFO: (18) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 9.725254ms)
Feb 18 12:44:09.082: INFO: (18) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 9.50006ms)
Feb 18 12:44:09.082: INFO: (18) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 9.602021ms)
Feb 18 12:44:09.083: INFO: (18) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 9.769495ms)
Feb 18 12:44:09.083: INFO: (18) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 10.019574ms)
Feb 18 12:44:09.083: INFO: (18) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 9.972269ms)
Feb 18 12:44:09.083: INFO: (18) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 10.186638ms)
Feb 18 12:44:09.083: INFO: (18) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 10.474739ms)
Feb 18 12:44:09.084: INFO: (18) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.681314ms)
Feb 18 12:44:09.084: INFO: (18) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.896659ms)
Feb 18 12:44:09.088: INFO: (19) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 4.202859ms)
Feb 18 12:44:09.093: INFO: (19) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.03448ms)
Feb 18 12:44:09.093: INFO: (19) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:443/proxy/tlsrewriteme... (200; 9.479584ms)
Feb 18 12:44:09.093: INFO: (19) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:162/proxy/: bar (200; 9.588961ms)
Feb 18 12:44:09.093: INFO: (19) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz/proxy/rewriteme">test</a> (200; 9.558843ms)
Feb 18 12:44:09.093: INFO: (19) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:462/proxy/: tls qux (200; 9.694815ms)
Feb 18 12:44:09.094: INFO: (19) /api/v1/namespaces/proxy-961/pods/https:proxy-service-zx6hz-wq4mz:460/proxy/: tls baz (200; 9.805819ms)
Feb 18 12:44:09.094: INFO: (19) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">t... (200; 10.106052ms)
Feb 18 12:44:09.094: INFO: (19) /api/v1/namespaces/proxy-961/pods/http:proxy-service-zx6hz-wq4mz:160/proxy/: foo (200; 10.080794ms)
Feb 18 12:44:09.094: INFO: (19) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname1/proxy/: tls baz (200; 10.387575ms)
Feb 18 12:44:09.094: INFO: (19) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname2/proxy/: bar (200; 10.425592ms)
Feb 18 12:44:09.094: INFO: (19) /api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/: <a href="/api/v1/namespaces/proxy-961/pods/proxy-service-zx6hz-wq4mz:1080/proxy/rewriteme">test</... (200; 10.717267ms)
Feb 18 12:44:09.094: INFO: (19) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname2/proxy/: bar (200; 10.714012ms)
Feb 18 12:44:09.094: INFO: (19) /api/v1/namespaces/proxy-961/services/http:proxy-service-zx6hz:portname1/proxy/: foo (200; 10.644671ms)
Feb 18 12:44:09.095: INFO: (19) /api/v1/namespaces/proxy-961/services/proxy-service-zx6hz:portname1/proxy/: foo (200; 10.705619ms)
Feb 18 12:44:09.096: INFO: (19) /api/v1/namespaces/proxy-961/services/https:proxy-service-zx6hz:tlsportname2/proxy/: tls qux (200; 12.055064ms)
STEP: deleting ReplicationController proxy-service-zx6hz in namespace proxy-961, will wait for the garbage collector to delete the pods
Feb 18 12:44:09.154: INFO: Deleting ReplicationController proxy-service-zx6hz took: 6.622441ms
Feb 18 12:44:09.654: INFO: Terminating ReplicationController proxy-service-zx6hz pods took: 500.305537ms
[AfterEach] version v1
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:44:23.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-961" for this suite.
Feb 18 12:44:29.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:44:29.148: INFO: namespace proxy-961 deletion completed in 6.085437008s

• [SLOW TEST:28.456 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:44:29.148: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb 18 12:44:29.222: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 18 12:44:38.257: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:44:38.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2954" for this suite.
Feb 18 12:44:44.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:44:44.430: INFO: namespace pods-2954 deletion completed in 6.168612424s

• [SLOW TEST:15.282 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:44:44.430: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-7060bce1-524c-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 12:44:44.475: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-70623b70-524c-11ea-bd69-fac0b7afc6af" in namespace "projected-8921" to be "success or failure"
Feb 18 12:44:44.480: INFO: Pod "pod-projected-secrets-70623b70-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.569815ms
Feb 18 12:44:46.483: INFO: Pod "pod-projected-secrets-70623b70-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007621989s
Feb 18 12:44:48.485: INFO: Pod "pod-projected-secrets-70623b70-524c-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010218386s
STEP: Saw pod success
Feb 18 12:44:48.485: INFO: Pod "pod-projected-secrets-70623b70-524c-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:44:48.488: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-secrets-70623b70-524c-11ea-bd69-fac0b7afc6af container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 12:44:48.505: INFO: Waiting for pod pod-projected-secrets-70623b70-524c-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:44:48.507: INFO: Pod pod-projected-secrets-70623b70-524c-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:44:48.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8921" for this suite.
Feb 18 12:44:54.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:44:54.676: INFO: namespace projected-8921 deletion completed in 6.167020008s

• [SLOW TEST:10.246 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:44:54.676: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 18 12:44:54.695: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 18 12:44:54.699: INFO: Waiting for terminating namespaces to be deleted...
Feb 18 12:44:54.700: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-116.eu-west-1.compute.internal before test
Feb 18 12:44:54.706: INFO: calico-node-5nng8 from kube-system started at 2020-02-18 12:04:31 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container calico-node ready: true, restart count 0
Feb 18 12:44:54.706: INFO: node-exporter-phhnx from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container node-exporter ready: true, restart count 0
Feb 18 12:44:54.706: INFO: nginx-ingress-controller-bzkzv from ingress-nginx started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 18 12:44:54.706: INFO: velero-restic-76fnt from kube-system started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container restic ready: true, restart count 0
Feb 18 12:44:54.706: INFO: sonobuoy-systemd-logs-daemon-set-31cf4124bed54e00-jh6ql from sonobuoy started at 2020-02-18 12:09:27 +0000 UTC (2 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 12:44:54.706: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 18 12:44:54.706: INFO: kube-proxy-spwpp from kube-system started at 2020-02-18 11:58:33 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 18 12:44:54.706: INFO: elasticsearch-0 from logging started at 2020-02-18 12:05:24 +0000 UTC (2 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container elasticsearch ready: true, restart count 0
Feb 18 12:44:54.706: INFO: 	Container exporter ready: true, restart count 0
Feb 18 12:44:54.706: INFO: prometheus-k8s-0 from monitoring started at 2020-02-18 12:06:25 +0000 UTC (3 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container prometheus ready: true, restart count 1
Feb 18 12:44:54.706: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb 18 12:44:54.706: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb 18 12:44:54.706: INFO: fluentd-cfbcp from logging started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container fluentd ready: true, restart count 0
Feb 18 12:44:54.706: INFO: goldpinger-mpmjx from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container goldpinger ready: true, restart count 0
Feb 18 12:44:54.706: INFO: coredns-6dcc67dcbc-kzd86 from kube-system started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container coredns ready: true, restart count 0
Feb 18 12:44:54.706: INFO: minio-setup-b9gv4 from kube-system started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.706: INFO: 	Container mc ready: false, restart count 4
Feb 18 12:44:54.706: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-235.eu-west-1.compute.internal before test
Feb 18 12:44:54.713: INFO: nginx-ingress-controller-v98c7 from ingress-nginx started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 18 12:44:54.713: INFO: local-path-provisioner-74c64c9987-kxrk8 from local-path-storage started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container local-path-provisioner ready: true, restart count 0
Feb 18 12:44:54.713: INFO: calico-kube-controllers-784774949-2b5pl from kube-system started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 18 12:44:54.713: INFO: forecastle-788c565ff4-4k25g from ingress-nginx started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container forecastle ready: true, restart count 0
Feb 18 12:44:54.713: INFO: goldpinger-wm8hn from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container goldpinger ready: true, restart count 0
Feb 18 12:44:54.713: INFO: cert-manager-webhook-bf467d894-vxrds from cert-manager started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container webhook ready: true, restart count 0
Feb 18 12:44:54.713: INFO: sonobuoy-e2e-job-044c93865a804752 from sonobuoy started at 2020-02-18 12:09:27 +0000 UTC (2 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container e2e ready: true, restart count 0
Feb 18 12:44:54.713: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 12:44:54.713: INFO: velero-restic-bq46s from kube-system started at 2020-02-18 12:04:44 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container restic ready: true, restart count 0
Feb 18 12:44:54.713: INFO: kibana-6f49c4b465-vql5n from logging started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container kibana ready: true, restart count 0
Feb 18 12:44:54.713: INFO: grafana-68f989d655-kcwx2 from monitoring started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container grafana ready: true, restart count 0
Feb 18 12:44:54.713: INFO: cert-manager-cainjector-78dcdf7fd7-fpcfb from cert-manager started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container cainjector ready: true, restart count 0
Feb 18 12:44:54.713: INFO: cerebro-7b55c4d445-2zks6 from logging started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container cerebro ready: true, restart count 0
Feb 18 12:44:54.713: INFO: minio-0 from kube-system started at 2020-02-18 12:06:16 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container minio ready: true, restart count 0
Feb 18 12:44:54.713: INFO: sonobuoy-systemd-logs-daemon-set-31cf4124bed54e00-qvtk7 from sonobuoy started at 2020-02-18 12:09:27 +0000 UTC (2 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 18 12:44:54.713: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 18 12:44:54.713: INFO: kube-state-metrics-5c9968c7dd-q9xj7 from monitoring started at 2020-02-18 12:06:32 +0000 UTC (2 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 18 12:44:54.713: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 18 12:44:54.713: INFO: kube-proxy-gwwx8 from kube-system started at 2020-02-18 11:58:33 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 18 12:44:54.713: INFO: coredns-6dcc67dcbc-w68cb from kube-system started at 2020-02-18 12:04:45 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container coredns ready: true, restart count 0
Feb 18 12:44:54.713: INFO: calico-node-2clft from kube-system started at 2020-02-18 12:04:31 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container calico-node ready: true, restart count 0
Feb 18 12:44:54.713: INFO: node-exporter-8wxrs from monitoring started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container node-exporter ready: true, restart count 0
Feb 18 12:44:54.713: INFO: velero-5b65f87655-pngzh from kube-system started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container velero ready: true, restart count 0
Feb 18 12:44:54.713: INFO: cert-manager-6c8d45976-vwf68 from cert-manager started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container cert-manager ready: true, restart count 0
Feb 18 12:44:54.713: INFO: fluentd-wcktw from logging started at 2020-02-18 12:04:32 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container fluentd ready: true, restart count 0
Feb 18 12:44:54.713: INFO: prometheus-operator-85d4fd776c-zc59s from monitoring started at 2020-02-18 12:04:46 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb 18 12:44:54.713: INFO: sonobuoy from sonobuoy started at 2020-02-18 12:09:21 +0000 UTC (1 container statuses recorded)
Feb 18 12:44:54.713: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-78e2eb8a-524c-11ea-bd69-fac0b7afc6af 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-78e2eb8a-524c-11ea-bd69-fac0b7afc6af off the node ip-10-100-10-235.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-78e2eb8a-524c-11ea-bd69-fac0b7afc6af
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:45:02.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8768" for this suite.
Feb 18 12:45:14.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:45:14.948: INFO: namespace sched-pred-8768 deletion completed in 12.166136931s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:20.272 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:45:14.948: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 18 12:45:14.989: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:14.990: INFO: Number of nodes with available pods: 0
Feb 18 12:45:14.990: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:45:16.001: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:16.017: INFO: Number of nodes with available pods: 0
Feb 18 12:45:16.017: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:45:16.993: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:16.995: INFO: Number of nodes with available pods: 0
Feb 18 12:45:16.995: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:45:17.993: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:17.995: INFO: Number of nodes with available pods: 2
Feb 18 12:45:17.995: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 18 12:45:18.005: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:18.007: INFO: Number of nodes with available pods: 1
Feb 18 12:45:18.007: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:45:19.009: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:19.011: INFO: Number of nodes with available pods: 1
Feb 18 12:45:19.011: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:45:20.010: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:20.011: INFO: Number of nodes with available pods: 1
Feb 18 12:45:20.011: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:45:21.009: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:21.011: INFO: Number of nodes with available pods: 1
Feb 18 12:45:21.011: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:45:22.009: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:22.011: INFO: Number of nodes with available pods: 1
Feb 18 12:45:22.011: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:45:23.010: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:23.011: INFO: Number of nodes with available pods: 1
Feb 18 12:45:23.011: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:45:24.012: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:45:24.014: INFO: Number of nodes with available pods: 2
Feb 18 12:45:24.014: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7699, will wait for the garbage collector to delete the pods
Feb 18 12:45:24.091: INFO: Deleting DaemonSet.extensions daemon-set took: 22.869927ms
Feb 18 12:45:24.591: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.174022ms
Feb 18 12:45:33.093: INFO: Number of nodes with available pods: 0
Feb 18 12:45:33.093: INFO: Number of running nodes: 0, number of available pods: 0
Feb 18 12:45:33.094: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7699/daemonsets","resourceVersion":"15033"},"items":null}

Feb 18 12:45:33.096: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7699/pods","resourceVersion":"15033"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:45:33.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7699" for this suite.
Feb 18 12:45:39.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:45:39.270: INFO: namespace daemonsets-7699 deletion completed in 6.167043979s

• [SLOW TEST:24.322 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:45:39.270: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Feb 18 12:45:39.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 api-versions'
Feb 18 12:45:39.355: INFO: stderr: ""
Feb 18 12:45:39.355: INFO: stdout: "admission.certmanager.k8s.io/v1beta1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncertmanager.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\nvelero.io/v1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:45:39.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5060" for this suite.
Feb 18 12:45:45.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:45:45.524: INFO: namespace kubectl-5060 deletion completed in 6.166334854s

• [SLOW TEST:6.253 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:45:45.524: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-94cb31c6-524c-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 12:45:45.560: INFO: Waiting up to 5m0s for pod "pod-secrets-94cb76eb-524c-11ea-bd69-fac0b7afc6af" in namespace "secrets-7164" to be "success or failure"
Feb 18 12:45:45.563: INFO: Pod "pod-secrets-94cb76eb-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.938762ms
Feb 18 12:45:47.566: INFO: Pod "pod-secrets-94cb76eb-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005197029s
Feb 18 12:45:49.568: INFO: Pod "pod-secrets-94cb76eb-524c-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007493823s
STEP: Saw pod success
Feb 18 12:45:49.568: INFO: Pod "pod-secrets-94cb76eb-524c-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:45:49.570: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-secrets-94cb76eb-524c-11ea-bd69-fac0b7afc6af container secret-env-test: <nil>
STEP: delete the pod
Feb 18 12:45:49.583: INFO: Waiting for pod pod-secrets-94cb76eb-524c-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:45:49.585: INFO: Pod pod-secrets-94cb76eb-524c-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:45:49.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7164" for this suite.
Feb 18 12:45:55.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:45:55.756: INFO: namespace secrets-7164 deletion completed in 6.169452448s

• [SLOW TEST:10.232 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:45:55.756: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Feb 18 12:45:55.778: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-639612178 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:45:55.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4695" for this suite.
Feb 18 12:46:01.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:46:02.000: INFO: namespace kubectl-4695 deletion completed in 6.16658128s

• [SLOW TEST:6.244 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:46:02.000: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5374.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5374.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 18 12:46:04.072: INFO: DNS probes using dns-5374/dns-test-9e9c0657-524c-11ea-bd69-fac0b7afc6af succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:46:04.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5374" for this suite.
Feb 18 12:46:10.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:46:10.265: INFO: namespace dns-5374 deletion completed in 6.172936517s

• [SLOW TEST:8.265 seconds]
[sig-network] DNS
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:46:10.265: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:46:10.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 version'
Feb 18 12:46:10.340: INFO: stderr: ""
Feb 18 12:46:10.340: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.10\", GitCommit:\"575467a0eaf3ca1f20eb86215b3bde40a5ae617a\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:41:00Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.10\", GitCommit:\"575467a0eaf3ca1f20eb86215b3bde40a5ae617a\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:32:32Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:46:10.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6662" for this suite.
Feb 18 12:46:16.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:46:16.512: INFO: namespace kubectl-6662 deletion completed in 6.16955074s

• [SLOW TEST:6.247 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:46:16.512: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-a7420a84-524c-11ea-bd69-fac0b7afc6af
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:46:16.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4053" for this suite.
Feb 18 12:46:22.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:46:22.704: INFO: namespace configmap-4053 deletion completed in 6.168321768s

• [SLOW TEST:6.192 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:46:22.705: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 18 12:46:22.784: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5848,SelfLink:/api/v1/namespaces/watch-5848/configmaps/e2e-watch-test-watch-closed,UID:aafe5c5d-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:15304,Generation:0,CreationTimestamp:2020-02-18 12:46:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 12:46:22.784: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5848,SelfLink:/api/v1/namespaces/watch-5848/configmaps/e2e-watch-test-watch-closed,UID:aafe5c5d-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:15305,Generation:0,CreationTimestamp:2020-02-18 12:46:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 18 12:46:22.791: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5848,SelfLink:/api/v1/namespaces/watch-5848/configmaps/e2e-watch-test-watch-closed,UID:aafe5c5d-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:15306,Generation:0,CreationTimestamp:2020-02-18 12:46:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 12:46:22.791: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5848,SelfLink:/api/v1/namespaces/watch-5848/configmaps/e2e-watch-test-watch-closed,UID:aafe5c5d-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:15307,Generation:0,CreationTimestamp:2020-02-18 12:46:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:46:22.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5848" for this suite.
Feb 18 12:46:28.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:46:28.959: INFO: namespace watch-5848 deletion completed in 6.16654408s

• [SLOW TEST:6.255 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:46:28.960: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-aeacecf6-524c-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 12:46:28.987: INFO: Waiting up to 5m0s for pod "pod-secrets-aeada33b-524c-11ea-bd69-fac0b7afc6af" in namespace "secrets-7441" to be "success or failure"
Feb 18 12:46:28.989: INFO: Pod "pod-secrets-aeada33b-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429829ms
Feb 18 12:46:30.992: INFO: Pod "pod-secrets-aeada33b-524c-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005442967s
STEP: Saw pod success
Feb 18 12:46:30.992: INFO: Pod "pod-secrets-aeada33b-524c-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:46:30.994: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-secrets-aeada33b-524c-11ea-bd69-fac0b7afc6af container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 12:46:31.011: INFO: Waiting for pod pod-secrets-aeada33b-524c-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:46:31.017: INFO: Pod pod-secrets-aeada33b-524c-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:46:31.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7441" for this suite.
Feb 18 12:46:37.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:46:37.189: INFO: namespace secrets-7441 deletion completed in 6.170156249s

• [SLOW TEST:8.229 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:46:37.189: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Feb 18 12:46:37.269: INFO: Waiting up to 5m0s for pod "downward-api-b39c9e7f-524c-11ea-bd69-fac0b7afc6af" in namespace "downward-api-7089" to be "success or failure"
Feb 18 12:46:37.273: INFO: Pod "downward-api-b39c9e7f-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.674118ms
Feb 18 12:46:39.275: INFO: Pod "downward-api-b39c9e7f-524c-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005754709s
STEP: Saw pod success
Feb 18 12:46:39.275: INFO: Pod "downward-api-b39c9e7f-524c-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:46:39.277: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downward-api-b39c9e7f-524c-11ea-bd69-fac0b7afc6af container dapi-container: <nil>
STEP: delete the pod
Feb 18 12:46:39.292: INFO: Waiting for pod downward-api-b39c9e7f-524c-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:46:39.294: INFO: Pod downward-api-b39c9e7f-524c-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:46:39.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7089" for this suite.
Feb 18 12:46:45.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:46:45.473: INFO: namespace downward-api-7089 deletion completed in 6.177288432s

• [SLOW TEST:8.283 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:46:45.473: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-b8850e25-524c-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:46:45.500: INFO: Waiting up to 5m0s for pod "pod-configmaps-b8856051-524c-11ea-bd69-fac0b7afc6af" in namespace "configmap-464" to be "success or failure"
Feb 18 12:46:45.505: INFO: Pod "pod-configmaps-b8856051-524c-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.936042ms
Feb 18 12:46:47.507: INFO: Pod "pod-configmaps-b8856051-524c-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007201429s
STEP: Saw pod success
Feb 18 12:46:47.507: INFO: Pod "pod-configmaps-b8856051-524c-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:46:47.509: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-b8856051-524c-11ea-bd69-fac0b7afc6af container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:46:47.546: INFO: Waiting for pod pod-configmaps-b8856051-524c-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:46:47.548: INFO: Pod pod-configmaps-b8856051-524c-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:46:47.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-464" for this suite.
Feb 18 12:46:53.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:46:53.721: INFO: namespace configmap-464 deletion completed in 6.166775095s

• [SLOW TEST:8.248 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:46:53.721: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:46:53.796: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 18 12:46:58.799: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 18 12:46:58.799: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 12:46:58.811: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-8230,SelfLink:/apis/apps/v1/namespaces/deployment-8230/deployments/test-cleanup-deployment,UID:c0779b14-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:15523,Generation:1,CreationTimestamp:2020-02-18 12:46:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 18 12:46:58.815: INFO: New ReplicaSet "test-cleanup-deployment-6865c98b76" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76,GenerateName:,Namespace:deployment-8230,SelfLink:/apis/apps/v1/namespaces/deployment-8230/replicasets/test-cleanup-deployment-6865c98b76,UID:c078f763-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:15525,Generation:1,CreationTimestamp:2020-02-18 12:46:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c0779b14-524c-11ea-b701-0ae3ad6fc27e 0xc002b39807 0xc002b39808}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 12:46:58.815: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 18 12:46:58.815: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-8230,SelfLink:/apis/apps/v1/namespaces/deployment-8230/replicasets/test-cleanup-controller,UID:bd7b23d8-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:15524,Generation:1,CreationTimestamp:2020-02-18 12:46:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c0779b14-524c-11ea-b701-0ae3ad6fc27e 0xc002b39727 0xc002b39728}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 18 12:46:58.828: INFO: Pod "test-cleanup-controller-b4lfc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-b4lfc,GenerateName:test-cleanup-controller-,Namespace:deployment-8230,SelfLink:/api/v1/namespaces/deployment-8230/pods/test-cleanup-controller-b4lfc,UID:bd7bdd48-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:15514,Generation:0,CreationTimestamp:2020-02-18 12:46:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.247/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller bd7b23d8-524c-11ea-b701-0ae3ad6fc27e 0xc0034f2267 0xc0034f2268}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hfdk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hfdk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hfdk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034f22d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034f22f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:46:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:46:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:46:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:46:53 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:172.16.102.247,StartTime:2020-02-18 12:46:53 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-18 12:46:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4217c9844c0b4ae6b2aded6a03969b7d45d4146c29c01f4a115e5313ff051886}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 12:46:58.828: INFO: Pod "test-cleanup-deployment-6865c98b76-79k87" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-6865c98b76-79k87,GenerateName:test-cleanup-deployment-6865c98b76-,Namespace:deployment-8230,SelfLink:/api/v1/namespaces/deployment-8230/pods/test-cleanup-deployment-6865c98b76-79k87,UID:c07969cd-524c-11ea-b701-0ae3ad6fc27e,ResourceVersion:15528,Generation:0,CreationTimestamp:2020-02-18 12:46:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 6865c98b76,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-6865c98b76 c078f763-524c-11ea-b701-0ae3ad6fc27e 0xc0034f23d7 0xc0034f23d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hfdk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hfdk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5hfdk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034f2440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034f2460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:46:58.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8230" for this suite.
Feb 18 12:47:04.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:47:05.011: INFO: namespace deployment-8230 deletion completed in 6.177159689s

• [SLOW TEST:11.289 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:47:05.011: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2367
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 18 12:47:05.038: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 18 12:47:27.148: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.26.161:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2367 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 12:47:27.148: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 12:47:27.293: INFO: Found all expected endpoints: [netserver-0]
Feb 18 12:47:27.295: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.102.249:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2367 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 12:47:27.295: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 12:47:27.440: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:47:27.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2367" for this suite.
Feb 18 12:47:49.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:47:49.609: INFO: namespace pod-network-test-2367 deletion completed in 22.166614412s

• [SLOW TEST:44.598 seconds]
[sig-network] Networking
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:47:49.610: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-l2kt
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 12:47:49.688: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-l2kt" in namespace "subpath-2262" to be "success or failure"
Feb 18 12:47:49.695: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.545942ms
Feb 18 12:47:51.729: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 2.036635965s
Feb 18 12:47:53.731: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 4.038880446s
Feb 18 12:47:55.736: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 6.043325556s
Feb 18 12:47:57.738: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 8.045630462s
Feb 18 12:47:59.740: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 10.047938732s
Feb 18 12:48:01.742: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 12.05021308s
Feb 18 12:48:03.745: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 14.052404676s
Feb 18 12:48:05.747: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 16.054548065s
Feb 18 12:48:07.749: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 18.056807419s
Feb 18 12:48:09.751: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 20.059114893s
Feb 18 12:48:11.754: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Running", Reason="", readiness=true. Elapsed: 22.061317999s
Feb 18 12:48:13.756: INFO: Pod "pod-subpath-test-secret-l2kt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.063962477s
STEP: Saw pod success
Feb 18 12:48:13.756: INFO: Pod "pod-subpath-test-secret-l2kt" satisfied condition "success or failure"
Feb 18 12:48:13.758: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-subpath-test-secret-l2kt container test-container-subpath-secret-l2kt: <nil>
STEP: delete the pod
Feb 18 12:48:13.773: INFO: Waiting for pod pod-subpath-test-secret-l2kt to disappear
Feb 18 12:48:13.774: INFO: Pod pod-subpath-test-secret-l2kt no longer exists
STEP: Deleting pod pod-subpath-test-secret-l2kt
Feb 18 12:48:13.774: INFO: Deleting pod "pod-subpath-test-secret-l2kt" in namespace "subpath-2262"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:48:13.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2262" for this suite.
Feb 18 12:48:19.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:48:19.943: INFO: namespace subpath-2262 deletion completed in 6.16540473s

• [SLOW TEST:30.333 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:48:19.943: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Feb 18 12:48:19.962: INFO: PodSpec: initContainers in spec.initContainers
Feb 18 12:49:07.823: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-f0d3da18-524c-11ea-bd69-fac0b7afc6af", GenerateName:"", Namespace:"init-container-4908", SelfLink:"/api/v1/namespaces/init-container-4908/pods/pod-init-f0d3da18-524c-11ea-bd69-fac0b7afc6af", UID:"f0d963aa-524c-11ea-b701-0ae3ad6fc27e", ResourceVersion:"16073", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63717626899, loc:(*time.Location)(0x882e100)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"962937501"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"172.16.102.252/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-px7ft", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00313ff40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-px7ft", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-px7ft", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-px7ft", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002952298), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-100-10-235.eu-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002dc0240), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002952320)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002952340)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002952348), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00295234c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717626899, loc:(*time.Location)(0x882e100)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717626899, loc:(*time.Location)(0x882e100)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717626899, loc:(*time.Location)(0x882e100)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717626900, loc:(*time.Location)(0x882e100)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.100.10.235", PodIP:"172.16.102.252", StartTime:(*v1.Time)(0xc0029e4620), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00209e150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00209e1c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://a33f7e2e87349f620afb6f13c234e357a03a548dcf4fb36ee9426f00c5de98f1"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0029e46c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0029e4640), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:49:07.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4908" for this suite.
Feb 18 12:49:29.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:49:29.998: INFO: namespace init-container-4908 deletion completed in 22.167768263s

• [SLOW TEST:70.056 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:49:29.998: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Feb 18 12:49:34.606: INFO: Successfully updated pod "annotationupdate1a9e254b-524d-11ea-bd69-fac0b7afc6af"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:49:36.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4142" for this suite.
Feb 18 12:49:58.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:49:58.785: INFO: namespace downward-api-4142 deletion completed in 22.166341967s

• [SLOW TEST:28.787 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:49:58.786: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 18 12:49:58.813: INFO: Waiting up to 5m0s for pod "pod-2bbe766c-524d-11ea-bd69-fac0b7afc6af" in namespace "emptydir-1981" to be "success or failure"
Feb 18 12:49:58.821: INFO: Pod "pod-2bbe766c-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 8.119286ms
Feb 18 12:50:00.823: INFO: Pod "pod-2bbe766c-524d-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010500799s
STEP: Saw pod success
Feb 18 12:50:00.823: INFO: Pod "pod-2bbe766c-524d-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:50:00.825: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-2bbe766c-524d-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:50:00.843: INFO: Waiting for pod pod-2bbe766c-524d-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:50:00.845: INFO: Pod pod-2bbe766c-524d-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:50:00.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1981" for this suite.
Feb 18 12:50:06.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:50:07.015: INFO: namespace emptydir-1981 deletion completed in 6.167798115s

• [SLOW TEST:8.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:50:07.015: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:50:07.060: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"30ae8d94-524d-11ea-b701-0ae3ad6fc27e", Controller:(*bool)(0xc002b398da), BlockOwnerDeletion:(*bool)(0xc002b398db)}}
Feb 18 12:50:07.070: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"30acfbdf-524d-11ea-b701-0ae3ad6fc27e", Controller:(*bool)(0xc003188336), BlockOwnerDeletion:(*bool)(0xc003188337)}}
Feb 18 12:50:07.077: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"30ad88fd-524d-11ea-b701-0ae3ad6fc27e", Controller:(*bool)(0xc002b39ab6), BlockOwnerDeletion:(*bool)(0xc002b39ab7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:50:12.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-933" for this suite.
Feb 18 12:50:18.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:50:18.255: INFO: namespace gc-933 deletion completed in 6.170972948s

• [SLOW TEST:11.240 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:50:18.255: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-37590060-524d-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:50:18.283: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-37595757-524d-11ea-bd69-fac0b7afc6af" in namespace "projected-5454" to be "success or failure"
Feb 18 12:50:18.289: INFO: Pod "pod-projected-configmaps-37595757-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 5.261305ms
Feb 18 12:50:20.291: INFO: Pod "pod-projected-configmaps-37595757-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007605465s
Feb 18 12:50:22.293: INFO: Pod "pod-projected-configmaps-37595757-524d-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009834371s
STEP: Saw pod success
Feb 18 12:50:22.293: INFO: Pod "pod-projected-configmaps-37595757-524d-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:50:22.295: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-configmaps-37595757-524d-11ea-bd69-fac0b7afc6af container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:50:22.317: INFO: Waiting for pod pod-projected-configmaps-37595757-524d-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:50:22.319: INFO: Pod pod-projected-configmaps-37595757-524d-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:50:22.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5454" for this suite.
Feb 18 12:50:28.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:50:28.489: INFO: namespace projected-5454 deletion completed in 6.168180894s

• [SLOW TEST:10.234 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:50:28.489: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:50:30.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4725" for this suite.
Feb 18 12:50:52.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:50:52.732: INFO: namespace replication-controller-4725 deletion completed in 22.189357959s

• [SLOW TEST:24.243 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:50:52.732: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb 18 12:50:55.320: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-600 pod-service-account-4c3a861a-524d-11ea-bd69-fac0b7afc6af -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb 18 12:50:55.507: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-600 pod-service-account-4c3a861a-524d-11ea-bd69-fac0b7afc6af -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb 18 12:50:55.710: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-600 pod-service-account-4c3a861a-524d-11ea-bd69-fac0b7afc6af -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:50:55.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-600" for this suite.
Feb 18 12:51:01.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:51:02.061: INFO: namespace svcaccounts-600 deletion completed in 6.16646117s

• [SLOW TEST:9.329 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:51:02.061: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1384
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 12:51:02.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8044'
Feb 18 12:51:02.318: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 12:51:02.318: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1390
Feb 18 12:51:02.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8044'
Feb 18 12:51:02.403: INFO: stderr: ""
Feb 18 12:51:02.403: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:51:02.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8044" for this suite.
Feb 18 12:51:08.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:51:08.574: INFO: namespace kubectl-8044 deletion completed in 6.168894835s

• [SLOW TEST:6.513 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:51:08.574: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-5556ffdd-524d-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:51:08.604: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5557a559-524d-11ea-bd69-fac0b7afc6af" in namespace "projected-130" to be "success or failure"
Feb 18 12:51:08.608: INFO: Pod "pod-projected-configmaps-5557a559-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.257401ms
Feb 18 12:51:10.611: INFO: Pod "pod-projected-configmaps-5557a559-524d-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007168259s
STEP: Saw pod success
Feb 18 12:51:10.611: INFO: Pod "pod-projected-configmaps-5557a559-524d-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:51:10.613: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-configmaps-5557a559-524d-11ea-bd69-fac0b7afc6af container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:51:10.649: INFO: Waiting for pod pod-projected-configmaps-5557a559-524d-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:51:10.651: INFO: Pod pod-projected-configmaps-5557a559-524d-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:51:10.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-130" for this suite.
Feb 18 12:51:16.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:51:16.821: INFO: namespace projected-130 deletion completed in 6.167245554s

• [SLOW TEST:8.246 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:51:16.821: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Feb 18 12:51:16.846: INFO: Waiting up to 5m0s for pod "client-containers-5a415a45-524d-11ea-bd69-fac0b7afc6af" in namespace "containers-1964" to be "success or failure"
Feb 18 12:51:16.850: INFO: Pod "client-containers-5a415a45-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.387654ms
Feb 18 12:51:18.857: INFO: Pod "client-containers-5a415a45-524d-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011271645s
STEP: Saw pod success
Feb 18 12:51:18.857: INFO: Pod "client-containers-5a415a45-524d-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:51:18.859: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod client-containers-5a415a45-524d-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 12:51:18.877: INFO: Waiting for pod client-containers-5a415a45-524d-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:51:18.880: INFO: Pod client-containers-5a415a45-524d-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:51:18.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1964" for this suite.
Feb 18 12:51:24.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:51:25.050: INFO: namespace containers-1964 deletion completed in 6.167898522s

• [SLOW TEST:8.229 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:51:25.050: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:51:43.136: INFO: Container started at 2020-02-18 12:51:26 +0000 UTC, pod became ready at 2020-02-18 12:51:41 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:51:43.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2911" for this suite.
Feb 18 12:52:05.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:52:05.304: INFO: namespace container-probe-2911 deletion completed in 22.166483986s

• [SLOW TEST:40.254 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:52:05.304: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:52:05.330: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7727545d-524d-11ea-bd69-fac0b7afc6af" in namespace "downward-api-3066" to be "success or failure"
Feb 18 12:52:05.332: INFO: Pod "downwardapi-volume-7727545d-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 1.760516ms
Feb 18 12:52:07.334: INFO: Pod "downwardapi-volume-7727545d-524d-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003994649s
STEP: Saw pod success
Feb 18 12:52:07.334: INFO: Pod "downwardapi-volume-7727545d-524d-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:52:07.336: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-7727545d-524d-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:52:07.347: INFO: Waiting for pod downwardapi-volume-7727545d-524d-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:52:07.351: INFO: Pod downwardapi-volume-7727545d-524d-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:52:07.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3066" for this suite.
Feb 18 12:52:13.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:52:13.520: INFO: namespace downward-api-3066 deletion completed in 6.166563144s

• [SLOW TEST:8.216 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:52:13.521: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 18 12:52:13.567: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:52:13.570: INFO: Number of nodes with available pods: 0
Feb 18 12:52:13.570: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:52:14.573: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:52:14.575: INFO: Number of nodes with available pods: 0
Feb 18 12:52:14.576: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:52:15.574: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:52:15.576: INFO: Number of nodes with available pods: 0
Feb 18 12:52:15.576: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 12:52:16.573: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:52:16.575: INFO: Number of nodes with available pods: 2
Feb 18 12:52:16.575: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 18 12:52:16.587: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 12:52:16.589: INFO: Number of nodes with available pods: 2
Feb 18 12:52:16.589: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9817, will wait for the garbage collector to delete the pods
Feb 18 12:52:17.672: INFO: Deleting DaemonSet.extensions daemon-set took: 21.28549ms
Feb 18 12:52:18.173: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.162632ms
Feb 18 12:53:53.074: INFO: Number of nodes with available pods: 0
Feb 18 12:53:53.074: INFO: Number of running nodes: 0, number of available pods: 0
Feb 18 12:53:53.088: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9817/daemonsets","resourceVersion":"17291"},"items":null}

Feb 18 12:53:53.090: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9817/pods","resourceVersion":"17291"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:53:53.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9817" for this suite.
Feb 18 12:53:59.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:53:59.323: INFO: namespace daemonsets-9817 deletion completed in 6.223646136s

• [SLOW TEST:105.802 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:53:59.324: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-bb1db419-524d-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:53:59.369: INFO: Waiting up to 5m0s for pod "pod-configmaps-bb1ee885-524d-11ea-bd69-fac0b7afc6af" in namespace "configmap-7711" to be "success or failure"
Feb 18 12:53:59.373: INFO: Pod "pod-configmaps-bb1ee885-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.179442ms
Feb 18 12:54:01.376: INFO: Pod "pod-configmaps-bb1ee885-524d-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00655336s
STEP: Saw pod success
Feb 18 12:54:01.376: INFO: Pod "pod-configmaps-bb1ee885-524d-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:54:01.378: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-bb1ee885-524d-11ea-bd69-fac0b7afc6af container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:54:01.390: INFO: Waiting for pod pod-configmaps-bb1ee885-524d-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:54:01.393: INFO: Pod pod-configmaps-bb1ee885-524d-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:54:01.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7711" for this suite.
Feb 18 12:54:07.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:54:07.562: INFO: namespace configmap-7711 deletion completed in 6.166305312s

• [SLOW TEST:8.238 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:54:07.562: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-c006b2ab-524d-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 12:54:07.593: INFO: Waiting up to 5m0s for pod "pod-configmaps-c006f26f-524d-11ea-bd69-fac0b7afc6af" in namespace "configmap-7978" to be "success or failure"
Feb 18 12:54:07.596: INFO: Pod "pod-configmaps-c006f26f-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723996ms
Feb 18 12:54:09.598: INFO: Pod "pod-configmaps-c006f26f-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005218656s
Feb 18 12:54:11.601: INFO: Pod "pod-configmaps-c006f26f-524d-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00749374s
STEP: Saw pod success
Feb 18 12:54:11.601: INFO: Pod "pod-configmaps-c006f26f-524d-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:54:11.603: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-c006f26f-524d-11ea-bd69-fac0b7afc6af container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 12:54:11.617: INFO: Waiting for pod pod-configmaps-c006f26f-524d-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:54:11.618: INFO: Pod pod-configmaps-c006f26f-524d-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:54:11.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7978" for this suite.
Feb 18 12:54:17.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:54:17.805: INFO: namespace configmap-7978 deletion completed in 6.18479883s

• [SLOW TEST:10.243 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:54:17.805: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-7320
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7320 to expose endpoints map[]
Feb 18 12:54:17.847: INFO: successfully validated that service endpoint-test2 in namespace services-7320 exposes endpoints map[] (6.784661ms elapsed)
STEP: Creating pod pod1 in namespace services-7320
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7320 to expose endpoints map[pod1:[80]]
Feb 18 12:54:19.876: INFO: successfully validated that service endpoint-test2 in namespace services-7320 exposes endpoints map[pod1:[80]] (2.020495737s elapsed)
STEP: Creating pod pod2 in namespace services-7320
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7320 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 18 12:54:22.904: INFO: successfully validated that service endpoint-test2 in namespace services-7320 exposes endpoints map[pod1:[80] pod2:[80]] (3.023451284s elapsed)
STEP: Deleting pod pod1 in namespace services-7320
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7320 to expose endpoints map[pod2:[80]]
Feb 18 12:54:22.920: INFO: successfully validated that service endpoint-test2 in namespace services-7320 exposes endpoints map[pod2:[80]] (10.457262ms elapsed)
STEP: Deleting pod pod2 in namespace services-7320
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7320 to expose endpoints map[]
Feb 18 12:54:22.937: INFO: successfully validated that service endpoint-test2 in namespace services-7320 exposes endpoints map[] (3.69172ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:54:23.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7320" for this suite.
Feb 18 12:54:45.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:54:45.455: INFO: namespace services-7320 deletion completed in 22.236793281s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:27.650 seconds]
[sig-network] Services
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:54:45.455: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1256
STEP: creating an rc
Feb 18 12:54:45.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-2999'
Feb 18 12:54:45.625: INFO: stderr: ""
Feb 18 12:54:45.625: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Feb 18 12:54:46.627: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 12:54:46.627: INFO: Found 0 / 1
Feb 18 12:54:47.628: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 12:54:47.628: INFO: Found 1 / 1
Feb 18 12:54:47.628: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 18 12:54:47.630: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 12:54:47.630: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 18 12:54:47.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 logs redis-master-7bd8r redis-master --namespace=kubectl-2999'
Feb 18 12:54:47.696: INFO: stderr: ""
Feb 18 12:54:47.696: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Feb 12:54:46.981 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Feb 12:54:46.981 # Server started, Redis version 3.2.12\n1:M 18 Feb 12:54:46.981 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Feb 12:54:46.981 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 18 12:54:47.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 log redis-master-7bd8r redis-master --namespace=kubectl-2999 --tail=1'
Feb 18 12:54:47.766: INFO: stderr: ""
Feb 18 12:54:47.766: INFO: stdout: "1:M 18 Feb 12:54:46.981 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 18 12:54:47.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 log redis-master-7bd8r redis-master --namespace=kubectl-2999 --limit-bytes=1'
Feb 18 12:54:47.831: INFO: stderr: ""
Feb 18 12:54:47.831: INFO: stdout: " "
STEP: exposing timestamps
Feb 18 12:54:47.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 log redis-master-7bd8r redis-master --namespace=kubectl-2999 --tail=1 --timestamps'
Feb 18 12:54:47.898: INFO: stderr: ""
Feb 18 12:54:47.898: INFO: stdout: "2020-02-18T12:54:46.98182422Z 1:M 18 Feb 12:54:46.981 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 18 12:54:50.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 log redis-master-7bd8r redis-master --namespace=kubectl-2999 --since=1s'
Feb 18 12:54:50.468: INFO: stderr: ""
Feb 18 12:54:50.468: INFO: stdout: ""
Feb 18 12:54:50.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 log redis-master-7bd8r redis-master --namespace=kubectl-2999 --since=24h'
Feb 18 12:54:50.536: INFO: stderr: ""
Feb 18 12:54:50.536: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Feb 12:54:46.981 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Feb 12:54:46.981 # Server started, Redis version 3.2.12\n1:M 18 Feb 12:54:46.981 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Feb 12:54:46.981 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
STEP: using delete to clean up resources
Feb 18 12:54:50.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-2999'
Feb 18 12:54:50.601: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:54:50.601: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 18 12:54:50.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get rc,svc -l name=nginx --no-headers --namespace=kubectl-2999'
Feb 18 12:54:50.684: INFO: stderr: "No resources found.\n"
Feb 18 12:54:50.684: INFO: stdout: ""
Feb 18 12:54:50.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -l name=nginx --namespace=kubectl-2999 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 12:54:50.756: INFO: stderr: ""
Feb 18 12:54:50.756: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:54:50.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2999" for this suite.
Feb 18 12:55:12.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:55:12.926: INFO: namespace kubectl-2999 deletion completed in 22.167448757s

• [SLOW TEST:27.471 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:55:12.927: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:55:39.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9199" for this suite.
Feb 18 12:55:45.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:55:45.368: INFO: namespace container-runtime-9199 deletion completed in 6.26177507s

• [SLOW TEST:32.442 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:55:45.368: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 12:55:47.411: INFO: Waiting up to 5m0s for pod "client-envvars-fb868c40-524d-11ea-bd69-fac0b7afc6af" in namespace "pods-6051" to be "success or failure"
Feb 18 12:55:47.414: INFO: Pod "client-envvars-fb868c40-524d-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.303882ms
Feb 18 12:55:49.420: INFO: Pod "client-envvars-fb868c40-524d-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008126252s
STEP: Saw pod success
Feb 18 12:55:49.420: INFO: Pod "client-envvars-fb868c40-524d-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:55:49.425: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod client-envvars-fb868c40-524d-11ea-bd69-fac0b7afc6af container env3cont: <nil>
STEP: delete the pod
Feb 18 12:55:49.438: INFO: Waiting for pod client-envvars-fb868c40-524d-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:55:49.440: INFO: Pod client-envvars-fb868c40-524d-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:55:49.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6051" for this suite.
Feb 18 12:56:35.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:56:35.609: INFO: namespace pods-6051 deletion completed in 46.166987429s

• [SLOW TEST:50.241 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:56:35.610: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 12:56:35.634: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1844c289-524e-11ea-bd69-fac0b7afc6af" in namespace "projected-8252" to be "success or failure"
Feb 18 12:56:35.642: INFO: Pod "downwardapi-volume-1844c289-524e-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019016ms
Feb 18 12:56:37.645: INFO: Pod "downwardapi-volume-1844c289-524e-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010799199s
STEP: Saw pod success
Feb 18 12:56:37.645: INFO: Pod "downwardapi-volume-1844c289-524e-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 12:56:37.647: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-1844c289-524e-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 12:56:37.660: INFO: Waiting for pod downwardapi-volume-1844c289-524e-11ea-bd69-fac0b7afc6af to disappear
Feb 18 12:56:37.662: INFO: Pod downwardapi-volume-1844c289-524e-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:56:37.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8252" for this suite.
Feb 18 12:56:43.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:56:43.830: INFO: namespace projected-8252 deletion completed in 6.165890974s

• [SLOW TEST:8.221 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:56:43.830: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Feb 18 12:56:43.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-4004'
Feb 18 12:56:44.113: INFO: stderr: ""
Feb 18 12:56:44.113: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 12:56:44.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4004'
Feb 18 12:56:44.186: INFO: stderr: ""
Feb 18 12:56:44.186: INFO: stdout: "update-demo-nautilus-8tq2v update-demo-nautilus-xr6k6 "
Feb 18 12:56:44.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-8tq2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4004'
Feb 18 12:56:44.256: INFO: stderr: ""
Feb 18 12:56:44.256: INFO: stdout: ""
Feb 18 12:56:44.256: INFO: update-demo-nautilus-8tq2v is created but not running
Feb 18 12:56:49.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4004'
Feb 18 12:56:49.317: INFO: stderr: ""
Feb 18 12:56:49.317: INFO: stdout: "update-demo-nautilus-8tq2v update-demo-nautilus-xr6k6 "
Feb 18 12:56:49.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-8tq2v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4004'
Feb 18 12:56:49.373: INFO: stderr: ""
Feb 18 12:56:49.373: INFO: stdout: "true"
Feb 18 12:56:49.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-8tq2v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4004'
Feb 18 12:56:49.429: INFO: stderr: ""
Feb 18 12:56:49.429: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 12:56:49.429: INFO: validating pod update-demo-nautilus-8tq2v
Feb 18 12:56:49.432: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 12:56:49.432: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 12:56:49.432: INFO: update-demo-nautilus-8tq2v is verified up and running
Feb 18 12:56:49.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-xr6k6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4004'
Feb 18 12:56:49.488: INFO: stderr: ""
Feb 18 12:56:49.488: INFO: stdout: "true"
Feb 18 12:56:49.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-xr6k6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4004'
Feb 18 12:56:49.545: INFO: stderr: ""
Feb 18 12:56:49.545: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 12:56:49.545: INFO: validating pod update-demo-nautilus-xr6k6
Feb 18 12:56:49.548: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 12:56:49.548: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 12:56:49.548: INFO: update-demo-nautilus-xr6k6 is verified up and running
STEP: using delete to clean up resources
Feb 18 12:56:49.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete --grace-period=0 --force -f - --namespace=kubectl-4004'
Feb 18 12:56:49.607: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 18 12:56:49.607: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 18 12:56:49.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4004'
Feb 18 12:56:49.668: INFO: stderr: "No resources found.\n"
Feb 18 12:56:49.668: INFO: stdout: ""
Feb 18 12:56:49.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -l name=update-demo --namespace=kubectl-4004 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 12:56:49.727: INFO: stderr: ""
Feb 18 12:56:49.727: INFO: stdout: "update-demo-nautilus-8tq2v\nupdate-demo-nautilus-xr6k6\n"
Feb 18 12:56:50.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4004'
Feb 18 12:56:50.303: INFO: stderr: "No resources found.\n"
Feb 18 12:56:50.303: INFO: stdout: ""
Feb 18 12:56:50.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -l name=update-demo --namespace=kubectl-4004 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 18 12:56:50.370: INFO: stderr: ""
Feb 18 12:56:50.370: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:56:50.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4004" for this suite.
Feb 18 12:57:12.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:57:12.539: INFO: namespace kubectl-4004 deletion completed in 22.166115606s

• [SLOW TEST:28.708 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:57:12.539: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5453
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-5453
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5453
Feb 18 12:57:12.627: INFO: Found 0 stateful pods, waiting for 1
Feb 18 12:57:22.630: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 18 12:57:22.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5453 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 12:57:22.850: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 12:57:22.850: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 12:57:22.850: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 12:57:22.853: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 18 12:57:32.855: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 12:57:32.855: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 12:57:32.865: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:57:32.865: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:57:32.865: INFO: 
Feb 18 12:57:32.865: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 18 12:57:33.870: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996641897s
Feb 18 12:57:34.872: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991879603s
Feb 18 12:57:35.875: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989448331s
Feb 18 12:57:36.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987030855s
Feb 18 12:57:37.880: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984593181s
Feb 18 12:57:38.882: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982104799s
Feb 18 12:57:39.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979300848s
Feb 18 12:57:40.888: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976998902s
Feb 18 12:57:41.891: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.523427ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5453
Feb 18 12:57:42.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5453 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 12:57:43.092: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 18 12:57:43.092: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 12:57:43.092: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 12:57:43.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5453 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 12:57:43.279: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 18 12:57:43.279: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 12:57:43.279: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 12:57:43.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5453 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 12:57:43.464: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 18 12:57:43.464: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 12:57:43.464: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 12:57:43.467: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Feb 18 12:57:53.469: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 12:57:53.469: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 12:57:53.469: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 18 12:57:53.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5453 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 12:57:53.662: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 12:57:53.662: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 12:57:53.662: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 12:57:53.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5453 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 12:57:53.873: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 12:57:53.873: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 12:57:53.873: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 12:57:53.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5453 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 12:57:54.083: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 12:57:54.083: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 12:57:54.083: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 12:57:54.083: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 12:57:54.087: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 18 12:58:04.091: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 12:58:04.091: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 12:58:04.091: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 12:58:04.098: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:58:04.098: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:58:04.098: INFO: ss-1  ip-10-100-10-116.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:04.098: INFO: ss-2  ip-10-100-10-235.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:04.099: INFO: 
Feb 18 12:58:04.099: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 12:58:05.101: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:58:05.101: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:58:05.101: INFO: ss-1  ip-10-100-10-116.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:05.101: INFO: ss-2  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:05.101: INFO: 
Feb 18 12:58:05.101: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 12:58:06.104: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:58:06.104: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:58:06.104: INFO: ss-1  ip-10-100-10-116.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:06.104: INFO: ss-2  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:06.104: INFO: 
Feb 18 12:58:06.104: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 12:58:07.106: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:58:07.106: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:58:07.106: INFO: ss-1  ip-10-100-10-116.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:07.106: INFO: ss-2  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:07.106: INFO: 
Feb 18 12:58:07.106: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 12:58:08.109: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:58:08.109: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:58:08.109: INFO: ss-1  ip-10-100-10-116.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:08.109: INFO: ss-2  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:08.109: INFO: 
Feb 18 12:58:08.109: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 12:58:09.111: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:58:09.111: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:58:09.111: INFO: ss-1  ip-10-100-10-116.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:09.111: INFO: ss-2  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:09.112: INFO: 
Feb 18 12:58:09.112: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 12:58:10.114: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:58:10.114: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:58:10.114: INFO: ss-1  ip-10-100-10-116.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:10.114: INFO: ss-2  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:10.114: INFO: 
Feb 18 12:58:10.114: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 12:58:11.116: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:58:11.116: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:58:11.116: INFO: ss-1  ip-10-100-10-116.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:11.116: INFO: ss-2  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:11.116: INFO: 
Feb 18 12:58:11.116: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 12:58:12.119: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 18 12:58:12.119: INFO: ss-0  ip-10-100-10-235.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:12 +0000 UTC  }]
Feb 18 12:58:12.119: INFO: ss-1  ip-10-100-10-116.eu-west-1.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:12.119: INFO: ss-2  ip-10-100-10-235.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 12:57:32 +0000 UTC  }]
Feb 18 12:58:12.119: INFO: 
Feb 18 12:58:12.119: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 18 12:58:13.121: INFO: Verifying statefulset ss doesn't scale past 0 for another 976.746439ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5453
Feb 18 12:58:14.124: INFO: Scaling statefulset ss to 0
Feb 18 12:58:14.130: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 12:58:14.132: INFO: Deleting all statefulset in ns statefulset-5453
Feb 18 12:58:14.134: INFO: Scaling statefulset ss to 0
Feb 18 12:58:14.140: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 12:58:14.142: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:58:14.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5453" for this suite.
Feb 18 12:58:20.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:58:20.349: INFO: namespace statefulset-5453 deletion completed in 6.172616109s

• [SLOW TEST:67.809 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:58:20.349: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1576
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 12:58:20.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6435'
Feb 18 12:58:20.435: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 12:58:20.435: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1581
Feb 18 12:58:20.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete jobs e2e-test-nginx-job --namespace=kubectl-6435'
Feb 18 12:58:20.510: INFO: stderr: ""
Feb 18 12:58:20.510: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:58:20.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6435" for this suite.
Feb 18 12:58:26.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 12:58:26.680: INFO: namespace kubectl-6435 deletion completed in 6.167083295s

• [SLOW TEST:6.331 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 12:58:26.680: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5a793a1a-524e-11ea-bd69-fac0b7afc6af
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5a793a1a-524e-11ea-bd69-fac0b7afc6af
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 12:59:54.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2123" for this suite.
Feb 18 13:00:16.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:00:17.149: INFO: namespace projected-2123 deletion completed in 22.166874305s

• [SLOW TEST:110.469 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:00:17.150: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:00:21.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1999" for this suite.
Feb 18 13:00:27.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:00:27.349: INFO: namespace kubelet-test-1999 deletion completed in 6.165883254s

• [SLOW TEST:10.199 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:00:27.349: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 18 13:00:27.375: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 18 13:00:32.377: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:00:32.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-707" for this suite.
Feb 18 13:00:38.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:00:38.575: INFO: namespace replication-controller-707 deletion completed in 6.177804322s

• [SLOW TEST:11.226 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:00:38.575: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:01:38.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-790" for this suite.
Feb 18 13:02:00.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:02:00.775: INFO: namespace container-probe-790 deletion completed in 22.166815891s

• [SLOW TEST:82.200 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:02:00.776: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:02:02.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7904" for this suite.
Feb 18 13:02:44.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:02:44.988: INFO: namespace kubelet-test-7904 deletion completed in 42.166535608s

• [SLOW TEST:44.212 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:02:44.988: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 18 13:02:45.027: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7424,SelfLink:/api/v1/namespaces/watch-7424/configmaps/e2e-watch-test-resource-version,UID:f4768824-524e-11ea-b701-0ae3ad6fc27e,ResourceVersion:19562,Generation:0,CreationTimestamp:2020-02-18 13:02:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 13:02:45.027: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7424,SelfLink:/api/v1/namespaces/watch-7424/configmaps/e2e-watch-test-resource-version,UID:f4768824-524e-11ea-b701-0ae3ad6fc27e,ResourceVersion:19563,Generation:0,CreationTimestamp:2020-02-18 13:02:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:02:45.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7424" for this suite.
Feb 18 13:02:51.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:02:51.201: INFO: namespace watch-7424 deletion completed in 6.171659419s

• [SLOW TEST:6.213 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:02:51.201: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-5946
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 18 13:02:51.220: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 18 13:03:15.285: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.102.242:8080/dial?request=hostName&protocol=udp&host=172.16.26.167&port=8081&tries=1'] Namespace:pod-network-test-5946 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:03:15.285: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:03:15.429: INFO: Waiting for endpoints: map[]
Feb 18 13:03:15.433: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.102.242:8080/dial?request=hostName&protocol=udp&host=172.16.102.241&port=8081&tries=1'] Namespace:pod-network-test-5946 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:03:15.433: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:03:15.577: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:03:15.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5946" for this suite.
Feb 18 13:03:37.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:03:37.750: INFO: namespace pod-network-test-5946 deletion completed in 22.170311913s

• [SLOW TEST:46.549 seconds]
[sig-network] Networking
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:03:37.750: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 13:03:37.779: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13e26452-524f-11ea-bd69-fac0b7afc6af" in namespace "projected-6437" to be "success or failure"
Feb 18 13:03:37.782: INFO: Pod "downwardapi-volume-13e26452-524f-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.530558ms
Feb 18 13:03:39.784: INFO: Pod "downwardapi-volume-13e26452-524f-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004862044s
STEP: Saw pod success
Feb 18 13:03:39.784: INFO: Pod "downwardapi-volume-13e26452-524f-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:03:39.786: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-13e26452-524f-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 13:03:39.802: INFO: Waiting for pod downwardapi-volume-13e26452-524f-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:03:39.803: INFO: Pod downwardapi-volume-13e26452-524f-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:03:39.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6437" for this suite.
Feb 18 13:03:45.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:03:45.971: INFO: namespace projected-6437 deletion completed in 6.16529903s

• [SLOW TEST:8.221 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:03:45.971: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Feb 18 13:03:46.012: INFO: Waiting up to 5m0s for pod "var-expansion-18c88a7c-524f-11ea-bd69-fac0b7afc6af" in namespace "var-expansion-458" to be "success or failure"
Feb 18 13:03:46.016: INFO: Pod "var-expansion-18c88a7c-524f-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.951357ms
Feb 18 13:03:48.018: INFO: Pod "var-expansion-18c88a7c-524f-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005940965s
STEP: Saw pod success
Feb 18 13:03:48.018: INFO: Pod "var-expansion-18c88a7c-524f-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:03:48.022: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod var-expansion-18c88a7c-524f-11ea-bd69-fac0b7afc6af container dapi-container: <nil>
STEP: delete the pod
Feb 18 13:03:48.063: INFO: Waiting for pod var-expansion-18c88a7c-524f-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:03:48.065: INFO: Pod var-expansion-18c88a7c-524f-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:03:48.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-458" for this suite.
Feb 18 13:03:54.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:03:54.234: INFO: namespace var-expansion-458 deletion completed in 6.166698783s

• [SLOW TEST:8.263 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:03:54.234: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 13:03:54.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-6975'
Feb 18 13:03:54.505: INFO: stderr: ""
Feb 18 13:03:54.505: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 18 13:03:59.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pod e2e-test-nginx-pod --namespace=kubectl-6975 -o json'
Feb 18 13:03:59.613: INFO: stderr: ""
Feb 18 13:03:59.613: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"172.16.102.246/32\"\n        },\n        \"creationTimestamp\": \"2020-02-18T13:03:54Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-6975\",\n        \"resourceVersion\": \"19919\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6975/pods/e2e-test-nginx-pod\",\n        \"uid\": \"1de0e203-524f-11ea-b701-0ae3ad6fc27e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-xn9nk\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-100-10-235.eu-west-1.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-xn9nk\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-xn9nk\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-18T13:03:54Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-18T13:03:56Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-18T13:03:56Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-18T13:03:54Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f60aa5dbc67ce9c65e7e7d070a84eec0592af0fa986f967b9ae520fbd7c851f6\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-18T13:03:55Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.100.10.235\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.102.246\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-18T13:03:54Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 18 13:03:59.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 replace -f - --namespace=kubectl-6975'
Feb 18 13:03:59.757: INFO: stderr: ""
Feb 18 13:03:59.757: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Feb 18 13:03:59.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete pods e2e-test-nginx-pod --namespace=kubectl-6975'
Feb 18 13:04:01.581: INFO: stderr: ""
Feb 18 13:04:01.581: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:04:01.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6975" for this suite.
Feb 18 13:04:07.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:04:07.751: INFO: namespace kubectl-6975 deletion completed in 6.166491167s

• [SLOW TEST:13.517 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:04:07.752: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-25c4c33f-524f-11ea-bd69-fac0b7afc6af
STEP: Creating secret with name s-test-opt-upd-25c4c3a7-524f-11ea-bd69-fac0b7afc6af
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-25c4c33f-524f-11ea-bd69-fac0b7afc6af
STEP: Updating secret s-test-opt-upd-25c4c3a7-524f-11ea-bd69-fac0b7afc6af
STEP: Creating secret with name s-test-opt-create-25c4c3c4-524f-11ea-bd69-fac0b7afc6af
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:04:13.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9481" for this suite.
Feb 18 13:04:35.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:04:36.017: INFO: namespace secrets-9481 deletion completed in 22.166096891s

• [SLOW TEST:28.265 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:04:36.017: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0218 13:04:37.066778      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 13:04:37.066: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:04:37.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3316" for this suite.
Feb 18 13:04:43.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:04:43.245: INFO: namespace gc-3316 deletion completed in 6.174677455s

• [SLOW TEST:7.229 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:04:43.246: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8290
Feb 18 13:04:47.330: INFO: Started pod liveness-http in namespace container-probe-8290
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 13:04:47.332: INFO: Initial restart count of pod liveness-http is 0
Feb 18 13:05:05.355: INFO: Restart count of pod container-probe-8290/liveness-http is now 1 (18.022770474s elapsed)
Feb 18 13:05:25.381: INFO: Restart count of pod container-probe-8290/liveness-http is now 2 (38.048844771s elapsed)
Feb 18 13:05:45.403: INFO: Restart count of pod container-probe-8290/liveness-http is now 3 (58.071101264s elapsed)
Feb 18 13:06:05.427: INFO: Restart count of pod container-probe-8290/liveness-http is now 4 (1m18.094655204s elapsed)
Feb 18 13:07:11.508: INFO: Restart count of pod container-probe-8290/liveness-http is now 5 (2m24.175690543s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:07:11.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8290" for this suite.
Feb 18 13:07:17.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:07:17.697: INFO: namespace container-probe-8290 deletion completed in 6.168853624s

• [SLOW TEST:154.451 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:07:17.698: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1521
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 13:07:17.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-2456'
Feb 18 13:07:17.803: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 13:07:17.803: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
Feb 18 13:07:19.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2456'
Feb 18 13:07:19.886: INFO: stderr: ""
Feb 18 13:07:19.886: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:07:19.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2456" for this suite.
Feb 18 13:07:41.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:07:42.061: INFO: namespace kubectl-2456 deletion completed in 22.170738297s

• [SLOW TEST:24.363 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:07:42.061: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-a5819474-524f-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 13:07:42.090: INFO: Waiting up to 5m0s for pod "pod-configmaps-a581f5d4-524f-11ea-bd69-fac0b7afc6af" in namespace "configmap-7379" to be "success or failure"
Feb 18 13:07:42.094: INFO: Pod "pod-configmaps-a581f5d4-524f-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.203894ms
Feb 18 13:07:44.096: INFO: Pod "pod-configmaps-a581f5d4-524f-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005456201s
STEP: Saw pod success
Feb 18 13:07:44.096: INFO: Pod "pod-configmaps-a581f5d4-524f-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:07:44.098: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-a581f5d4-524f-11ea-bd69-fac0b7afc6af container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 13:07:44.110: INFO: Waiting for pod pod-configmaps-a581f5d4-524f-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:07:44.113: INFO: Pod pod-configmaps-a581f5d4-524f-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:07:44.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7379" for this suite.
Feb 18 13:07:50.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:07:50.283: INFO: namespace configmap-7379 deletion completed in 6.167734966s

• [SLOW TEST:8.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:07:50.283: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-aa679c9d-524f-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 13:07:50.318: INFO: Waiting up to 5m0s for pod "pod-secrets-aa68a2f2-524f-11ea-bd69-fac0b7afc6af" in namespace "secrets-6395" to be "success or failure"
Feb 18 13:07:50.320: INFO: Pod "pod-secrets-aa68a2f2-524f-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066308ms
Feb 18 13:07:52.322: INFO: Pod "pod-secrets-aa68a2f2-524f-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004194261s
STEP: Saw pod success
Feb 18 13:07:52.323: INFO: Pod "pod-secrets-aa68a2f2-524f-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:07:52.324: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-secrets-aa68a2f2-524f-11ea-bd69-fac0b7afc6af container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 13:07:52.340: INFO: Waiting for pod pod-secrets-aa68a2f2-524f-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:07:52.342: INFO: Pod pod-secrets-aa68a2f2-524f-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:07:52.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6395" for this suite.
Feb 18 13:07:58.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:07:58.515: INFO: namespace secrets-6395 deletion completed in 6.171034425s

• [SLOW TEST:8.232 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:07:58.515: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 18 13:07:58.542: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-a,UID:af562d2a-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20853,Generation:0,CreationTimestamp:2020-02-18 13:07:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 13:07:58.542: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-a,UID:af562d2a-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20853,Generation:0,CreationTimestamp:2020-02-18 13:07:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 18 13:08:08.547: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-a,UID:af562d2a-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20880,Generation:0,CreationTimestamp:2020-02-18 13:07:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 18 13:08:08.547: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-a,UID:af562d2a-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20880,Generation:0,CreationTimestamp:2020-02-18 13:07:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 18 13:08:18.552: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-a,UID:af562d2a-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20911,Generation:0,CreationTimestamp:2020-02-18 13:07:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 13:08:18.552: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-a,UID:af562d2a-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20911,Generation:0,CreationTimestamp:2020-02-18 13:07:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 18 13:08:28.556: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-a,UID:af562d2a-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20939,Generation:0,CreationTimestamp:2020-02-18 13:07:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 13:08:28.556: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-a,UID:af562d2a-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20939,Generation:0,CreationTimestamp:2020-02-18 13:07:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 18 13:08:38.560: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-b,UID:c73030dc-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20966,Generation:0,CreationTimestamp:2020-02-18 13:08:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 13:08:38.560: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-b,UID:c73030dc-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20966,Generation:0,CreationTimestamp:2020-02-18 13:08:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 18 13:08:48.564: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-b,UID:c73030dc-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20994,Generation:0,CreationTimestamp:2020-02-18 13:08:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 13:08:48.564: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5296,SelfLink:/api/v1/namespaces/watch-5296/configmaps/e2e-watch-test-configmap-b,UID:c73030dc-524f-11ea-b701-0ae3ad6fc27e,ResourceVersion:20994,Generation:0,CreationTimestamp:2020-02-18 13:08:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:08:58.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5296" for this suite.
Feb 18 13:09:04.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:09:04.734: INFO: namespace watch-5296 deletion completed in 6.166955946s

• [SLOW TEST:66.219 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:09:04.735: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Feb 18 13:09:04.760: INFO: Waiting up to 5m0s for pod "var-expansion-d6c80691-524f-11ea-bd69-fac0b7afc6af" in namespace "var-expansion-6876" to be "success or failure"
Feb 18 13:09:04.763: INFO: Pod "var-expansion-d6c80691-524f-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.741156ms
Feb 18 13:09:06.765: INFO: Pod "var-expansion-d6c80691-524f-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005547171s
STEP: Saw pod success
Feb 18 13:09:06.765: INFO: Pod "var-expansion-d6c80691-524f-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:09:06.767: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod var-expansion-d6c80691-524f-11ea-bd69-fac0b7afc6af container dapi-container: <nil>
STEP: delete the pod
Feb 18 13:09:06.779: INFO: Waiting for pod var-expansion-d6c80691-524f-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:09:06.782: INFO: Pod var-expansion-d6c80691-524f-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:09:06.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6876" for this suite.
Feb 18 13:09:12.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:09:12.955: INFO: namespace var-expansion-6876 deletion completed in 6.170313192s

• [SLOW TEST:8.220 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:09:12.955: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 13:09:12.995: INFO: Create a RollingUpdate DaemonSet
Feb 18 13:09:12.999: INFO: Check that daemon pods launch on every node of the cluster
Feb 18 13:09:13.003: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 13:09:13.005: INFO: Number of nodes with available pods: 0
Feb 18 13:09:13.005: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:09:14.012: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 13:09:14.022: INFO: Number of nodes with available pods: 0
Feb 18 13:09:14.022: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:09:15.008: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 13:09:15.010: INFO: Number of nodes with available pods: 1
Feb 18 13:09:15.010: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:09:16.008: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 13:09:16.010: INFO: Number of nodes with available pods: 2
Feb 18 13:09:16.010: INFO: Number of running nodes: 2, number of available pods: 2
Feb 18 13:09:16.010: INFO: Update the DaemonSet to trigger a rollout
Feb 18 13:09:16.015: INFO: Updating DaemonSet daemon-set
Feb 18 13:09:24.030: INFO: Roll back the DaemonSet before rollout is complete
Feb 18 13:09:24.046: INFO: Updating DaemonSet daemon-set
Feb 18 13:09:24.046: INFO: Make sure DaemonSet rollback is complete
Feb 18 13:09:24.057: INFO: Wrong image for pod: daemon-set-7ff65. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 18 13:09:24.057: INFO: Pod daemon-set-7ff65 is not available
Feb 18 13:09:24.061: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 13:09:25.063: INFO: Wrong image for pod: daemon-set-7ff65. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 18 13:09:25.063: INFO: Pod daemon-set-7ff65 is not available
Feb 18 13:09:25.066: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 13:09:26.063: INFO: Wrong image for pod: daemon-set-7ff65. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Feb 18 13:09:26.063: INFO: Pod daemon-set-7ff65 is not available
Feb 18 13:09:26.065: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 18 13:09:27.063: INFO: Pod daemon-set-xw8dm is not available
Feb 18 13:09:27.066: INFO: DaemonSet pods can't tolerate node ip-10-100-0-131.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4640, will wait for the garbage collector to delete the pods
Feb 18 13:09:27.125: INFO: Deleting DaemonSet.extensions daemon-set took: 4.519376ms
Feb 18 13:09:27.626: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.172103ms
Feb 18 13:10:47.528: INFO: Number of nodes with available pods: 0
Feb 18 13:10:47.528: INFO: Number of running nodes: 0, number of available pods: 0
Feb 18 13:10:47.530: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4640/daemonsets","resourceVersion":"21473"},"items":null}

Feb 18 13:10:47.532: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4640/pods","resourceVersion":"21473"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:10:47.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4640" for this suite.
Feb 18 13:10:53.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:10:53.729: INFO: namespace daemonsets-4640 deletion completed in 6.187478751s

• [SLOW TEST:100.774 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:10:53.729: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 18 13:10:53.758: INFO: Waiting up to 5m0s for pod "pod-17c02242-5250-11ea-bd69-fac0b7afc6af" in namespace "emptydir-9078" to be "success or failure"
Feb 18 13:10:53.764: INFO: Pod "pod-17c02242-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 5.758615ms
Feb 18 13:10:55.767: INFO: Pod "pod-17c02242-5250-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008155742s
STEP: Saw pod success
Feb 18 13:10:55.767: INFO: Pod "pod-17c02242-5250-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:10:55.770: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-17c02242-5250-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 13:10:55.787: INFO: Waiting for pod pod-17c02242-5250-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:10:55.790: INFO: Pod pod-17c02242-5250-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:10:55.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9078" for this suite.
Feb 18 13:11:01.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:11:01.959: INFO: namespace emptydir-9078 deletion completed in 6.166548948s

• [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:11:01.959: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 13:11:01.984: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 18 13:11:06.986: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 18 13:11:06.986: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 18 13:11:08.988: INFO: Creating deployment "test-rollover-deployment"
Feb 18 13:11:08.993: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 18 13:11:10.998: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 18 13:11:11.002: INFO: Ensure that both replica sets have 1 created replica
Feb 18 13:11:11.005: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 18 13:11:11.009: INFO: Updating deployment test-rollover-deployment
Feb 18 13:11:11.009: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 18 13:11:13.014: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 18 13:11:13.018: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 18 13:11:13.021: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 13:11:13.021: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628271, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:11:15.025: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 13:11:15.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628273, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:11:17.025: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 13:11:17.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628273, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:11:19.025: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 13:11:19.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628273, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:11:21.025: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 13:11:21.025: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628273, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:11:23.026: INFO: all replica sets need to contain the pod-template-hash label
Feb 18 13:11:23.026: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628273, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628269, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-659c699649\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:11:25.026: INFO: 
Feb 18 13:11:25.026: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 13:11:25.032: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3664,SelfLink:/apis/apps/v1/namespaces/deployment-3664/deployments/test-rollover-deployment,UID:20da2057-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:21714,Generation:2,CreationTimestamp:2020-02-18 13:11:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2020-02-18 13:11:09 +0000 UTC 2020-02-18 13:11:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2020-02-18 13:11:23 +0000 UTC 2020-02-18 13:11:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-659c699649" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 18 13:11:25.034: INFO: New ReplicaSet "test-rollover-deployment-659c699649" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649,GenerateName:,Namespace:deployment-3664,SelfLink:/apis/apps/v1/namespaces/deployment-3664/replicasets/test-rollover-deployment-659c699649,UID:220e85f7-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:21704,Generation:2,CreationTimestamp:2020-02-18 13:11:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 20da2057-5250-11ea-b701-0ae3ad6fc27e 0xc0039714c7 0xc0039714c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 18 13:11:25.034: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 18 13:11:25.034: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3664,SelfLink:/apis/apps/v1/namespaces/deployment-3664/replicasets/test-rollover-controller,UID:1cac7dfd-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:21713,Generation:2,CreationTimestamp:2020-02-18 13:11:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 20da2057-5250-11ea-b701-0ae3ad6fc27e 0xc0039713f7 0xc0039713f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 13:11:25.034: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-7b45b6464,GenerateName:,Namespace:deployment-3664,SelfLink:/apis/apps/v1/namespaces/deployment-3664/replicasets/test-rollover-deployment-7b45b6464,UID:20db83c1-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:21650,Generation:2,CreationTimestamp:2020-02-18 13:11:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 20da2057-5250-11ea-b701-0ae3ad6fc27e 0xc003971590 0xc003971591}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 7b45b6464,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 13:11:25.036: INFO: Pod "test-rollover-deployment-659c699649-d5xm8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-659c699649-d5xm8,GenerateName:test-rollover-deployment-659c699649-,Namespace:deployment-3664,SelfLink:/api/v1/namespaces/deployment-3664/pods/test-rollover-deployment-659c699649-d5xm8,UID:22123eb7-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:21672,Generation:0,CreationTimestamp:2020-02-18 13:11:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 659c699649,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.213/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-659c699649 220e85f7-5250-11ea-b701-0ae3ad6fc27e 0xc002632177 0xc002632178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qpv6q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qpv6q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qpv6q true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0026321e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002632200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:11:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:11:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:11:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:11:11 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:172.16.102.213,StartTime:2020-02-18 13:11:11 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2020-02-18 13:11:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://02cfdff3fc734c1261b3ba60975bc9977ff82e754c87dd404bccff9a8934df66}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:11:25.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3664" for this suite.
Feb 18 13:11:31.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:11:31.207: INFO: namespace deployment-3664 deletion completed in 6.168837846s

• [SLOW TEST:29.248 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:11:31.207: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 18 13:11:39.265: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:39.269: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:41.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:41.271: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:43.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:43.271: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:45.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:45.271: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:47.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:47.271: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:49.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:49.271: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:51.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:51.271: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:53.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:53.272: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:55.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:55.271: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:57.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:57.271: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:11:59.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:11:59.271: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:12:01.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:12:01.273: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 18 13:12:03.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 18 13:12:03.271: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:12:03.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6206" for this suite.
Feb 18 13:12:25.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:12:25.441: INFO: namespace container-lifecycle-hook-6206 deletion completed in 22.166800866s

• [SLOW TEST:54.234 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:12:25.442: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 13:12:25.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e698f70-5250-11ea-bd69-fac0b7afc6af" in namespace "projected-3625" to be "success or failure"
Feb 18 13:12:25.474: INFO: Pod "downwardapi-volume-4e698f70-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 5.836783ms
Feb 18 13:12:27.476: INFO: Pod "downwardapi-volume-4e698f70-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007976568s
Feb 18 13:12:29.479: INFO: Pod "downwardapi-volume-4e698f70-5250-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01033654s
STEP: Saw pod success
Feb 18 13:12:29.479: INFO: Pod "downwardapi-volume-4e698f70-5250-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:12:29.481: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-4e698f70-5250-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 13:12:29.497: INFO: Waiting for pod downwardapi-volume-4e698f70-5250-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:12:29.500: INFO: Pod downwardapi-volume-4e698f70-5250-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:12:29.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3625" for this suite.
Feb 18 13:12:35.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:12:35.673: INFO: namespace projected-3625 deletion completed in 6.171646424s

• [SLOW TEST:10.232 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:12:35.674: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-548a914f-5250-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 13:12:35.750: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-548ae4a4-5250-11ea-bd69-fac0b7afc6af" in namespace "projected-7161" to be "success or failure"
Feb 18 13:12:35.753: INFO: Pod "pod-projected-secrets-548ae4a4-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 1.805861ms
Feb 18 13:12:37.756: INFO: Pod "pod-projected-secrets-548ae4a4-5250-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004370334s
STEP: Saw pod success
Feb 18 13:12:37.756: INFO: Pod "pod-projected-secrets-548ae4a4-5250-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:12:37.758: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-secrets-548ae4a4-5250-11ea-bd69-fac0b7afc6af container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 13:12:37.769: INFO: Waiting for pod pod-projected-secrets-548ae4a4-5250-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:12:37.771: INFO: Pod pod-projected-secrets-548ae4a4-5250-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:12:37.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7161" for this suite.
Feb 18 13:12:43.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:12:43.956: INFO: namespace projected-7161 deletion completed in 6.183130736s

• [SLOW TEST:8.282 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:12:43.956: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0218 13:13:24.030303      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 13:13:24.030: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:13:24.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8018" for this suite.
Feb 18 13:13:30.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:13:30.204: INFO: namespace gc-8018 deletion completed in 6.168549225s

• [SLOW TEST:46.248 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:13:30.204: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 13:13:30.232: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7503d09a-5250-11ea-bd69-fac0b7afc6af" in namespace "downward-api-2607" to be "success or failure"
Feb 18 13:13:30.238: INFO: Pod "downwardapi-volume-7503d09a-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 6.263996ms
Feb 18 13:13:32.240: INFO: Pod "downwardapi-volume-7503d09a-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008693755s
Feb 18 13:13:34.243: INFO: Pod "downwardapi-volume-7503d09a-5250-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011107347s
STEP: Saw pod success
Feb 18 13:13:34.243: INFO: Pod "downwardapi-volume-7503d09a-5250-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:13:34.245: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-7503d09a-5250-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 13:13:34.258: INFO: Waiting for pod downwardapi-volume-7503d09a-5250-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:13:34.260: INFO: Pod downwardapi-volume-7503d09a-5250-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:13:34.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2607" for this suite.
Feb 18 13:13:40.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:13:40.435: INFO: namespace downward-api-2607 deletion completed in 6.17236968s

• [SLOW TEST:10.231 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:13:40.436: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1649
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 13:13:40.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4787'
Feb 18 13:13:40.526: INFO: stderr: ""
Feb 18 13:13:40.526: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1654
Feb 18 13:13:40.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete pods e2e-test-nginx-pod --namespace=kubectl-4787'
Feb 18 13:13:53.045: INFO: stderr: ""
Feb 18 13:13:53.045: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:13:53.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4787" for this suite.
Feb 18 13:13:59.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:13:59.214: INFO: namespace kubectl-4787 deletion completed in 6.166021481s

• [SLOW TEST:18.779 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:13:59.215: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Feb 18 13:13:59.286: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:14:02.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5832" for this suite.
Feb 18 13:14:08.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:14:08.484: INFO: namespace init-container-5832 deletion completed in 6.168641514s

• [SLOW TEST:9.269 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:14:08.484: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 18 13:14:08.575: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7650,SelfLink:/api/v1/namespaces/watch-7650/configmaps/e2e-watch-test-label-changed,UID:8be36129-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:22676,Generation:0,CreationTimestamp:2020-02-18 13:14:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 18 13:14:08.575: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7650,SelfLink:/api/v1/namespaces/watch-7650/configmaps/e2e-watch-test-label-changed,UID:8be36129-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:22677,Generation:0,CreationTimestamp:2020-02-18 13:14:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 18 13:14:08.576: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7650,SelfLink:/api/v1/namespaces/watch-7650/configmaps/e2e-watch-test-label-changed,UID:8be36129-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:22678,Generation:0,CreationTimestamp:2020-02-18 13:14:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 18 13:14:18.590: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7650,SelfLink:/api/v1/namespaces/watch-7650/configmaps/e2e-watch-test-label-changed,UID:8be36129-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:22706,Generation:0,CreationTimestamp:2020-02-18 13:14:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 18 13:14:18.590: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7650,SelfLink:/api/v1/namespaces/watch-7650/configmaps/e2e-watch-test-label-changed,UID:8be36129-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:22707,Generation:0,CreationTimestamp:2020-02-18 13:14:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 18 13:14:18.590: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7650,SelfLink:/api/v1/namespaces/watch-7650/configmaps/e2e-watch-test-label-changed,UID:8be36129-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:22708,Generation:0,CreationTimestamp:2020-02-18 13:14:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:14:18.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7650" for this suite.
Feb 18 13:14:24.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:14:24.760: INFO: namespace watch-7650 deletion completed in 6.16702882s

• [SLOW TEST:16.276 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:14:24.760: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 13:14:24.784: INFO: Waiting up to 5m0s for pod "downwardapi-volume-958816e3-5250-11ea-bd69-fac0b7afc6af" in namespace "projected-5984" to be "success or failure"
Feb 18 13:14:24.787: INFO: Pod "downwardapi-volume-958816e3-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.870122ms
Feb 18 13:14:26.789: INFO: Pod "downwardapi-volume-958816e3-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005214477s
Feb 18 13:14:28.791: INFO: Pod "downwardapi-volume-958816e3-5250-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007472443s
STEP: Saw pod success
Feb 18 13:14:28.792: INFO: Pod "downwardapi-volume-958816e3-5250-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:14:28.793: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-958816e3-5250-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 13:14:28.808: INFO: Waiting for pod downwardapi-volume-958816e3-5250-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:14:28.809: INFO: Pod downwardapi-volume-958816e3-5250-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:14:28.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5984" for this suite.
Feb 18 13:14:34.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:14:34.984: INFO: namespace projected-5984 deletion completed in 6.172768562s

• [SLOW TEST:10.224 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:14:34.985: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 18 13:14:37.534: INFO: Successfully updated pod "pod-update-9ba051ea-5250-11ea-bd69-fac0b7afc6af"
STEP: verifying the updated pod is in kubernetes
Feb 18 13:14:37.539: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:14:37.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3713" for this suite.
Feb 18 13:14:59.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:14:59.709: INFO: namespace pods-3713 deletion completed in 22.167782257s

• [SLOW TEST:24.724 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:14:59.709: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Feb 18 13:15:00.348: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 18 13:15:02.378: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:15:04.380: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:15:06.380: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:15:08.380: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717628500, loc:(*time.Location)(0x882e100)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-65db6755fc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 18 13:15:11.300: INFO: Waited 917.628818ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:15:11.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6256" for this suite.
Feb 18 13:15:18.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:15:18.289: INFO: namespace aggregator-6256 deletion completed in 6.260762965s

• [SLOW TEST:18.581 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:15:18.290: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 18 13:15:20.336: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-b57021d2-5250-11ea-bd69-fac0b7afc6af,GenerateName:,Namespace:events-6381,SelfLink:/api/v1/namespaces/events-6381/pods/send-events-b57021d2-5250-11ea-bd69-fac0b7afc6af,UID:b576412b-5250-11ea-b701-0ae3ad6fc27e,ResourceVersion:23039,Generation:0,CreationTimestamp:2020-02-18 13:15:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 311960257,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.233/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kd5dw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kd5dw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-kd5dw true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e36f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e36f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:15:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:15:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:15:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:15:18 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:172.16.102.233,StartTime:2020-02-18 13:15:18 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2020-02-18 13:15:19 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://f25f99a341eaf78218e987077bcfdfe4017d64b72f8e45fcea3b74124a0b3c1e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 18 13:15:22.339: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 18 13:15:24.341: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:15:24.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6381" for this suite.
Feb 18 13:16:04.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:16:04.523: INFO: namespace events-6381 deletion completed in 40.174056494s

• [SLOW TEST:46.234 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:16:04.524: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 18 13:16:04.551: INFO: Waiting up to 5m0s for pod "pod-d0fef91a-5250-11ea-bd69-fac0b7afc6af" in namespace "emptydir-3058" to be "success or failure"
Feb 18 13:16:04.553: INFO: Pod "pod-d0fef91a-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.631111ms
Feb 18 13:16:06.556: INFO: Pod "pod-d0fef91a-5250-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005635264s
STEP: Saw pod success
Feb 18 13:16:06.556: INFO: Pod "pod-d0fef91a-5250-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:16:06.559: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-d0fef91a-5250-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 13:16:06.579: INFO: Waiting for pod pod-d0fef91a-5250-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:16:06.581: INFO: Pod pod-d0fef91a-5250-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:16:06.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3058" for this suite.
Feb 18 13:16:12.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:16:12.765: INFO: namespace emptydir-3058 deletion completed in 6.182119025s

• [SLOW TEST:8.241 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:16:12.765: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-d5e86535-5250-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 13:16:12.794: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d5e8d276-5250-11ea-bd69-fac0b7afc6af" in namespace "projected-8662" to be "success or failure"
Feb 18 13:16:12.799: INFO: Pod "pod-projected-configmaps-d5e8d276-5250-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.635472ms
Feb 18 13:16:14.801: INFO: Pod "pod-projected-configmaps-d5e8d276-5250-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00677029s
STEP: Saw pod success
Feb 18 13:16:14.801: INFO: Pod "pod-projected-configmaps-d5e8d276-5250-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:16:14.803: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-configmaps-d5e8d276-5250-11ea-bd69-fac0b7afc6af container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 13:16:14.816: INFO: Waiting for pod pod-projected-configmaps-d5e8d276-5250-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:16:14.818: INFO: Pod pod-projected-configmaps-d5e8d276-5250-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:16:14.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8662" for this suite.
Feb 18 13:16:20.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:16:20.989: INFO: namespace projected-8662 deletion completed in 6.168610724s

• [SLOW TEST:8.224 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:16:20.989: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3501
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Feb 18 13:16:21.029: INFO: Found 0 stateful pods, waiting for 3
Feb 18 13:16:31.031: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 13:16:31.032: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 13:16:31.032: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 13:16:31.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-3501 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 13:16:31.205: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 13:16:31.205: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 13:16:31.205: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 18 13:16:41.230: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 18 13:16:51.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-3501 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 13:16:51.433: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 18 13:16:51.433: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 13:16:51.433: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 13:17:01.444: INFO: Waiting for StatefulSet statefulset-3501/ss2 to complete update
Feb 18 13:17:01.444: INFO: Waiting for Pod statefulset-3501/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 18 13:17:01.444: INFO: Waiting for Pod statefulset-3501/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 18 13:17:01.445: INFO: Waiting for Pod statefulset-3501/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 18 13:17:11.449: INFO: Waiting for StatefulSet statefulset-3501/ss2 to complete update
Feb 18 13:17:11.449: INFO: Waiting for Pod statefulset-3501/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 18 13:17:11.449: INFO: Waiting for Pod statefulset-3501/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Feb 18 13:17:21.449: INFO: Waiting for StatefulSet statefulset-3501/ss2 to complete update
Feb 18 13:17:21.449: INFO: Waiting for Pod statefulset-3501/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Feb 18 13:17:31.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-3501 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 13:17:31.633: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 13:17:31.633: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 13:17:31.633: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 13:17:41.657: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 18 13:17:51.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-3501 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 13:17:51.846: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 18 13:17:51.846: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 13:17:51.846: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 13:18:01.858: INFO: Waiting for StatefulSet statefulset-3501/ss2 to complete update
Feb 18 13:18:01.858: INFO: Waiting for Pod statefulset-3501/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 18 13:18:01.858: INFO: Waiting for Pod statefulset-3501/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 18 13:18:01.858: INFO: Waiting for Pod statefulset-3501/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 18 13:18:11.862: INFO: Waiting for StatefulSet statefulset-3501/ss2 to complete update
Feb 18 13:18:11.862: INFO: Waiting for Pod statefulset-3501/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 18 13:18:11.862: INFO: Waiting for Pod statefulset-3501/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Feb 18 13:18:21.862: INFO: Waiting for StatefulSet statefulset-3501/ss2 to complete update
Feb 18 13:18:21.862: INFO: Waiting for Pod statefulset-3501/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 13:18:31.862: INFO: Deleting all statefulset in ns statefulset-3501
Feb 18 13:18:31.864: INFO: Scaling statefulset ss2 to 0
Feb 18 13:18:51.875: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 13:18:51.877: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:18:51.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3501" for this suite.
Feb 18 13:18:57.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:18:58.063: INFO: namespace statefulset-3501 deletion completed in 6.17217453s

• [SLOW TEST:157.074 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:18:58.063: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Feb 18 13:18:58.095: INFO: Waiting up to 5m0s for pod "downward-api-386f51e2-5251-11ea-bd69-fac0b7afc6af" in namespace "downward-api-5174" to be "success or failure"
Feb 18 13:18:58.096: INFO: Pod "downward-api-386f51e2-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 1.566042ms
Feb 18 13:19:00.099: INFO: Pod "downward-api-386f51e2-5251-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003860442s
STEP: Saw pod success
Feb 18 13:19:00.099: INFO: Pod "downward-api-386f51e2-5251-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:19:00.100: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downward-api-386f51e2-5251-11ea-bd69-fac0b7afc6af container dapi-container: <nil>
STEP: delete the pod
Feb 18 13:19:00.114: INFO: Waiting for pod downward-api-386f51e2-5251-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:19:00.115: INFO: Pod downward-api-386f51e2-5251-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:19:00.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5174" for this suite.
Feb 18 13:19:06.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:19:06.285: INFO: namespace downward-api-5174 deletion completed in 6.167414618s

• [SLOW TEST:8.222 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:19:06.285: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Feb 18 13:19:08.841: INFO: Successfully updated pod "labelsupdate3d55aa8b-5251-11ea-bd69-fac0b7afc6af"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:19:10.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8249" for this suite.
Feb 18 13:19:32.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:19:33.021: INFO: namespace projected-8249 deletion completed in 22.16648996s

• [SLOW TEST:26.736 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:19:33.022: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 13:19:33.042: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:19:35.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-68" for this suite.
Feb 18 13:20:25.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:20:25.261: INFO: namespace pods-68 deletion completed in 50.168796559s

• [SLOW TEST:52.240 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:20:25.261: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Feb 18 13:20:25.286: INFO: Waiting up to 5m0s for pod "downward-api-6c685c53-5251-11ea-bd69-fac0b7afc6af" in namespace "downward-api-1923" to be "success or failure"
Feb 18 13:20:25.291: INFO: Pod "downward-api-6c685c53-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 5.62905ms
Feb 18 13:20:27.293: INFO: Pod "downward-api-6c685c53-5251-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007765954s
STEP: Saw pod success
Feb 18 13:20:27.293: INFO: Pod "downward-api-6c685c53-5251-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:20:27.295: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downward-api-6c685c53-5251-11ea-bd69-fac0b7afc6af container dapi-container: <nil>
STEP: delete the pod
Feb 18 13:20:27.308: INFO: Waiting for pod downward-api-6c685c53-5251-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:20:27.310: INFO: Pod downward-api-6c685c53-5251-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:20:27.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1923" for this suite.
Feb 18 13:20:33.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:20:33.482: INFO: namespace downward-api-1923 deletion completed in 6.167684783s

• [SLOW TEST:8.221 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:20:33.482: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Feb 18 13:20:33.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-5699'
Feb 18 13:20:33.885: INFO: stderr: ""
Feb 18 13:20:33.885: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 13:20:33.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5699'
Feb 18 13:20:33.951: INFO: stderr: ""
Feb 18 13:20:33.951: INFO: stdout: "update-demo-nautilus-fkgbn update-demo-nautilus-pkhxl "
Feb 18 13:20:33.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-fkgbn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5699'
Feb 18 13:20:34.010: INFO: stderr: ""
Feb 18 13:20:34.010: INFO: stdout: ""
Feb 18 13:20:34.010: INFO: update-demo-nautilus-fkgbn is created but not running
Feb 18 13:20:39.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5699'
Feb 18 13:20:39.074: INFO: stderr: ""
Feb 18 13:20:39.074: INFO: stdout: "update-demo-nautilus-fkgbn update-demo-nautilus-pkhxl "
Feb 18 13:20:39.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-fkgbn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5699'
Feb 18 13:20:39.129: INFO: stderr: ""
Feb 18 13:20:39.129: INFO: stdout: "true"
Feb 18 13:20:39.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-fkgbn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5699'
Feb 18 13:20:39.189: INFO: stderr: ""
Feb 18 13:20:39.189: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 13:20:39.189: INFO: validating pod update-demo-nautilus-fkgbn
Feb 18 13:20:39.192: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 13:20:39.192: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 13:20:39.192: INFO: update-demo-nautilus-fkgbn is verified up and running
Feb 18 13:20:39.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-pkhxl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5699'
Feb 18 13:20:39.249: INFO: stderr: ""
Feb 18 13:20:39.249: INFO: stdout: "true"
Feb 18 13:20:39.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-nautilus-pkhxl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5699'
Feb 18 13:20:39.306: INFO: stderr: ""
Feb 18 13:20:39.306: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 18 13:20:39.306: INFO: validating pod update-demo-nautilus-pkhxl
Feb 18 13:20:39.309: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 18 13:20:39.309: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 18 13:20:39.309: INFO: update-demo-nautilus-pkhxl is verified up and running
STEP: rolling-update to new replication controller
Feb 18 13:20:39.311: INFO: scanned /root for discovery docs: <nil>
Feb 18 13:20:39.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5699'
Feb 18 13:21:01.600: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 18 13:21:01.600: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 18 13:21:01.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5699'
Feb 18 13:21:01.667: INFO: stderr: ""
Feb 18 13:21:01.667: INFO: stdout: "update-demo-kitten-444z4 update-demo-kitten-cp7zt update-demo-nautilus-fkgbn "
STEP: Replicas for name=update-demo: expected=2 actual=3
Feb 18 13:21:06.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5699'
Feb 18 13:21:06.727: INFO: stderr: ""
Feb 18 13:21:06.727: INFO: stdout: "update-demo-kitten-444z4 update-demo-kitten-cp7zt "
Feb 18 13:21:06.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-kitten-444z4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5699'
Feb 18 13:21:06.787: INFO: stderr: ""
Feb 18 13:21:06.787: INFO: stdout: "true"
Feb 18 13:21:06.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-kitten-444z4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5699'
Feb 18 13:21:06.844: INFO: stderr: ""
Feb 18 13:21:06.844: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 18 13:21:06.844: INFO: validating pod update-demo-kitten-444z4
Feb 18 13:21:06.847: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 18 13:21:06.847: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 18 13:21:06.847: INFO: update-demo-kitten-444z4 is verified up and running
Feb 18 13:21:06.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-kitten-cp7zt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5699'
Feb 18 13:21:06.906: INFO: stderr: ""
Feb 18 13:21:06.906: INFO: stdout: "true"
Feb 18 13:21:06.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 get pods update-demo-kitten-cp7zt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5699'
Feb 18 13:21:06.963: INFO: stderr: ""
Feb 18 13:21:06.963: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 18 13:21:06.963: INFO: validating pod update-demo-kitten-cp7zt
Feb 18 13:21:06.966: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 18 13:21:06.966: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 18 13:21:06.966: INFO: update-demo-kitten-cp7zt is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:21:06.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5699" for this suite.
Feb 18 13:21:28.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:21:29.137: INFO: namespace kubectl-5699 deletion completed in 22.169178323s

• [SLOW TEST:55.655 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:21:29.137: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Feb 18 13:21:29.165: INFO: Waiting up to 5m0s for pod "var-expansion-927b3b72-5251-11ea-bd69-fac0b7afc6af" in namespace "var-expansion-8594" to be "success or failure"
Feb 18 13:21:29.167: INFO: Pod "var-expansion-927b3b72-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 1.959739ms
Feb 18 13:21:31.169: INFO: Pod "var-expansion-927b3b72-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004012547s
Feb 18 13:21:33.171: INFO: Pod "var-expansion-927b3b72-5251-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006029011s
STEP: Saw pod success
Feb 18 13:21:33.171: INFO: Pod "var-expansion-927b3b72-5251-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:21:33.173: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod var-expansion-927b3b72-5251-11ea-bd69-fac0b7afc6af container dapi-container: <nil>
STEP: delete the pod
Feb 18 13:21:33.185: INFO: Waiting for pod var-expansion-927b3b72-5251-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:21:33.186: INFO: Pod var-expansion-927b3b72-5251-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:21:33.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8594" for this suite.
Feb 18 13:21:39.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:21:39.354: INFO: namespace var-expansion-8594 deletion completed in 6.166091258s

• [SLOW TEST:10.217 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:21:39.355: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3808.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3808.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3808.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3808.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3808.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3808.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 18 13:21:43.453: INFO: DNS probes using dns-3808/dns-test-9899a953-5251-11ea-bd69-fac0b7afc6af succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:21:43.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3808" for this suite.
Feb 18 13:21:49.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:21:49.635: INFO: namespace dns-3808 deletion completed in 6.170901876s

• [SLOW TEST:10.280 seconds]
[sig-network] DNS
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:21:49.636: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5078
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5078
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5078
Feb 18 13:21:49.671: INFO: Found 0 stateful pods, waiting for 1
Feb 18 13:21:59.673: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 18 13:21:59.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5078 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 13:21:59.871: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 13:21:59.871: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 13:21:59.871: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 13:21:59.874: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 18 13:22:09.876: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 13:22:09.876: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 13:22:09.885: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999871s
Feb 18 13:22:10.888: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996660197s
Feb 18 13:22:11.890: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994334191s
Feb 18 13:22:12.892: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992130768s
Feb 18 13:22:13.895: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.989981828s
Feb 18 13:22:14.897: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.987076426s
Feb 18 13:22:15.899: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.984847926s
Feb 18 13:22:16.901: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.982642029s
Feb 18 13:22:17.904: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.980395256s
Feb 18 13:22:18.906: INFO: Verifying statefulset ss doesn't scale past 1 for another 977.931901ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5078
Feb 18 13:22:19.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5078 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 13:22:20.115: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 18 13:22:20.115: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 13:22:20.115: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 13:22:20.118: INFO: Found 1 stateful pods, waiting for 3
Feb 18 13:22:30.120: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 13:22:30.120: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 18 13:22:30.120: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 18 13:22:30.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5078 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 13:22:30.323: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 13:22:30.323: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 13:22:30.323: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 13:22:30.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5078 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 13:22:30.535: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 13:22:30.535: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 13:22:30.535: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 13:22:30.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5078 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 18 13:22:30.780: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Feb 18 13:22:30.780: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 18 13:22:30.780: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 18 13:22:30.780: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 13:22:30.784: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb 18 13:22:40.788: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 13:22:40.788: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 13:22:40.788: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 18 13:22:40.799: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999792s
Feb 18 13:22:41.801: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993434398s
Feb 18 13:22:42.804: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991007982s
Feb 18 13:22:43.806: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988411717s
Feb 18 13:22:44.809: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985793293s
Feb 18 13:22:45.811: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98343126s
Feb 18 13:22:46.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.980838078s
Feb 18 13:22:47.816: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.978311243s
Feb 18 13:22:48.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.975784534s
Feb 18 13:22:49.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.355797ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5078
Feb 18 13:22:50.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5078 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 13:22:51.008: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 18 13:22:51.008: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 13:22:51.008: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 13:22:51.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5078 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 13:22:51.216: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 18 13:22:51.216: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 13:22:51.216: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 13:22:51.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 exec --namespace=statefulset-5078 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 18 13:22:51.440: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Feb 18 13:22:51.440: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 18 13:22:51.440: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 18 13:22:51.440: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 18 13:23:11.449: INFO: Deleting all statefulset in ns statefulset-5078
Feb 18 13:23:11.451: INFO: Scaling statefulset ss to 0
Feb 18 13:23:11.457: INFO: Waiting for statefulset status.replicas updated to 0
Feb 18 13:23:11.458: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:23:11.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5078" for this suite.
Feb 18 13:23:17.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:23:17.646: INFO: namespace statefulset-5078 deletion completed in 6.169560067s

• [SLOW TEST:88.011 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:23:17.647: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:23:23.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5005" for this suite.
Feb 18 13:23:29.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:23:29.894: INFO: namespace namespaces-5005 deletion completed in 6.167992955s
STEP: Destroying namespace "nsdeletetest-998" for this suite.
Feb 18 13:23:29.895: INFO: Namespace nsdeletetest-998 was already deleted
STEP: Destroying namespace "nsdeletetest-3745" for this suite.
Feb 18 13:23:35.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:23:36.061: INFO: namespace nsdeletetest-3745 deletion completed in 6.165587638s

• [SLOW TEST:18.414 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:23:36.062: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 18 13:23:36.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2475'
Feb 18 13:23:36.148: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 18 13:23:36.148: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 18 13:23:36.164: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-qbzd8]
Feb 18 13:23:36.164: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-qbzd8" in namespace "kubectl-2475" to be "running and ready"
Feb 18 13:23:36.169: INFO: Pod "e2e-test-nginx-rc-qbzd8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.916408ms
Feb 18 13:23:38.171: INFO: Pod "e2e-test-nginx-rc-qbzd8": Phase="Running", Reason="", readiness=true. Elapsed: 2.006976644s
Feb 18 13:23:38.171: INFO: Pod "e2e-test-nginx-rc-qbzd8" satisfied condition "running and ready"
Feb 18 13:23:38.171: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-qbzd8]
Feb 18 13:23:38.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 logs rc/e2e-test-nginx-rc --namespace=kubectl-2475'
Feb 18 13:23:38.246: INFO: stderr: ""
Feb 18 13:23:38.246: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1425
Feb 18 13:23:38.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 delete rc e2e-test-nginx-rc --namespace=kubectl-2475'
Feb 18 13:23:38.307: INFO: stderr: ""
Feb 18 13:23:38.307: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:23:38.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2475" for this suite.
Feb 18 13:24:00.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:24:00.481: INFO: namespace kubectl-2475 deletion completed in 22.171240179s

• [SLOW TEST:24.420 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:24:00.481: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 18 13:24:00.508: INFO: Waiting up to 5m0s for pod "pod-ecb04d12-5251-11ea-bd69-fac0b7afc6af" in namespace "emptydir-5353" to be "success or failure"
Feb 18 13:24:00.512: INFO: Pod "pod-ecb04d12-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.982746ms
Feb 18 13:24:02.514: INFO: Pod "pod-ecb04d12-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006358445s
Feb 18 13:24:04.517: INFO: Pod "pod-ecb04d12-5251-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008669811s
STEP: Saw pod success
Feb 18 13:24:04.517: INFO: Pod "pod-ecb04d12-5251-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:24:04.519: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-ecb04d12-5251-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 13:24:04.531: INFO: Waiting for pod pod-ecb04d12-5251-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:24:04.533: INFO: Pod pod-ecb04d12-5251-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:24:04.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5353" for this suite.
Feb 18 13:24:10.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:24:10.703: INFO: namespace emptydir-5353 deletion completed in 6.167782056s

• [SLOW TEST:10.222 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:24:10.704: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 13:24:10.741: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2c95638-5251-11ea-bd69-fac0b7afc6af" in namespace "projected-4816" to be "success or failure"
Feb 18 13:24:10.749: INFO: Pod "downwardapi-volume-f2c95638-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.74025ms
Feb 18 13:24:12.751: INFO: Pod "downwardapi-volume-f2c95638-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010054551s
Feb 18 13:24:14.754: INFO: Pod "downwardapi-volume-f2c95638-5251-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012527498s
STEP: Saw pod success
Feb 18 13:24:14.754: INFO: Pod "downwardapi-volume-f2c95638-5251-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:24:14.756: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-f2c95638-5251-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 13:24:14.768: INFO: Waiting for pod downwardapi-volume-f2c95638-5251-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:24:14.770: INFO: Pod downwardapi-volume-f2c95638-5251-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:24:14.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4816" for this suite.
Feb 18 13:24:20.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:24:20.940: INFO: namespace projected-4816 deletion completed in 6.168089202s

• [SLOW TEST:10.237 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:24:20.940: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f8e29296-5251-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 13:24:20.972: INFO: Waiting up to 5m0s for pod "pod-secrets-f8e30826-5251-11ea-bd69-fac0b7afc6af" in namespace "secrets-997" to be "success or failure"
Feb 18 13:24:20.974: INFO: Pod "pod-secrets-f8e30826-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063662ms
Feb 18 13:24:22.976: INFO: Pod "pod-secrets-f8e30826-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004385323s
Feb 18 13:24:24.978: INFO: Pod "pod-secrets-f8e30826-5251-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006694463s
STEP: Saw pod success
Feb 18 13:24:24.978: INFO: Pod "pod-secrets-f8e30826-5251-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:24:24.980: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-secrets-f8e30826-5251-11ea-bd69-fac0b7afc6af container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 13:24:24.992: INFO: Waiting for pod pod-secrets-f8e30826-5251-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:24:24.994: INFO: Pod pod-secrets-f8e30826-5251-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:24:24.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-997" for this suite.
Feb 18 13:24:31.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:24:31.163: INFO: namespace secrets-997 deletion completed in 6.166248924s

• [SLOW TEST:10.222 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:24:31.163: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-fefb87ea-5251-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 13:24:31.206: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fefc5562-5251-11ea-bd69-fac0b7afc6af" in namespace "projected-9947" to be "success or failure"
Feb 18 13:24:31.211: INFO: Pod "pod-projected-secrets-fefc5562-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.291926ms
Feb 18 13:24:33.213: INFO: Pod "pod-projected-secrets-fefc5562-5251-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006552064s
Feb 18 13:24:35.215: INFO: Pod "pod-projected-secrets-fefc5562-5251-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008813258s
STEP: Saw pod success
Feb 18 13:24:35.215: INFO: Pod "pod-projected-secrets-fefc5562-5251-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:24:35.217: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-secrets-fefc5562-5251-11ea-bd69-fac0b7afc6af container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 13:24:35.229: INFO: Waiting for pod pod-projected-secrets-fefc5562-5251-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:24:35.231: INFO: Pod pod-projected-secrets-fefc5562-5251-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:24:35.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9947" for this suite.
Feb 18 13:24:41.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:24:41.401: INFO: namespace projected-9947 deletion completed in 6.166444898s

• [SLOW TEST:10.238 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:24:41.401: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-9283
Feb 18 13:24:43.432: INFO: Started pod liveness-http in namespace container-probe-9283
STEP: checking the pod's current state and verifying that restartCount is present
Feb 18 13:24:43.435: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:28:43.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9283" for this suite.
Feb 18 13:28:49.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:28:49.903: INFO: namespace container-probe-9283 deletion completed in 6.168063356s

• [SLOW TEST:248.502 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:28:49.904: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:28:53.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8006" for this suite.
Feb 18 13:29:33.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:29:34.114: INFO: namespace kubelet-test-8006 deletion completed in 40.171269702s

• [SLOW TEST:44.211 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:29:34.115: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 13:29:34.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b38ea185-5252-11ea-bd69-fac0b7afc6af" in namespace "projected-3413" to be "success or failure"
Feb 18 13:29:34.155: INFO: Pod "downwardapi-volume-b38ea185-5252-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.127202ms
Feb 18 13:29:36.161: INFO: Pod "downwardapi-volume-b38ea185-5252-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009209403s
STEP: Saw pod success
Feb 18 13:29:36.161: INFO: Pod "downwardapi-volume-b38ea185-5252-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:29:36.166: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-b38ea185-5252-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 13:29:36.179: INFO: Waiting for pod downwardapi-volume-b38ea185-5252-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:29:36.181: INFO: Pod downwardapi-volume-b38ea185-5252-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:29:36.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3413" for this suite.
Feb 18 13:29:42.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:29:42.351: INFO: namespace projected-3413 deletion completed in 6.165595812s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:29:42.352: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Feb 18 13:29:42.373: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:29:46.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7498" for this suite.
Feb 18 13:29:52.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:29:52.538: INFO: namespace init-container-7498 deletion completed in 6.166525486s

• [SLOW TEST:10.187 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:29:52.538: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-be87f5d4-5252-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 13:29:52.567: INFO: Waiting up to 5m0s for pod "pod-configmaps-be888740-5252-11ea-bd69-fac0b7afc6af" in namespace "configmap-4810" to be "success or failure"
Feb 18 13:29:52.570: INFO: Pod "pod-configmaps-be888740-5252-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.805971ms
Feb 18 13:29:54.572: INFO: Pod "pod-configmaps-be888740-5252-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005154537s
STEP: Saw pod success
Feb 18 13:29:54.572: INFO: Pod "pod-configmaps-be888740-5252-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:29:54.574: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-be888740-5252-11ea-bd69-fac0b7afc6af container configmap-volume-test: <nil>
STEP: delete the pod
Feb 18 13:29:54.588: INFO: Waiting for pod pod-configmaps-be888740-5252-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:29:54.591: INFO: Pod pod-configmaps-be888740-5252-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:29:54.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4810" for this suite.
Feb 18 13:30:00.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:30:00.766: INFO: namespace configmap-4810 deletion completed in 6.169512934s

• [SLOW TEST:8.228 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:30:00.766: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Feb 18 13:30:00.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-3232'
Feb 18 13:30:00.934: INFO: stderr: ""
Feb 18 13:30:00.934: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 18 13:30:01.937: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 13:30:01.937: INFO: Found 0 / 1
Feb 18 13:30:02.937: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 13:30:02.937: INFO: Found 0 / 1
Feb 18 13:30:03.937: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 13:30:03.937: INFO: Found 1 / 1
Feb 18 13:30:03.937: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 18 13:30:03.940: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 13:30:03.940: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 18 13:30:03.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 patch pod redis-master-r9gmq --namespace=kubectl-3232 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 18 13:30:04.015: INFO: stderr: ""
Feb 18 13:30:04.016: INFO: stdout: "pod/redis-master-r9gmq patched\n"
STEP: checking annotations
Feb 18 13:30:04.023: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 13:30:04.023: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:30:04.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3232" for this suite.
Feb 18 13:30:26.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:30:26.198: INFO: namespace kubectl-3232 deletion completed in 22.171141699s

• [SLOW TEST:25.432 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:30:26.199: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-3451
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3451
STEP: Deleting pre-stop pod
Feb 18 13:30:41.254: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:30:41.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3451" for this suite.
Feb 18 13:31:19.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:31:19.438: INFO: namespace prestop-3451 deletion completed in 38.172525426s

• [SLOW TEST:53.239 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:31:19.438: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 13:31:19.516: INFO: (0) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.228615ms)
Feb 18 13:31:19.519: INFO: (1) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.735741ms)
Feb 18 13:31:19.521: INFO: (2) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.042583ms)
Feb 18 13:31:19.523: INFO: (3) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.998706ms)
Feb 18 13:31:19.529: INFO: (4) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 6.645514ms)
Feb 18 13:31:19.534: INFO: (5) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.042481ms)
Feb 18 13:31:19.537: INFO: (6) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.211806ms)
Feb 18 13:31:19.539: INFO: (7) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.437703ms)
Feb 18 13:31:19.541: INFO: (8) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.162235ms)
Feb 18 13:31:19.543: INFO: (9) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.907241ms)
Feb 18 13:31:19.548: INFO: (10) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.778219ms)
Feb 18 13:31:19.552: INFO: (11) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.603442ms)
Feb 18 13:31:19.554: INFO: (12) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.297194ms)
Feb 18 13:31:19.556: INFO: (13) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.487011ms)
Feb 18 13:31:19.559: INFO: (14) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.130176ms)
Feb 18 13:31:19.561: INFO: (15) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.608608ms)
Feb 18 13:31:19.564: INFO: (16) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.001513ms)
Feb 18 13:31:19.567: INFO: (17) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.505162ms)
Feb 18 13:31:19.569: INFO: (18) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.611234ms)
Feb 18 13:31:19.572: INFO: (19) /api/v1/nodes/ip-10-100-10-116.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.36525ms)
[AfterEach] version v1
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:31:19.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9437" for this suite.
Feb 18 13:31:25.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:31:25.649: INFO: namespace proxy-9437 deletion completed in 6.075478323s

• [SLOW TEST:6.211 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:31:25.649: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 13:31:25.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-7863'
Feb 18 13:31:26.003: INFO: stderr: ""
Feb 18 13:31:26.003: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 18 13:31:26.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 create -f - --namespace=kubectl-7863'
Feb 18 13:31:26.183: INFO: stderr: ""
Feb 18 13:31:26.183: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 18 13:31:27.186: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 13:31:27.186: INFO: Found 0 / 1
Feb 18 13:31:28.185: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 13:31:28.185: INFO: Found 0 / 1
Feb 18 13:31:29.185: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 13:31:29.186: INFO: Found 1 / 1
Feb 18 13:31:29.186: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 18 13:31:29.188: INFO: Selector matched 1 pods for map[app:redis]
Feb 18 13:31:29.188: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 18 13:31:29.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 describe pod redis-master-f5gqv --namespace=kubectl-7863'
Feb 18 13:31:29.257: INFO: stderr: ""
Feb 18 13:31:29.257: INFO: stdout: "Name:               redis-master-f5gqv\nNamespace:          kubectl-7863\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-100-10-235.eu-west-1.compute.internal/10.100.10.235\nStart Time:         Tue, 18 Feb 2020 13:31:26 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 172.16.102.223/32\nStatus:             Running\nIP:                 172.16.102.223\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://302b1e28896677b0766256e9859520ddb68ac4c0ad596cd7707f941ced65d19d\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 18 Feb 2020 13:31:27 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-nf4r6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-nf4r6:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-nf4r6\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                  Message\n  ----    ------     ----  ----                                                  -------\n  Normal  Scheduled  3s    default-scheduler                                     Successfully assigned kubectl-7863/redis-master-f5gqv to ip-10-100-10-235.eu-west-1.compute.internal\n  Normal  Pulled     2s    kubelet, ip-10-100-10-235.eu-west-1.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-10-100-10-235.eu-west-1.compute.internal  Created container redis-master\n  Normal  Started    2s    kubelet, ip-10-100-10-235.eu-west-1.compute.internal  Started container redis-master\n"
Feb 18 13:31:29.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 describe rc redis-master --namespace=kubectl-7863'
Feb 18 13:31:29.328: INFO: stderr: ""
Feb 18 13:31:29.328: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-7863\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-f5gqv\n"
Feb 18 13:31:29.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 describe service redis-master --namespace=kubectl-7863'
Feb 18 13:31:29.393: INFO: stderr: ""
Feb 18 13:31:29.393: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-7863\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.111.221.5\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.16.102.223:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 18 13:31:29.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 describe node ip-10-100-0-131.eu-west-1.compute.internal'
Feb 18 13:31:29.481: INFO: stderr: ""
Feb 18 13:31:29.481: INFO: stdout: "Name:               ip-10-100-0-131.eu-west-1.compute.internal\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-100-0-131.eu-west-1.compute.internal\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.100.0.131/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.16.110.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 18 Feb 2020 11:58:12 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 18 Feb 2020 12:04:43 +0000   Tue, 18 Feb 2020 12:04:43 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 18 Feb 2020 13:31:24 +0000   Tue, 18 Feb 2020 11:58:09 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 18 Feb 2020 13:31:24 +0000   Tue, 18 Feb 2020 11:58:09 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 18 Feb 2020 13:31:24 +0000   Tue, 18 Feb 2020 11:58:09 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 18 Feb 2020 13:31:24 +0000   Tue, 18 Feb 2020 12:04:44 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.100.0.131\n  Hostname:    ip-10-100-0-131.eu-west-1.compute.internal\nCapacity:\n cpu:                2\n ephemeral-storage:  101583780Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7865424Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  93619611493\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7763024Ki\n pods:               110\nSystem Info:\n Machine ID:                 ec2e9da6c8349dbf41c4ee2f9d7de8d3\n System UUID:                EC2E9DA6-C834-9DBF-41C4-EE2F9D7DE8D3\n Boot ID:                    0981ccc1-1501-4000-b68c-4b2e9bfe9fa9\n Kernel Version:             4.15.0-1058-aws\n OS Image:                   Ubuntu 18.04.4 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://19.3.6\n Kubelet Version:            v1.14.8\n Kube-Proxy Version:         v1.14.8\nPodCIDR:                     172.16.0.0/24\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                                  ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-s6zlk                                                     250m (12%)    0 (0%)      0 (0%)           0 (0%)         86m\n  kube-system                etcd-ip-10-100-0-131.eu-west-1.compute.internal                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         92m\n  kube-system                kube-apiserver-ip-10-100-0-131.eu-west-1.compute.internal             250m (12%)    0 (0%)      0 (0%)           0 (0%)         92m\n  kube-system                kube-controller-manager-ip-10-100-0-131.eu-west-1.compute.internal    200m (10%)    0 (0%)      0 (0%)           0 (0%)         92m\n  kube-system                kube-proxy-52kzx                                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         92m\n  kube-system                kube-scheduler-ip-10-100-0-131.eu-west-1.compute.internal             100m (5%)     0 (0%)      0 (0%)           0 (0%)         92m\n  logging                    fluentd-74q7m                                                         300m (15%)    1 (50%)     400Mi (5%)       400Mi (5%)     86m\n  monitoring                 goldpinger-qlwbt                                                      1m (0%)       0 (0%)      40Mi (0%)        80Mi (1%)      86m\n  monitoring                 node-exporter-ps84w                                                   102m (5%)     102m (5%)   180Mi (2%)       180Mi (2%)     86m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-31cf4124bed54e00-z4qk7               0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1203m (60%)  1102m (55%)\n  memory             620Mi (8%)   660Mi (8%)\n  ephemeral-storage  0 (0%)       0 (0%)\nEvents:              <none>\n"
Feb 18 13:31:29.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-639612178 describe namespace kubectl-7863'
Feb 18 13:31:29.548: INFO: stderr: ""
Feb 18 13:31:29.548: INFO: stdout: "Name:         kubectl-7863\nLabels:       e2e-framework=kubectl\n              e2e-run=92355115-5247-11ea-bd69-fac0b7afc6af\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:31:29.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7863" for this suite.
Feb 18 13:31:51.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:31:51.720: INFO: namespace kubectl-7863 deletion completed in 22.169650868s

• [SLOW TEST:26.071 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:31:51.721: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-0591b559-5253-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 13:31:51.749: INFO: Waiting up to 5m0s for pod "pod-secrets-0592191b-5253-11ea-bd69-fac0b7afc6af" in namespace "secrets-2503" to be "success or failure"
Feb 18 13:31:51.753: INFO: Pod "pod-secrets-0592191b-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.254305ms
Feb 18 13:31:53.755: INFO: Pod "pod-secrets-0592191b-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006569853s
Feb 18 13:31:55.757: INFO: Pod "pod-secrets-0592191b-5253-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008840432s
STEP: Saw pod success
Feb 18 13:31:55.757: INFO: Pod "pod-secrets-0592191b-5253-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:31:55.759: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-secrets-0592191b-5253-11ea-bd69-fac0b7afc6af container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 13:31:55.772: INFO: Waiting for pod pod-secrets-0592191b-5253-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:31:55.773: INFO: Pod pod-secrets-0592191b-5253-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:31:55.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2503" for this suite.
Feb 18 13:32:01.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:32:01.945: INFO: namespace secrets-2503 deletion completed in 6.169894062s

• [SLOW TEST:10.225 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:32:01.946: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-9015
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9015 to expose endpoints map[]
Feb 18 13:32:01.977: INFO: Get endpoints failed (3.325481ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 18 13:32:02.980: INFO: successfully validated that service multi-endpoint-test in namespace services-9015 exposes endpoints map[] (1.006381732s elapsed)
STEP: Creating pod pod1 in namespace services-9015
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9015 to expose endpoints map[pod1:[100]]
Feb 18 13:32:06.013: INFO: successfully validated that service multi-endpoint-test in namespace services-9015 exposes endpoints map[pod1:[100]] (3.026032269s elapsed)
STEP: Creating pod pod2 in namespace services-9015
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9015 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 18 13:32:09.040: INFO: successfully validated that service multi-endpoint-test in namespace services-9015 exposes endpoints map[pod1:[100] pod2:[101]] (3.023246674s elapsed)
STEP: Deleting pod pod1 in namespace services-9015
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9015 to expose endpoints map[pod2:[101]]
Feb 18 13:32:09.052: INFO: successfully validated that service multi-endpoint-test in namespace services-9015 exposes endpoints map[pod2:[101]] (6.330616ms elapsed)
STEP: Deleting pod pod2 in namespace services-9015
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9015 to expose endpoints map[]
Feb 18 13:32:09.064: INFO: successfully validated that service multi-endpoint-test in namespace services-9015 exposes endpoints map[] (2.736245ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:32:09.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9015" for this suite.
Feb 18 13:32:31.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:32:31.263: INFO: namespace services-9015 deletion completed in 22.167862753s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:29.317 seconds]
[sig-network] Services
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:32:31.263: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0218 13:33:01.333738      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 13:33:01.333: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:33:01.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8127" for this suite.
Feb 18 13:33:07.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:33:07.506: INFO: namespace gc-8127 deletion completed in 6.170899363s

• [SLOW TEST:36.243 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:33:07.507: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-fldn
STEP: Creating a pod to test atomic-volume-subpath
Feb 18 13:33:07.549: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fldn" in namespace "subpath-8855" to be "success or failure"
Feb 18 13:33:07.553: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12537ms
Feb 18 13:33:09.556: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 2.006340439s
Feb 18 13:33:11.558: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 4.008556996s
Feb 18 13:33:13.560: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 6.010594367s
Feb 18 13:33:15.562: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 8.012724s
Feb 18 13:33:17.565: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 10.015510989s
Feb 18 13:33:19.567: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 12.018034247s
Feb 18 13:33:21.569: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 14.02022827s
Feb 18 13:33:23.572: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 16.022676588s
Feb 18 13:33:25.574: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 18.024893672s
Feb 18 13:33:27.576: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 20.02708568s
Feb 18 13:33:29.579: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Running", Reason="", readiness=true. Elapsed: 22.029312378s
Feb 18 13:33:31.581: INFO: Pod "pod-subpath-test-configmap-fldn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.03162119s
STEP: Saw pod success
Feb 18 13:33:31.581: INFO: Pod "pod-subpath-test-configmap-fldn" satisfied condition "success or failure"
Feb 18 13:33:31.583: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-subpath-test-configmap-fldn container test-container-subpath-configmap-fldn: <nil>
STEP: delete the pod
Feb 18 13:33:31.597: INFO: Waiting for pod pod-subpath-test-configmap-fldn to disappear
Feb 18 13:33:31.599: INFO: Pod pod-subpath-test-configmap-fldn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fldn
Feb 18 13:33:31.599: INFO: Deleting pod "pod-subpath-test-configmap-fldn" in namespace "subpath-8855"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:33:31.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8855" for this suite.
Feb 18 13:33:37.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:33:37.769: INFO: namespace subpath-8855 deletion completed in 6.166717055s

• [SLOW TEST:30.262 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:33:37.769: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:163
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 18 13:33:42.319: INFO: Successfully updated pod "pod-update-activedeadlineseconds-44c7a4a8-5253-11ea-bd69-fac0b7afc6af"
Feb 18 13:33:42.319: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-44c7a4a8-5253-11ea-bd69-fac0b7afc6af" in namespace "pods-7620" to be "terminated due to deadline exceeded"
Feb 18 13:33:42.325: INFO: Pod "pod-update-activedeadlineseconds-44c7a4a8-5253-11ea-bd69-fac0b7afc6af": Phase="Running", Reason="", readiness=true. Elapsed: 5.889492ms
Feb 18 13:33:44.328: INFO: Pod "pod-update-activedeadlineseconds-44c7a4a8-5253-11ea-bd69-fac0b7afc6af": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.009691636s
Feb 18 13:33:44.328: INFO: Pod "pod-update-activedeadlineseconds-44c7a4a8-5253-11ea-bd69-fac0b7afc6af" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:33:44.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7620" for this suite.
Feb 18 13:33:50.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:33:50.497: INFO: namespace pods-7620 deletion completed in 6.166254335s

• [SLOW TEST:12.728 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:33:50.497: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-4c5d8135-5253-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 13:33:50.525: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4c5de695-5253-11ea-bd69-fac0b7afc6af" in namespace "projected-1456" to be "success or failure"
Feb 18 13:33:50.529: INFO: Pod "pod-projected-secrets-4c5de695-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.520816ms
Feb 18 13:33:52.531: INFO: Pod "pod-projected-secrets-4c5de695-5253-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006368693s
STEP: Saw pod success
Feb 18 13:33:52.531: INFO: Pod "pod-projected-secrets-4c5de695-5253-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:33:52.533: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-secrets-4c5de695-5253-11ea-bd69-fac0b7afc6af container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 13:33:52.544: INFO: Waiting for pod pod-projected-secrets-4c5de695-5253-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:33:52.546: INFO: Pod pod-projected-secrets-4c5de695-5253-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:33:52.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1456" for this suite.
Feb 18 13:33:58.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:33:58.713: INFO: namespace projected-1456 deletion completed in 6.164924906s

• [SLOW TEST:8.216 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:33:58.713: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-5143155e-5253-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 13:33:58.762: INFO: Waiting up to 5m0s for pod "pod-secrets-5146e4d1-5253-11ea-bd69-fac0b7afc6af" in namespace "secrets-6459" to be "success or failure"
Feb 18 13:33:58.770: INFO: Pod "pod-secrets-5146e4d1-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 7.449494ms
Feb 18 13:34:00.772: INFO: Pod "pod-secrets-5146e4d1-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009952102s
Feb 18 13:34:02.775: INFO: Pod "pod-secrets-5146e4d1-5253-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012180818s
STEP: Saw pod success
Feb 18 13:34:02.775: INFO: Pod "pod-secrets-5146e4d1-5253-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:34:02.777: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-secrets-5146e4d1-5253-11ea-bd69-fac0b7afc6af container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 13:34:02.799: INFO: Waiting for pod pod-secrets-5146e4d1-5253-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:34:02.801: INFO: Pod pod-secrets-5146e4d1-5253-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:34:02.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6459" for this suite.
Feb 18 13:34:08.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:34:08.971: INFO: namespace secrets-6459 deletion completed in 6.167498398s
STEP: Destroying namespace "secret-namespace-4334" for this suite.
Feb 18 13:34:14.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:34:15.137: INFO: namespace secret-namespace-4334 deletion completed in 6.166165945s

• [SLOW TEST:16.424 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:34:15.138: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 18 13:34:15.417: INFO: Pod name wrapped-volume-race-5b1bdc6a-5253-11ea-bd69-fac0b7afc6af: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5b1bdc6a-5253-11ea-bd69-fac0b7afc6af in namespace emptydir-wrapper-8281, will wait for the garbage collector to delete the pods
Feb 18 13:34:37.520: INFO: Deleting ReplicationController wrapped-volume-race-5b1bdc6a-5253-11ea-bd69-fac0b7afc6af took: 6.648432ms
Feb 18 13:34:38.021: INFO: Terminating ReplicationController wrapped-volume-race-5b1bdc6a-5253-11ea-bd69-fac0b7afc6af pods took: 500.155743ms
STEP: Creating RC which spawns configmap-volume pods
Feb 18 13:35:15.538: INFO: Pod name wrapped-volume-race-7f07f22a-5253-11ea-bd69-fac0b7afc6af: Found 0 pods out of 5
Feb 18 13:35:20.545: INFO: Pod name wrapped-volume-race-7f07f22a-5253-11ea-bd69-fac0b7afc6af: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7f07f22a-5253-11ea-bd69-fac0b7afc6af in namespace emptydir-wrapper-8281, will wait for the garbage collector to delete the pods
Feb 18 13:35:32.618: INFO: Deleting ReplicationController wrapped-volume-race-7f07f22a-5253-11ea-bd69-fac0b7afc6af took: 4.573132ms
Feb 18 13:35:33.118: INFO: Terminating ReplicationController wrapped-volume-race-7f07f22a-5253-11ea-bd69-fac0b7afc6af pods took: 500.181346ms
STEP: Creating RC which spawns configmap-volume pods
Feb 18 13:36:10.229: INFO: Pod name wrapped-volume-race-9fa2190e-5253-11ea-bd69-fac0b7afc6af: Found 0 pods out of 5
Feb 18 13:36:15.233: INFO: Pod name wrapped-volume-race-9fa2190e-5253-11ea-bd69-fac0b7afc6af: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9fa2190e-5253-11ea-bd69-fac0b7afc6af in namespace emptydir-wrapper-8281, will wait for the garbage collector to delete the pods
Feb 18 13:36:27.325: INFO: Deleting ReplicationController wrapped-volume-race-9fa2190e-5253-11ea-bd69-fac0b7afc6af took: 4.499014ms
Feb 18 13:36:27.825: INFO: Terminating ReplicationController wrapped-volume-race-9fa2190e-5253-11ea-bd69-fac0b7afc6af pods took: 500.16819ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:37:13.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8281" for this suite.
Feb 18 13:37:19.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:37:19.849: INFO: namespace emptydir-wrapper-8281 deletion completed in 6.167349226s

• [SLOW TEST:184.711 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:37:19.849: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 18 13:37:27.894: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:27.894: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:28.033: INFO: Exec stderr: ""
Feb 18 13:37:28.033: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:28.033: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:28.178: INFO: Exec stderr: ""
Feb 18 13:37:28.178: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:28.178: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:28.296: INFO: Exec stderr: ""
Feb 18 13:37:28.296: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:28.296: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:28.435: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 18 13:37:28.435: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:28.435: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:28.578: INFO: Exec stderr: ""
Feb 18 13:37:28.578: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:28.578: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:28.713: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 18 13:37:28.713: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:28.713: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:28.845: INFO: Exec stderr: ""
Feb 18 13:37:28.846: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:28.846: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:28.977: INFO: Exec stderr: ""
Feb 18 13:37:28.977: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:28.977: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:29.126: INFO: Exec stderr: ""
Feb 18 13:37:29.126: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1307 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 18 13:37:29.126: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
Feb 18 13:37:29.269: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:37:29.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1307" for this suite.
Feb 18 13:38:15.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:38:15.441: INFO: namespace e2e-kubelet-etc-hosts-1307 deletion completed in 46.168823256s

• [SLOW TEST:55.592 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:38:15.442: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Feb 18 13:38:15.474: INFO: Waiting up to 5m0s for pod "client-containers-ea4a0173-5253-11ea-bd69-fac0b7afc6af" in namespace "containers-508" to be "success or failure"
Feb 18 13:38:15.478: INFO: Pod "client-containers-ea4a0173-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.8534ms
Feb 18 13:38:17.481: INFO: Pod "client-containers-ea4a0173-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006225623s
Feb 18 13:38:19.483: INFO: Pod "client-containers-ea4a0173-5253-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008282908s
STEP: Saw pod success
Feb 18 13:38:19.483: INFO: Pod "client-containers-ea4a0173-5253-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:38:19.485: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod client-containers-ea4a0173-5253-11ea-bd69-fac0b7afc6af container test-container: <nil>
STEP: delete the pod
Feb 18 13:38:19.498: INFO: Waiting for pod client-containers-ea4a0173-5253-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:38:19.499: INFO: Pod client-containers-ea4a0173-5253-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:38:19.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-508" for this suite.
Feb 18 13:38:25.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:38:25.668: INFO: namespace containers-508 deletion completed in 6.165679607s

• [SLOW TEST:10.226 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:38:25.668: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-f061639c-5253-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 13:38:25.698: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f06218a4-5253-11ea-bd69-fac0b7afc6af" in namespace "projected-3866" to be "success or failure"
Feb 18 13:38:25.705: INFO: Pod "pod-projected-secrets-f06218a4-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 6.16493ms
Feb 18 13:38:27.707: INFO: Pod "pod-projected-secrets-f06218a4-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008288501s
Feb 18 13:38:29.709: INFO: Pod "pod-projected-secrets-f06218a4-5253-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010348444s
STEP: Saw pod success
Feb 18 13:38:29.709: INFO: Pod "pod-projected-secrets-f06218a4-5253-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:38:29.711: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-projected-secrets-f06218a4-5253-11ea-bd69-fac0b7afc6af container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 18 13:38:29.727: INFO: Waiting for pod pod-projected-secrets-f06218a4-5253-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:38:29.729: INFO: Pod pod-projected-secrets-f06218a4-5253-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:38:29.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3866" for this suite.
Feb 18 13:38:35.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:38:35.899: INFO: namespace projected-3866 deletion completed in 6.167634843s

• [SLOW TEST:10.231 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:38:35.899: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 13:38:35.921: INFO: Creating deployment "nginx-deployment"
Feb 18 13:38:35.924: INFO: Waiting for observed generation 1
Feb 18 13:38:37.928: INFO: Waiting for all required pods to come up
Feb 18 13:38:37.934: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 18 13:38:39.949: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 18 13:38:39.952: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 18 13:38:39.956: INFO: Updating deployment nginx-deployment
Feb 18 13:38:39.956: INFO: Waiting for observed generation 2
Feb 18 13:38:41.962: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 18 13:38:41.964: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 18 13:38:41.966: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 18 13:38:41.970: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 18 13:38:41.970: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 18 13:38:41.972: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 18 13:38:41.974: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 18 13:38:41.974: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 18 13:38:41.978: INFO: Updating deployment nginx-deployment
Feb 18 13:38:41.978: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 18 13:38:41.986: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 18 13:38:41.996: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 18 13:38:42.025: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-7477,SelfLink:/apis/apps/v1/namespaces/deployment-7477/deployments/nginx-deployment,UID:f67de72c-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29973,Generation:3,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2020-02-18 13:38:40 +0000 UTC 2020-02-18 13:38:35 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-b79c9d74d" is progressing.} {Available False 2020-02-18 13:38:42 +0000 UTC 2020-02-18 13:38:42 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 18 13:38:42.035: INFO: New ReplicaSet "nginx-deployment-b79c9d74d" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d,GenerateName:,Namespace:deployment-7477,SelfLink:/apis/apps/v1/namespaces/deployment-7477/replicasets/nginx-deployment-b79c9d74d,UID:f8e5c436-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29965,Generation:3,CreationTimestamp:2020-02-18 13:38:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f67de72c-5253-11ea-b701-0ae3ad6fc27e 0xc003b5e5a7 0xc003b5e5a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 18 13:38:42.035: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 18 13:38:42.035: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5,GenerateName:,Namespace:deployment-7477,SelfLink:/apis/apps/v1/namespaces/deployment-7477/replicasets/nginx-deployment-85db8c99c5,UID:f67e6d6f-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29963,Generation:3,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f67de72c-5253-11ea-b701-0ae3ad6fc27e 0xc003b5e4d7 0xc003b5e4d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 18 13:38:42.074: INFO: Pod "nginx-deployment-85db8c99c5-5jm6r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-5jm6r,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-5jm6r,UID:fa1ecaca-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:30002,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5ef07 0xc003b5ef08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5ef70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5ef90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-5vfql" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-5vfql,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-5vfql,UID:fa1ebc02-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29992,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5f010 0xc003b5f011}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5f070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5f090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-688jj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-688jj,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-688jj,UID:f68315cc-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29858,Generation:0,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.26.140/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5f120 0xc003b5f121}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5f180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5f1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.116,PodIP:172.16.26.140,StartTime:2020-02-18 13:38:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-18 13:38:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4b1d92411fc8d4e271effbe4e2918d64e4f84b3e06f6079533fd6ede7e2ffb71}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-6csjs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-6csjs,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-6csjs,UID:f6814996-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29855,Generation:0,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.26.141/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5f287 0xc003b5f288}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5f2f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5f310}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.116,PodIP:172.16.26.141,StartTime:2020-02-18 13:38:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-18 13:38:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6a1c8c8a66f9e6eace9e2096c8754d738a81106dded4362f9344b2f81a6bf170}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-7btr2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-7btr2,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-7btr2,UID:fa23f67b-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29996,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5f3e7 0xc003b5f3e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5f450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5f470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-8ff52" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-8ff52,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-8ff52,UID:fa1ed498-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:30004,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5f4d7 0xc003b5f4d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5f540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5f560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-8kzlm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-8kzlm,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-8kzlm,UID:f6852187-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29867,Generation:0,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.232/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5f5e0 0xc003b5f5e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5f640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5f660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:36 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:172.16.102.232,StartTime:2020-02-18 13:38:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-18 13:38:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b11aff369fb4a66dfe386e723bbf3ffdc2490860c1849688857b2c1c09357fc2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-9bk74" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-9bk74,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-9bk74,UID:fa2437ba-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29999,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5f737 0xc003b5f738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5f7a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5f7c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-c7zhx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-c7zhx,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-c7zhx,UID:fa2421f0-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29997,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5f827 0xc003b5f828}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5f890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5f8b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-g4qvb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-g4qvb,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-g4qvb,UID:f681318d-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29870,Generation:0,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.236/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5f917 0xc003b5f918}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5f980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5f9a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:172.16.102.236,StartTime:2020-02-18 13:38:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-18 13:38:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://42799735dea2144c2f3388cc3b411299f08adccfc04461a560ed1b7e4f41549a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.075: INFO: Pod "nginx-deployment-85db8c99c5-hhd9l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-hhd9l,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-hhd9l,UID:f6832607-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29876,Generation:0,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.238/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5fa77 0xc003b5fa78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5fae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5fb00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:172.16.102.238,StartTime:2020-02-18 13:38:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-18 13:38:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f6e96a4e39a945c0b948737b2e27cdd71bc24c0f2a70922ebacba58315be2267}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-85db8c99c5-k4tk4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-k4tk4,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-k4tk4,UID:f6832b08-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29861,Generation:0,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.26.139/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5fbe7 0xc003b5fbe8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5fc50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5fc70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.116,PodIP:172.16.26.139,StartTime:2020-02-18 13:38:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-18 13:38:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e33f70cfb40022a982390ad174260795b7da09e6e1381b99bf7cd0cfb81de2be}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-85db8c99c5-nsd75" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-nsd75,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-nsd75,UID:fa1c8570-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29978,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5fd47 0xc003b5fd48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5fdb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5fdd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-85db8c99c5-qkzs7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-qkzs7,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-qkzs7,UID:fa1c4b2f-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29988,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5fe50 0xc003b5fe51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b5feb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b5fed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:,StartTime:2020-02-18 13:38:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-85db8c99c5-r6rtl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-r6rtl,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-r6rtl,UID:fa1ad7c5-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:30003,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc003b5ff97 0xc003b5ff98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3c000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3c020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.116,PodIP:,StartTime:2020-02-18 13:38:42 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-85db8c99c5-rl422" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-rl422,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-rl422,UID:fa242daf-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29998,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc002e3c0e7 0xc002e3c0e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3c150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3c170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-85db8c99c5-vw9d5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-vw9d5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-vw9d5,UID:f682e4e9-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29829,Generation:0,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.234/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc002e3c1d7 0xc002e3c1d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3c240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3c260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:35 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:172.16.102.234,StartTime:2020-02-18 13:38:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-18 13:38:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d613b269d295acddaa56f50ea6dd409b8ee47c1064d7a0fc2b19670ce5d2fc01}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-85db8c99c5-wc6k5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-wc6k5,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-wc6k5,UID:fa1e89d6-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29985,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc002e3c337 0xc002e3c338}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3c3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3c3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-85db8c99c5-x9ssg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-x9ssg,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-x9ssg,UID:fa233bc4-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:30006,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc002e3c440 0xc002e3c441}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3c4a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3c4c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-85db8c99c5-zrt29" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-85db8c99c5-zrt29,GenerateName:nginx-deployment-85db8c99c5-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-85db8c99c5-zrt29,UID:f6852fb5-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29820,Generation:0,CreationTimestamp:2020-02-18 13:38:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 85db8c99c5,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.233/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-85db8c99c5 f67e6d6f-5253-11ea-b701-0ae3ad6fc27e 0xc002e3c540 0xc002e3c541}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3c5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3c5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:36 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:172.16.102.233,StartTime:2020-02-18 13:38:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2020-02-18 13:38:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4d4d238f367f4db052f42663011d62e42a37f32a7e9c4e7993d231dc4343f095}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.076: INFO: Pod "nginx-deployment-b79c9d74d-4cndb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-4cndb,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-4cndb,UID:f8e77686-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29945,Generation:0,CreationTimestamp:2020-02-18 13:38:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.237/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3c697 0xc002e3c698}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3c700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3c720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:,StartTime:2020-02-18 13:38:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.077: INFO: Pod "nginx-deployment-b79c9d74d-8m9z8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-8m9z8,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-8m9z8,UID:fa1c916c-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29981,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3c7f0 0xc002e3c7f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3c860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3c880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.077: INFO: Pod "nginx-deployment-b79c9d74d-dsqf7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-dsqf7,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-dsqf7,UID:fa244ae8-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:30001,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3c900 0xc002e3c901}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3c970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3c990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.077: INFO: Pod "nginx-deployment-b79c9d74d-jh5ft" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-jh5ft,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-jh5ft,UID:fa23e895-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29995,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3c9f7 0xc002e3c9f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3ca60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3ca80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.109: INFO: Pod "nginx-deployment-b79c9d74d-r84hz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-r84hz,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-r84hz,UID:f8e64fdc-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29953,Generation:0,CreationTimestamp:2020-02-18 13:38:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.239/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3cae7 0xc002e3cae8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3cb50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3cb70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:,StartTime:2020-02-18 13:38:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.109: INFO: Pod "nginx-deployment-b79c9d74d-rqdx4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-rqdx4,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-rqdx4,UID:f8f891aa-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29959,Generation:0,CreationTimestamp:2020-02-18 13:38:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.102.240/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3cc40 0xc002e3cc41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3ccb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3ccd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.235,PodIP:,StartTime:2020-02-18 13:38:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.119: INFO: Pod "nginx-deployment-b79c9d74d-tg549" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-tg549,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-tg549,UID:f8e77620-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29946,Generation:0,CreationTimestamp:2020-02-18 13:38:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.26.144/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3cdb0 0xc002e3cdb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3ce20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3ce40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.116,PodIP:,StartTime:2020-02-18 13:38:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.119: INFO: Pod "nginx-deployment-b79c9d74d-tzzn5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-tzzn5,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-tzzn5,UID:fa23ab0e-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29994,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3cf10 0xc002e3cf11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3cf80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3cfa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.121: INFO: Pod "nginx-deployment-b79c9d74d-vmnx2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-vmnx2,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-vmnx2,UID:fa1f0c23-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29991,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3d007 0xc002e3d008}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3d070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3d090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.121: INFO: Pod "nginx-deployment-b79c9d74d-wtmwp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-wtmwp,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-wtmwp,UID:fa24419a-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:30000,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3d110 0xc002e3d111}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3d180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3d1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.121: INFO: Pod "nginx-deployment-b79c9d74d-xg684" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-xg684,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-xg684,UID:fa1f1b2e-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29993,Generation:0,CreationTimestamp:2020-02-18 13:38:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3d207 0xc002e3d208}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-235.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3d270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3d290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:42 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 18 13:38:42.122: INFO: Pod "nginx-deployment-b79c9d74d-zdxtx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-b79c9d74d-zdxtx,GenerateName:nginx-deployment-b79c9d74d-,Namespace:deployment-7477,SelfLink:/api/v1/namespaces/deployment-7477/pods/nginx-deployment-b79c9d74d-zdxtx,UID:f8f50fa3-5253-11ea-b701-0ae3ad6fc27e,ResourceVersion:29954,Generation:0,CreationTimestamp:2020-02-18 13:38:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: b79c9d74d,},Annotations:map[string]string{cni.projectcalico.org/podIP: 172.16.26.145/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-b79c9d74d f8e5c436-5253-11ea-b701-0ae3ad6fc27e 0xc002e3d320 0xc002e3d321}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wn89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wn89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wn89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-116.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e3d390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e3d3b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-18 13:38:40 +0000 UTC  }],Message:,Reason:,HostIP:10.100.10.116,PodIP:,StartTime:2020-02-18 13:38:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:38:42.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7477" for this suite.
Feb 18 13:38:48.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:38:48.553: INFO: namespace deployment-7477 deletion completed in 6.329603933s

• [SLOW TEST:12.654 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:38:48.553: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Feb 18 13:38:48.580: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe05c338-5253-11ea-bd69-fac0b7afc6af" in namespace "downward-api-5304" to be "success or failure"
Feb 18 13:38:48.585: INFO: Pod "downwardapi-volume-fe05c338-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.831429ms
Feb 18 13:38:50.590: INFO: Pod "downwardapi-volume-fe05c338-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009512487s
Feb 18 13:38:52.592: INFO: Pod "downwardapi-volume-fe05c338-5253-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011629771s
Feb 18 13:38:54.594: INFO: Pod "downwardapi-volume-fe05c338-5253-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013613334s
STEP: Saw pod success
Feb 18 13:38:54.594: INFO: Pod "downwardapi-volume-fe05c338-5253-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:38:54.596: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod downwardapi-volume-fe05c338-5253-11ea-bd69-fac0b7afc6af container client-container: <nil>
STEP: delete the pod
Feb 18 13:38:54.607: INFO: Waiting for pod downwardapi-volume-fe05c338-5253-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:38:54.610: INFO: Pod downwardapi-volume-fe05c338-5253-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:38:54.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5304" for this suite.
Feb 18 13:39:00.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:39:01.004: INFO: namespace downward-api-5304 deletion completed in 6.391682258s

• [SLOW TEST:12.451 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:39:01.004: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 13:39:01.023: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:39:01.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-694" for this suite.
Feb 18 13:39:07.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:39:07.818: INFO: namespace custom-resource-definition-694 deletion completed in 6.16709816s

• [SLOW TEST:6.814 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:32
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:39:07.818: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-5805/configmap-test-09818ff7-5254-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 13:39:07.865: INFO: Waiting up to 5m0s for pod "pod-configmaps-0982368e-5254-11ea-bd69-fac0b7afc6af" in namespace "configmap-5805" to be "success or failure"
Feb 18 13:39:07.881: INFO: Pod "pod-configmaps-0982368e-5254-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 16.397946ms
Feb 18 13:39:09.884: INFO: Pod "pod-configmaps-0982368e-5254-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019023416s
Feb 18 13:39:11.886: INFO: Pod "pod-configmaps-0982368e-5254-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021253119s
STEP: Saw pod success
Feb 18 13:39:11.886: INFO: Pod "pod-configmaps-0982368e-5254-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:39:11.896: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-0982368e-5254-11ea-bd69-fac0b7afc6af container env-test: <nil>
STEP: delete the pod
Feb 18 13:39:11.911: INFO: Waiting for pod pod-configmaps-0982368e-5254-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:39:11.916: INFO: Pod pod-configmaps-0982368e-5254-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:39:11.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5805" for this suite.
Feb 18 13:39:17.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:39:18.085: INFO: namespace configmap-5805 deletion completed in 6.166181413s

• [SLOW TEST:10.267 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:39:18.085: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Feb 18 13:39:22.631: INFO: Successfully updated pod "labelsupdate0f9f5aa2-5254-11ea-bd69-fac0b7afc6af"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:39:24.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4228" for this suite.
Feb 18 13:39:46.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:39:46.813: INFO: namespace downward-api-4228 deletion completed in 22.165962612s

• [SLOW TEST:28.727 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:39:46.813: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-20bf1303-5254-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume secrets
Feb 18 13:39:46.842: INFO: Waiting up to 5m0s for pod "pod-secrets-20bfa180-5254-11ea-bd69-fac0b7afc6af" in namespace "secrets-9855" to be "success or failure"
Feb 18 13:39:46.846: INFO: Pod "pod-secrets-20bfa180-5254-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.937425ms
Feb 18 13:39:48.849: INFO: Pod "pod-secrets-20bfa180-5254-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006121801s
STEP: Saw pod success
Feb 18 13:39:48.849: INFO: Pod "pod-secrets-20bfa180-5254-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:39:48.850: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-secrets-20bfa180-5254-11ea-bd69-fac0b7afc6af container secret-volume-test: <nil>
STEP: delete the pod
Feb 18 13:39:48.862: INFO: Waiting for pod pod-secrets-20bfa180-5254-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:39:48.864: INFO: Pod pod-secrets-20bfa180-5254-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:39:48.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9855" for this suite.
Feb 18 13:39:54.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:39:55.032: INFO: namespace secrets-9855 deletion completed in 6.165139049s

• [SLOW TEST:8.219 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:39:55.032: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:39:55.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8978" for this suite.
Feb 18 13:40:01.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:40:01.222: INFO: namespace services-8978 deletion completed in 6.168079381s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.191 seconds]
[sig-network] Services
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:40:01.223: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-730/configmap-test-2955b6c3-5254-11ea-bd69-fac0b7afc6af
STEP: Creating a pod to test consume configMaps
Feb 18 13:40:01.250: INFO: Waiting up to 5m0s for pod "pod-configmaps-29560252-5254-11ea-bd69-fac0b7afc6af" in namespace "configmap-730" to be "success or failure"
Feb 18 13:40:01.253: INFO: Pod "pod-configmaps-29560252-5254-11ea-bd69-fac0b7afc6af": Phase="Pending", Reason="", readiness=false. Elapsed: 3.101283ms
Feb 18 13:40:03.256: INFO: Pod "pod-configmaps-29560252-5254-11ea-bd69-fac0b7afc6af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005718069s
STEP: Saw pod success
Feb 18 13:40:03.256: INFO: Pod "pod-configmaps-29560252-5254-11ea-bd69-fac0b7afc6af" satisfied condition "success or failure"
Feb 18 13:40:03.258: INFO: Trying to get logs from node ip-10-100-10-235.eu-west-1.compute.internal pod pod-configmaps-29560252-5254-11ea-bd69-fac0b7afc6af container env-test: <nil>
STEP: delete the pod
Feb 18 13:40:03.269: INFO: Waiting for pod pod-configmaps-29560252-5254-11ea-bd69-fac0b7afc6af to disappear
Feb 18 13:40:03.270: INFO: Pod pod-configmaps-29560252-5254-11ea-bd69-fac0b7afc6af no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:40:03.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-730" for this suite.
Feb 18 13:40:09.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:40:09.439: INFO: namespace configmap-730 deletion completed in 6.166311562s

• [SLOW TEST:8.216 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:40:09.439: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Feb 18 13:40:10.027: INFO: created pod pod-service-account-defaultsa
Feb 18 13:40:10.027: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 18 13:40:10.036: INFO: created pod pod-service-account-mountsa
Feb 18 13:40:10.036: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 18 13:40:10.048: INFO: created pod pod-service-account-nomountsa
Feb 18 13:40:10.049: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 18 13:40:10.053: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 18 13:40:10.053: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 18 13:40:10.063: INFO: created pod pod-service-account-mountsa-mountspec
Feb 18 13:40:10.063: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 18 13:40:10.071: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 18 13:40:10.071: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 18 13:40:10.082: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 18 13:40:10.082: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 18 13:40:10.085: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 18 13:40:10.085: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 18 13:40:10.094: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 18 13:40:10.094: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:40:10.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1458" for this suite.
Feb 18 13:40:32.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:40:32.271: INFO: namespace svcaccounts-1458 deletion completed in 22.173433907s

• [SLOW TEST:22.832 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:40:32.271: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 18 13:40:37.314: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:40:38.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8337" for this suite.
Feb 18 13:41:00.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:41:00.500: INFO: namespace replicaset-8337 deletion completed in 22.166817621s

• [SLOW TEST:28.229 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:41:00.500: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Feb 18 13:41:00.557: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 18 13:41:00.562: INFO: Number of nodes with available pods: 0
Feb 18 13:41:00.562: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 18 13:41:00.590: INFO: Number of nodes with available pods: 0
Feb 18 13:41:00.590: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:01.592: INFO: Number of nodes with available pods: 0
Feb 18 13:41:01.592: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:02.592: INFO: Number of nodes with available pods: 0
Feb 18 13:41:02.592: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:03.592: INFO: Number of nodes with available pods: 1
Feb 18 13:41:03.592: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 18 13:41:03.606: INFO: Number of nodes with available pods: 1
Feb 18 13:41:03.606: INFO: Number of running nodes: 0, number of available pods: 1
Feb 18 13:41:04.608: INFO: Number of nodes with available pods: 0
Feb 18 13:41:04.608: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 18 13:41:04.617: INFO: Number of nodes with available pods: 0
Feb 18 13:41:04.617: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:05.620: INFO: Number of nodes with available pods: 0
Feb 18 13:41:05.620: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:06.620: INFO: Number of nodes with available pods: 0
Feb 18 13:41:06.620: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:07.620: INFO: Number of nodes with available pods: 0
Feb 18 13:41:07.620: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:08.620: INFO: Number of nodes with available pods: 0
Feb 18 13:41:08.620: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:09.620: INFO: Number of nodes with available pods: 0
Feb 18 13:41:09.620: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:10.624: INFO: Number of nodes with available pods: 0
Feb 18 13:41:10.624: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:11.620: INFO: Number of nodes with available pods: 0
Feb 18 13:41:11.620: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:12.619: INFO: Number of nodes with available pods: 0
Feb 18 13:41:12.619: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:13.620: INFO: Number of nodes with available pods: 0
Feb 18 13:41:13.620: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:14.620: INFO: Number of nodes with available pods: 0
Feb 18 13:41:14.620: INFO: Node ip-10-100-10-116.eu-west-1.compute.internal is running more than one daemon pod
Feb 18 13:41:15.620: INFO: Number of nodes with available pods: 1
Feb 18 13:41:15.620: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6825, will wait for the garbage collector to delete the pods
Feb 18 13:41:15.679: INFO: Deleting DaemonSet.extensions daemon-set took: 4.222476ms
Feb 18 13:41:16.179: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.192456ms
Feb 18 13:41:19.281: INFO: Number of nodes with available pods: 0
Feb 18 13:41:19.281: INFO: Number of running nodes: 0, number of available pods: 0
Feb 18 13:41:19.283: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6825/daemonsets","resourceVersion":"31278"},"items":null}

Feb 18 13:41:19.285: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6825/pods","resourceVersion":"31278"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:41:19.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6825" for this suite.
Feb 18 13:41:25.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:41:25.472: INFO: namespace daemonsets-6825 deletion completed in 6.169024558s

• [SLOW TEST:24.972 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Feb 18 13:41:25.472: INFO: >>> kubeConfig: /tmp/kubeconfig-639612178
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0218 13:41:35.526828      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 18 13:41:35.526: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Feb 18 13:41:35.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3501" for this suite.
Feb 18 13:41:41.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 18 13:41:41.705: INFO: namespace gc-3501 deletion completed in 6.175809229s

• [SLOW TEST:16.233 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.10-beta.0.24+b52f9ef85bc776/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSFeb 18 13:41:41.705: INFO: Running AfterSuite actions on all nodes
Feb 18 13:41:41.705: INFO: Running AfterSuite actions on node 1
Feb 18 13:41:41.705: INFO: Skipping dumping logs from cluster

Ran 204 of 3585 Specs in 5507.106 seconds
SUCCESS! -- 204 Passed | 0 Failed | 0 Pending | 3381 Skipped PASS

Ginkgo ran 1 suite in 1h31m48.042565647s
Test Suite Passed
